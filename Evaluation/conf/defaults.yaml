# conf/config.yaml
hydra:
  run:
    dir: outputs/${now:%y-%m-%d_%H:%M}_${model.model_name_short}

defaults:
  - model: qwen2_5-VL-7B-Instruct.yaml
  - dataset: scivqaOutputFormat
  - mlflow: scivqa
  - _self_

metrics:
  - F1
  - BLEU:
      n_grams: 1
  - ROUGEDetailed:
      rouge_type: rouge1
  - ROUGEDetailed:
      rouge_type: rougeL
  - BERTScore:
      lang: en
  - GeneratedAnswerLength
  - ExactMatch

output_folder: outputs/${now:%y-%m-%d_%H:%M}_${model.model_name_short}
template_folder: /ltstorage/home/9schleid/scivqa
template_name: /src/scivqa/prompts/templates/version_v7.j2
use_vllm: false
base_url: http://localhost:${vllm_port}/v1/
vllm_port: 15833
apply_few_shot: false
few_shot_template: /ltstorage/home/9schleid/scivqa/src/scivqa/prompts/templates/few_shot_v1.j2
few_shot_dataset_path: /ltstorage/home/9schleid/SciVQA/unsloth/few_shot_example.json
few_shot_images_path: /ltstorage/home/9schleid/SciVQA/unsloth/few_shot_image

# config f√ºr finetunedOhneUnsloth Inference Server
model_id : "Qwen/Qwen2.5-VL-32B-Instruct"
