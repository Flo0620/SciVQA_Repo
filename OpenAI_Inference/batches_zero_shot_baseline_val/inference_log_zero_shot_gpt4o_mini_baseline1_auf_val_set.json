[
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Number of documents with an \u201cattack\u201ding country per 3-month period, and coreference posterior uncertainty for that quantity. The dark line is the posterior mean, and the shaded region is the 95% posterior credible interval. See appendix for more examples.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Number of documents with an \u201cattack\u201ding country per 3-month period, and coreference posterior uncertainty for that quantity. The dark line is the posterior mean, and the shaded region is the 95% posterior credible interval. See appendix for more examples.",
            "categories": "['cs.CL']",
            "figure_id": "1508.05154v2-Figure6-1",
            "image_path": "1508.05154v2-Figure6-1.png",
            "instance_id": "795f4ef16511f4f3496aac9b62885a1c",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate maximum value of the shaded area for the blue line in the lower plot?",
            "reference_answer": "15"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Number of documents with an \u201cattack\u201ding country per 3-month period, and coreference posterior uncertainty for that quantity. The dark line is the posterior mean, and the shaded region is the 95% posterior credible interval. See appendix for more examples.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Number of documents with an \u201cattack\u201ding country per 3-month period, and coreference posterior uncertainty for that quantity. The dark line is the posterior mean, and the shaded region is the 95% posterior credible interval. See appendix for more examples.",
            "categories": "['cs.CL']",
            "figure_id": "1508.05154v2-Figure6-1",
            "image_path": "1508.05154v2-Figure6-1.png",
            "instance_id": "52e8d789c0d9ce7e1ab2f379da7ada5a",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "Which country is referenced in the first plot?",
            "reference_answer": "USA"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "USA",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Number of documents with an \u201cattack\u201ding country per 3-month period, and coreference posterior uncertainty for that quantity. The dark line is the posterior mean, and the shaded region is the 95% posterior credible interval. See appendix for more examples.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Number of documents with an \u201cattack\u201ding country per 3-month period, and coreference posterior uncertainty for that quantity. The dark line is the posterior mean, and the shaded region is the 95% posterior credible interval. See appendix for more examples.",
            "categories": "['cs.CL']",
            "figure_id": "1508.05154v2-Figure6-1",
            "image_path": "1508.05154v2-Figure6-1.png",
            "instance_id": "a635ada76a4f9093c8da14c0daa1eaa2",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the shaded region for 'NATO' consistently below that of 'Serbia/Yugo.' in the bottom plot?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, the shaded region for 'NATO' is not consistently below that of 'Serbia/Yugo.' in the bottom plot.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Number of documents with an \u201cattack\u201ding country per 3-month period, and coreference posterior uncertainty for that quantity. The dark line is the posterior mean, and the shaded region is the 95% posterior credible interval. See appendix for more examples.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Number of documents with an \u201cattack\u201ding country per 3-month period, and coreference posterior uncertainty for that quantity. The dark line is the posterior mean, and the shaded region is the 95% posterior credible interval. See appendix for more examples.",
            "categories": "['cs.CL']",
            "figure_id": "1508.05154v2-Figure6-1",
            "image_path": "1508.05154v2-Figure6-1.png",
            "instance_id": "245acd477189c90de73f3e203bdaac4b",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the number of documents with an \"attacking\" country per 3-month period for the USA consistently higher than that of Serbia/Yugoslavia?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The blue line"
                    },
                    {
                        "B": "The red line"
                    },
                    {
                        "C": "The gray line"
                    },
                    {
                        "D": "All of the above"
                    }
                ],
                "caption": "Figure 6: Number of documents with an \u201cattack\u201ding country per 3-month period, and coreference posterior uncertainty for that quantity. The dark line is the posterior mean, and the shaded region is the 95% posterior credible interval. See appendix for more examples.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Number of documents with an \u201cattack\u201ding country per 3-month period, and coreference posterior uncertainty for that quantity. The dark line is the posterior mean, and the shaded region is the 95% posterior credible interval. See appendix for more examples.",
            "categories": "['cs.CL']",
            "figure_id": "1508.05154v2-Figure6-1",
            "image_path": "1508.05154v2-Figure6-1.png",
            "instance_id": "c0774879c6c363397342aa618ece9a59",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line represents the quantity of documents with an \"attacking\" country for Serbia/Yugoslavia?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "USA"
                    },
                    {
                        "B": "NATO"
                    },
                    {
                        "C": "Serbia/Yugo."
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 6: Number of documents with an \u201cattack\u201ding country per 3-month period, and coreference posterior uncertainty for that quantity. The dark line is the posterior mean, and the shaded region is the 95% posterior credible interval. See appendix for more examples.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Number of documents with an \u201cattack\u201ding country per 3-month period, and coreference posterior uncertainty for that quantity. The dark line is the posterior mean, and the shaded region is the 95% posterior credible interval. See appendix for more examples.",
            "categories": "['cs.CL']",
            "figure_id": "1508.05154v2-Figure6-1",
            "image_path": "1508.05154v2-Figure6-1.png",
            "instance_id": "47c14eccb3142b9464a3583bd8ae4685",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following has the highest number of documents with an \"attack\"ing country per 3-month period, during the time period shown in the figure?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Number of documents with an \u201cattack\u201ding country per 3-month period, and coreference posterior uncertainty for that quantity. The dark line is the posterior mean, and the shaded region is the 95% posterior credible interval. See appendix for more examples.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Number of documents with an \u201cattack\u201ding country per 3-month period, and coreference posterior uncertainty for that quantity. The dark line is the posterior mean, and the shaded region is the 95% posterior credible interval. See appendix for more examples.",
            "categories": "['cs.CL']",
            "figure_id": "1508.05154v2-Figure6-1",
            "image_path": "1508.05154v2-Figure6-1.png",
            "instance_id": "09b3b3fa0698b1ff9418353b6d2375f9",
            "qa_pair_type": "unanswerable",
            "question": "What is the relationship between the number of documents mentioning an 'attacking' country and the coreference posterior uncertainty?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5 Logistic function h(x) = 1 1+exp{\u2212x} truncates polarity values to (0, 1) smoothly. The computed values are used as polarity probabilities.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5 Logistic function h(x) = 1 1+exp{\u2212x} truncates polarity values to (0, 1) smoothly. The computed values are used as polarity probabilities.",
            "categories": "['cs.CL']",
            "figure_id": "1401.6330v2-Figure5-1",
            "image_path": "1401.6330v2-Figure5-1.png",
            "instance_id": "bb604bafa63c2ee962816fb015e27c8d",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the shape of the curve representing the logistic function?",
            "reference_answer": "S-shaped"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The shape of the curve representing the logistic function is S-shaped (sigmoidal). It starts slowly, increases rapidly in the middle, and then levels off as it approaches its maximum value.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5 Logistic function h(x) = 1 1+exp{\u2212x} truncates polarity values to (0, 1) smoothly. The computed values are used as polarity probabilities.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5 Logistic function h(x) = 1 1+exp{\u2212x} truncates polarity values to (0, 1) smoothly. The computed values are used as polarity probabilities.",
            "categories": "['cs.CL']",
            "figure_id": "1401.6330v2-Figure5-1",
            "image_path": "1401.6330v2-Figure5-1.png",
            "instance_id": "a68ab9204d5b33a082d95740357be109",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "Which functions are represented in the graph?",
            "reference_answer": "Linear function and Logistic function"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The functions represented in the graph are a linear function (dashed blue line) and a logistic function (solid red line).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5 Logistic function h(x) = 1 1+exp{\u2212x} truncates polarity values to (0, 1) smoothly. The computed values are used as polarity probabilities.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5 Logistic function h(x) = 1 1+exp{\u2212x} truncates polarity values to (0, 1) smoothly. The computed values are used as polarity probabilities.",
            "categories": "['cs.CL']",
            "figure_id": "1401.6330v2-Figure5-1",
            "image_path": "1401.6330v2-Figure5-1.png",
            "instance_id": "37d72e680ccbb6e77170d8b81160299d",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the red line, representing the logistic function,  approach the blue dashed line, representing the linear function, as the x-axis values increase?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5 Logistic function h(x) = 1 1+exp{\u2212x} truncates polarity values to (0, 1) smoothly. The computed values are used as polarity probabilities.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5 Logistic function h(x) = 1 1+exp{\u2212x} truncates polarity values to (0, 1) smoothly. The computed values are used as polarity probabilities.",
            "categories": "['cs.CL']",
            "figure_id": "1401.6330v2-Figure5-1",
            "image_path": "1401.6330v2-Figure5-1.png",
            "instance_id": "34bf899a5351f5a38045ce6d4e692738",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the linear function have a constant increase?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the linear function has a constant increase. A linear function has a constant slope, which means it increases (or decreases) at a consistent rate across its entire domain.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The solid red line"
                    },
                    {
                        "B": "The dotted blue line"
                    },
                    {
                        "C": "Both lines"
                    },
                    {
                        "D": "Neither line"
                    }
                ],
                "caption": "Figure 5 Logistic function h(x) = 1 1+exp{\u2212x} truncates polarity values to (0, 1) smoothly. The computed values are used as polarity probabilities.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5 Logistic function h(x) = 1 1+exp{\u2212x} truncates polarity values to (0, 1) smoothly. The computed values are used as polarity probabilities.",
            "categories": "['cs.CL']",
            "figure_id": "1401.6330v2-Figure5-1",
            "image_path": "1401.6330v2-Figure5-1.png",
            "instance_id": "b2eeafd1ecb4a1ad0fe1365ff37e6908",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line in the graph represents the logistic function?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "0.1"
                    },
                    {
                        "B": "0.5"
                    },
                    {
                        "C": "0.3"
                    },
                    {
                        "D": "0.2"
                    }
                ],
                "caption": "Figure 5 Logistic function h(x) = 1 1+exp{\u2212x} truncates polarity values to (0, 1) smoothly. The computed values are used as polarity probabilities.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5 Logistic function h(x) = 1 1+exp{\u2212x} truncates polarity values to (0, 1) smoothly. The computed values are used as polarity probabilities.",
            "categories": "['cs.CL']",
            "figure_id": "1401.6330v2-Figure5-1",
            "image_path": "1401.6330v2-Figure5-1.png",
            "instance_id": "2cf8e217725cc8ce34ea8ec3706240f7",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "At what value do both the logistic and linear functions meet the halfway point?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5 Logistic function h(x) = 1 1+exp{\u2212x} truncates polarity values to (0, 1) smoothly. The computed values are used as polarity probabilities.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5 Logistic function h(x) = 1 1+exp{\u2212x} truncates polarity values to (0, 1) smoothly. The computed values are used as polarity probabilities.",
            "categories": "['cs.CL']",
            "figure_id": "1401.6330v2-Figure5-1",
            "image_path": "1401.6330v2-Figure5-1.png",
            "instance_id": "c1085cbd85d0322728ad39b71ebb539a",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific application of the logistic function in this study and what data were used to generate the plot?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Smoothed convergence curves of F1 scores formodels using \ud835\udc60\ud835\udc4e or not on both validation set and test set ofWikiKBP. Results for two evaluation criteria \ud835\udc60\ud835\udc64 and \ud835\udc60\ud835\udc5d are presented respectively.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Smoothed convergence curves of F1 scores formodels using \ud835\udc60\ud835\udc4e or not on both validation set and test set ofWikiKBP. Results for two evaluation criteria \ud835\udc60\ud835\udc64 and \ud835\udc60\ud835\udc5d are presented respectively.",
            "categories": "['cs.CL']",
            "figure_id": "2010.13544v1-Figure6-1",
            "image_path": "2010.13544v1-Figure6-1.png",
            "instance_id": "dfc84746a77f1826f4428b525f0ad6cb",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate maximum value of the blue solid line in the lower right plot?",
            "reference_answer": "0.58"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Smoothed convergence curves of F1 scores formodels using \ud835\udc60\ud835\udc4e or not on both validation set and test set ofWikiKBP. Results for two evaluation criteria \ud835\udc60\ud835\udc64 and \ud835\udc60\ud835\udc5d are presented respectively.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Smoothed convergence curves of F1 scores formodels using \ud835\udc60\ud835\udc4e or not on both validation set and test set ofWikiKBP. Results for two evaluation criteria \ud835\udc60\ud835\udc64 and \ud835\udc60\ud835\udc5d are presented respectively.",
            "categories": "['cs.CL']",
            "figure_id": "2010.13544v1-Figure6-1",
            "image_path": "2010.13544v1-Figure6-1.png",
            "instance_id": "8696af9321fe3b85fc928f0f43da0cef",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "Besides 'with sa' and 'w/o sa', what other method is being compared in the graph?",
            "reference_answer": "L2RW"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The other method being compared in the graph is 'L2RW'.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Smoothed convergence curves of F1 scores formodels using \ud835\udc60\ud835\udc4e or not on both validation set and test set ofWikiKBP. Results for two evaluation criteria \ud835\udc60\ud835\udc64 and \ud835\udc60\ud835\udc5d are presented respectively.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Smoothed convergence curves of F1 scores formodels using \ud835\udc60\ud835\udc4e or not on both validation set and test set ofWikiKBP. Results for two evaluation criteria \ud835\udc60\ud835\udc64 and \ud835\udc60\ud835\udc5d are presented respectively.",
            "categories": "['cs.CL']",
            "figure_id": "2010.13544v1-Figure6-1",
            "image_path": "2010.13544v1-Figure6-1.png",
            "instance_id": "29e3147dab88e8a5c4a4ee7cb5bc510c",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the blue dashed line with circles, representing the 'w/o sa' model, consistently have a higher F1 score than the turquoise line with triangles, representing the 'L2RW' model, in the 'test' section of the figure?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Smoothed convergence curves of F1 scores formodels using \ud835\udc60\ud835\udc4e or not on both validation set and test set ofWikiKBP. Results for two evaluation criteria \ud835\udc60\ud835\udc64 and \ud835\udc60\ud835\udc5d are presented respectively.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Smoothed convergence curves of F1 scores formodels using \ud835\udc60\ud835\udc4e or not on both validation set and test set ofWikiKBP. Results for two evaluation criteria \ud835\udc60\ud835\udc64 and \ud835\udc60\ud835\udc5d are presented respectively.",
            "categories": "['cs.CL']",
            "figure_id": "2010.13544v1-Figure6-1",
            "image_path": "2010.13544v1-Figure6-1.png",
            "instance_id": "133b769bb2f74d35b8951d9f13961ef4",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Are the F1 scores for models with 'sa' consistently higher than the F1 scores for models without 'sa' in the validation set?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the F1 scores for models with 'sa' are consistently higher than the F1 scores for models without 'sa' in the validation set, as shown by the lines on the validation plot.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Triangle"
                    },
                    {
                        "B": "Square"
                    },
                    {
                        "C": "Circle"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 6: Smoothed convergence curves of F1 scores formodels using \ud835\udc60\ud835\udc4e or not on both validation set and test set ofWikiKBP. Results for two evaluation criteria \ud835\udc60\ud835\udc64 and \ud835\udc60\ud835\udc5d are presented respectively.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Smoothed convergence curves of F1 scores formodels using \ud835\udc60\ud835\udc4e or not on both validation set and test set ofWikiKBP. Results for two evaluation criteria \ud835\udc60\ud835\udc64 and \ud835\udc60\ud835\udc5d are presented respectively.",
            "categories": "['cs.CL']",
            "figure_id": "2010.13544v1-Figure6-1",
            "image_path": "2010.13544v1-Figure6-1.png",
            "instance_id": "ddd7d7b14748c89026fb14c7cf49de3f",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What shape is the turquoise line marked with?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "with sa"
                    },
                    {
                        "B": "w/o sa"
                    },
                    {
                        "C": "L2RW"
                    },
                    {
                        "D": "All the above"
                    }
                ],
                "caption": "Figure 6: Smoothed convergence curves of F1 scores formodels using \ud835\udc60\ud835\udc4e or not on both validation set and test set ofWikiKBP. Results for two evaluation criteria \ud835\udc60\ud835\udc64 and \ud835\udc60\ud835\udc5d are presented respectively.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Smoothed convergence curves of F1 scores formodels using \ud835\udc60\ud835\udc4e or not on both validation set and test set ofWikiKBP. Results for two evaluation criteria \ud835\udc60\ud835\udc64 and \ud835\udc60\ud835\udc5d are presented respectively.",
            "categories": "['cs.CL']",
            "figure_id": "2010.13544v1-Figure6-1",
            "image_path": "2010.13544v1-Figure6-1.png",
            "instance_id": "474023184bc856cd55a246cd8b086e15",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which model has the highest F1 score at epoch 10 in the 'test' set?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Smoothed convergence curves of F1 scores formodels using \ud835\udc60\ud835\udc4e or not on both validation set and test set ofWikiKBP. Results for two evaluation criteria \ud835\udc60\ud835\udc64 and \ud835\udc60\ud835\udc5d are presented respectively.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Smoothed convergence curves of F1 scores formodels using \ud835\udc60\ud835\udc4e or not on both validation set and test set ofWikiKBP. Results for two evaluation criteria \ud835\udc60\ud835\udc64 and \ud835\udc60\ud835\udc5d are presented respectively.",
            "categories": "['cs.CL']",
            "figure_id": "2010.13544v1-Figure6-1",
            "image_path": "2010.13544v1-Figure6-1.png",
            "instance_id": "d898e15c34a3dd10890f45ba93f9c299",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific implementation of the 'sa' technique used in the models shown in Figure 6?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Relative intent classification accuracy increases as average entropy decreases for all model and training strategies considered.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Relative intent classification accuracy increases as average entropy decreases for all model and training strategies considered.",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2008.02858v1-Figure2-1",
            "image_path": "2008.02858v1-Figure2-1.png",
            "instance_id": "a9aabfe2880b2e317a028240f597b5bb",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of relative IC accuracy for the green line at an average entropy of 6?",
            "reference_answer": "0.95"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Relative intent classification accuracy increases as average entropy decreases for all model and training strategies considered.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Relative intent classification accuracy increases as average entropy decreases for all model and training strategies considered.",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2008.02858v1-Figure2-1",
            "image_path": "2008.02858v1-Figure2-1.png",
            "instance_id": "f8eb4162479102f4fe8176be08ecb4bb",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "How many training strategies are shown in the graph?",
            "reference_answer": "4"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "There are four training strategies shown in the graph.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Relative intent classification accuracy increases as average entropy decreases for all model and training strategies considered.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Relative intent classification accuracy increases as average entropy decreases for all model and training strategies considered.",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2008.02858v1-Figure2-1",
            "image_path": "2008.02858v1-Figure2-1.png",
            "instance_id": "9aac3c5b3b175e0d0c46a4b87ef2f5c3",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the purple line representing the 'Multi-task Model in [10]' consistently above the red line representing the 'Model in [9] - No Unfreezing'?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Relative intent classification accuracy increases as average entropy decreases for all model and training strategies considered.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Relative intent classification accuracy increases as average entropy decreases for all model and training strategies considered.",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2008.02858v1-Figure2-1",
            "image_path": "2008.02858v1-Figure2-1.png",
            "instance_id": "614da39b77210bc992512a7fddb6e9b2",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the relative IC accuracy of the 'Multi-task Model [10]' lower than the accuracy of the 'Model in [9] - Unfreeze all layers' when the average entropy is 8?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Red dashed line"
                    },
                    {
                        "B": "Green dashed line"
                    },
                    {
                        "C": "Blue dashed line"
                    },
                    {
                        "D": "Purple dashed line"
                    }
                ],
                "caption": "Figure 2: Relative intent classification accuracy increases as average entropy decreases for all model and training strategies considered.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Relative intent classification accuracy increases as average entropy decreases for all model and training strategies considered.",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2008.02858v1-Figure2-1",
            "image_path": "2008.02858v1-Figure2-1.png",
            "instance_id": "d6616be735e75934a62c7b90f0a06d01",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line represents the training strategy 'Unfreeze All Layers'?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "0.5"
                    },
                    {
                        "B": "0.6"
                    },
                    {
                        "C": "0.4"
                    },
                    {
                        "D": "0.65"
                    }
                ],
                "caption": "Figure 2: Relative intent classification accuracy increases as average entropy decreases for all model and training strategies considered.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Relative intent classification accuracy increases as average entropy decreases for all model and training strategies considered.",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2008.02858v1-Figure2-1",
            "image_path": "2008.02858v1-Figure2-1.png",
            "instance_id": "1888d868b87f60174e10129f0083a996",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the starting value of Relative IC Accuracy shown on the graph?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Relative intent classification accuracy increases as average entropy decreases for all model and training strategies considered.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Relative intent classification accuracy increases as average entropy decreases for all model and training strategies considered.",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2008.02858v1-Figure2-1",
            "image_path": "2008.02858v1-Figure2-1.png",
            "instance_id": "7243c2017a77b011a51752ab145c847e",
            "qa_pair_type": "unanswerable",
            "question": "On which task are models being evaluated on?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 3. Learning curves per area. The reported results are average F1 on positive class. The label mapping is inclusive. The dashed lines represent the result obtained on full datasets.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 3. Learning curves per area. The reported results are average F1 on positive class. The label mapping is inclusive. The dashed lines represent the result obtained on full datasets.",
            "categories": "['cs.CL']",
            "figure_id": "1906.02053v1-Figure3-1",
            "image_path": "1906.02053v1-Figure3-1.png",
            "instance_id": "5fe86db41d235af229b308fa74bcfab3",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the solid black line at a training size of 200?",
            "reference_answer": "0.43"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 3. Learning curves per area. The reported results are average F1 on positive class. The label mapping is inclusive. The dashed lines represent the result obtained on full datasets.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 3. Learning curves per area. The reported results are average F1 on positive class. The label mapping is inclusive. The dashed lines represent the result obtained on full datasets.",
            "categories": "['cs.CL']",
            "figure_id": "1906.02053v1-Figure3-1",
            "image_path": "1906.02053v1-Figure3-1.png",
            "instance_id": "85e1371d1faa12bdc6c64c4abf927d46",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the approximate F1 score for 'Chemistry' when using full datasets?",
            "reference_answer": "0.65"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 3. Learning curves per area. The reported results are average F1 on positive class. The label mapping is inclusive. The dashed lines represent the result obtained on full datasets.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 3. Learning curves per area. The reported results are average F1 on positive class. The label mapping is inclusive. The dashed lines represent the result obtained on full datasets.",
            "categories": "['cs.CL']",
            "figure_id": "1906.02053v1-Figure3-1",
            "image_path": "1906.02053v1-Figure3-1.png",
            "instance_id": "decec01e4c9022e301e7bd08e576a583",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the dashed line representing 'Overall' fall above the dashed line representing 'Chemistry' at the training size of 500?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the dashed line representing 'Overall' falls above the dashed line representing 'Chemistry' at the training size of 500.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 3. Learning curves per area. The reported results are average F1 on positive class. The label mapping is inclusive. The dashed lines represent the result obtained on full datasets.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 3. Learning curves per area. The reported results are average F1 on positive class. The label mapping is inclusive. The dashed lines represent the result obtained on full datasets.",
            "categories": "['cs.CL']",
            "figure_id": "1906.02053v1-Figure3-1",
            "image_path": "1906.02053v1-Figure3-1.png",
            "instance_id": "5d3b4558e1076ef01f316f40a3f960c4",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the performance of 'Computer science' on full datasets lower than that of 'Political science'?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Red solid line"
                    },
                    {
                        "B": "Blue solid line"
                    },
                    {
                        "C": "Purple solid line"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Fig. 3. Learning curves per area. The reported results are average F1 on positive class. The label mapping is inclusive. The dashed lines represent the result obtained on full datasets.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 3. Learning curves per area. The reported results are average F1 on positive class. The label mapping is inclusive. The dashed lines represent the result obtained on full datasets.",
            "categories": "['cs.CL']",
            "figure_id": "1906.02053v1-Figure3-1",
            "image_path": "1906.02053v1-Figure3-1.png",
            "instance_id": "e8b4daa26e1fdd45d0550cf3f072ab05",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which solid line is constantly higher than other solid lines?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Chemistry"
                    },
                    {
                        "B": "Physics"
                    },
                    {
                        "C": "Political Science"
                    },
                    {
                        "D": "Math"
                    }
                ],
                "caption": "Fig. 3. Learning curves per area. The reported results are average F1 on positive class. The label mapping is inclusive. The dashed lines represent the result obtained on full datasets.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 3. Learning curves per area. The reported results are average F1 on positive class. The label mapping is inclusive. The dashed lines represent the result obtained on full datasets.",
            "categories": "['cs.CL']",
            "figure_id": "1906.02053v1-Figure3-1",
            "image_path": "1906.02053v1-Figure3-1.png",
            "instance_id": "f1e3092c2f9180fefb9d4e35262f5428",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following datasets have a dashed line representing the result obtained on full datasets?",
            "reference_answer": "A,C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 3. Learning curves per area. The reported results are average F1 on positive class. The label mapping is inclusive. The dashed lines represent the result obtained on full datasets.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 3. Learning curves per area. The reported results are average F1 on positive class. The label mapping is inclusive. The dashed lines represent the result obtained on full datasets.",
            "categories": "['cs.CL']",
            "figure_id": "1906.02053v1-Figure3-1",
            "image_path": "1906.02053v1-Figure3-1.png",
            "instance_id": "42b0547335dcb9443039fd439340c2c1",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific research question that this figure aims to address?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 6: Learning Curve using active learning with SVM and closest-to-hyperplane sampling on the TREC dataset. The TPC is set to 10%, about the earliest the current state-of-theart can be set to without sacrificing large amounts of forecast quality. The stopping percent automatically determined during active learning by the Stabilizing Predictions (SP) method from [14] is shown by the SP vertical line.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 6: Learning Curve using active learning with SVM and closest-to-hyperplane sampling on the TREC dataset. The TPC is set to 10%, about the earliest the current state-of-theart can be set to without sacrificing large amounts of forecast quality. The stopping percent automatically determined during active learning by the Stabilizing Predictions (SP) method from [14] is shown by the SP vertical line.",
            "categories": "['cs.IR cs.CL cs.LG stat.ML']",
            "figure_id": "2001.10337v2-Figure6-1",
            "image_path": "2001.10337v2-Figure6-1.png",
            "instance_id": "b29e428236d7fe34ff06501887af1c60",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the purple vertical line on the x-axis?",
            "reference_answer": "10"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The approximate value of the purple vertical line on the x-axis is 10.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 6: Learning Curve using active learning with SVM and closest-to-hyperplane sampling on the TREC dataset. The TPC is set to 10%, about the earliest the current state-of-theart can be set to without sacrificing large amounts of forecast quality. The stopping percent automatically determined during active learning by the Stabilizing Predictions (SP) method from [14] is shown by the SP vertical line.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 6: Learning Curve using active learning with SVM and closest-to-hyperplane sampling on the TREC dataset. The TPC is set to 10%, about the earliest the current state-of-theart can be set to without sacrificing large amounts of forecast quality. The stopping percent automatically determined during active learning by the Stabilizing Predictions (SP) method from [14] is shown by the SP vertical line.",
            "categories": "['cs.IR cs.CL cs.LG stat.ML']",
            "figure_id": "2001.10337v2-Figure6-1",
            "image_path": "2001.10337v2-Figure6-1.png",
            "instance_id": "56518be1b97e909a4969f8145e9a95e3",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "At approximately what training percentage does the F-Measure first reach 1.0?",
            "reference_answer": "5"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 6: Learning Curve using active learning with SVM and closest-to-hyperplane sampling on the TREC dataset. The TPC is set to 10%, about the earliest the current state-of-theart can be set to without sacrificing large amounts of forecast quality. The stopping percent automatically determined during active learning by the Stabilizing Predictions (SP) method from [14] is shown by the SP vertical line.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 6: Learning Curve using active learning with SVM and closest-to-hyperplane sampling on the TREC dataset. The TPC is set to 10%, about the earliest the current state-of-theart can be set to without sacrificing large amounts of forecast quality. The stopping percent automatically determined during active learning by the Stabilizing Predictions (SP) method from [14] is shown by the SP vertical line.",
            "categories": "['cs.IR cs.CL cs.LG stat.ML']",
            "figure_id": "2001.10337v2-Figure6-1",
            "image_path": "2001.10337v2-Figure6-1.png",
            "instance_id": "99b3965d3b3cebac2a597928c7a51997",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the cyan vertical line on the graph representing the SP method located at a training percentage value of 10?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 6: Learning Curve using active learning with SVM and closest-to-hyperplane sampling on the TREC dataset. The TPC is set to 10%, about the earliest the current state-of-theart can be set to without sacrificing large amounts of forecast quality. The stopping percent automatically determined during active learning by the Stabilizing Predictions (SP) method from [14] is shown by the SP vertical line.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 6: Learning Curve using active learning with SVM and closest-to-hyperplane sampling on the TREC dataset. The TPC is set to 10%, about the earliest the current state-of-theart can be set to without sacrificing large amounts of forecast quality. The stopping percent automatically determined during active learning by the Stabilizing Predictions (SP) method from [14] is shown by the SP vertical line.",
            "categories": "['cs.IR cs.CL cs.LG stat.ML']",
            "figure_id": "2001.10337v2-Figure6-1",
            "image_path": "2001.10337v2-Figure6-1.png",
            "instance_id": "87b83bb1bb503a00efe71673d8d43062",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the performance remain stable after the cutoff?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Based on the graph, the performance appears to remain stable after the cutoff, with the F-Measure staying at a high level (around 1.0) for training percentages beyond the cutoff point.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "circle"
                    },
                    {
                        "B": "star"
                    },
                    {
                        "C": "triangle"
                    },
                    {
                        "D": "diamond"
                    }
                ],
                "caption": "Fig. 6: Learning Curve using active learning with SVM and closest-to-hyperplane sampling on the TREC dataset. The TPC is set to 10%, about the earliest the current state-of-theart can be set to without sacrificing large amounts of forecast quality. The stopping percent automatically determined during active learning by the Stabilizing Predictions (SP) method from [14] is shown by the SP vertical line.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 6: Learning Curve using active learning with SVM and closest-to-hyperplane sampling on the TREC dataset. The TPC is set to 10%, about the earliest the current state-of-theart can be set to without sacrificing large amounts of forecast quality. The stopping percent automatically determined during active learning by the Stabilizing Predictions (SP) method from [14] is shown by the SP vertical line.",
            "categories": "['cs.IR cs.CL cs.LG stat.ML']",
            "figure_id": "2001.10337v2-Figure6-1",
            "image_path": "2001.10337v2-Figure6-1.png",
            "instance_id": "ffeb1c9a68ac19fac9bdecf44a5d3e0d",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What shape is used to represent the performance points before the cutoff in the graph?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Training Accuracy"
                    },
                    {
                        "B": "Measured Performance Points Before Cutoff"
                    },
                    {
                        "C": "Loss Function"
                    },
                    {
                        "D": "SP"
                    }
                ],
                "caption": "Fig. 6: Learning Curve using active learning with SVM and closest-to-hyperplane sampling on the TREC dataset. The TPC is set to 10%, about the earliest the current state-of-theart can be set to without sacrificing large amounts of forecast quality. The stopping percent automatically determined during active learning by the Stabilizing Predictions (SP) method from [14] is shown by the SP vertical line.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 6: Learning Curve using active learning with SVM and closest-to-hyperplane sampling on the TREC dataset. The TPC is set to 10%, about the earliest the current state-of-theart can be set to without sacrificing large amounts of forecast quality. The stopping percent automatically determined during active learning by the Stabilizing Predictions (SP) method from [14] is shown by the SP vertical line.",
            "categories": "['cs.IR cs.CL cs.LG stat.ML']",
            "figure_id": "2001.10337v2-Figure6-1",
            "image_path": "2001.10337v2-Figure6-1.png",
            "instance_id": "66063feb7a8c7bf9d4e68cf716e8ec84",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following labels are found in the legend?",
            "reference_answer": "B,D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "BD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 6: Learning Curve using active learning with SVM and closest-to-hyperplane sampling on the TREC dataset. The TPC is set to 10%, about the earliest the current state-of-theart can be set to without sacrificing large amounts of forecast quality. The stopping percent automatically determined during active learning by the Stabilizing Predictions (SP) method from [14] is shown by the SP vertical line.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 6: Learning Curve using active learning with SVM and closest-to-hyperplane sampling on the TREC dataset. The TPC is set to 10%, about the earliest the current state-of-theart can be set to without sacrificing large amounts of forecast quality. The stopping percent automatically determined during active learning by the Stabilizing Predictions (SP) method from [14] is shown by the SP vertical line.",
            "categories": "['cs.IR cs.CL cs.LG stat.ML']",
            "figure_id": "2001.10337v2-Figure6-1",
            "image_path": "2001.10337v2-Figure6-1.png",
            "instance_id": "5473dedeb22a38d1a5125fcba852d938",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific implementation of the Support Vector Machine (SVM) algorithm used in this experiment, and how does it compare to other SVM variants in terms of its performance on the TREC dataset?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: The accuracy values of nodes sets with different hops to the labeled node. We display the result of all the four experiment models with different node pair loss weights (0/0.5/1.0). We can obviously find that for all models, adding node pair loss can help predict long-distance nodes better.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The accuracy values of nodes sets with different hops to the labeled node. We display the result of all the four experiment models with different node pair loss weights (0/0.5/1.0). We can obviously find that for all models, adding node pair loss can help predict long-distance nodes better.",
            "categories": "['cs.LG cs.CL cs.SI stat.ML']",
            "figure_id": "1911.03904v2-Figure4-1",
            "image_path": "1911.03904v2-Figure4-1.png",
            "instance_id": "18353667b816d223fa73101125bd30cd",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate accuracy value of the solid purple line in the first graph when the number of hops is 4?",
            "reference_answer": "64"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: The accuracy values of nodes sets with different hops to the labeled node. We display the result of all the four experiment models with different node pair loss weights (0/0.5/1.0). We can obviously find that for all models, adding node pair loss can help predict long-distance nodes better.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The accuracy values of nodes sets with different hops to the labeled node. We display the result of all the four experiment models with different node pair loss weights (0/0.5/1.0). We can obviously find that for all models, adding node pair loss can help predict long-distance nodes better.",
            "categories": "['cs.LG cs.CL cs.SI stat.ML']",
            "figure_id": "1911.03904v2-Figure4-1",
            "image_path": "1911.03904v2-Figure4-1.png",
            "instance_id": "ff9228f359a56480ca8abcbf66ea019d",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "How many different values are used for weights?",
            "reference_answer": "3"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "There are three different values used for weights: 0, 0.5, and 1.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: The accuracy values of nodes sets with different hops to the labeled node. We display the result of all the four experiment models with different node pair loss weights (0/0.5/1.0). We can obviously find that for all models, adding node pair loss can help predict long-distance nodes better.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The accuracy values of nodes sets with different hops to the labeled node. We display the result of all the four experiment models with different node pair loss weights (0/0.5/1.0). We can obviously find that for all models, adding node pair loss can help predict long-distance nodes better.",
            "categories": "['cs.LG cs.CL cs.SI stat.ML']",
            "figure_id": "1911.03904v2-Figure4-1",
            "image_path": "1911.03904v2-Figure4-1.png",
            "instance_id": "e2150adcbb2b10854043b45958be7304",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the accuracy value of the purple line in the graph labeled 'GCN' lower than the accuracy value of the red dashed line at 3 hops?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: The accuracy values of nodes sets with different hops to the labeled node. We display the result of all the four experiment models with different node pair loss weights (0/0.5/1.0). We can obviously find that for all models, adding node pair loss can help predict long-distance nodes better.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The accuracy values of nodes sets with different hops to the labeled node. We display the result of all the four experiment models with different node pair loss weights (0/0.5/1.0). We can obviously find that for all models, adding node pair loss can help predict long-distance nodes better.",
            "categories": "['cs.LG cs.CL cs.SI stat.ML']",
            "figure_id": "1911.03904v2-Figure4-1",
            "image_path": "1911.03904v2-Figure4-1.png",
            "instance_id": "2da4b9e3a5dc34715ff41f090bcba4a9",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "For the SAGE model, is the accuracy higher for weight=1 than weight=0 at 4 hops?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Purple line"
                    },
                    {
                        "B": "Red line"
                    },
                    {
                        "C": "Yellow line"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 4: The accuracy values of nodes sets with different hops to the labeled node. We display the result of all the four experiment models with different node pair loss weights (0/0.5/1.0). We can obviously find that for all models, adding node pair loss can help predict long-distance nodes better.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The accuracy values of nodes sets with different hops to the labeled node. We display the result of all the four experiment models with different node pair loss weights (0/0.5/1.0). We can obviously find that for all models, adding node pair loss can help predict long-distance nodes better.",
            "categories": "['cs.LG cs.CL cs.SI stat.ML']",
            "figure_id": "1911.03904v2-Figure4-1",
            "image_path": "1911.03904v2-Figure4-1.png",
            "instance_id": "e894be4e8f80969aaf2890b67e71538c",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "In the second plot, which of the following lines remains constant after 4 hops?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "weight=0"
                    },
                    {
                        "B": "weight=0.5"
                    },
                    {
                        "C": "weight=1"
                    },
                    {
                        "D": "weight=0.1"
                    }
                ],
                "caption": "Figure 4: The accuracy values of nodes sets with different hops to the labeled node. We display the result of all the four experiment models with different node pair loss weights (0/0.5/1.0). We can obviously find that for all models, adding node pair loss can help predict long-distance nodes better.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The accuracy values of nodes sets with different hops to the labeled node. We display the result of all the four experiment models with different node pair loss weights (0/0.5/1.0). We can obviously find that for all models, adding node pair loss can help predict long-distance nodes better.",
            "categories": "['cs.LG cs.CL cs.SI stat.ML']",
            "figure_id": "1911.03904v2-Figure4-1",
            "image_path": "1911.03904v2-Figure4-1.png",
            "instance_id": "fe20aab6a13a31b0d86cea04d4ba6d08",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which weight configuration results in the lowest accuracy across all hop distances for SAGE model?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: The accuracy values of nodes sets with different hops to the labeled node. We display the result of all the four experiment models with different node pair loss weights (0/0.5/1.0). We can obviously find that for all models, adding node pair loss can help predict long-distance nodes better.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The accuracy values of nodes sets with different hops to the labeled node. We display the result of all the four experiment models with different node pair loss weights (0/0.5/1.0). We can obviously find that for all models, adding node pair loss can help predict long-distance nodes better.",
            "categories": "['cs.LG cs.CL cs.SI stat.ML']",
            "figure_id": "1911.03904v2-Figure4-1",
            "image_path": "1911.03904v2-Figure4-1.png",
            "instance_id": "53358d98dbba8ffd742751e339c4b4bd",
            "qa_pair_type": "unanswerable",
            "question": "Which specific dataset was used for this experiment? ",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 9: Graph showing the dual value L(u(k)) versus the number of iterations k, for different fixed step sizes.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: Graph showing the dual value L(u(k)) versus the number of iterations k, for different fixed step sizes.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1405.5208v1-Figure9-1",
            "image_path": "1405.5208v1-Figure9-1.png",
            "instance_id": "2ebdefe86965265f23ea00cd9e6d5580",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the red line at the 30th iteration?",
            "reference_answer": "-15.3"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 9: Graph showing the dual value L(u(k)) versus the number of iterations k, for different fixed step sizes.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: Graph showing the dual value L(u(k)) versus the number of iterations k, for different fixed step sizes.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1405.5208v1-Figure9-1",
            "image_path": "1405.5208v1-Figure9-1.png",
            "instance_id": "673751abc2e87a103afd3076b9c4b269",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "How many different step sizes are represented in the graph?",
            "reference_answer": "3"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Three different step sizes are represented in the graph.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 9: Graph showing the dual value L(u(k)) versus the number of iterations k, for different fixed step sizes.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: Graph showing the dual value L(u(k)) versus the number of iterations k, for different fixed step sizes.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1405.5208v1-Figure9-1",
            "image_path": "1405.5208v1-Figure9-1.png",
            "instance_id": "c071632f6cef15ce464df82e7458cac6",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the green dashed line have a higher value than the red line at round 10?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 9: Graph showing the dual value L(u(k)) versus the number of iterations k, for different fixed step sizes.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: Graph showing the dual value L(u(k)) versus the number of iterations k, for different fixed step sizes.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1405.5208v1-Figure9-1",
            "image_path": "1405.5208v1-Figure9-1.png",
            "instance_id": "85c26f76bd8d812ab0e5563937550ef7",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the step size of 0.0005 show a consistently decreasing trend with increasing iterations?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Red"
                    },
                    {
                        "B": "Green"
                    },
                    {
                        "C": "Blue"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 9: Graph showing the dual value L(u(k)) versus the number of iterations k, for different fixed step sizes.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: Graph showing the dual value L(u(k)) versus the number of iterations k, for different fixed step sizes.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1405.5208v1-Figure9-1",
            "image_path": "1405.5208v1-Figure9-1.png",
            "instance_id": "34893c5b0bbeab7560ab976afedee91d",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line represents a fixed step size of 0.01?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "0.01, 0.005, 0.0005"
                    },
                    {
                        "B": "0.001, 0.0001, 0.00001"
                    },
                    {
                        "C": "0.01, 0.0005, 0.00005"
                    },
                    {
                        "D": "0.01, 0.005, 0.000005"
                    }
                ],
                "caption": "Figure 9: Graph showing the dual value L(u(k)) versus the number of iterations k, for different fixed step sizes.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: Graph showing the dual value L(u(k)) versus the number of iterations k, for different fixed step sizes.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1405.5208v1-Figure9-1",
            "image_path": "1405.5208v1-Figure9-1.png",
            "instance_id": "bb85bd16cf135d4fe4b725564e16f09d",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which step sizes correspond to the lines in the graph?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 9: Graph showing the dual value L(u(k)) versus the number of iterations k, for different fixed step sizes.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: Graph showing the dual value L(u(k)) versus the number of iterations k, for different fixed step sizes.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1405.5208v1-Figure9-1",
            "image_path": "1405.5208v1-Figure9-1.png",
            "instance_id": "39424b637a0d0b37c7ce09ab7cd7a4f0",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific application or context of this graph, considering the function L(u(k)) and the fixed step sizes?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Individual (a) and mean (b) accuracies vs. text length in terms of the number of sentences",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Individual (a) and mean (b) accuracies vs. text length in terms of the number of sentences",
            "categories": "['cs.CL cs.LG cs.NE']",
            "figure_id": "1602.07393v1-Figure3-1",
            "image_path": "1602.07393v1-Figure3-1.png",
            "instance_id": "091bd44487d9115d89cd64bbf319c6f3",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the highest value of the red dashed line in the bottom figure?",
            "reference_answer": "1"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Individual (a) and mean (b) accuracies vs. text length in terms of the number of sentences",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Individual (a) and mean (b) accuracies vs. text length in terms of the number of sentences",
            "categories": "['cs.CL cs.LG cs.NE']",
            "figure_id": "1602.07393v1-Figure3-1",
            "image_path": "1602.07393v1-Figure3-1.png",
            "instance_id": "1a1053dc48a7ef59f49d15d5a0b7e422",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "Which method reaches the highest average accuracy for the course?",
            "reference_answer": "4gram (NNLM) "
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Individual (a) and mean (b) accuracies vs. text length in terms of the number of sentences",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Individual (a) and mean (b) accuracies vs. text length in terms of the number of sentences",
            "categories": "['cs.CL cs.LG cs.NE']",
            "figure_id": "1602.07393v1-Figure3-1",
            "image_path": "1602.07393v1-Figure3-1.png",
            "instance_id": "c57f7eca002655fe1c321a40350d1f99",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the accuracy of the blue line generally higher than that of the green line in the top figure?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Individual (a) and mean (b) accuracies vs. text length in terms of the number of sentences",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Individual (a) and mean (b) accuracies vs. text length in terms of the number of sentences",
            "categories": "['cs.CL cs.LG cs.NE']",
            "figure_id": "1602.07393v1-Figure3-1",
            "image_path": "1602.07393v1-Figure3-1.png",
            "instance_id": "4d3a883c55b3469cf73fb6e0ec926f66",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the average accuracy of unigram (SRI) lower than the average accuracy of 4gram (NNLM) for 2 sentences?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "A steady upward slope with no flattening"
                    },
                    {
                        "B": "A sharp upward slope at first, followed by a plateau"
                    },
                    {
                        "C": "A downward slope throughout"
                    },
                    {
                        "D": "U-shaped"
                    }
                ],
                "caption": "Figure 3: Individual (a) and mean (b) accuracies vs. text length in terms of the number of sentences",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Individual (a) and mean (b) accuracies vs. text length in terms of the number of sentences",
            "categories": "['cs.CL cs.LG cs.NE']",
            "figure_id": "1602.07393v1-Figure3-1",
            "image_path": "1602.07393v1-Figure3-1.png",
            "instance_id": "865664b92f5c8cbe934b66db0a67ce26",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What is the general shape of the accuracy curves in both plots as the number of sentences increases?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Individual"
                    },
                    {
                        "B": "Mean"
                    },
                    {
                        "C": "Course average"
                    },
                    {
                        "D": "Average"
                    }
                ],
                "caption": "Figure 3: Individual (a) and mean (b) accuracies vs. text length in terms of the number of sentences",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Individual (a) and mean (b) accuracies vs. text length in terms of the number of sentences",
            "categories": "['cs.CL cs.LG cs.NE']",
            "figure_id": "1602.07393v1-Figure3-1",
            "image_path": "1602.07393v1-Figure3-1.png",
            "instance_id": "ca3abd6ccbc30e6fb630625bc1bac227",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "At what number of sentences does the Unigram model reach 1.0 accuracy?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Individual (a) and mean (b) accuracies vs. text length in terms of the number of sentences",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Individual (a) and mean (b) accuracies vs. text length in terms of the number of sentences",
            "categories": "['cs.CL cs.LG cs.NE']",
            "figure_id": "1602.07393v1-Figure3-1",
            "image_path": "1602.07393v1-Figure3-1.png",
            "instance_id": "77d1d715e11a14657e5f8a76310e64dd",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific algorithm used to train the 4-gram model with the SRI dataset?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: The loss and gradient norms during DR training (after BM25 warm up). The gradient norms are on the bottom (1-4), middle (5-8), and top (9-12) BERT layers. The x-axes are training steps.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The loss and gradient norms during DR training (after BM25 warm up). The gradient norms are on the bottom (1-4), middle (5-8), and top (9-12) BERT layers. The x-axes are training steps.",
            "categories": "['cs.IR cs.CL cs.LG']",
            "figure_id": "2007.00808v2-Figure4-1",
            "image_path": "2007.00808v2-Figure4-1.png",
            "instance_id": "625e7f91a29dafca336878518ff6932a",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the gradient norm for the blue line for the top BERT layer at training step 25k?",
            "reference_answer": "8"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: The loss and gradient norms during DR training (after BM25 warm up). The gradient norms are on the bottom (1-4), middle (5-8), and top (9-12) BERT layers. The x-axes are training steps.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The loss and gradient norms during DR training (after BM25 warm up). The gradient norms are on the bottom (1-4), middle (5-8), and top (9-12) BERT layers. The x-axes are training steps.",
            "categories": "['cs.IR cs.CL cs.LG']",
            "figure_id": "2007.00808v2-Figure4-1",
            "image_path": "2007.00808v2-Figure4-1.png",
            "instance_id": "930ef7121270ddbb3ac1edc6beb56fc6",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the maximum value shown on the y-axis of the 'Training Loss' plot?",
            "reference_answer": "0.6"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: The loss and gradient norms during DR training (after BM25 warm up). The gradient norms are on the bottom (1-4), middle (5-8), and top (9-12) BERT layers. The x-axes are training steps.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The loss and gradient norms during DR training (after BM25 warm up). The gradient norms are on the bottom (1-4), middle (5-8), and top (9-12) BERT layers. The x-axes are training steps.",
            "categories": "['cs.IR cs.CL cs.LG']",
            "figure_id": "2007.00808v2-Figure4-1",
            "image_path": "2007.00808v2-Figure4-1.png",
            "instance_id": "59414c7052e87d62930a70e92a3cb34a",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the value of the blue line in the fourth plot (Grad Norm (Top)) lower at the training step 20k than at the training step 5k?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: The loss and gradient norms during DR training (after BM25 warm up). The gradient norms are on the bottom (1-4), middle (5-8), and top (9-12) BERT layers. The x-axes are training steps.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The loss and gradient norms during DR training (after BM25 warm up). The gradient norms are on the bottom (1-4), middle (5-8), and top (9-12) BERT layers. The x-axes are training steps.",
            "categories": "['cs.IR cs.CL cs.LG']",
            "figure_id": "2007.00808v2-Figure4-1",
            "image_path": "2007.00808v2-Figure4-1.png",
            "instance_id": "ca27f9bce7afa786c6745acc7db83de4",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the gradient norm for the top BERT layers decrease as training progresses?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The gradient norm for the top BERT layers, as shown in plot (d), decreases as training progresses.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Red line"
                    },
                    {
                        "B": "Green line"
                    },
                    {
                        "C": "Orange line"
                    },
                    {
                        "D": "Blue line"
                    }
                ],
                "caption": "Figure 4: The loss and gradient norms during DR training (after BM25 warm up). The gradient norms are on the bottom (1-4), middle (5-8), and top (9-12) BERT layers. The x-axes are training steps.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The loss and gradient norms during DR training (after BM25 warm up). The gradient norms are on the bottom (1-4), middle (5-8), and top (9-12) BERT layers. The x-axes are training steps.",
            "categories": "['cs.IR cs.CL cs.LG']",
            "figure_id": "2007.00808v2-Figure4-1",
            "image_path": "2007.00808v2-Figure4-1.png",
            "instance_id": "ad7f3c645aade3a31bce0ed637b4559d",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line(s) remain relatively constant throughout training?",
            "reference_answer": "A,B,C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Grad Norm (Bottom)"
                    },
                    {
                        "B": "Grad Norm (Middle)"
                    },
                    {
                        "C": "Grad Norm (Top)"
                    },
                    {
                        "D": "All have the same peak value."
                    }
                ],
                "caption": "Figure 4: The loss and gradient norms during DR training (after BM25 warm up). The gradient norms are on the bottom (1-4), middle (5-8), and top (9-12) BERT layers. The x-axes are training steps.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The loss and gradient norms during DR training (after BM25 warm up). The gradient norms are on the bottom (1-4), middle (5-8), and top (9-12) BERT layers. The x-axes are training steps.",
            "categories": "['cs.IR cs.CL cs.LG']",
            "figure_id": "2007.00808v2-Figure4-1",
            "image_path": "2007.00808v2-Figure4-1.png",
            "instance_id": "66320a77f50fba55d0ec3c7311f14d13",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following plots shows the highest peak value?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "BC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: The loss and gradient norms during DR training (after BM25 warm up). The gradient norms are on the bottom (1-4), middle (5-8), and top (9-12) BERT layers. The x-axes are training steps.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The loss and gradient norms during DR training (after BM25 warm up). The gradient norms are on the bottom (1-4), middle (5-8), and top (9-12) BERT layers. The x-axes are training steps.",
            "categories": "['cs.IR cs.CL cs.LG']",
            "figure_id": "2007.00808v2-Figure4-1",
            "image_path": "2007.00808v2-Figure4-1.png",
            "instance_id": "924b21930d8cbf6ba62a97eb06ef8b14",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific implementation of the BM25 warm up, and how does it differ from other warm-up techniques?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6.9: The Chinese comparison between the DLM approach and the baseline on different number of tokens per sentence.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6.9: The Chinese comparison between the DLM approach and the baseline on different number of tokens per sentence.",
            "categories": "['cs.CL']",
            "figure_id": "1810.02100v1-Figure6.9-1",
            "image_path": "1810.02100v1-Figure6.9-1.png",
            "instance_id": "6089db1a548de69485c00bfc72927d7e",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the black line at 30 tokens?",
            "reference_answer": "38"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6.9: The Chinese comparison between the DLM approach and the baseline on different number of tokens per sentence.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6.9: The Chinese comparison between the DLM approach and the baseline on different number of tokens per sentence.",
            "categories": "['cs.CL']",
            "figure_id": "1810.02100v1-Figure6.9-1",
            "image_path": "1810.02100v1-Figure6.9-1.png",
            "instance_id": "9e5e740fbc34c0624a32d72173df3b9e",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the approximate number of sentences at 40 tokens?",
            "reference_answer": "25"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6.9: The Chinese comparison between the DLM approach and the baseline on different number of tokens per sentence.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6.9: The Chinese comparison between the DLM approach and the baseline on different number of tokens per sentence.",
            "categories": "['cs.CL']",
            "figure_id": "1810.02100v1-Figure6.9-1",
            "image_path": "1810.02100v1-Figure6.9-1.png",
            "instance_id": "bc68de12c1553fef3353fef980c2d59e",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the value of the dotted red line higher than the dashed blue line at the token value 30?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6.9: The Chinese comparison between the DLM approach and the baseline on different number of tokens per sentence.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6.9: The Chinese comparison between the DLM approach and the baseline on different number of tokens per sentence.",
            "categories": "['cs.CL']",
            "figure_id": "1810.02100v1-Figure6.9-1",
            "image_path": "1810.02100v1-Figure6.9-1.png",
            "instance_id": "121ea724690c1e0d5a68173e1da96c02",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the number of sentences generally decrease as the number of tokens per sentence increases?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Dashed-dotted black line"
                    },
                    {
                        "B": "Solid black line"
                    },
                    {
                        "C": "Dashed blue line"
                    },
                    {
                        "D": "Dotted red line"
                    }
                ],
                "caption": "Figure 6.9: The Chinese comparison between the DLM approach and the baseline on different number of tokens per sentence.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6.9: The Chinese comparison between the DLM approach and the baseline on different number of tokens per sentence.",
            "categories": "['cs.CL']",
            "figure_id": "1810.02100v1-Figure6.9-1",
            "image_path": "1810.02100v1-Figure6.9-1.png",
            "instance_id": "990439e08c6e5201b3aa15417c3a09e3",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "At 10 tokens, which of the lines is the highest?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Number of Sentences"
                    },
                    {
                        "B": "Number of Tokens"
                    },
                    {
                        "C": "Percentage"
                    },
                    {
                        "D": "All of the above"
                    }
                ],
                "caption": "Figure 6.9: The Chinese comparison between the DLM approach and the baseline on different number of tokens per sentence.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6.9: The Chinese comparison between the DLM approach and the baseline on different number of tokens per sentence.",
            "categories": "['cs.CL']",
            "figure_id": "1810.02100v1-Figure6.9-1",
            "image_path": "1810.02100v1-Figure6.9-1.png",
            "instance_id": "2cb3c7fe30cf62be11a37df6dfe07d03",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of these are represented in the figure?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6.9: The Chinese comparison between the DLM approach and the baseline on different number of tokens per sentence.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6.9: The Chinese comparison between the DLM approach and the baseline on different number of tokens per sentence.",
            "categories": "['cs.CL']",
            "figure_id": "1810.02100v1-Figure6.9-1",
            "image_path": "1810.02100v1-Figure6.9-1.png",
            "instance_id": "ed5bf651c746b3649ebbbc3aafbf3c32",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific DLM approach used in the experiment?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: BLEU and cumulative costs on IWSLT for Reg3 and -greedy with \u2208 [0.1, 0.25, 0.5, 0.75, 0.9].",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: BLEU and cumulative costs on IWSLT for Reg3 and -greedy with \u2208 [0.1, 0.25, 0.5, 0.75, 0.9].",
            "categories": "['cs.CL stat.ML']",
            "figure_id": "1907.05190v2-Figure5-1",
            "image_path": "1907.05190v2-Figure5-1.png",
            "instance_id": "ce5210873886847d790d1d73abd3f637",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the blue line at a cumulative cost of 20000?",
            "reference_answer": "28.65"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: BLEU and cumulative costs on IWSLT for Reg3 and -greedy with \u2208 [0.1, 0.25, 0.5, 0.75, 0.9].",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: BLEU and cumulative costs on IWSLT for Reg3 and -greedy with \u2208 [0.1, 0.25, 0.5, 0.75, 0.9].",
            "categories": "['cs.CL stat.ML']",
            "figure_id": "1907.05190v2-Figure5-1",
            "image_path": "1907.05190v2-Figure5-1.png",
            "instance_id": "bd538c2d161672f3527cf6b9f6e6b4d2",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "For which epsilon value does the performance stabilize the most after 15000 of cumulative cost?",
            "reference_answer": "0.1"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: BLEU and cumulative costs on IWSLT for Reg3 and -greedy with \u2208 [0.1, 0.25, 0.5, 0.75, 0.9].",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: BLEU and cumulative costs on IWSLT for Reg3 and -greedy with \u2208 [0.1, 0.25, 0.5, 0.75, 0.9].",
            "categories": "['cs.CL stat.ML']",
            "figure_id": "1907.05190v2-Figure5-1",
            "image_path": "1907.05190v2-Figure5-1.png",
            "instance_id": "c7092be7cdcaddee1870da5ff19c774c",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the green dotted line representing eps0.25 consistently higher than the orange dashed line representing eps0.1?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: BLEU and cumulative costs on IWSLT for Reg3 and -greedy with \u2208 [0.1, 0.25, 0.5, 0.75, 0.9].",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: BLEU and cumulative costs on IWSLT for Reg3 and -greedy with \u2208 [0.1, 0.25, 0.5, 0.75, 0.9].",
            "categories": "['cs.CL stat.ML']",
            "figure_id": "1907.05190v2-Figure5-1",
            "image_path": "1907.05190v2-Figure5-1.png",
            "instance_id": "71ddc4df69ad4386294e842a3e248788",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the BLEU score for eps0.9 generally increase with cumulative cost?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The solid blue line"
                    },
                    {
                        "B": "The dashed purple line"
                    },
                    {
                        "C": "The dotted green line"
                    },
                    {
                        "D": "The dashed red line"
                    }
                ],
                "caption": "Figure 5: BLEU and cumulative costs on IWSLT for Reg3 and -greedy with \u2208 [0.1, 0.25, 0.5, 0.75, 0.9].",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: BLEU and cumulative costs on IWSLT for Reg3 and -greedy with \u2208 [0.1, 0.25, 0.5, 0.75, 0.9].",
            "categories": "['cs.CL stat.ML']",
            "figure_id": "1907.05190v2-Figure5-1",
            "image_path": "1907.05190v2-Figure5-1.png",
            "instance_id": "40538da7374d4eacbb91ad8a0fd423b5",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line on the graph represents the epsilon value of 0.75?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "0.1"
                    },
                    {
                        "B": "0.2"
                    },
                    {
                        "C": "0.5"
                    },
                    {
                        "D": "0.75"
                    }
                ],
                "caption": "Figure 5: BLEU and cumulative costs on IWSLT for Reg3 and -greedy with \u2208 [0.1, 0.25, 0.5, 0.75, 0.9].",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: BLEU and cumulative costs on IWSLT for Reg3 and -greedy with \u2208 [0.1, 0.25, 0.5, 0.75, 0.9].",
            "categories": "['cs.CL stat.ML']",
            "figure_id": "1907.05190v2-Figure5-1",
            "image_path": "1907.05190v2-Figure5-1.png",
            "instance_id": "532940008f6b6510941fa1e98a592a8e",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "For which of the following epsilon values is the performance the highest when the cumulative cost is 5000?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: BLEU and cumulative costs on IWSLT for Reg3 and -greedy with \u2208 [0.1, 0.25, 0.5, 0.75, 0.9].",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: BLEU and cumulative costs on IWSLT for Reg3 and -greedy with \u2208 [0.1, 0.25, 0.5, 0.75, 0.9].",
            "categories": "['cs.CL stat.ML']",
            "figure_id": "1907.05190v2-Figure5-1",
            "image_path": "1907.05190v2-Figure5-1.png",
            "instance_id": "06b5ae31537219d350e7f216d8d2747d",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific dataset used for training Reg3 and -greedy models in Figure 5?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 4. Mean Redundancy Fig. 5. Mean Coverage",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 4. Mean Redundancy Fig. 5. Mean Coverage",
            "categories": "['cs.CL cs.IR']",
            "figure_id": "1807.00303v1-Figure4-1",
            "image_path": "1807.00303v1-Figure4-1.png",
            "instance_id": "2743b35599ba36a55a51140819888b38",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the dotted line at 6 sentences in left graph?",
            "reference_answer": "0.24"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 4. Mean Redundancy Fig. 5. Mean Coverage",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 4. Mean Redundancy Fig. 5. Mean Coverage",
            "categories": "['cs.CL cs.IR']",
            "figure_id": "1807.00303v1-Figure4-1",
            "image_path": "1807.00303v1-Figure4-1.png",
            "instance_id": "99245580177e57b78189e3a23acc4682",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the approximate value of Coverage (%) at 5 sentences for the graph centrality method?",
            "reference_answer": "0.17"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 4. Mean Redundancy Fig. 5. Mean Coverage",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 4. Mean Redundancy Fig. 5. Mean Coverage",
            "categories": "['cs.CL cs.IR']",
            "figure_id": "1807.00303v1-Figure4-1",
            "image_path": "1807.00303v1-Figure4-1.png",
            "instance_id": "6259f7179d4f0971f4a668323eb7c90d",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the dotted line consistently above the solid line in both graphs?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, the dotted line is not consistently above the solid line in both graphs. In the left graph for Repetition, the solid line is above the dotted line for most of the range, and in the right graph for Coverage, they appear to intersect without one consistently staying above the other.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 4. Mean Redundancy Fig. 5. Mean Coverage",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 4. Mean Redundancy Fig. 5. Mean Coverage",
            "categories": "['cs.CL cs.IR']",
            "figure_id": "1807.00303v1-Figure4-1",
            "image_path": "1807.00303v1-Figure4-1.png",
            "instance_id": "e49e31d9cd6c5a57564efda2266d98e7",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the mean coverage increase as the number of sentences increases for both 'Powered by Post-Processing' and 'Graph Centrality'?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the mean coverage increases as the number of sentences increases for both 'Powered by Post-Processing' and 'Graph Centrality' based on the graphs provided.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Between 4 and 5"
                    },
                    {
                        "B": "between 5 and 6"
                    },
                    {
                        "C": "Between 1 and 2"
                    },
                    {
                        "D": "Between 2 and 3"
                    }
                ],
                "caption": "Fig. 4. Mean Redundancy Fig. 5. Mean Coverage",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 4. Mean Redundancy Fig. 5. Mean Coverage",
            "categories": "['cs.CL cs.IR']",
            "figure_id": "1807.00303v1-Figure4-1",
            "image_path": "1807.00303v1-Figure4-1.png",
            "instance_id": "70fd58b6497db8d031b8d11f334da03d",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "At what number of sentences does the solid line reach a value higher than 0.15 in the left plot?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "0.9"
                    },
                    {
                        "B": "0.1"
                    },
                    {
                        "C": "0.5"
                    },
                    {
                        "D": "0.2"
                    }
                ],
                "caption": "Fig. 4. Mean Redundancy Fig. 5. Mean Coverage",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 4. Mean Redundancy Fig. 5. Mean Coverage",
            "categories": "['cs.CL cs.IR']",
            "figure_id": "1807.00303v1-Figure4-1",
            "image_path": "1807.00303v1-Figure4-1.png",
            "instance_id": "61a1b331a0be28f86d1b364bfcae5489",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the approximate reception value for 'Powered by Post-Processing' at 3 sentences?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 4. Mean Redundancy Fig. 5. Mean Coverage",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 4. Mean Redundancy Fig. 5. Mean Coverage",
            "categories": "['cs.CL cs.IR']",
            "figure_id": "1807.00303v1-Figure4-1",
            "image_path": "1807.00303v1-Figure4-1.png",
            "instance_id": "7d09f51b88a0314c0fca33afffa58ee6",
            "qa_pair_type": "unanswerable",
            "question": "What specific task or domain does this experiment focus on?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Speed accuracy tradeoff of UAS vs. the number of BP iterations for standard conditional likelihood training (CLL) and our approximation-aware training with either an L2 objective (L2) or a staged training of L2 followed by annealed risk (L2+AR). Note that x-axis shows the number of iterations used for both training and testing. We use a 2nd-order model with Grand.+Sib. factors.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Speed accuracy tradeoff of UAS vs. the number of BP iterations for standard conditional likelihood training (CLL) and our approximation-aware training with either an L2 objective (L2) or a staged training of L2 followed by annealed risk (L2+AR). Note that x-axis shows the number of iterations used for both training and testing. We use a 2nd-order model with Grand.+Sib. factors.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1508.02375v1-Figure3-1",
            "image_path": "1508.02375v1-Figure3-1.png",
            "instance_id": "3a2abc0ce149b56182dde60adfc3edbf",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate UAS value for the red line at 6 iterations?",
            "reference_answer": "92.2"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Speed accuracy tradeoff of UAS vs. the number of BP iterations for standard conditional likelihood training (CLL) and our approximation-aware training with either an L2 objective (L2) or a staged training of L2 followed by annealed risk (L2+AR). Note that x-axis shows the number of iterations used for both training and testing. We use a 2nd-order model with Grand.+Sib. factors.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Speed accuracy tradeoff of UAS vs. the number of BP iterations for standard conditional likelihood training (CLL) and our approximation-aware training with either an L2 objective (L2) or a staged training of L2 followed by annealed risk (L2+AR). Note that x-axis shows the number of iterations used for both training and testing. We use a 2nd-order model with Grand.+Sib. factors.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1508.02375v1-Figure3-1",
            "image_path": "1508.02375v1-Figure3-1.png",
            "instance_id": "a49bb654500ff3d972b34262bbd95e1f",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "Which training method reaches the lowest UAS value at 8 iterations?",
            "reference_answer": "CLL"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "L2",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Speed accuracy tradeoff of UAS vs. the number of BP iterations for standard conditional likelihood training (CLL) and our approximation-aware training with either an L2 objective (L2) or a staged training of L2 followed by annealed risk (L2+AR). Note that x-axis shows the number of iterations used for both training and testing. We use a 2nd-order model with Grand.+Sib. factors.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Speed accuracy tradeoff of UAS vs. the number of BP iterations for standard conditional likelihood training (CLL) and our approximation-aware training with either an L2 objective (L2) or a staged training of L2 followed by annealed risk (L2+AR). Note that x-axis shows the number of iterations used for both training and testing. We use a 2nd-order model with Grand.+Sib. factors.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1508.02375v1-Figure3-1",
            "image_path": "1508.02375v1-Figure3-1.png",
            "instance_id": "deae3248bc82258e3443e986c3655404",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the value of the red square at iteration 4 higher than the value of the blue diamond at iteration 7?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Speed accuracy tradeoff of UAS vs. the number of BP iterations for standard conditional likelihood training (CLL) and our approximation-aware training with either an L2 objective (L2) or a staged training of L2 followed by annealed risk (L2+AR). Note that x-axis shows the number of iterations used for both training and testing. We use a 2nd-order model with Grand.+Sib. factors.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Speed accuracy tradeoff of UAS vs. the number of BP iterations for standard conditional likelihood training (CLL) and our approximation-aware training with either an L2 objective (L2) or a staged training of L2 followed by annealed risk (L2+AR). Note that x-axis shows the number of iterations used for both training and testing. We use a 2nd-order model with Grand.+Sib. factors.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1508.02375v1-Figure3-1",
            "image_path": "1508.02375v1-Figure3-1.png",
            "instance_id": "8c852f4cb76f51d69c3956b1b9829a65",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the UAS value for L2+AR training consistently surpass the UAS value for CLL training throughout the iterations?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Blue"
                    },
                    {
                        "B": "Red"
                    },
                    {
                        "C": "Green"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 3: Speed accuracy tradeoff of UAS vs. the number of BP iterations for standard conditional likelihood training (CLL) and our approximation-aware training with either an L2 objective (L2) or a staged training of L2 followed by annealed risk (L2+AR). Note that x-axis shows the number of iterations used for both training and testing. We use a 2nd-order model with Grand.+Sib. factors.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Speed accuracy tradeoff of UAS vs. the number of BP iterations for standard conditional likelihood training (CLL) and our approximation-aware training with either an L2 objective (L2) or a staged training of L2 followed by annealed risk (L2+AR). Note that x-axis shows the number of iterations used for both training and testing. We use a 2nd-order model with Grand.+Sib. factors.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1508.02375v1-Figure3-1",
            "image_path": "1508.02375v1-Figure3-1.png",
            "instance_id": "1818093c7795414a5e84fb0d810eea75",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line represents the UAS value for approximation-aware training with an L2 objective?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "CLL"
                    },
                    {
                        "B": "L2"
                    },
                    {
                        "C": "L2 + AR"
                    },
                    {
                        "D": "They all have the same UAS value."
                    }
                ],
                "caption": "Figure 3: Speed accuracy tradeoff of UAS vs. the number of BP iterations for standard conditional likelihood training (CLL) and our approximation-aware training with either an L2 objective (L2) or a staged training of L2 followed by annealed risk (L2+AR). Note that x-axis shows the number of iterations used for both training and testing. We use a 2nd-order model with Grand.+Sib. factors.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Speed accuracy tradeoff of UAS vs. the number of BP iterations for standard conditional likelihood training (CLL) and our approximation-aware training with either an L2 objective (L2) or a staged training of L2 followed by annealed risk (L2+AR). Note that x-axis shows the number of iterations used for both training and testing. We use a 2nd-order model with Grand.+Sib. factors.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1508.02375v1-Figure3-1",
            "image_path": "1508.02375v1-Figure3-1.png",
            "instance_id": "546e2a87c89866198548e72a1c67519d",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following shows the highest UAS value at 5 iterations?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Speed accuracy tradeoff of UAS vs. the number of BP iterations for standard conditional likelihood training (CLL) and our approximation-aware training with either an L2 objective (L2) or a staged training of L2 followed by annealed risk (L2+AR). Note that x-axis shows the number of iterations used for both training and testing. We use a 2nd-order model with Grand.+Sib. factors.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Speed accuracy tradeoff of UAS vs. the number of BP iterations for standard conditional likelihood training (CLL) and our approximation-aware training with either an L2 objective (L2) or a staged training of L2 followed by annealed risk (L2+AR). Note that x-axis shows the number of iterations used for both training and testing. We use a 2nd-order model with Grand.+Sib. factors.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1508.02375v1-Figure3-1",
            "image_path": "1508.02375v1-Figure3-1.png",
            "instance_id": "8d8a300d653ce0c53a656c8e6a7583fd",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific task or domain that this UAS metric represents, and how does it relate to the Grand.+Sib. factors mentioned in the caption?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Accuracy values on the training set during training for one model per training set.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Accuracy values on the training set during training for one model per training set.",
            "categories": "['cs.CL']",
            "figure_id": "1906.01280v1-Figure1-1",
            "image_path": "1906.01280v1-Figure1-1.png",
            "instance_id": "4cbd4bce6c3e196b154f19f8bd948ba8",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the dashed line labeled 'Irreg' on the left graph at 20 epochs?",
            "reference_answer": "18"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Accuracy values on the training set during training for one model per training set.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Accuracy values on the training set during training for one model per training set.",
            "categories": "['cs.CL']",
            "figure_id": "1906.01280v1-Figure1-1",
            "image_path": "1906.01280v1-Figure1-1.png",
            "instance_id": "584c79b47d1a0f606375f1f181c3fb48",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "Which training sets are shown in the figure?",
            "reference_answer": "A&H; K&C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The training sets shown in the figure are A&H training data and K&C training data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Accuracy values on the training set during training for one model per training set.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Accuracy values on the training set during training for one model per training set.",
            "categories": "['cs.CL']",
            "figure_id": "1906.01280v1-Figure1-1",
            "image_path": "1906.01280v1-Figure1-1.png",
            "instance_id": "a9b2cef6b32b33654d3f41d644441c19",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the solid line in the graph labeled 'A&H training data' represent the 'Reg' model?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The solid line in the graph labeled 'A&H training data' represents the 'Reg' model.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Accuracy values on the training set during training for one model per training set.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Accuracy values on the training set during training for one model per training set.",
            "categories": "['cs.CL']",
            "figure_id": "1906.01280v1-Figure1-1",
            "image_path": "1906.01280v1-Figure1-1.png",
            "instance_id": "10a43cc380a7dd4a48497ec8e457f61c",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the accuracy of the model for training set A&H stabilize after 10 epochs?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the accuracy of the model for the training set A&H stabilizes after approximately 10 epochs, as indicated by the graph showing that the accuracy plateaus around that point.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The solid line"
                    },
                    {
                        "B": "The dashed line"
                    },
                    {
                        "C": "The dotted line"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 1: Accuracy values on the training set during training for one model per training set.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Accuracy values on the training set during training for one model per training set.",
            "categories": "['cs.CL']",
            "figure_id": "1906.01280v1-Figure1-1",
            "image_path": "1906.01280v1-Figure1-1.png",
            "instance_id": "a6ca1e0a733b1942e8bdc86f4ef35b20",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the lines on the left graph has the highest value at 30 epochs?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "1"
                    },
                    {
                        "B": "2"
                    },
                    {
                        "C": "3"
                    },
                    {
                        "D": "4"
                    }
                ],
                "caption": "Figure 1: Accuracy values on the training set during training for one model per training set.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Accuracy values on the training set during training for one model per training set.",
            "categories": "['cs.CL']",
            "figure_id": "1906.01280v1-Figure1-1",
            "image_path": "1906.01280v1-Figure1-1.png",
            "instance_id": "bf5af7966427af9ba37d63713b428222",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "How many training sets are presented in this figure?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Accuracy values on the training set during training for one model per training set.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Accuracy values on the training set during training for one model per training set.",
            "categories": "['cs.CL']",
            "figure_id": "1906.01280v1-Figure1-1",
            "image_path": "1906.01280v1-Figure1-1.png",
            "instance_id": "6e5e3f0a91c7ae9bf36366aa637b9e33",
            "qa_pair_type": "unanswerable",
            "question": "What is the size of the training datasets?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Throughput of our approach per second in comparison to the average Twitter (Firehose) and Sina Weibo stream",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Throughput of our approach per second in comparison to the average Twitter (Firehose) and Sina Weibo stream",
            "categories": "['cs.SI cs.CL cs.IR']",
            "figure_id": "1611.06322v1-Figure2-1",
            "image_path": "1611.06322v1-Figure2-1.png",
            "instance_id": "678bf6ceac9ba5de4aed5a4c591b9c9b",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the red square at 20000 Weibos processed?",
            "reference_answer": "7000"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Throughput of our approach per second in comparison to the average Twitter (Firehose) and Sina Weibo stream",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Throughput of our approach per second in comparison to the average Twitter (Firehose) and Sina Weibo stream",
            "categories": "['cs.SI cs.CL cs.IR']",
            "figure_id": "1611.06322v1-Figure2-1",
            "image_path": "1611.06322v1-Figure2-1.png",
            "instance_id": "4703843589529922964a929799edf3ba",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What does the x-axis represent?",
            "reference_answer": "Weibos processed"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The x-axis represents the \"Weibos processed.\"",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Throughput of our approach per second in comparison to the average Twitter (Firehose) and Sina Weibo stream",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Throughput of our approach per second in comparison to the average Twitter (Firehose) and Sina Weibo stream",
            "categories": "['cs.SI cs.CL cs.IR']",
            "figure_id": "1611.06322v1-Figure2-1",
            "image_path": "1611.06322v1-Figure2-1.png",
            "instance_id": "3ed04adbdbce48c49592421ff1a56164",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the value of the red line (our approach) consistently higher than the green line (Sina Weibo) throughout the x-axis?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the value of the red line (our approach) is consistently higher than the green line (Sina Weibo) throughout the x-axis.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Throughput of our approach per second in comparison to the average Twitter (Firehose) and Sina Weibo stream",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Throughput of our approach per second in comparison to the average Twitter (Firehose) and Sina Weibo stream",
            "categories": "['cs.SI cs.CL cs.IR']",
            "figure_id": "1611.06322v1-Figure2-1",
            "image_path": "1611.06322v1-Figure2-1.png",
            "instance_id": "66bec122df077de3e107f143a0cfa046",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the value of the 'our approach' consistently exceed that of Sina Weibo and Twitter throughout the range shown in Figure 2?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the value of 'our approach' consistently exceeds that of Sina Weibo and Twitter throughout the range shown in the figure.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "They rise"
                    },
                    {
                        "B": "They drop"
                    },
                    {
                        "C": "They fluctuate"
                    },
                    {
                        "D": "They remain stable"
                    }
                ],
                "caption": "Figure 2: Throughput of our approach per second in comparison to the average Twitter (Firehose) and Sina Weibo stream",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Throughput of our approach per second in comparison to the average Twitter (Firehose) and Sina Weibo stream",
            "categories": "['cs.SI cs.CL cs.IR']",
            "figure_id": "1611.06322v1-Figure2-1",
            "image_path": "1611.06322v1-Figure2-1.png",
            "instance_id": "af55f2376fd6adc687af492cc02934f3",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following best describes the lines shown in the graph?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Between 5000 and 6000"
                    },
                    {
                        "B": "Between 4000 and 5000"
                    },
                    {
                        "C": "Between 1000 and 2000"
                    },
                    {
                        "D": "Between 7000 and 8000"
                    }
                ],
                "caption": "Figure 2: Throughput of our approach per second in comparison to the average Twitter (Firehose) and Sina Weibo stream",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Throughput of our approach per second in comparison to the average Twitter (Firehose) and Sina Weibo stream",
            "categories": "['cs.SI cs.CL cs.IR']",
            "figure_id": "1611.06322v1-Figure2-1",
            "image_path": "1611.06322v1-Figure2-1.png",
            "instance_id": "fb0346a5479848191496e0c448aa2601",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the value of 'Twitter' at 80000 Weibos processed?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Throughput of our approach per second in comparison to the average Twitter (Firehose) and Sina Weibo stream",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Throughput of our approach per second in comparison to the average Twitter (Firehose) and Sina Weibo stream",
            "categories": "['cs.SI cs.CL cs.IR']",
            "figure_id": "1611.06322v1-Figure2-1",
            "image_path": "1611.06322v1-Figure2-1.png",
            "instance_id": "1f04a7de5044af26edad66f96be13ef1",
            "qa_pair_type": "unanswerable",
            "question": "What is the standard deviation of the throughput for our approach across different Weibo processed values shown in Figure 2?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: the performance of a selected model.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: the performance of a selected model.",
            "categories": "['cs.CL']",
            "figure_id": "1808.09718v1-Figure1-1",
            "image_path": "1808.09718v1-Figure1-1.png",
            "instance_id": "bb796b79b311261081ca888034787e47",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of the correlation at feature number 1 for the black line in the bottom plot?",
            "reference_answer": "0.65"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: the performance of a selected model.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: the performance of a selected model.",
            "categories": "['cs.CL']",
            "figure_id": "1808.09718v1-Figure1-1",
            "image_path": "1808.09718v1-Figure1-1.png",
            "instance_id": "397ae7b874bfae3067231d2b962930fa",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the highest approximate correlation value achieved by the model?",
            "reference_answer": "0.9"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: the performance of a selected model.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: the performance of a selected model.",
            "categories": "['cs.CL']",
            "figure_id": "1808.09718v1-Figure1-1",
            "image_path": "1808.09718v1-Figure1-1.png",
            "instance_id": "41da7fa7ed7ed6c5f205db07f8281b33",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "In the top plot, is the RMSE value of the black line at 11th feature number than at 31st feature number?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: the performance of a selected model.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: the performance of a selected model.",
            "categories": "['cs.CL']",
            "figure_id": "1808.09718v1-Figure1-1",
            "image_path": "1808.09718v1-Figure1-1.png",
            "instance_id": "47847f5790d33a988634364e137570c5",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the correlation remain constant after feature number 30?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "It steadily decreases"
                    },
                    {
                        "B": "It stays constant throughout"
                    },
                    {
                        "C": "It fluctuates randomly"
                    },
                    {
                        "D": "It decreases initially but jumps up sharply after feature ~30"
                    }
                ],
                "caption": "Figure 1: the performance of a selected model.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: the performance of a selected model.",
            "categories": "['cs.CL']",
            "figure_id": "1808.09718v1-Figure1-1",
            "image_path": "1808.09718v1-Figure1-1.png",
            "instance_id": "61fdac019ed22c187f5ae835c53ed7f0",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What happens to the black line in the RMSE plot as the feature number increases?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "31"
                    },
                    {
                        "B": "41"
                    },
                    {
                        "C": "21"
                    },
                    {
                        "D": "11"
                    }
                ],
                "caption": "Figure 1: the performance of a selected model.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: the performance of a selected model.",
            "categories": "['cs.CL']",
            "figure_id": "1808.09718v1-Figure1-1",
            "image_path": "1808.09718v1-Figure1-1.png",
            "instance_id": "dedfbefb46d396ccb1278986a7291b2d",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the highest feature number value shown in the graph?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: the performance of a selected model.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: the performance of a selected model.",
            "categories": "['cs.CL']",
            "figure_id": "1808.09718v1-Figure1-1",
            "image_path": "1808.09718v1-Figure1-1.png",
            "instance_id": "9a0980973b1c2d7659c374fa34179258",
            "qa_pair_type": "unanswerable",
            "question": "What is the exact value of the RMSE for feature number 20?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Spearman\u2019s Correlation and Kendall\u2019s Correlation v.s. Number of human references.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Spearman\u2019s Correlation and Kendall\u2019s Correlation v.s. Number of human references.",
            "categories": "['cs.CL']",
            "figure_id": "2010.02498v1-Figure3-1",
            "image_path": "2010.02498v1-Figure3-1.png",
            "instance_id": "fcfde7116eb3387fc871e68116d8493d",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of the orange line in the left subplot when the number of references is 6?",
            "reference_answer": "Between 0.55 and 0.65"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Spearman\u2019s Correlation and Kendall\u2019s Correlation v.s. Number of human references.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Spearman\u2019s Correlation and Kendall\u2019s Correlation v.s. Number of human references.",
            "categories": "['cs.CL']",
            "figure_id": "2010.02498v1-Figure3-1",
            "image_path": "2010.02498v1-Figure3-1.png",
            "instance_id": "9da33862496116ad567db63b65ab983f",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "How many different methods are represented in the graph?",
            "reference_answer": "4"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "There are four different methods represented in the graph: ROUGE-W, METEOR, MoverScore, and GRUEN.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Spearman\u2019s Correlation and Kendall\u2019s Correlation v.s. Number of human references.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Spearman\u2019s Correlation and Kendall\u2019s Correlation v.s. Number of human references.",
            "categories": "['cs.CL']",
            "figure_id": "2010.02498v1-Figure3-1",
            "image_path": "2010.02498v1-Figure3-1.png",
            "instance_id": "53bf904d182043767b7d41f211682c8a",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the green line representing MoverScore have a consistently higher value than the orange line representing METEOR in the left graph?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, the green line representing MoverScore does not have a consistently higher value than the orange line representing METEOR in the left graph.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Spearman\u2019s Correlation and Kendall\u2019s Correlation v.s. Number of human references.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Spearman\u2019s Correlation and Kendall\u2019s Correlation v.s. Number of human references.",
            "categories": "['cs.CL']",
            "figure_id": "2010.02498v1-Figure3-1",
            "image_path": "2010.02498v1-Figure3-1.png",
            "instance_id": "d6fdf3b5ffc0246f4c1ef51b79ed246f",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the Kendall's correlation value generally increase as the number of human references increases?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the Kendall's correlation value generally increases as the number of human references increases.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "green"
                    },
                    {
                        "B": "orange"
                    },
                    {
                        "C": "blue"
                    },
                    {
                        "D": "red"
                    }
                ],
                "caption": "Figure 3: Spearman\u2019s Correlation and Kendall\u2019s Correlation v.s. Number of human references.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Spearman\u2019s Correlation and Kendall\u2019s Correlation v.s. Number of human references.",
            "categories": "['cs.CL']",
            "figure_id": "2010.02498v1-Figure3-1",
            "image_path": "2010.02498v1-Figure3-1.png",
            "instance_id": "539698b9a62f26b97d44e1235c66687e",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line has the lowest value for Spearman's Correlation at 4 human references?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "METEOR"
                    },
                    {
                        "B": "GRUEN"
                    },
                    {
                        "C": "ROUGE-W"
                    },
                    {
                        "D": "MoverScore"
                    }
                ],
                "caption": "Figure 3: Spearman\u2019s Correlation and Kendall\u2019s Correlation v.s. Number of human references.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Spearman\u2019s Correlation and Kendall\u2019s Correlation v.s. Number of human references.",
            "categories": "['cs.CL']",
            "figure_id": "2010.02498v1-Figure3-1",
            "image_path": "2010.02498v1-Figure3-1.png",
            "instance_id": "2f6ee89a995b34a7f8884b67be3af67d",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following has the highest Spearman's Correlation value at 8 references?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Spearman\u2019s Correlation and Kendall\u2019s Correlation v.s. Number of human references.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Spearman\u2019s Correlation and Kendall\u2019s Correlation v.s. Number of human references.",
            "categories": "['cs.CL']",
            "figure_id": "2010.02498v1-Figure3-1",
            "image_path": "2010.02498v1-Figure3-1.png",
            "instance_id": "0afc6008084b46a57adcba752b8c5f60",
            "qa_pair_type": "unanswerable",
            "question": "What is the exact value of the Spearman's correlation for the ROUGE-W metric when the number of references is 3?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Performance of PETAL (sep) on all four tasks as a function of the number of verbalizations per label (nv)",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Performance of PETAL (sep) on all four tasks as a function of the number of verbalizations per label (nv)",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "2010.13641v1-Figure2-1",
            "image_path": "2010.13641v1-Figure2-1.png",
            "instance_id": "e9f1a03bca8e1c6e43eb4b91fe29376a",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate accuracy value of the blue circle at 5 verbalizations per label?",
            "reference_answer": "55"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Performance of PETAL (sep) on all four tasks as a function of the number of verbalizations per label (nv)",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Performance of PETAL (sep) on all four tasks as a function of the number of verbalizations per label (nv)",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "2010.13641v1-Figure2-1",
            "image_path": "2010.13641v1-Figure2-1.png",
            "instance_id": "9712af92ee843ce02759ed889cc28df0",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the approximate highest accuracy achieved by PETAL (sep) on the Yahoo task?",
            "reference_answer": "65%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Performance of PETAL (sep) on all four tasks as a function of the number of verbalizations per label (nv)",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Performance of PETAL (sep) on all four tasks as a function of the number of verbalizations per label (nv)",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "2010.13641v1-Figure2-1",
            "image_path": "2010.13641v1-Figure2-1.png",
            "instance_id": "e79b6a32d8d095b0b9bc36805147e671",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the the blue line consistently below the green line?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The blue line (representing Yahoo) is consistently below the green line (representing MNLI) throughout the data points.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Performance of PETAL (sep) on all four tasks as a function of the number of verbalizations per label (nv)",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Performance of PETAL (sep) on all four tasks as a function of the number of verbalizations per label (nv)",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "2010.13641v1-Figure2-1",
            "image_path": "2010.13641v1-Figure2-1.png",
            "instance_id": "fa2aebbb40064df4b617fc1eb0b316d4",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the accuracy of Yahoo consistently lower than the accuracy of MNLI?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Blue line"
                    },
                    {
                        "B": "Purple line"
                    },
                    {
                        "C": "Green line"
                    },
                    {
                        "D": "Red line"
                    }
                ],
                "caption": "Figure 2: Performance of PETAL (sep) on all four tasks as a function of the number of verbalizations per label (nv)",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Performance of PETAL (sep) on all four tasks as a function of the number of verbalizations per label (nv)",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "2010.13641v1-Figure2-1",
            "image_path": "2010.13641v1-Figure2-1.png",
            "instance_id": "964d2dabd5b5e18c79437d89c9f66d80",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line in the graph has the highest accuracy at 1 verbalization per label?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "AG's"
                    },
                    {
                        "B": "MNLI"
                    },
                    {
                        "C": "Yahoo"
                    },
                    {
                        "D": "Yelp"
                    }
                ],
                "caption": "Figure 2: Performance of PETAL (sep) on all four tasks as a function of the number of verbalizations per label (nv)",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Performance of PETAL (sep) on all four tasks as a function of the number of verbalizations per label (nv)",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "2010.13641v1-Figure2-1",
            "image_path": "2010.13641v1-Figure2-1.png",
            "instance_id": "b09de0eba43dfde0cf55331af193153f",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "On which of the following tasks does PETAL have the most stable performance?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Performance of PETAL (sep) on all four tasks as a function of the number of verbalizations per label (nv)",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Performance of PETAL (sep) on all four tasks as a function of the number of verbalizations per label (nv)",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "2010.13641v1-Figure2-1",
            "image_path": "2010.13641v1-Figure2-1.png",
            "instance_id": "3f4d400c8188e5fc6c9e5820bed86765",
            "qa_pair_type": "unanswerable",
            "question": "What is the average performance of PETAL (sep) on the MNLI task for all verbalizations per label?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Interference with prior knowledge caused by na\u0131\u0308ve use of our approach",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Interference with prior knowledge caused by na\u0131\u0308ve use of our approach",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1710.10280v2-Figure5-1",
            "image_path": "1710.10280v2-Figure5-1.png",
            "instance_id": "d4dd9123069676c5573bfb2318f52296",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the green solid line in the 'rice' subplot in the bottom figure?",
            "reference_answer": "0"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Interference with prior knowledge caused by na\u0131\u0308ve use of our approach",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Interference with prior knowledge caused by na\u0131\u0308ve use of our approach",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1710.10280v2-Figure5-1",
            "image_path": "1710.10280v2-Figure5-1.png",
            "instance_id": "75b0d8530d478e4d80d055a10430d120",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "How many approaches are represented in the graph?",
            "reference_answer": "5"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "There are five approaches represented in the graph.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Interference with prior knowledge caused by na\u0131\u0308ve use of our approach",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Interference with prior knowledge caused by na\u0131\u0308ve use of our approach",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1710.10280v2-Figure5-1",
            "image_path": "1710.10280v2-Figure5-1.png",
            "instance_id": "294b04beb47bccf59a4e52ef4944e841",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "In graph (b), is the green solid line in the 'rice' subplot higher than the green dashed line in the 'immune' subplot?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Interference with prior knowledge caused by na\u0131\u0308ve use of our approach",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Interference with prior knowledge caused by na\u0131\u0308ve use of our approach",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1710.10280v2-Figure5-1",
            "image_path": "1710.10280v2-Figure5-1.png",
            "instance_id": "4fe3a6b124712c484d250204fa2e310f",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is there at least one approach that shows a positive change in perplexity for the word 'rice'?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "green"
                    },
                    {
                        "B": "orange"
                    },
                    {
                        "C": "blue"
                    },
                    {
                        "D": "red"
                    }
                ],
                "caption": "Figure 5: Interference with prior knowledge caused by na\u0131\u0308ve use of our approach",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Interference with prior knowledge caused by na\u0131\u0308ve use of our approach",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1710.10280v2-Figure5-1",
            "image_path": "1710.10280v2-Figure5-1.png",
            "instance_id": "8f88cdb511a44a5d0766399763066e4e",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What is the colour of the line representing 'Optimizing from current' approach?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "40"
                    },
                    {
                        "B": "20"
                    },
                    {
                        "C": "50"
                    },
                    {
                        "D": "30"
                    }
                ],
                "caption": "Figure 5: Interference with prior knowledge caused by na\u0131\u0308ve use of our approach",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Interference with prior knowledge caused by na\u0131\u0308ve use of our approach",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1710.10280v2-Figure5-1",
            "image_path": "1710.10280v2-Figure5-1.png",
            "instance_id": "5da133e55452a191f6b46cdb7fdb76a2",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the approximate value of change in perplexity on new word test data for 'Optimizing from centroid' in 'immune' subplot when the number of sentences is 10?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Interference with prior knowledge caused by na\u0131\u0308ve use of our approach",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Interference with prior knowledge caused by na\u0131\u0308ve use of our approach",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1710.10280v2-Figure5-1",
            "image_path": "1710.10280v2-Figure5-1.png",
            "instance_id": "249f91eca1cc650e3e5a75511bd87de9",
            "qa_pair_type": "unanswerable",
            "question": "What is the significance of the dashed green line in each of the graphs?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The dashed green line in each of the graphs typically represents a baseline or reference point for comparison. It may indicate the level of perplexity achieved through full training with the word, serving to show how different approaches affect performance relative to this baseline.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Goal imagination properties. (a) Coverage and precision of different goal imagination heuristics. (b) SR on testing set. (c) IC on G test. We report sem (standard error of the mean) instead of std to improve readability. Stars indicate significant differences w.r.t the no imagination condition.",
                "compound": true,
                "figure_type": "Line Chart,Table",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Goal imagination properties. (a) Coverage and precision of different goal imagination heuristics. (b) SR on testing set. (c) IC on G test. We report sem (standard error of the mean) instead of std to improve readability. Stars indicate significant differences w.r.t the no imagination condition.",
            "categories": "['cs.AI cs.CL cs.LG']",
            "figure_id": "2002.09253v4-Figure4-1",
            "image_path": "2002.09253v4-Figure4-1.png",
            "instance_id": "a7135d1987f8219d3fc513db02364955",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the success rate for the 'Oracle' condition at 50 episodes in the left graph?",
            "reference_answer": "0.7"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Goal imagination properties. (a) Coverage and precision of different goal imagination heuristics. (b) SR on testing set. (c) IC on G test. We report sem (standard error of the mean) instead of std to improve readability. Stars indicate significant differences w.r.t the no imagination condition.",
                "compound": true,
                "figure_type": "Line Chart,Table",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Goal imagination properties. (a) Coverage and precision of different goal imagination heuristics. (b) SR on testing set. (c) IC on G test. We report sem (standard error of the mean) instead of std to improve readability. Stars indicate significant differences w.r.t the no imagination condition.",
            "categories": "['cs.AI cs.CL cs.LG']",
            "figure_id": "2002.09253v4-Figure4-1",
            "image_path": "2002.09253v4-Figure4-1.png",
            "instance_id": "23dc547821b5bcf30b9297796b2a5976",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the value of coverage for the CGH heuristic?",
            "reference_answer": "0.87"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The value of coverage for the CGH heuristic is 0.87.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Goal imagination properties. (a) Coverage and precision of different goal imagination heuristics. (b) SR on testing set. (c) IC on G test. We report sem (standard error of the mean) instead of std to improve readability. Stars indicate significant differences w.r.t the no imagination condition.",
                "compound": true,
                "figure_type": "Line Chart,Table",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Goal imagination properties. (a) Coverage and precision of different goal imagination heuristics. (b) SR on testing set. (c) IC on G test. We report sem (standard error of the mean) instead of std to improve readability. Stars indicate significant differences w.r.t the no imagination condition.",
            "categories": "['cs.AI cs.CL cs.LG']",
            "figure_id": "2002.09253v4-Figure4-1",
            "image_path": "2002.09253v4-Figure4-1.png",
            "instance_id": "3f5cf2b010a43d3c6a598872716fecc8",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the yellow line representing 'Random' consistently below the purple line representing 'Oracle' in the graph labeled (b)?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Goal imagination properties. (a) Coverage and precision of different goal imagination heuristics. (b) SR on testing set. (c) IC on G test. We report sem (standard error of the mean) instead of std to improve readability. Stars indicate significant differences w.r.t the no imagination condition.",
                "compound": true,
                "figure_type": "Line Chart,Table",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Goal imagination properties. (a) Coverage and precision of different goal imagination heuristics. (b) SR on testing set. (c) IC on G test. We report sem (standard error of the mean) instead of std to improve readability. Stars indicate significant differences w.r.t the no imagination condition.",
            "categories": "['cs.AI cs.CL cs.LG']",
            "figure_id": "2002.09253v4-Figure4-1",
            "image_path": "2002.09253v4-Figure4-1.png",
            "instance_id": "9e19fcb044c0d878f11f43f71e003e8d",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the Oracle condition have a precision value of 1?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the Oracle condition has a precision value of 1.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "yellow"
                    },
                    {
                        "B": "green"
                    },
                    {
                        "C": "red"
                    },
                    {
                        "D": "purple"
                    }
                ],
                "caption": "Figure 4: Goal imagination properties. (a) Coverage and precision of different goal imagination heuristics. (b) SR on testing set. (c) IC on G test. We report sem (standard error of the mean) instead of std to improve readability. Stars indicate significant differences w.r.t the no imagination condition.",
                "compound": true,
                "figure_type": "Line Chart,Table",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Goal imagination properties. (a) Coverage and precision of different goal imagination heuristics. (b) SR on testing set. (c) IC on G test. We report sem (standard error of the mean) instead of std to improve readability. Stars indicate significant differences w.r.t the no imagination condition.",
            "categories": "['cs.AI cs.CL cs.LG']",
            "figure_id": "2002.09253v4-Figure4-1",
            "image_path": "2002.09253v4-Figure4-1.png",
            "instance_id": "42afa1dfccc0b60fa966c19e3cbd96fa",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line in figure (b) has the highest value at the point where the x-axis value is 80 in the right graph?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "CGH"
                    },
                    {
                        "B": "Oracle"
                    },
                    {
                        "C": "Low Coverage"
                    },
                    {
                        "D": "Low Precision"
                    }
                ],
                "caption": "Figure 4: Goal imagination properties. (a) Coverage and precision of different goal imagination heuristics. (b) SR on testing set. (c) IC on G test. We report sem (standard error of the mean) instead of std to improve readability. Stars indicate significant differences w.r.t the no imagination condition.",
                "compound": true,
                "figure_type": "Line Chart,Table",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Goal imagination properties. (a) Coverage and precision of different goal imagination heuristics. (b) SR on testing set. (c) IC on G test. We report sem (standard error of the mean) instead of std to improve readability. Stars indicate significant differences w.r.t the no imagination condition.",
            "categories": "['cs.AI cs.CL cs.LG']",
            "figure_id": "2002.09253v4-Figure4-1",
            "image_path": "2002.09253v4-Figure4-1.png",
            "instance_id": "22d2f676baccdf1fc9ca0b4e3d680b90",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following goal imagination heuristics have a coverage score of 0.44?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Goal imagination properties. (a) Coverage and precision of different goal imagination heuristics. (b) SR on testing set. (c) IC on G test. We report sem (standard error of the mean) instead of std to improve readability. Stars indicate significant differences w.r.t the no imagination condition.",
                "compound": true,
                "figure_type": "Line Chart,Table",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Goal imagination properties. (a) Coverage and precision of different goal imagination heuristics. (b) SR on testing set. (c) IC on G test. We report sem (standard error of the mean) instead of std to improve readability. Stars indicate significant differences w.r.t the no imagination condition.",
            "categories": "['cs.AI cs.CL cs.LG']",
            "figure_id": "2002.09253v4-Figure4-1",
            "image_path": "2002.09253v4-Figure4-1.png",
            "instance_id": "7b6eeaa97882a68bd9d54b7f54286955",
            "qa_pair_type": "unanswerable",
            "question": "What is the difference in the SR for the Oracle and the No Imagination conditions after 50,000 episodes?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Left and Center: Comparison of BERT and ELECTRA for different model sizes. Right: A small ELECTRA model converges to higher downstream accuracy than BERT, showing the improvement comes from more than just faster training.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Left and Center: Comparison of BERT and ELECTRA for different model sizes. Right: A small ELECTRA model converges to higher downstream accuracy than BERT, showing the improvement comes from more than just faster training.",
            "categories": "['cs.CL']",
            "figure_id": "2003.10555v1-Figure4-1",
            "image_path": "2003.10555v1-Figure4-1.png",
            "instance_id": "0916fda502a3920e24c237945ba3638c",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate GLUE Score of the orange line at the hidden state size of 256?",
            "reference_answer": "76"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Left and Center: Comparison of BERT and ELECTRA for different model sizes. Right: A small ELECTRA model converges to higher downstream accuracy than BERT, showing the improvement comes from more than just faster training.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Left and Center: Comparison of BERT and ELECTRA for different model sizes. Right: A small ELECTRA model converges to higher downstream accuracy than BERT, showing the improvement comes from more than just faster training.",
            "categories": "['cs.CL']",
            "figure_id": "2003.10555v1-Figure4-1",
            "image_path": "2003.10555v1-Figure4-1.png",
            "instance_id": "a4d5cad52f25adba088a1fbe3686ef31",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the approximate GLUE score achieved by ELECTRA with a hidden state size of 768?",
            "reference_answer": "85"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The approximate GLUE score achieved by ELECTRA with a hidden state size of 768 is around 84.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Left and Center: Comparison of BERT and ELECTRA for different model sizes. Right: A small ELECTRA model converges to higher downstream accuracy than BERT, showing the improvement comes from more than just faster training.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Left and Center: Comparison of BERT and ELECTRA for different model sizes. Right: A small ELECTRA model converges to higher downstream accuracy than BERT, showing the improvement comes from more than just faster training.",
            "categories": "['cs.CL']",
            "figure_id": "2003.10555v1-Figure4-1",
            "image_path": "2003.10555v1-Figure4-1.png",
            "instance_id": "69a34b8453615daa39a05034fb25e3df",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the blue line representing ELECTRA reach a higher GLUE score than the orange line representing BERT at the hidden state size of 768?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the blue line representing ELECTRA reaches a higher GLUE score than the orange line representing BERT at the hidden state size of 768.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Left and Center: Comparison of BERT and ELECTRA for different model sizes. Right: A small ELECTRA model converges to higher downstream accuracy than BERT, showing the improvement comes from more than just faster training.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Left and Center: Comparison of BERT and ELECTRA for different model sizes. Right: A small ELECTRA model converges to higher downstream accuracy than BERT, showing the improvement comes from more than just faster training.",
            "categories": "['cs.CL']",
            "figure_id": "2003.10555v1-Figure4-1",
            "image_path": "2003.10555v1-Figure4-1.png",
            "instance_id": "52a1e9d2ef5dd6608a678c7d887e26f5",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does ELECTRA consistently outperform BERT for different model sizes?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the graphs suggest that ELECTRA consistently outperforms BERT across different hidden state sizes, as indicated by the higher GLUE scores for ELECTRA compared to BERT.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "ELECTRA"
                    },
                    {
                        "B": "BERT"
                    },
                    {
                        "C": "LSTM"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 4: Left and Center: Comparison of BERT and ELECTRA for different model sizes. Right: A small ELECTRA model converges to higher downstream accuracy than BERT, showing the improvement comes from more than just faster training.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Left and Center: Comparison of BERT and ELECTRA for different model sizes. Right: A small ELECTRA model converges to higher downstream accuracy than BERT, showing the improvement comes from more than just faster training.",
            "categories": "['cs.CL']",
            "figure_id": "2003.10555v1-Figure4-1",
            "image_path": "2003.10555v1-Figure4-1.png",
            "instance_id": "a5d33d35db0a2b3d4203fbb32a266532",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which model does the orange represent?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "75"
                    },
                    {
                        "B": "50"
                    },
                    {
                        "C": "30"
                    },
                    {
                        "D": "10"
                    }
                ],
                "caption": "Figure 4: Left and Center: Comparison of BERT and ELECTRA for different model sizes. Right: A small ELECTRA model converges to higher downstream accuracy than BERT, showing the improvement comes from more than just faster training.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Left and Center: Comparison of BERT and ELECTRA for different model sizes. Right: A small ELECTRA model converges to higher downstream accuracy than BERT, showing the improvement comes from more than just faster training.",
            "categories": "['cs.CL']",
            "figure_id": "2003.10555v1-Figure4-1",
            "image_path": "2003.10555v1-Figure4-1.png",
            "instance_id": "457edef51c7bf26e2d0edaa5da18e8fe",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the approximate GLUE Score of 'BERT-256' at 4 pre-train FLOPs?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Left and Center: Comparison of BERT and ELECTRA for different model sizes. Right: A small ELECTRA model converges to higher downstream accuracy than BERT, showing the improvement comes from more than just faster training.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Left and Center: Comparison of BERT and ELECTRA for different model sizes. Right: A small ELECTRA model converges to higher downstream accuracy than BERT, showing the improvement comes from more than just faster training.",
            "categories": "['cs.CL']",
            "figure_id": "2003.10555v1-Figure4-1",
            "image_path": "2003.10555v1-Figure4-1.png",
            "instance_id": "ca308fbc9f9dc728ce9b0506159ec65e",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific dataset used to train the BERT and ELECTRA models shown in Figure 4?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Gapped clause Sue Bill",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Gapped clause Sue Bill",
            "categories": "nan",
            "figure_id": "Y16-2028.pdf-Figure1",
            "image_path": "Y16-2028.pdf-Figure1.png",
            "instance_id": "1add1818606f1f6d3d0f34b418152d73",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What are the labels of the two triangles shown in the graph?",
            "reference_answer": "Sue and Bill"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The labels of the two triangles shown in the graph are \"Sue\" and \"Bill.\"",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Gapped clause Sue Bill",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Gapped clause Sue Bill",
            "categories": "nan",
            "figure_id": "Y16-2028.pdf-Figure1",
            "image_path": "Y16-2028.pdf-Figure1.png",
            "instance_id": "7c8941d33eab491b361b86e2ee3c7caa",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the semantic (SEM) representation of the clause?",
            "reference_answer": "love(s,b)"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The semantic (SEM) representation of the clause is:\n\n**love(s, b)**",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Gapped clause Sue Bill",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Gapped clause Sue Bill",
            "categories": "nan",
            "figure_id": "Y16-2028.pdf-Figure1",
            "image_path": "Y16-2028.pdf-Figure1.png",
            "instance_id": "da6756e35bf943b90e7fe2f1519ef9d1",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the word 'Sue' positioned below the word 'NP'?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the word 'Sue' is positioned below the word 'NP'.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Gapped clause Sue Bill",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Gapped clause Sue Bill",
            "categories": "nan",
            "figure_id": "Y16-2028.pdf-Figure1",
            "image_path": "Y16-2028.pdf-Figure1.png",
            "instance_id": "e9d27ebd130e8327566f49e509d8958d",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the image contain a syntactic analysis?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the image contains a syntactic analysis.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Dashed lines"
                    },
                    {
                        "B": "Arrows"
                    },
                    {
                        "C": "Solid lines"
                    },
                    {
                        "D": "Dotted lines"
                    }
                ],
                "caption": "Figure 1: Gapped clause Sue Bill",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Gapped clause Sue Bill",
            "categories": "nan",
            "figure_id": "Y16-2028.pdf-Figure1",
            "image_path": "Y16-2028.pdf-Figure1.png",
            "instance_id": "12c1b3d9359c9d62bb11bbfd3801fe12",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What kind of line is used to connect the two NP nodes to the top part of the graph?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "1"
                    },
                    {
                        "B": "2"
                    },
                    {
                        "C": "3"
                    },
                    {
                        "D": "4"
                    }
                ],
                "caption": "Figure 1: Gapped clause Sue Bill",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Gapped clause Sue Bill",
            "categories": "nan",
            "figure_id": "Y16-2028.pdf-Figure1",
            "image_path": "Y16-2028.pdf-Figure1.png",
            "instance_id": "7a290faf20e0e4a7b48c5cb4439ac944",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "How many arguments does the lambda expression under Q abstract over?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Gapped clause Sue Bill",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Gapped clause Sue Bill",
            "categories": "nan",
            "figure_id": "Y16-2028.pdf-Figure1",
            "image_path": "Y16-2028.pdf-Figure1.png",
            "instance_id": "4e00de86feaba05966a1d59836d0baee",
            "qa_pair_type": "unanswerable",
            "question": "What research question is the study trying to asnwer?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Network underlying (12)",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Network underlying (12)",
            "categories": "nan",
            "figure_id": "C00-2088.pdf-Figure6",
            "image_path": "C00-2088.pdf-Figure6.png",
            "instance_id": "33685c8da34ce797ab1b82d05bb67db6",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "Does the arrow pointing to 'purpose' originate from the left or right 'conjunction' node?",
            "reference_answer": "Right"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The arrow pointing to 'purpose' originates from the right 'conjunction' node.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Network underlying (12)",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Network underlying (12)",
            "categories": "nan",
            "figure_id": "C00-2088.pdf-Figure6",
            "image_path": "C00-2088.pdf-Figure6.png",
            "instance_id": "447fbaca5d257027edad210c3ffb5922",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the  parent node of the node labeled 'fire_fighting'?",
            "reference_answer": "purpose"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The parent node of the node labeled 'fire_fighting' is 'purpose'.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Network underlying (12)",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Network underlying (12)",
            "categories": "nan",
            "figure_id": "C00-2088.pdf-Figure6",
            "image_path": "C00-2088.pdf-Figure6.png",
            "instance_id": "a5ad107be0c60e79a4e3cc2ee7170f16",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is there a direct arrow connecting the node labeled 'purpose' to the node labeled 'fitted_with'?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, there is no direct arrow connecting the node labeled 'purpose' to the node labeled 'fitted_with'.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Network underlying (12)",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Network underlying (12)",
            "categories": "nan",
            "figure_id": "C00-2088.pdf-Figure6",
            "image_path": "C00-2088.pdf-Figure6.png",
            "instance_id": "e26f16352d18abf66197a479a8294512",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the node labeled 'solid bulk carrier' a parent node of the node 'fitted_with'?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No. The node labeled 'solid bulk carrier' is not a parent node of the node 'fitted_with'; rather, 'fitted_with' is a child node of the 'conjunction' that also connects to 'solid bulk carrier'.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "fitted_with and purpose"
                    },
                    {
                        "B": "fitted_with and conjunction"
                    },
                    {
                        "C": "purpose and states"
                    },
                    {
                        "D": "fitted_with and states"
                    }
                ],
                "caption": "Figure 6: Network underlying (12)",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Network underlying (12)",
            "categories": "nan",
            "figure_id": "C00-2088.pdf-Figure6",
            "image_path": "C00-2088.pdf-Figure6.png",
            "instance_id": "556c8b108feb0ed868df4632b1efd66a",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What are the nodes that the node labeled 'conjunction' on the top of the figure points to?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "fitted_with"
                    },
                    {
                        "B": "bilge pump"
                    },
                    {
                        "C": "states"
                    },
                    {
                        "D": "fire_fighting"
                    }
                ],
                "caption": "Figure 6: Network underlying (12)",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Network underlying (12)",
            "categories": "nan",
            "figure_id": "C00-2088.pdf-Figure6",
            "image_path": "C00-2088.pdf-Figure6.png",
            "instance_id": "9f720a12fff9cbbc49b10e59484f497e",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following are direct descendants of 'purpose'?",
            "reference_answer": "B,D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Network underlying (12)",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Network underlying (12)",
            "categories": "nan",
            "figure_id": "C00-2088.pdf-Figure6",
            "image_path": "C00-2088.pdf-Figure6.png",
            "instance_id": "14b2877a9b7d6436f87bb0601bbf67be",
            "qa_pair_type": "unanswerable",
            "question": "What is the exact semantic relationship between the concepts 'fitted_with', 'bilge pump', 'solid bulk carrier' and 'fire fighting' in the network shown in Figure 6?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 9: The three elementary trees for ditransitive constructions: (a) double object; (b)dative complement (low attachment); dative complement (high attachment)",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: The three elementary trees for ditransitive constructions: (a) double object; (b)dative complement (low attachment); dative complement (high attachment)",
            "categories": "nan",
            "figure_id": "W12-4626.pdf-Figure9",
            "image_path": "W12-4626.pdf-Figure9.png",
            "instance_id": "a3649241d0f486cc1c90096e604e49ae",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "Which node is directly below the node labeled 'V' in the figure labeled '(c)'?",
            "reference_answer": "gave"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The node directly below the node labeled 'V' in the figure labeled '(c)' is 'DP'.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 9: The three elementary trees for ditransitive constructions: (a) double object; (b)dative complement (low attachment); dative complement (high attachment)",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: The three elementary trees for ditransitive constructions: (a) double object; (b)dative complement (low attachment); dative complement (high attachment)",
            "categories": "nan",
            "figure_id": "W12-4626.pdf-Figure9",
            "image_path": "W12-4626.pdf-Figure9.png",
            "instance_id": "5d3b8d060acce3684524ba0aec28ba74",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the root node of the graph (b)?",
            "reference_answer": "TP"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The root node of graph (b) is \"TP\".",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 9: The three elementary trees for ditransitive constructions: (a) double object; (b)dative complement (low attachment); dative complement (high attachment)",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: The three elementary trees for ditransitive constructions: (a) double object; (b)dative complement (low attachment); dative complement (high attachment)",
            "categories": "nan",
            "figure_id": "W12-4626.pdf-Figure9",
            "image_path": "W12-4626.pdf-Figure9.png",
            "instance_id": "fa6d388ed652531ba867b78a92ec3de5",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does tree (a) have 3 branches directly extending from the root node?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 9: The three elementary trees for ditransitive constructions: (a) double object; (b)dative complement (low attachment); dative complement (high attachment)",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: The three elementary trees for ditransitive constructions: (a) double object; (b)dative complement (low attachment); dative complement (high attachment)",
            "categories": "nan",
            "figure_id": "W12-4626.pdf-Figure9",
            "image_path": "W12-4626.pdf-Figure9.png",
            "instance_id": "9b31d8cee8b227bd161c5d390b6fa711",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the \"P\" node in tree (b) have any children?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the \"P\" node in tree (b) has one child, which is \"DP\".",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "(a)"
                    },
                    {
                        "B": "(b)"
                    },
                    {
                        "C": "(c)"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 9: The three elementary trees for ditransitive constructions: (a) double object; (b)dative complement (low attachment); dative complement (high attachment)",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: The three elementary trees for ditransitive constructions: (a) double object; (b)dative complement (low attachment); dative complement (high attachment)",
            "categories": "nan",
            "figure_id": "W12-4626.pdf-Figure9",
            "image_path": "W12-4626.pdf-Figure9.png",
            "instance_id": "e5a355ffb5f36cc5d59ed359872a8d47",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which tree diagram has the word 'to' directly below the node 'P'?",
            "reference_answer": "B,C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "'V' is a child of 'VP'"
                    },
                    {
                        "B": "'V' is the parent of 'VP'"
                    },
                    {
                        "C": "'V' and 'VP' are on the same level"
                    },
                    {
                        "D": "'V' has no connection to 'VP'"
                    }
                ],
                "caption": "Figure 9: The three elementary trees for ditransitive constructions: (a) double object; (b)dative complement (low attachment); dative complement (high attachment)",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: The three elementary trees for ditransitive constructions: (a) double object; (b)dative complement (low attachment); dative complement (high attachment)",
            "categories": "nan",
            "figure_id": "W12-4626.pdf-Figure9",
            "image_path": "W12-4626.pdf-Figure9.png",
            "instance_id": "3937621960f6b098efd3fe53307835b0",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the relationship between 'V' and 'VP' in tree (b)?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 9: The three elementary trees for ditransitive constructions: (a) double object; (b)dative complement (low attachment); dative complement (high attachment)",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: The three elementary trees for ditransitive constructions: (a) double object; (b)dative complement (low attachment); dative complement (high attachment)",
            "categories": "nan",
            "figure_id": "W12-4626.pdf-Figure9",
            "image_path": "W12-4626.pdf-Figure9.png",
            "instance_id": "816ca9d4039443f798fc0ea997ae457e",
            "qa_pair_type": "unanswerable",
            "question": "What methodology was used to gather the data for the study?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: A high-level view of our multi-task learning approach for dialogue coherence modeling.",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: A high-level view of our multi-task learning approach for dialogue coherence modeling.",
            "categories": "nan",
            "figure_id": "2020.acl-main.133.pdf-Figure1",
            "image_path": "2020.acl-main.133.pdf-Figure1.png",
            "instance_id": "6a88ffeb409caf5509a5ae95499cd9a2",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the node located below the 'DA labels' node?",
            "reference_answer": "DiCoh model"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The node located below the 'DA labels' node is the 'shared utterance encoder' node.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: A high-level view of our multi-task learning approach for dialogue coherence modeling.",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: A high-level view of our multi-task learning approach for dialogue coherence modeling.",
            "categories": "nan",
            "figure_id": "2020.acl-main.133.pdf-Figure1",
            "image_path": "2020.acl-main.133.pdf-Figure1.png",
            "instance_id": "6671792028517335e3dfeb99f3685323",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the name of the model that outputs dialogue coherence scores?",
            "reference_answer": "DiCoh model"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The model that outputs dialogue coherence scores is called the DiCoh model.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: A high-level view of our multi-task learning approach for dialogue coherence modeling.",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: A high-level view of our multi-task learning approach for dialogue coherence modeling.",
            "categories": "nan",
            "figure_id": "2020.acl-main.133.pdf-Figure1",
            "image_path": "2020.acl-main.133.pdf-Figure1.png",
            "instance_id": "2c31bff58d12dda81b52a1369e15eda5",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the 'shared utterance encoder' box point upwards to the 'DA labels' box?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, the 'shared utterance encoder' box does not point upwards to the 'DA labels' box.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: A high-level view of our multi-task learning approach for dialogue coherence modeling.",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: A high-level view of our multi-task learning approach for dialogue coherence modeling.",
            "categories": "nan",
            "figure_id": "2020.acl-main.133.pdf-Figure1",
            "image_path": "2020.acl-main.133.pdf-Figure1.png",
            "instance_id": "7ec24ca7d6a7ae41ccea4c75ee628c5b",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the approach involve a shared utterance encoder?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "DiCoh model"
                    },
                    {
                        "B": "DAP model"
                    },
                    {
                        "C": "shared utterance encoder"
                    },
                    {
                        "D": "coherence score"
                    }
                ],
                "caption": "Figure 1: A high-level view of our multi-task learning approach for dialogue coherence modeling.",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: A high-level view of our multi-task learning approach for dialogue coherence modeling.",
            "categories": "nan",
            "figure_id": "2020.acl-main.133.pdf-Figure1",
            "image_path": "2020.acl-main.133.pdf-Figure1.png",
            "instance_id": "09504f78f40230c7dfb87a0da7dd6fbc",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following node are shown within a box?",
            "reference_answer": "A,B,C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "DiCoh model"
                    },
                    {
                        "B": "Shared utterance encoder"
                    },
                    {
                        "C": "DAP model"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 1: A high-level view of our multi-task learning approach for dialogue coherence modeling.",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: A high-level view of our multi-task learning approach for dialogue coherence modeling.",
            "categories": "nan",
            "figure_id": "2020.acl-main.133.pdf-Figure1",
            "image_path": "2020.acl-main.133.pdf-Figure1.png",
            "instance_id": "89099685fe845b8c783f34a25e35837a",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following are part of the multi-task learning approach shown in the image?",
            "reference_answer": "A,B,C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ABCD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: A high-level view of our multi-task learning approach for dialogue coherence modeling.",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: A high-level view of our multi-task learning approach for dialogue coherence modeling.",
            "categories": "nan",
            "figure_id": "2020.acl-main.133.pdf-Figure1",
            "image_path": "2020.acl-main.133.pdf-Figure1.png",
            "instance_id": "533803d3b3525d78569b573d14558e60",
            "qa_pair_type": "unanswerable",
            "question": "What specific algorithms are used for the DiCoh and DAP models in Figure 1?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: From left to right, LDA downsampled representation of BERT on Frames (Goal oriented), MultiWOZ (Goal oriented), PersonaChat (chit-chat) and DailyDialog (chit-chat)",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: From left to right, LDA downsampled representation of BERT on Frames (Goal oriented), MultiWOZ (Goal oriented), PersonaChat (chit-chat) and DailyDialog (chit-chat)",
            "categories": "nan",
            "figure_id": "2020.acl-main.220.pdf-Figure3",
            "image_path": "2020.acl-main.220.pdf-Figure3.png",
            "instance_id": "740d1b2cc5e0650ab4d00b5b797669b7",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "How many distinct colors are visible in each scatter plot?",
            "reference_answer": "4"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: From left to right, LDA downsampled representation of BERT on Frames (Goal oriented), MultiWOZ (Goal oriented), PersonaChat (chit-chat) and DailyDialog (chit-chat)",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: From left to right, LDA downsampled representation of BERT on Frames (Goal oriented), MultiWOZ (Goal oriented), PersonaChat (chit-chat) and DailyDialog (chit-chat)",
            "categories": "nan",
            "figure_id": "2020.acl-main.220.pdf-Figure3",
            "image_path": "2020.acl-main.220.pdf-Figure3.png",
            "instance_id": "06ec1c19b3ea061c435248114a7b4269",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the highest y-axis value shown in all the graphs?",
            "reference_answer": "4"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: From left to right, LDA downsampled representation of BERT on Frames (Goal oriented), MultiWOZ (Goal oriented), PersonaChat (chit-chat) and DailyDialog (chit-chat)",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: From left to right, LDA downsampled representation of BERT on Frames (Goal oriented), MultiWOZ (Goal oriented), PersonaChat (chit-chat) and DailyDialog (chit-chat)",
            "categories": "nan",
            "figure_id": "2020.acl-main.220.pdf-Figure3",
            "image_path": "2020.acl-main.220.pdf-Figure3.png",
            "instance_id": "58441089425fb00d3538c8d3555897cb",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Are the dots in the second plot from the left clustered more tightly together than the dots in the fourth plot from the left?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: From left to right, LDA downsampled representation of BERT on Frames (Goal oriented), MultiWOZ (Goal oriented), PersonaChat (chit-chat) and DailyDialog (chit-chat)",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: From left to right, LDA downsampled representation of BERT on Frames (Goal oriented), MultiWOZ (Goal oriented), PersonaChat (chit-chat) and DailyDialog (chit-chat)",
            "categories": "nan",
            "figure_id": "2020.acl-main.220.pdf-Figure3",
            "image_path": "2020.acl-main.220.pdf-Figure3.png",
            "instance_id": "5e0ee1fe15bc0abcd1d12126a1acf411",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Do all four scatter plots share the same x-axis range?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Red"
                    },
                    {
                        "B": "Black"
                    },
                    {
                        "C": "Pink"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 3: From left to right, LDA downsampled representation of BERT on Frames (Goal oriented), MultiWOZ (Goal oriented), PersonaChat (chit-chat) and DailyDialog (chit-chat)",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: From left to right, LDA downsampled representation of BERT on Frames (Goal oriented), MultiWOZ (Goal oriented), PersonaChat (chit-chat) and DailyDialog (chit-chat)",
            "categories": "nan",
            "figure_id": "2020.acl-main.220.pdf-Figure3",
            "image_path": "2020.acl-main.220.pdf-Figure3.png",
            "instance_id": "d556a09ae122163d78b31fcf24e3b3af",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following colours are used to display the data points?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "-2"
                    },
                    {
                        "B": "-3"
                    },
                    {
                        "C": "-4"
                    },
                    {
                        "D": "-6"
                    }
                ],
                "caption": "Figure 3: From left to right, LDA downsampled representation of BERT on Frames (Goal oriented), MultiWOZ (Goal oriented), PersonaChat (chit-chat) and DailyDialog (chit-chat)",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: From left to right, LDA downsampled representation of BERT on Frames (Goal oriented), MultiWOZ (Goal oriented), PersonaChat (chit-chat) and DailyDialog (chit-chat)",
            "categories": "nan",
            "figure_id": "2020.acl-main.220.pdf-Figure3",
            "image_path": "2020.acl-main.220.pdf-Figure3.png",
            "instance_id": "e3724d33c31e11aae84b16e28fb604e3",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the minimum value on the x-axis for the plot representing 'Frames'?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: From left to right, LDA downsampled representation of BERT on Frames (Goal oriented), MultiWOZ (Goal oriented), PersonaChat (chit-chat) and DailyDialog (chit-chat)",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: From left to right, LDA downsampled representation of BERT on Frames (Goal oriented), MultiWOZ (Goal oriented), PersonaChat (chit-chat) and DailyDialog (chit-chat)",
            "categories": "nan",
            "figure_id": "2020.acl-main.220.pdf-Figure3",
            "image_path": "2020.acl-main.220.pdf-Figure3.png",
            "instance_id": "ddbdd5b8bbe926ca605cb20e3353a211",
            "qa_pair_type": "unanswerable",
            "question": "What is the average Euclidean distance between the data points represented by the blue dots and the data points represented by the purple dots in the first plot of Figure 3?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Change of the DAT-ACC order when the DAT argument accompanies an adverbial particle. These results indicate that the DAT argument with an adverbial particle (DATadv) is more likely to be placed before the ACC argument. In addition, this trend differs for each particle.",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Change of the DAT-ACC order when the DAT argument accompanies an adverbial particle. These results indicate that the DAT argument with an adverbial particle (DATadv) is more likely to be placed before the ACC argument. In addition, this trend differs for each particle.",
            "categories": "nan",
            "figure_id": "2020.acl-main.47.pdf-Figure6",
            "image_path": "2020.acl-main.47.pdf-Figure6.png",
            "instance_id": "380e801ef3a96b912ad0d767d4a4d427",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "With what colour is 'also' represented in the graph?",
            "reference_answer": "yellow"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "'Also' is represented by the yellow triangle in the graph.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Change of the DAT-ACC order when the DAT argument accompanies an adverbial particle. These results indicate that the DAT argument with an adverbial particle (DATadv) is more likely to be placed before the ACC argument. In addition, this trend differs for each particle.",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Change of the DAT-ACC order when the DAT argument accompanies an adverbial particle. These results indicate that the DAT argument with an adverbial particle (DATadv) is more likely to be placed before the ACC argument. In addition, this trend differs for each particle.",
            "categories": "nan",
            "figure_id": "2020.acl-main.47.pdf-Figure6",
            "image_path": "2020.acl-main.47.pdf-Figure6.png",
            "instance_id": "6cbb6a045aff979b01e55bada75eded2",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "Which two models are used in the experiment?",
            "reference_answer": "CLM and SLM"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The two models used in the experiment are CLM and SLM.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Change of the DAT-ACC order when the DAT argument accompanies an adverbial particle. These results indicate that the DAT argument with an adverbial particle (DATadv) is more likely to be placed before the ACC argument. In addition, this trend differs for each particle.",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Change of the DAT-ACC order when the DAT argument accompanies an adverbial particle. These results indicate that the DAT argument with an adverbial particle (DATadv) is more likely to be placed before the ACC argument. In addition, this trend differs for each particle.",
            "categories": "nan",
            "figure_id": "2020.acl-main.47.pdf-Figure6",
            "image_path": "2020.acl-main.47.pdf-Figure6.png",
            "instance_id": "2b4e2d32817e2a14d9daea95acda5c81",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is there a noticeable difference in the density of yellow triangles above and below the diagonal dashed line?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Change of the DAT-ACC order when the DAT argument accompanies an adverbial particle. These results indicate that the DAT argument with an adverbial particle (DATadv) is more likely to be placed before the ACC argument. In addition, this trend differs for each particle.",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Change of the DAT-ACC order when the DAT argument accompanies an adverbial particle. These results indicate that the DAT argument with an adverbial particle (DATadv) is more likely to be placed before the ACC argument. In addition, this trend differs for each particle.",
            "categories": "nan",
            "figure_id": "2020.acl-main.47.pdf-Figure6",
            "image_path": "2020.acl-main.47.pdf-Figure6.png",
            "instance_id": "51bf4258bcf0fc85387b20f41569cafd",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Are 4 different particle types presented in the graph?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The graph presents four different particle types represented by different shapes and colors.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "square"
                    },
                    {
                        "B": "circle"
                    },
                    {
                        "C": "diamond"
                    },
                    {
                        "D": "star"
                    }
                ],
                "caption": "Figure 6: Change of the DAT-ACC order when the DAT argument accompanies an adverbial particle. These results indicate that the DAT argument with an adverbial particle (DATadv) is more likely to be placed before the ACC argument. In addition, this trend differs for each particle.",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Change of the DAT-ACC order when the DAT argument accompanies an adverbial particle. These results indicate that the DAT argument with an adverbial particle (DATadv) is more likely to be placed before the ACC argument. In addition, this trend differs for each particle.",
            "categories": "nan",
            "figure_id": "2020.acl-main.47.pdf-Figure6",
            "image_path": "2020.acl-main.47.pdf-Figure6.png",
            "instance_id": "8112e17d91fa0895a7b84315ec3f1277",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "With what symbol is particle type 'emphasis' respresented?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The DAT-ACC rate is extremely low"
                    },
                    {
                        "B": "The DAT argument is positioned very close to the verb"
                    },
                    {
                        "C": "The DAT argument moved toward the beginning of the sentence"
                    },
                    {
                        "D": "The DAT-ACC rate is extremely high"
                    }
                ],
                "caption": "Figure 6: Change of the DAT-ACC order when the DAT argument accompanies an adverbial particle. These results indicate that the DAT argument with an adverbial particle (DATadv) is more likely to be placed before the ACC argument. In addition, this trend differs for each particle.",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Change of the DAT-ACC order when the DAT argument accompanies an adverbial particle. These results indicate that the DAT argument with an adverbial particle (DATadv) is more likely to be placed before the ACC argument. In addition, this trend differs for each particle.",
            "categories": "nan",
            "figure_id": "2020.acl-main.47.pdf-Figure6",
            "image_path": "2020.acl-main.47.pdf-Figure6.png",
            "instance_id": "6e2beca97317a60fa3a06674c97f021c",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "If a data point is close to the origin on the graph, what does that indicate?",
            "reference_answer": "A,B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Change of the DAT-ACC order when the DAT argument accompanies an adverbial particle. These results indicate that the DAT argument with an adverbial particle (DATadv) is more likely to be placed before the ACC argument. In addition, this trend differs for each particle.",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Change of the DAT-ACC order when the DAT argument accompanies an adverbial particle. These results indicate that the DAT argument with an adverbial particle (DATadv) is more likely to be placed before the ACC argument. In addition, this trend differs for each particle.",
            "categories": "nan",
            "figure_id": "2020.acl-main.47.pdf-Figure6",
            "image_path": "2020.acl-main.47.pdf-Figure6.png",
            "instance_id": "b5f7bf2a0f1035e33554197ce8b97366",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific effect of the adverbial particle '\u3082' on the DAT-ACC order compared to the other particles?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: The degree distribution of the network. The degree distribution of the network fits the power law distribution. The vertices with 0 degree are omitted. And 20% of the tweets are retweeted or replied for 80% times.",
                "compound": false,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The degree distribution of the network. The degree distribution of the network fits the power law distribution. The vertices with 0 degree are omitted. And 20% of the tweets are retweeted or replied for 80% times.",
            "categories": "['cs.SI cs.CL']",
            "figure_id": "1805.10856v2-Figure4-1",
            "image_path": "1805.10856v2-Figure4-1.png",
            "instance_id": "c7f855ad400decbc355bfb83cb7fb441",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate degree value of the highest black dot shown in the graph?",
            "reference_answer": "70"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: The degree distribution of the network. The degree distribution of the network fits the power law distribution. The vertices with 0 degree are omitted. And 20% of the tweets are retweeted or replied for 80% times.",
                "compound": false,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The degree distribution of the network. The degree distribution of the network fits the power law distribution. The vertices with 0 degree are omitted. And 20% of the tweets are retweeted or replied for 80% times.",
            "categories": "['cs.SI cs.CL']",
            "figure_id": "1805.10856v2-Figure4-1",
            "image_path": "1805.10856v2-Figure4-1.png",
            "instance_id": "cab3f564632b8aa7ea0dd128573f8c6d",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What does the x-axis represent?",
            "reference_answer": "Rank"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The x-axis represents \"rank.\"",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: The degree distribution of the network. The degree distribution of the network fits the power law distribution. The vertices with 0 degree are omitted. And 20% of the tweets are retweeted or replied for 80% times.",
                "compound": false,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The degree distribution of the network. The degree distribution of the network fits the power law distribution. The vertices with 0 degree are omitted. And 20% of the tweets are retweeted or replied for 80% times.",
            "categories": "['cs.SI cs.CL']",
            "figure_id": "1805.10856v2-Figure4-1",
            "image_path": "1805.10856v2-Figure4-1.png",
            "instance_id": "5cd6610807cee0e9fc0140852175133d",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Are the data points on the graph primarily clustered towards the bottom left of the graph?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: The degree distribution of the network. The degree distribution of the network fits the power law distribution. The vertices with 0 degree are omitted. And 20% of the tweets are retweeted or replied for 80% times.",
                "compound": false,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The degree distribution of the network. The degree distribution of the network fits the power law distribution. The vertices with 0 degree are omitted. And 20% of the tweets are retweeted or replied for 80% times.",
            "categories": "['cs.SI cs.CL']",
            "figure_id": "1805.10856v2-Figure4-1",
            "image_path": "1805.10856v2-Figure4-1.png",
            "instance_id": "2c1284ab327152c61ce4d05b5a89abd9",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the highest degree value shown on the y-axis 100?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "2"
                    },
                    {
                        "B": "10"
                    },
                    {
                        "C": "100"
                    },
                    {
                        "D": "50"
                    }
                ],
                "caption": "Figure 4: The degree distribution of the network. The degree distribution of the network fits the power law distribution. The vertices with 0 degree are omitted. And 20% of the tweets are retweeted or replied for 80% times.",
                "compound": false,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The degree distribution of the network. The degree distribution of the network fits the power law distribution. The vertices with 0 degree are omitted. And 20% of the tweets are retweeted or replied for 80% times.",
            "categories": "['cs.SI cs.CL']",
            "figure_id": "1805.10856v2-Figure4-1",
            "image_path": "1805.10856v2-Figure4-1.png",
            "instance_id": "9f46577c629aa0f10de30d59b02449d2",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What is the approximate degree value of the lowest black dot shown in the graph?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "100,000"
                    },
                    {
                        "B": "10,000"
                    },
                    {
                        "C": "1,000"
                    },
                    {
                        "D": "100"
                    }
                ],
                "caption": "Figure 4: The degree distribution of the network. The degree distribution of the network fits the power law distribution. The vertices with 0 degree are omitted. And 20% of the tweets are retweeted or replied for 80% times.",
                "compound": false,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The degree distribution of the network. The degree distribution of the network fits the power law distribution. The vertices with 0 degree are omitted. And 20% of the tweets are retweeted or replied for 80% times.",
            "categories": "['cs.SI cs.CL']",
            "figure_id": "1805.10856v2-Figure4-1",
            "image_path": "1805.10856v2-Figure4-1.png",
            "instance_id": "9f1f8c33832a15003276bcacfdecc386",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the value of the highest point on the x-axis?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: The degree distribution of the network. The degree distribution of the network fits the power law distribution. The vertices with 0 degree are omitted. And 20% of the tweets are retweeted or replied for 80% times.",
                "compound": false,
                "figure_type": "scatter plot",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The degree distribution of the network. The degree distribution of the network fits the power law distribution. The vertices with 0 degree are omitted. And 20% of the tweets are retweeted or replied for 80% times.",
            "categories": "['cs.SI cs.CL']",
            "figure_id": "1805.10856v2-Figure4-1",
            "image_path": "1805.10856v2-Figure4-1.png",
            "instance_id": "cbdcddbf2f32836f60c51833fe60c4e3",
            "qa_pair_type": "unanswerable",
            "question": "What is the average degree of the network?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Correlation of Wordfish results using the entire text (5th legislation) with European Integration positioning.",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Correlation of Wordfish results using the entire text (5th legislation) with European Integration positioning.",
            "categories": "['cs.CL']",
            "figure_id": "1904.06217v2-Figure1-1",
            "image_path": "1904.06217v2-Figure1-1.png",
            "instance_id": "8765ead07ff4290dc77e9b8a5e9e874e",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate European Integration positioning of the blue dot in the FR plot that is furthest to the right?",
            "reference_answer": "0.8"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Correlation of Wordfish results using the entire text (5th legislation) with European Integration positioning.",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Correlation of Wordfish results using the entire text (5th legislation) with European Integration positioning.",
            "categories": "['cs.CL']",
            "figure_id": "1904.06217v2-Figure1-1",
            "image_path": "1904.06217v2-Figure1-1.png",
            "instance_id": "2dc57e4992e9ea8552ca15868a154772",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "How many languages are included in the analysis?",
            "reference_answer": "5"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Correlation of Wordfish results using the entire text (5th legislation) with European Integration positioning.",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Correlation of Wordfish results using the entire text (5th legislation) with European Integration positioning.",
            "categories": "['cs.CL']",
            "figure_id": "1904.06217v2-Figure1-1",
            "image_path": "1904.06217v2-Figure1-1.png",
            "instance_id": "f609e4aed479505b6ea3eb6c48059ac7",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the orange line in the 'IT' subplot  positioned below the orange line in the 'EN' subplot?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Correlation of Wordfish results using the entire text (5th legislation) with European Integration positioning.",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Correlation of Wordfish results using the entire text (5th legislation) with European Integration positioning.",
            "categories": "['cs.CL']",
            "figure_id": "1904.06217v2-Figure1-1",
            "image_path": "1904.06217v2-Figure1-1.png",
            "instance_id": "5830dd6ed49a3dcd5daf36c047dfbb96",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is one of the languages being analysed Portuguese?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "red"
                    },
                    {
                        "B": "yellow"
                    },
                    {
                        "C": "blue"
                    },
                    {
                        "D": "green"
                    }
                ],
                "caption": "Figure 1: Correlation of Wordfish results using the entire text (5th legislation) with European Integration positioning.",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Correlation of Wordfish results using the entire text (5th legislation) with European Integration positioning.",
            "categories": "['cs.CL']",
            "figure_id": "1904.06217v2-Figure1-1",
            "image_path": "1904.06217v2-Figure1-1.png",
            "instance_id": "dd92c50a64caa37714b2241017e78f6b",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What is the colour of the data points represented in the graph?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "French"
                    },
                    {
                        "B": "English"
                    },
                    {
                        "C": "Spanish"
                    },
                    {
                        "D": "German"
                    }
                ],
                "caption": "Figure 1: Correlation of Wordfish results using the entire text (5th legislation) with European Integration positioning.",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Correlation of Wordfish results using the entire text (5th legislation) with European Integration positioning.",
            "categories": "['cs.CL']",
            "figure_id": "1904.06217v2-Figure1-1",
            "image_path": "1904.06217v2-Figure1-1.png",
            "instance_id": "6e6f07a133e152db993d9773b21062f0",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following languages are depicted in the figure?",
            "reference_answer": "A,B,C,D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ABCD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Correlation of Wordfish results using the entire text (5th legislation) with European Integration positioning.",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Correlation of Wordfish results using the entire text (5th legislation) with European Integration positioning.",
            "categories": "['cs.CL']",
            "figure_id": "1904.06217v2-Figure1-1",
            "image_path": "1904.06217v2-Figure1-1.png",
            "instance_id": "58de5328f80ada4de5169d2c897ee9ad",
            "qa_pair_type": "unanswerable",
            "question": "What is the correlation coefficient for the Wordfish results for each country?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Sentiment distribution over the sarcastic tweets.",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Sentiment distribution over the sarcastic tweets.",
            "categories": "nan",
            "figure_id": "2020.osact-1.5.pdf-Figure2",
            "image_path": "2020.osact-1.5.pdf-Figure2.png",
            "instance_id": "a6d69219877a382b840eaba73d7b1aff",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What percentage of the red segment representing negatively sarcastic tweets?",
            "reference_answer": "88%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Sentiment distribution over the sarcastic tweets.",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Sentiment distribution over the sarcastic tweets.",
            "categories": "nan",
            "figure_id": "2020.osact-1.5.pdf-Figure2",
            "image_path": "2020.osact-1.5.pdf-Figure2.png",
            "instance_id": "09dab5a715034cebb2a62f0f1c2a75c9",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What percentage of sarcastic tweets are positive?",
            "reference_answer": "52,3%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Sentiment distribution over the sarcastic tweets.",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Sentiment distribution over the sarcastic tweets.",
            "categories": "nan",
            "figure_id": "2020.osact-1.5.pdf-Figure2",
            "image_path": "2020.osact-1.5.pdf-Figure2.png",
            "instance_id": "6a9fbbad394ec0a76cdbfbedbad5d895",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the red portion of the pie chart larger than the gray portion?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the red portion of the pie chart is larger than the gray portion.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Sentiment distribution over the sarcastic tweets.",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Sentiment distribution over the sarcastic tweets.",
            "categories": "nan",
            "figure_id": "2020.osact-1.5.pdf-Figure2",
            "image_path": "2020.osact-1.5.pdf-Figure2.png",
            "instance_id": "a9871876ebe878928365773de5dc17aa",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the percentage of negative sentiment higher than the combined percentage of positive and neutral sentiment?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The percentage of negative sentiment (88%) is higher than the combined percentage of positive (3%) and neutral (9%) sentiment, which totals 12%.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Red"
                    },
                    {
                        "B": "Green"
                    },
                    {
                        "C": "Gray"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 2: Sentiment distribution over the sarcastic tweets.",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Sentiment distribution over the sarcastic tweets.",
            "categories": "nan",
            "figure_id": "2020.osact-1.5.pdf-Figure2",
            "image_path": "2020.osact-1.5.pdf-Figure2.png",
            "instance_id": "3833fc2eadbb7d9fdc072b039f3ec7e7",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following colors represents the sentiment with the highest percentage?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Positive"
                    },
                    {
                        "B": "Neutral"
                    },
                    {
                        "C": "Negative"
                    },
                    {
                        "D": "All of the above"
                    }
                ],
                "caption": "Figure 2: Sentiment distribution over the sarcastic tweets.",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Sentiment distribution over the sarcastic tweets.",
            "categories": "nan",
            "figure_id": "2020.osact-1.5.pdf-Figure2",
            "image_path": "2020.osact-1.5.pdf-Figure2.png",
            "instance_id": "73d2b157374e86b7a6aa2201069658db",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following sentiments were expressed in the sarcastic tweets?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Sentiment distribution over the sarcastic tweets.",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Sentiment distribution over the sarcastic tweets.",
            "categories": "nan",
            "figure_id": "2020.osact-1.5.pdf-Figure2",
            "image_path": "2020.osact-1.5.pdf-Figure2.png",
            "instance_id": "04933d8693f427f05da7a72bdb55dd6e",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific methodology used to identify and classify the sarcastic tweets?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2. A typical LVCSR system",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2. A typical LVCSR system",
            "categories": "nan",
            "figure_id": "O06-2002.pdf-Figure2",
            "image_path": "O06-2002.pdf-Figure2.png",
            "instance_id": "450ea67458928b0a6b12705a23f15a82",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the name of the knowledge source left of 'Acoustic model'?",
            "reference_answer": "Pronunciation Lexicon"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The name of the knowledge source left of 'Acoustic model' is 'Pronunciation Lexicon P(B|W)'.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2. A typical LVCSR system",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2. A typical LVCSR system",
            "categories": "nan",
            "figure_id": "O06-2002.pdf-Figure2",
            "image_path": "O06-2002.pdf-Figure2.png",
            "instance_id": "769a128534f461ba3ae2c7728b05323b",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "How many knowledge sources does the LVCSR system utilize?",
            "reference_answer": "3"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The LVCSR system utilizes three knowledge sources.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2. A typical LVCSR system",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2. A typical LVCSR system",
            "categories": "nan",
            "figure_id": "O06-2002.pdf-Figure2",
            "image_path": "O06-2002.pdf-Figure2.png",
            "instance_id": "fa136b42cb8d79ecba56c859a14d3d58",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the Acoustic Model connected to the Decoder with an arrow pointing towards the Decoder?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the Acoustic Model is connected to the Decoder with an arrow pointing towards the Decoder.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2. A typical LVCSR system",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2. A typical LVCSR system",
            "categories": "nan",
            "figure_id": "O06-2002.pdf-Figure2",
            "image_path": "O06-2002.pdf-Figure2.png",
            "instance_id": "08e563cc0d14ecab622cc5137db37bf9",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the LVCSR system recognize word sequences?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the LVCSR (Large Vocabulary Continuous Speech Recognition) system is designed to recognize word sequences. The output of the decoder in the diagram is the recognized word sequence.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Square"
                    },
                    {
                        "B": "Rectangle"
                    },
                    {
                        "C": "Hexagon"
                    },
                    {
                        "D": "Circle"
                    }
                ],
                "caption": "Figure 2. A typical LVCSR system",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2. A typical LVCSR system",
            "categories": "nan",
            "figure_id": "O06-2002.pdf-Figure2",
            "image_path": "O06-2002.pdf-Figure2.png",
            "instance_id": "eef475b7dda8bd7b481e9e7ed24d65ce",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What shape is used to represent the 'Decoder'?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Language Model"
                    },
                    {
                        "B": "Pronunciation Lexicon"
                    },
                    {
                        "C": "Acoustic Model"
                    },
                    {
                        "D": "Front-End Processing"
                    }
                ],
                "caption": "Figure 2. A typical LVCSR system",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2. A typical LVCSR system",
            "categories": "nan",
            "figure_id": "O06-2002.pdf-Figure2",
            "image_path": "O06-2002.pdf-Figure2.png",
            "instance_id": "157c9707c4941e1e0140de20b522931c",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following are considered knowledge sources in an LVCSR system?",
            "reference_answer": "['A', 'B', 'C']"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ABC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2. A typical LVCSR system",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2. A typical LVCSR system",
            "categories": "nan",
            "figure_id": "O06-2002.pdf-Figure2",
            "image_path": "O06-2002.pdf-Figure2.png",
            "instance_id": "4ecf31cd63d2400d143b300666983f43",
            "qa_pair_type": "unanswerable",
            "question": "What is the training dataset used for the acoustic model in this LVCSR system?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8: Letter-value plot (Hofmann et al., 2017) considering only the oldest citation per paper among all papers published in a given year. The solid black lines denote the median, boxes correspond to quantiles.",
                "compound": false,
                "figure_type": "box plot",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: Letter-value plot (Hofmann et al., 2017) considering only the oldest citation per paper among all papers published in a given year. The solid black lines denote the median, boxes correspond to quantiles.",
            "categories": "nan",
            "figure_id": "2020.acl-main.699.pdf-Figure8",
            "image_path": "2020.acl-main.699.pdf-Figure8.png",
            "instance_id": "359fea3fadeb981bafc3366e0c12033a",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate median age of citations in 2015, as indicated by the horizontal black line within the corresponding box plot?",
            "reference_answer": "24"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8: Letter-value plot (Hofmann et al., 2017) considering only the oldest citation per paper among all papers published in a given year. The solid black lines denote the median, boxes correspond to quantiles.",
                "compound": false,
                "figure_type": "box plot",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: Letter-value plot (Hofmann et al., 2017) considering only the oldest citation per paper among all papers published in a given year. The solid black lines denote the median, boxes correspond to quantiles.",
            "categories": "nan",
            "figure_id": "2020.acl-main.699.pdf-Figure8",
            "image_path": "2020.acl-main.699.pdf-Figure8.png",
            "instance_id": "86291d5b31b21094201ea9bf08d9d5fd",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the time period covered by the data presented in Figure 8?",
            "reference_answer": "2010-2019"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The time period covered by the data presented in Figure 8 is from 2010 to 2019.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8: Letter-value plot (Hofmann et al., 2017) considering only the oldest citation per paper among all papers published in a given year. The solid black lines denote the median, boxes correspond to quantiles.",
                "compound": false,
                "figure_type": "box plot",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: Letter-value plot (Hofmann et al., 2017) considering only the oldest citation per paper among all papers published in a given year. The solid black lines denote the median, boxes correspond to quantiles.",
            "categories": "nan",
            "figure_id": "2020.acl-main.699.pdf-Figure8",
            "image_path": "2020.acl-main.699.pdf-Figure8.png",
            "instance_id": "0bfaa230cb4f93d72cf9f9b7cfea8e8d",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Are all the boxes representing quantiles in the figure colored in shades of blue?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. All the boxes representing quantiles in the figure are colored in shades of blue.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8: Letter-value plot (Hofmann et al., 2017) considering only the oldest citation per paper among all papers published in a given year. The solid black lines denote the median, boxes correspond to quantiles.",
                "compound": false,
                "figure_type": "box plot",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: Letter-value plot (Hofmann et al., 2017) considering only the oldest citation per paper among all papers published in a given year. The solid black lines denote the median, boxes correspond to quantiles.",
            "categories": "nan",
            "figure_id": "2020.acl-main.699.pdf-Figure8",
            "image_path": "2020.acl-main.699.pdf-Figure8.png",
            "instance_id": "70c017b414002868d9c05a52f07b6d90",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the median age of citations highest for year 2010?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The median age of citations generally increased from 2010 to 2019."
                    },
                    {
                        "B": "The median age of citations remained relatively constant throughout the years shown."
                    },
                    {
                        "C": "The median age of citations shows a significant downward trend from 2010 to 2019."
                    },
                    {
                        "D": "The median age of citations in 2012 is higher than in 2018."
                    }
                ],
                "caption": "Figure 8: Letter-value plot (Hofmann et al., 2017) considering only the oldest citation per paper among all papers published in a given year. The solid black lines denote the median, boxes correspond to quantiles.",
                "compound": false,
                "figure_type": "box plot",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: Letter-value plot (Hofmann et al., 2017) considering only the oldest citation per paper among all papers published in a given year. The solid black lines denote the median, boxes correspond to quantiles.",
            "categories": "nan",
            "figure_id": "2020.acl-main.699.pdf-Figure8",
            "image_path": "2020.acl-main.699.pdf-Figure8.png",
            "instance_id": "4f5c628ac3e2e44fa8df20842149f832",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Based on Figure 8, which of the following statements about the median age of citations (represented by the horizontal black lines within the blue boxes) are correct?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "2010"
                    },
                    {
                        "B": "2011"
                    },
                    {
                        "C": "2012"
                    },
                    {
                        "D": "2013"
                    }
                ],
                "caption": "Figure 8: Letter-value plot (Hofmann et al., 2017) considering only the oldest citation per paper among all papers published in a given year. The solid black lines denote the median, boxes correspond to quantiles.",
                "compound": false,
                "figure_type": "box plot",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: Letter-value plot (Hofmann et al., 2017) considering only the oldest citation per paper among all papers published in a given year. The solid black lines denote the median, boxes correspond to quantiles.",
            "categories": "nan",
            "figure_id": "2020.acl-main.699.pdf-Figure8",
            "image_path": "2020.acl-main.699.pdf-Figure8.png",
            "instance_id": "a74ee1dc112be7b132e1ac7a03b80c5d",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "For which of the following years is the median age of citations the highest?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8: Letter-value plot (Hofmann et al., 2017) considering only the oldest citation per paper among all papers published in a given year. The solid black lines denote the median, boxes correspond to quantiles.",
                "compound": false,
                "figure_type": "box plot",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: Letter-value plot (Hofmann et al., 2017) considering only the oldest citation per paper among all papers published in a given year. The solid black lines denote the median, boxes correspond to quantiles.",
            "categories": "nan",
            "figure_id": "2020.acl-main.699.pdf-Figure8",
            "image_path": "2020.acl-main.699.pdf-Figure8.png",
            "instance_id": "01ccce1b662b5cf3fe87b08490afb52a",
            "qa_pair_type": "unanswerable",
            "question": "What is the precise number of papers published in 2015 that had an oldest citation age below 10 years?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Context Dependent Additive Recurrent Neural Network. Note that only nCARNN has the previous hidden state hm1 in its gate computation, iCARNN and sCARNN do not.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Context Dependent Additive Recurrent Neural Network. Note that only nCARNN has the previous hidden state hm1 in its gate computation, iCARNN and sCARNN do not.",
            "categories": "nan",
            "figure_id": "N18-1115.pdf-Figure1",
            "image_path": "N18-1115.pdf-Figure1.png",
            "instance_id": "92ce419d7a3d377a4d2005b62bacf53c",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the colour of the circle in the diagram that has an arrow pointing towards it from the box labeled 'h_m'?",
            "reference_answer": "Purple"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The circle in the diagram that has an arrow pointing towards it from the box labeled 'h_m' is blue.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Context Dependent Additive Recurrent Neural Network. Note that only nCARNN has the previous hidden state hm1 in its gate computation, iCARNN and sCARNN do not.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Context Dependent Additive Recurrent Neural Network. Note that only nCARNN has the previous hidden state hm1 in its gate computation, iCARNN and sCARNN do not.",
            "categories": "nan",
            "figure_id": "N18-1115.pdf-Figure1",
            "image_path": "N18-1115.pdf-Figure1.png",
            "instance_id": "aa13d2a6bd480756e58250c58b821ab0",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "How many total gates are involved in computing h_m based on the graph?",
            "reference_answer": "2"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Context Dependent Additive Recurrent Neural Network. Note that only nCARNN has the previous hidden state hm1 in its gate computation, iCARNN and sCARNN do not.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Context Dependent Additive Recurrent Neural Network. Note that only nCARNN has the previous hidden state hm1 in its gate computation, iCARNN and sCARNN do not.",
            "categories": "nan",
            "figure_id": "N18-1115.pdf-Figure1",
            "image_path": "N18-1115.pdf-Figure1.png",
            "instance_id": "ab2ab2fdad400ae1ed5a86557571a956",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the red circle with a diagonal line inside receive an input arrow from a green rectangle?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the red circle with a diagonal line inside does receive an input arrow from the green rectangle.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Context Dependent Additive Recurrent Neural Network. Note that only nCARNN has the previous hidden state hm1 in its gate computation, iCARNN and sCARNN do not.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Context Dependent Additive Recurrent Neural Network. Note that only nCARNN has the previous hidden state hm1 in its gate computation, iCARNN and sCARNN do not.",
            "categories": "nan",
            "figure_id": "N18-1115.pdf-Figure1",
            "image_path": "N18-1115.pdf-Figure1.png",
            "instance_id": "c86b6de60a95e17a9500c26ca1701a67",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is h_m\u22121 used in more than one part of the architecture?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, \\( h_{m-1} \\) is used in more than one part of the architecture.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "purple"
                    },
                    {
                        "B": "red"
                    },
                    {
                        "C": "blue"
                    },
                    {
                        "D": "yellow"
                    }
                ],
                "caption": "Figure 1: Context Dependent Additive Recurrent Neural Network. Note that only nCARNN has the previous hidden state hm1 in its gate computation, iCARNN and sCARNN do not.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Context Dependent Additive Recurrent Neural Network. Note that only nCARNN has the previous hidden state hm1 in its gate computation, iCARNN and sCARNN do not.",
            "categories": "nan",
            "figure_id": "N18-1115.pdf-Figure1",
            "image_path": "N18-1115.pdf-Figure1.png",
            "instance_id": "a5e0039267c39bec00b4f01b14d9df60",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What is the colour of the circle representing the gate in the top side of the graph?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Concatenation"
                    },
                    {
                        "B": "Subtraction"
                    },
                    {
                        "C": "Element-wise multiplication"
                    },
                    {
                        "D": "Element-wise addition"
                    }
                ],
                "caption": "Figure 1: Context Dependent Additive Recurrent Neural Network. Note that only nCARNN has the previous hidden state hm1 in its gate computation, iCARNN and sCARNN do not.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Context Dependent Additive Recurrent Neural Network. Note that only nCARNN has the previous hidden state hm1 in its gate computation, iCARNN and sCARNN do not.",
            "categories": "nan",
            "figure_id": "N18-1115.pdf-Figure1",
            "image_path": "N18-1115.pdf-Figure1.png",
            "instance_id": "49a1e7cdc1ab0a0ede953668c02dba58",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What operation is applied right before producing the output h_m?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "CD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Context Dependent Additive Recurrent Neural Network. Note that only nCARNN has the previous hidden state hm1 in its gate computation, iCARNN and sCARNN do not.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Context Dependent Additive Recurrent Neural Network. Note that only nCARNN has the previous hidden state hm1 in its gate computation, iCARNN and sCARNN do not.",
            "categories": "nan",
            "figure_id": "N18-1115.pdf-Figure1",
            "image_path": "N18-1115.pdf-Figure1.png",
            "instance_id": "d828d1e1f159aa021aa9663de0823641",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific mathematical function used to calculate the g^f_m element in the iCARNN network?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Confusion matrix of trigger classes with abbreviations mentioned in Table 1",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Confusion matrix of trigger classes with abbreviations mentioned in Table 1",
            "categories": "nan",
            "figure_id": "W17-2340.pdf-Figure3",
            "image_path": "W17-2340.pdf-Figure3.png",
            "instance_id": "c4abd28bb58d5adb23281643aa4dd9c5",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the colour of the cell in the 10th row and 20th column?",
            "reference_answer": "purple"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Confusion matrix of trigger classes with abbreviations mentioned in Table 1",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Confusion matrix of trigger classes with abbreviations mentioned in Table 1",
            "categories": "nan",
            "figure_id": "W17-2340.pdf-Figure3",
            "image_path": "W17-2340.pdf-Figure3.png",
            "instance_id": "29d370c63c51d4235a5d4763d7dfaaa6",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the total number of trigger classes represented in the confusion matrix?",
            "reference_answer": "20"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Confusion matrix of trigger classes with abbreviations mentioned in Table 1",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Confusion matrix of trigger classes with abbreviations mentioned in Table 1",
            "categories": "nan",
            "figure_id": "W17-2340.pdf-Figure3",
            "image_path": "W17-2340.pdf-Figure3.png",
            "instance_id": "d5a148a1b64dc151de16037aeda8dceb",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the value on the diagonal of the confusion matrix higher than any other value in the corresponding row?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Confusion matrix of trigger classes with abbreviations mentioned in Table 1",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Confusion matrix of trigger classes with abbreviations mentioned in Table 1",
            "categories": "nan",
            "figure_id": "W17-2340.pdf-Figure3",
            "image_path": "W17-2340.pdf-Figure3.png",
            "instance_id": "a80325fb9fa0525535cb81c567c2d767",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the value of the cell in the row labeled \"GENXP\" and the column labeled \"REG\" bigger than 100?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The value of the cell in the row labeled \"GENXP\" and the column labeled \"REG\" is 109, which is bigger than 100.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "1st"
                    },
                    {
                        "B": "2nd"
                    },
                    {
                        "C": "3rd"
                    },
                    {
                        "D": "Last"
                    }
                ],
                "caption": "Figure 3: Confusion matrix of trigger classes with abbreviations mentioned in Table 1",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Confusion matrix of trigger classes with abbreviations mentioned in Table 1",
            "categories": "nan",
            "figure_id": "W17-2340.pdf-Figure3",
            "image_path": "W17-2340.pdf-Figure3.png",
            "instance_id": "b7275c67295ccfbe7fc3b7842bbe156f",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "In the topmost row what square has the highest value?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "3"
                    },
                    {
                        "B": "5"
                    },
                    {
                        "C": "12"
                    },
                    {
                        "D": "2"
                    }
                ],
                "caption": "Figure 3: Confusion matrix of trigger classes with abbreviations mentioned in Table 1",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Confusion matrix of trigger classes with abbreviations mentioned in Table 1",
            "categories": "nan",
            "figure_id": "W17-2340.pdf-Figure3",
            "image_path": "W17-2340.pdf-Figure3.png",
            "instance_id": "7a6676381e5af23849f998ece5c461fa",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the value of the cell in the row labeled \"LOC\" and the column labeled \"DEV\"?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Confusion matrix of trigger classes with abbreviations mentioned in Table 1",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Confusion matrix of trigger classes with abbreviations mentioned in Table 1",
            "categories": "nan",
            "figure_id": "W17-2340.pdf-Figure3",
            "image_path": "W17-2340.pdf-Figure3.png",
            "instance_id": "348f7eab472a3d57b57289ebc502a9df",
            "qa_pair_type": "unanswerable",
            "question": "Which model was used to generate these results?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Standard backoff path for a 4-gram language model over words (left) and backoff graph for 4-gram over factors (right).",
                "compound": true,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Standard backoff path for a 4-gram language model over words (left) and backoff graph for 4-gram over factors (right).",
            "categories": "nan",
            "figure_id": "C04-1022.pdf-Figure1",
            "image_path": "C04-1022.pdf-Figure1.png",
            "instance_id": "e8921347ace55d989584007478fa0877",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "How many boxes are connected to the bottom box in the right image?",
            "reference_answer": "3"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Standard backoff path for a 4-gram language model over words (left) and backoff graph for 4-gram over factors (right).",
                "compound": true,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Standard backoff path for a 4-gram language model over words (left) and backoff graph for 4-gram over factors (right).",
            "categories": "nan",
            "figure_id": "C04-1022.pdf-Figure1",
            "image_path": "C04-1022.pdf-Figure1.png",
            "instance_id": "96d5b07e7a693e430812a545ba83c5e3",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "How many total nodes are in the factor backoff graph (b)?",
            "reference_answer": "8"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Standard backoff path for a 4-gram language model over words (left) and backoff graph for 4-gram over factors (right).",
                "compound": true,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Standard backoff path for a 4-gram language model over words (left) and backoff graph for 4-gram over factors (right).",
            "categories": "nan",
            "figure_id": "C04-1022.pdf-Figure1",
            "image_path": "C04-1022.pdf-Figure1.png",
            "instance_id": "92617d2175740733e201d3603c9703a6",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the left graph show a strictly linear path?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the left graph shows a strictly linear path.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Standard backoff path for a 4-gram language model over words (left) and backoff graph for 4-gram over factors (right).",
                "compound": true,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Standard backoff path for a 4-gram language model over words (left) and backoff graph for 4-gram over factors (right).",
            "categories": "nan",
            "figure_id": "C04-1022.pdf-Figure1",
            "image_path": "C04-1022.pdf-Figure1.png",
            "instance_id": "6bf7a71037e439d5a3ff7b85a1d00a97",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Are there five nodes connected to node F | F2?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "A word is added to the context"
                    },
                    {
                        "B": "A word is removed from the context"
                    },
                    {
                        "C": "The word W\u209c is replaced"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 1: Standard backoff path for a 4-gram language model over words (left) and backoff graph for 4-gram over factors (right).",
                "compound": true,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Standard backoff path for a 4-gram language model over words (left) and backoff graph for 4-gram over factors (right).",
            "categories": "nan",
            "figure_id": "C04-1022.pdf-Figure1",
            "image_path": "C04-1022.pdf-Figure1.png",
            "instance_id": "736136e9d3f768d3103c4fcd6d9bc371",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What happens at each step as we move downward in diagram (a)?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Factor"
                    },
                    {
                        "B": "Word"
                    },
                    {
                        "C": "Sentence"
                    },
                    {
                        "D": "Graph"
                    }
                ],
                "caption": "Figure 1: Standard backoff path for a 4-gram language model over words (left) and backoff graph for 4-gram over factors (right).",
                "compound": true,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Standard backoff path for a 4-gram language model over words (left) and backoff graph for 4-gram over factors (right).",
            "categories": "nan",
            "figure_id": "C04-1022.pdf-Figure1",
            "image_path": "C04-1022.pdf-Figure1.png",
            "instance_id": "006afb5e6472bf7803363eeaa6947e0a",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What does 'F' represent in the image?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Standard backoff path for a 4-gram language model over words (left) and backoff graph for 4-gram over factors (right).",
                "compound": true,
                "figure_type": "graph",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Standard backoff path for a 4-gram language model over words (left) and backoff graph for 4-gram over factors (right).",
            "categories": "nan",
            "figure_id": "C04-1022.pdf-Figure1",
            "image_path": "C04-1022.pdf-Figure1.png",
            "instance_id": "6953be73bada71e9b3980d9f9ddf7c57",
            "qa_pair_type": "unanswerable",
            "question": "What research questions does the study try to answer?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Evolution of usage type distributions in the period 19102009, generated with occurrences of coach, tenure, curtain and disk in COHA (Davies, 2012). The legends show sample usages per identified usage type.",
                "compound": true,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Evolution of usage type distributions in the period 19102009, generated with occurrences of coach, tenure, curtain and disk in COHA (Davies, 2012). The legends show sample usages per identified usage type.",
            "categories": "nan",
            "figure_id": "2020.acl-main.365.pdf-Figure2",
            "image_path": "2020.acl-main.365.pdf-Figure2.png",
            "instance_id": "5e4a99031b1928ae032f2726be5d71bf",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the orange bar in the graph labeled (a) coach for the year 1930?",
            "reference_answer": "0.7"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Evolution of usage type distributions in the period 19102009, generated with occurrences of coach, tenure, curtain and disk in COHA (Davies, 2012). The legends show sample usages per identified usage type.",
                "compound": true,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Evolution of usage type distributions in the period 19102009, generated with occurrences of coach, tenure, curtain and disk in COHA (Davies, 2012). The legends show sample usages per identified usage type.",
            "categories": "nan",
            "figure_id": "2020.acl-main.365.pdf-Figure2",
            "image_path": "2020.acl-main.365.pdf-Figure2.png",
            "instance_id": "3a1ac78b1fe669b6f0ed99052210e63e",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "Occurrences of which word are represented in the graph (a)?",
            "reference_answer": "Coach"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The occurrences of the word \"coach\" are represented in the graph (a).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Evolution of usage type distributions in the period 19102009, generated with occurrences of coach, tenure, curtain and disk in COHA (Davies, 2012). The legends show sample usages per identified usage type.",
                "compound": true,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Evolution of usage type distributions in the period 19102009, generated with occurrences of coach, tenure, curtain and disk in COHA (Davies, 2012). The legends show sample usages per identified usage type.",
            "categories": "nan",
            "figure_id": "2020.acl-main.365.pdf-Figure2",
            "image_path": "2020.acl-main.365.pdf-Figure2.png",
            "instance_id": "fc7766c441f0aa65c3d8906b27a0bc5d",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "In the figure labelled '(b) tenure', is the value of the brown bar for the year 1960 greater than that of the year 1990?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Evolution of usage type distributions in the period 19102009, generated with occurrences of coach, tenure, curtain and disk in COHA (Davies, 2012). The legends show sample usages per identified usage type.",
                "compound": true,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Evolution of usage type distributions in the period 19102009, generated with occurrences of coach, tenure, curtain and disk in COHA (Davies, 2012). The legends show sample usages per identified usage type.",
            "categories": "nan",
            "figure_id": "2020.acl-main.365.pdf-Figure2",
            "image_path": "2020.acl-main.365.pdf-Figure2.png",
            "instance_id": "f6683d795aeaa23ba9b55d4d892e4f0c",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the usage type 'employment and tenure' consistently higher than 'tenure of office' in Figure 2 (b)?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "employment and tenure"
                    },
                    {
                        "B": "tenure of office"
                    },
                    {
                        "C": "tenure-track faculty position"
                    },
                    {
                        "D": "the polished disk"
                    }
                ],
                "caption": "Figure 2: Evolution of usage type distributions in the period 19102009, generated with occurrences of coach, tenure, curtain and disk in COHA (Davies, 2012). The legends show sample usages per identified usage type.",
                "compound": true,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Evolution of usage type distributions in the period 19102009, generated with occurrences of coach, tenure, curtain and disk in COHA (Davies, 2012). The legends show sample usages per identified usage type.",
            "categories": "nan",
            "figure_id": "2020.acl-main.365.pdf-Figure2",
            "image_path": "2020.acl-main.365.pdf-Figure2.png",
            "instance_id": "b07ebfe9b9c185b1d01dcd82ddac8957",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What does the blue bar in the top right corner represent?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "0.4"
                    },
                    {
                        "B": "0.2"
                    },
                    {
                        "C": "0.6"
                    },
                    {
                        "D": "0.9"
                    }
                ],
                "caption": "Figure 2: Evolution of usage type distributions in the period 19102009, generated with occurrences of coach, tenure, curtain and disk in COHA (Davies, 2012). The legends show sample usages per identified usage type.",
                "compound": true,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Evolution of usage type distributions in the period 19102009, generated with occurrences of coach, tenure, curtain and disk in COHA (Davies, 2012). The legends show sample usages per identified usage type.",
            "categories": "nan",
            "figure_id": "2020.acl-main.365.pdf-Figure2",
            "image_path": "2020.acl-main.365.pdf-Figure2.png",
            "instance_id": "8910aaa326d428f8d9daf70f4b869c5a",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the approximate value of \"reasons for short term leases and insecurity of tenure\" in 1910?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Evolution of usage type distributions in the period 19102009, generated with occurrences of coach, tenure, curtain and disk in COHA (Davies, 2012). The legends show sample usages per identified usage type.",
                "compound": true,
                "figure_type": "bar chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Evolution of usage type distributions in the period 19102009, generated with occurrences of coach, tenure, curtain and disk in COHA (Davies, 2012). The legends show sample usages per identified usage type.",
            "categories": "nan",
            "figure_id": "2020.acl-main.365.pdf-Figure2",
            "image_path": "2020.acl-main.365.pdf-Figure2.png",
            "instance_id": "fb1cb54ce62fc03eace0b06da5e9143f",
            "qa_pair_type": "unanswerable",
            "question": "What is the size of the dataset used in the experiment?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: GAP and ELEA Group Scores Before Scaling",
                "compound": false,
                "figure_type": "Histogram",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: GAP and ELEA Group Scores Before Scaling",
            "categories": "['eess.AS cs.CL cs.LG cs.SD']",
            "figure_id": "1907.01369v2-Figure1-1",
            "image_path": "1907.01369v2-Figure1-1.png",
            "instance_id": "9dd795e9cba89124de08588ecded76ff",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the group scores at the peak of the green curve?",
            "reference_answer": "50"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: GAP and ELEA Group Scores Before Scaling",
                "compound": false,
                "figure_type": "Histogram",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: GAP and ELEA Group Scores Before Scaling",
            "categories": "['eess.AS cs.CL cs.LG cs.SD']",
            "figure_id": "1907.01369v2-Figure1-1",
            "image_path": "1907.01369v2-Figure1-1.png",
            "instance_id": "9187ba086ccc05db5c5448e13cc6beae",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What does the y-axis represent?",
            "reference_answer": "Density"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The y-axis represents \"Density.\"",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: GAP and ELEA Group Scores Before Scaling",
                "compound": false,
                "figure_type": "Histogram",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: GAP and ELEA Group Scores Before Scaling",
            "categories": "['eess.AS cs.CL cs.LG cs.SD']",
            "figure_id": "1907.01369v2-Figure1-1",
            "image_path": "1907.01369v2-Figure1-1.png",
            "instance_id": "bd2cdee595c6ae6ae6e9930afaf26c93",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the tallest bar in the figure green?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: GAP and ELEA Group Scores Before Scaling",
                "compound": false,
                "figure_type": "Histogram",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: GAP and ELEA Group Scores Before Scaling",
            "categories": "['eess.AS cs.CL cs.LG cs.SD']",
            "figure_id": "1907.01369v2-Figure1-1",
            "image_path": "1907.01369v2-Figure1-1.png",
            "instance_id": "02d99d694f8f9a7947f5df7d959a9d4a",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Do ELEA scores have a higher peak density than GAP scores?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "green"
                    },
                    {
                        "B": "blue"
                    },
                    {
                        "C": "red"
                    },
                    {
                        "D": "purple"
                    }
                ],
                "caption": "Figure 1: GAP and ELEA Group Scores Before Scaling",
                "compound": false,
                "figure_type": "Histogram",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: GAP and ELEA Group Scores Before Scaling",
            "categories": "['eess.AS cs.CL cs.LG cs.SD']",
            "figure_id": "1907.01369v2-Figure1-1",
            "image_path": "1907.01369v2-Figure1-1.png",
            "instance_id": "9b75be9018d25a4d23ad689d9c014bf0",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "With what colour are the GAP scores represented?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "20 to 80"
                    },
                    {
                        "B": "40 to 90"
                    },
                    {
                        "C": "50 to 100"
                    },
                    {
                        "D": "40 to 50"
                    }
                ],
                "caption": "Figure 1: GAP and ELEA Group Scores Before Scaling",
                "compound": false,
                "figure_type": "Histogram",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: GAP and ELEA Group Scores Before Scaling",
            "categories": "['eess.AS cs.CL cs.LG cs.SD']",
            "figure_id": "1907.01369v2-Figure1-1",
            "image_path": "1907.01369v2-Figure1-1.png",
            "instance_id": "26f93adc7dd4c75d7fd1a38b79c83dbe",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the approximate range of GAP group scores?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: GAP and ELEA Group Scores Before Scaling",
                "compound": false,
                "figure_type": "Histogram",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: GAP and ELEA Group Scores Before Scaling",
            "categories": "['eess.AS cs.CL cs.LG cs.SD']",
            "figure_id": "1907.01369v2-Figure1-1",
            "image_path": "1907.01369v2-Figure1-1.png",
            "instance_id": "196a7fc7d29f2ffdcbb5685024940186",
            "qa_pair_type": "unanswerable",
            "question": "What is the p-value of the t-test comparing the GAP and ELEA group scores?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Comparison of inflectional distributions for SpanBERTSQuAD 2. The adversarial distributions include only examples that degrade model performance. To make the best use of limited space, we omit the RBR, RBS, and NNPS tags since they do not vary much across distributions. Full figures in Appendix D.",
                "compound": true,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison of inflectional distributions for SpanBERTSQuAD 2. The adversarial distributions include only examples that degrade model performance. To make the best use of limited space, we omit the RBR, RBS, and NNPS tags since they do not vary much across distributions. Full figures in Appendix D.",
            "categories": "nan",
            "figure_id": "2020.acl-main.263.pdf-Figure2",
            "image_path": "2020.acl-main.263.pdf-Figure2.png",
            "instance_id": "5a300ccdcce8cbb4611a7672083ccec0",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the blue bar corresponding to the Penn Treebank POS Tag 'VB' in the bottom graph?",
            "reference_answer": "0.05"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Comparison of inflectional distributions for SpanBERTSQuAD 2. The adversarial distributions include only examples that degrade model performance. To make the best use of limited space, we omit the RBR, RBS, and NNPS tags since they do not vary much across distributions. Full figures in Appendix D.",
                "compound": true,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison of inflectional distributions for SpanBERTSQuAD 2. The adversarial distributions include only examples that degrade model performance. To make the best use of limited space, we omit the RBR, RBS, and NNPS tags since they do not vary much across distributions. Full figures in Appendix D.",
            "categories": "nan",
            "figure_id": "2020.acl-main.263.pdf-Figure2",
            "image_path": "2020.acl-main.263.pdf-Figure2.png",
            "instance_id": "0d360ecbcac3326d9a0a9e213bcb9921",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What POS tag has the highest proportion value for 'Original Distribution'?",
            "reference_answer": "NN"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Comparison of inflectional distributions for SpanBERTSQuAD 2. The adversarial distributions include only examples that degrade model performance. To make the best use of limited space, we omit the RBR, RBS, and NNPS tags since they do not vary much across distributions. Full figures in Appendix D.",
                "compound": true,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison of inflectional distributions for SpanBERTSQuAD 2. The adversarial distributions include only examples that degrade model performance. To make the best use of limited space, we omit the RBR, RBS, and NNPS tags since they do not vary much across distributions. Full figures in Appendix D.",
            "categories": "nan",
            "figure_id": "2020.acl-main.263.pdf-Figure2",
            "image_path": "2020.acl-main.263.pdf-Figure2.png",
            "instance_id": "0943f0570c628e5d11bb397fc263ed57",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the blue bar representing the 'Original Distribution' taller than the orange bar representing the 'Morpheus Adversarial Distribution' for the 'VB' Penn Treebank POS Tag in the top graph?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the blue bar representing the 'Original Distribution' is taller than the orange bar representing the 'Morpheus Adversarial Distribution' for the 'VB' Penn Treebank POS Tag in the top graph.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Comparison of inflectional distributions for SpanBERTSQuAD 2. The adversarial distributions include only examples that degrade model performance. To make the best use of limited space, we omit the RBR, RBS, and NNPS tags since they do not vary much across distributions. Full figures in Appendix D.",
                "compound": true,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison of inflectional distributions for SpanBERTSQuAD 2. The adversarial distributions include only examples that degrade model performance. To make the best use of limited space, we omit the RBR, RBS, and NNPS tags since they do not vary much across distributions. Full figures in Appendix D.",
            "categories": "nan",
            "figure_id": "2020.acl-main.263.pdf-Figure2",
            "image_path": "2020.acl-main.263.pdf-Figure2.png",
            "instance_id": "adb6f7d76fc67f0af277eb9d173bc5c5",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the proportion value of 'Original Distribution' higher than the proportion value of the 'Morpheus Adversarial Distribution' for the 'NNS' Penn Treebank POS Tag?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "yellow"
                    },
                    {
                        "B": "blue"
                    },
                    {
                        "C": "green"
                    },
                    {
                        "D": "orange"
                    }
                ],
                "caption": "Figure 2: Comparison of inflectional distributions for SpanBERTSQuAD 2. The adversarial distributions include only examples that degrade model performance. To make the best use of limited space, we omit the RBR, RBS, and NNPS tags since they do not vary much across distributions. Full figures in Appendix D.",
                "compound": true,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison of inflectional distributions for SpanBERTSQuAD 2. The adversarial distributions include only examples that degrade model performance. To make the best use of limited space, we omit the RBR, RBS, and NNPS tags since they do not vary much across distributions. Full figures in Appendix D.",
            "categories": "nan",
            "figure_id": "2020.acl-main.263.pdf-Figure2",
            "image_path": "2020.acl-main.263.pdf-Figure2.png",
            "instance_id": "fb816798c10345cb3f383ad72c28508c",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What is the colour of the bars representing 'Adversarial Training Set Distribution'?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "JJS"
                    },
                    {
                        "B": "NN"
                    },
                    {
                        "C": "JJ"
                    },
                    {
                        "D": "VB"
                    }
                ],
                "caption": "Figure 2: Comparison of inflectional distributions for SpanBERTSQuAD 2. The adversarial distributions include only examples that degrade model performance. To make the best use of limited space, we omit the RBR, RBS, and NNPS tags since they do not vary much across distributions. Full figures in Appendix D.",
                "compound": true,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison of inflectional distributions for SpanBERTSQuAD 2. The adversarial distributions include only examples that degrade model performance. To make the best use of limited space, we omit the RBR, RBS, and NNPS tags since they do not vary much across distributions. Full figures in Appendix D.",
            "categories": "nan",
            "figure_id": "2020.acl-main.263.pdf-Figure2",
            "image_path": "2020.acl-main.263.pdf-Figure2.png",
            "instance_id": "1b0617e29134e263b3be0d228032426b",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following tags has the highest proportion value for 'Original Training Set Distribution'?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Comparison of inflectional distributions for SpanBERTSQuAD 2. The adversarial distributions include only examples that degrade model performance. To make the best use of limited space, we omit the RBR, RBS, and NNPS tags since they do not vary much across distributions. Full figures in Appendix D.",
                "compound": true,
                "figure_type": "bar chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison of inflectional distributions for SpanBERTSQuAD 2. The adversarial distributions include only examples that degrade model performance. To make the best use of limited space, we omit the RBR, RBS, and NNPS tags since they do not vary much across distributions. Full figures in Appendix D.",
            "categories": "nan",
            "figure_id": "2020.acl-main.263.pdf-Figure2",
            "image_path": "2020.acl-main.263.pdf-Figure2.png",
            "instance_id": "6fbf6b710c1b2b3550ea82e222cd1c3a",
            "qa_pair_type": "unanswerable",
            "question": "What is the exact performance degradation of the model due to the adversarial distributions in the development set?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8: The overlap of true positives among the investigated models was low.",
                "compound": false,
                "figure_type": "venn diagram",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: The overlap of true positives among the investigated models was low.",
            "categories": "nan",
            "figure_id": "W16-2920.pdf-Figure8",
            "image_path": "W16-2920.pdf-Figure8.png",
            "instance_id": "27d8fd87fa0ad9cd02b47003895fc19c",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value represented in the blue circle?",
            "reference_answer": "2"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The value represented in the blue circle is 2.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8: The overlap of true positives among the investigated models was low.",
                "compound": false,
                "figure_type": "venn diagram",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: The overlap of true positives among the investigated models was low.",
            "categories": "nan",
            "figure_id": "W16-2920.pdf-Figure8",
            "image_path": "W16-2920.pdf-Figure8.png",
            "instance_id": "6eb885deb1f9ccbc3326862487a0db7f",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the value representing the shared predictions between the Latent and Feature-based models?",
            "reference_answer": "47"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The value representing the shared predictions between the Latent and Feature-based models is 47.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8: The overlap of true positives among the investigated models was low.",
                "compound": false,
                "figure_type": "venn diagram",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: The overlap of true positives among the investigated models was low.",
            "categories": "nan",
            "figure_id": "W16-2920.pdf-Figure8",
            "image_path": "W16-2920.pdf-Figure8.png",
            "instance_id": "2ec919c9759b1e0ffa61f7e8fe734f4b",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the number of predictions in the yellow (Latent) region greater than in the blue (Rules) region?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The number of predictions in the yellow (Latent) region is 34, which is greater than the number in the blue (Rules) region, which is 2.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8: The overlap of true positives among the investigated models was low.",
                "compound": false,
                "figure_type": "venn diagram",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: The overlap of true positives among the investigated models was low.",
            "categories": "nan",
            "figure_id": "W16-2920.pdf-Figure8",
            "image_path": "W16-2920.pdf-Figure8.png",
            "instance_id": "812c1f4c659c2c0eb834755e0b83ab6a",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the total number of predictions made by the Feature-based model 50? ",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The Latent model\u2019s unique section"
                    },
                    {
                        "B": "The Feature-based model\u2019s unique section"
                    },
                    {
                        "C": "The shared section between Latent and Feature-based models"
                    },
                    {
                        "D": "The Rules model"
                    }
                ],
                "caption": "Figure 8: The overlap of true positives among the investigated models was low.",
                "compound": false,
                "figure_type": "venn diagram",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: The overlap of true positives among the investigated models was low.",
            "categories": "nan",
            "figure_id": "W16-2920.pdf-Figure8",
            "image_path": "W16-2920.pdf-Figure8.png",
            "instance_id": "b09a3fe8675850b84e29aa597f77408a",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which section of the diagram is the largest?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "2"
                    },
                    {
                        "B": "34"
                    },
                    {
                        "C": "83"
                    },
                    {
                        "D": "47"
                    }
                ],
                "caption": "Figure 8: The overlap of true positives among the investigated models was low.",
                "compound": false,
                "figure_type": "venn diagram",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: The overlap of true positives among the investigated models was low.",
            "categories": "nan",
            "figure_id": "W16-2920.pdf-Figure8",
            "image_path": "W16-2920.pdf-Figure8.png",
            "instance_id": "42a3d2e14c494d8291278b34712018c4",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the total number of predictions made by the Latent model?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8: The overlap of true positives among the investigated models was low.",
                "compound": false,
                "figure_type": "venn diagram",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: The overlap of true positives among the investigated models was low.",
            "categories": "nan",
            "figure_id": "W16-2920.pdf-Figure8",
            "image_path": "W16-2920.pdf-Figure8.png",
            "instance_id": "5144d2ad87617ef9dd9abc75ea2a9830",
            "qa_pair_type": "unanswerable",
            "question": "What data was used to generate these true positive values?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: (a) Average test accuracy for d = 4096. (b) Test accuracy of wpoly2 on the ESIM model.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: (a) Average test accuracy for d = 4096. (b) Test accuracy of wpoly2 on the ESIM model.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1802.07374v1-Figure2-1",
            "image_path": "1802.07374v1-Figure2-1.png",
            "instance_id": "9009dcbb27e10b50c58ce234ababbb1f",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the test accuracy of the blue line for a scaling factor of 8 in the left graph?",
            "reference_answer": "84.5 - 85"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The test accuracy of the blue line (Wpoly2) for a scaling factor of 8 in the left graph is approximately 84.5.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: (a) Average test accuracy for d = 4096. (b) Test accuracy of wpoly2 on the ESIM model.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: (a) Average test accuracy for d = 4096. (b) Test accuracy of wpoly2 on the ESIM model.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1802.07374v1-Figure2-1",
            "image_path": "1802.07374v1-Figure2-1.png",
            "instance_id": "9bdbae9cb32cbb9ccd6a7d59e1e0e702",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the value of d in the second plot?",
            "reference_answer": "600"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The value of \\( d \\) in the second plot is 600.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: (a) Average test accuracy for d = 4096. (b) Test accuracy of wpoly2 on the ESIM model.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: (a) Average test accuracy for d = 4096. (b) Test accuracy of wpoly2 on the ESIM model.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1802.07374v1-Figure2-1",
            "image_path": "1802.07374v1-Figure2-1.png",
            "instance_id": "303cd64f2658b3f1ad38f7d1a9f2a2e8",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the test accuracy for the blue data points higher at the scaling factor 32 than at 8 in the right plot?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: (a) Average test accuracy for d = 4096. (b) Test accuracy of wpoly2 on the ESIM model.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: (a) Average test accuracy for d = 4096. (b) Test accuracy of wpoly2 on the ESIM model.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1802.07374v1-Figure2-1",
            "image_path": "1802.07374v1-Figure2-1.png",
            "instance_id": "2b4babe86ed657b49163e0b4f0ed34e0",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the test accuracy of wpoly2 on the ESIM model exceed 86?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "84.2"
                    },
                    {
                        "B": "85.2"
                    },
                    {
                        "C": "84.8"
                    },
                    {
                        "D": "83.8"
                    }
                ],
                "caption": "Figure 2: (a) Average test accuracy for d = 4096. (b) Test accuracy of wpoly2 on the ESIM model.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: (a) Average test accuracy for d = 4096. (b) Test accuracy of wpoly2 on the ESIM model.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1802.07374v1-Figure2-1",
            "image_path": "1802.07374v1-Figure2-1.png",
            "instance_id": "212260cc0d4e562b50c66e8d2935611d",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What is the test accuracy of the orange line when the scaling factor is 16?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "1, 2, 4, 8, 16, 32, 64"
                    },
                    {
                        "B": "1, 2, 3, 4, 5, 6, 7"
                    },
                    {
                        "C": "1, 4, 8, 12, 16, 20, 24"
                    },
                    {
                        "D": "1, 2, 4, 10, 16, 32, 64"
                    }
                ],
                "caption": "Figure 2: (a) Average test accuracy for d = 4096. (b) Test accuracy of wpoly2 on the ESIM model.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: (a) Average test accuracy for d = 4096. (b) Test accuracy of wpoly2 on the ESIM model.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1802.07374v1-Figure2-1",
            "image_path": "1802.07374v1-Figure2-1.png",
            "instance_id": "402905e79bceca41ac2a40e2e1b1a513",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What are the values of the scaling factor 'n' used in the graphs?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: (a) Average test accuracy for d = 4096. (b) Test accuracy of wpoly2 on the ESIM model.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: (a) Average test accuracy for d = 4096. (b) Test accuracy of wpoly2 on the ESIM model.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1802.07374v1-Figure2-1",
            "image_path": "1802.07374v1-Figure2-1.png",
            "instance_id": "6f5ed4daec7dcdaaa43c6a58db296742",
            "qa_pair_type": "unanswerable",
            "question": "Which dataset is used to calculate the test accuracy of wpoly2 on the ESIM model?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: More predictions changed for the Conf-T2LSTM model, when the source vectors are randomly set to 0 during decoding.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: More predictions changed for the Conf-T2LSTM model, when the source vectors are randomly set to 0 during decoding.",
            "categories": "['cs.CL']",
            "figure_id": "1910.08684v3-Figure4-1",
            "image_path": "1910.08684v3-Figure4-1.png",
            "instance_id": "ab94fc02b1c1daff2a2044c2c52c660c",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "At approximately what noise level does the blue line reach a difference of 70%?",
            "reference_answer": "0.1"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: More predictions changed for the Conf-T2LSTM model, when the source vectors are randomly set to 0 during decoding.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: More predictions changed for the Conf-T2LSTM model, when the source vectors are randomly set to 0 during decoding.",
            "categories": "['cs.CL']",
            "figure_id": "1910.08684v3-Figure4-1",
            "image_path": "1910.08684v3-Figure4-1.png",
            "instance_id": "1ff89f36b804683ac65209d26d7163cd",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is approximately the highest difference seen for the Conf-T2LSTM model?",
            "reference_answer": "70%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: More predictions changed for the Conf-T2LSTM model, when the source vectors are randomly set to 0 during decoding.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: More predictions changed for the Conf-T2LSTM model, when the source vectors are randomly set to 0 during decoding.",
            "categories": "['cs.CL']",
            "figure_id": "1910.08684v3-Figure4-1",
            "image_path": "1910.08684v3-Figure4-1.png",
            "instance_id": "b872ecf36aff6cc67aa45ac29257cca0",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the blue line representing Conf-T2LSTM consistently higher than the orange line representing BERT-to-LSTM?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the blue line representing Conf-T2LSTM is consistently higher than the orange line representing BERT-to-LSTM across all noise levels.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: More predictions changed for the Conf-T2LSTM model, when the source vectors are randomly set to 0 during decoding.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: More predictions changed for the Conf-T2LSTM model, when the source vectors are randomly set to 0 during decoding.",
            "categories": "['cs.CL']",
            "figure_id": "1910.08684v3-Figure4-1",
            "image_path": "1910.08684v3-Figure4-1.png",
            "instance_id": "9c4376e050791715bcfd8adfb9e08ac0",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Did both models have more than 50% difference in predictions changed before a noise level of 0.025?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The blue line"
                    },
                    {
                        "B": "The orange line"
                    },
                    {
                        "C": "Both lines"
                    },
                    {
                        "D": "Neither line"
                    }
                ],
                "caption": "Figure 4: More predictions changed for the Conf-T2LSTM model, when the source vectors are randomly set to 0 during decoding.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: More predictions changed for the Conf-T2LSTM model, when the source vectors are randomly set to 0 during decoding.",
            "categories": "['cs.CL']",
            "figure_id": "1910.08684v3-Figure4-1",
            "image_path": "1910.08684v3-Figure4-1.png",
            "instance_id": "54a767da5db5aa8aa6f3eb6ae7981d58",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line represents the model with more changes in predictions when the source vectors are set to 0 during decoding?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Conf-T2LSTM"
                    },
                    {
                        "B": "BERT-to-LSTM"
                    },
                    {
                        "C": "LSTM-to-BERT"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 4: More predictions changed for the Conf-T2LSTM model, when the source vectors are randomly set to 0 during decoding.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: More predictions changed for the Conf-T2LSTM model, when the source vectors are randomly set to 0 during decoding.",
            "categories": "['cs.CL']",
            "figure_id": "1910.08684v3-Figure4-1",
            "image_path": "1910.08684v3-Figure4-1.png",
            "instance_id": "9b264ea16497a674ad13cda7afb5cf61",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which model showed a higher differnce in predictions changed at a noise level of 0.025?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: More predictions changed for the Conf-T2LSTM model, when the source vectors are randomly set to 0 during decoding.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: More predictions changed for the Conf-T2LSTM model, when the source vectors are randomly set to 0 during decoding.",
            "categories": "['cs.CL']",
            "figure_id": "1910.08684v3-Figure4-1",
            "image_path": "1910.08684v3-Figure4-1.png",
            "instance_id": "03ba10bb8508a02b0fcaaa92a0ac8ad2",
            "qa_pair_type": "unanswerable",
            "question": "What specific dataset was used for the Conf-T2LSTM and BERT-to-LSTM models in this experiment?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Comparison between the bound Bk(n), valid for all primitive NZ sets, and rtk(M) for (a) M =MCPR and (b)M =MK .",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison between the bound Bk(n), valid for all primitive NZ sets, and rtk(M) for (a) M =MCPR and (b)M =MK .",
            "categories": "['cs.DM cs.CL math.CO']",
            "figure_id": "1903.10421v2-Figure2-1",
            "image_path": "1903.10421v2-Figure2-1.png",
            "instance_id": "fdb3919ff0a591d84a392ba71a84698d",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of the orange line between k=3 and k=4 in the left graph?",
            "reference_answer": "0 - 5"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Comparison between the bound Bk(n), valid for all primitive NZ sets, and rtk(M) for (a) M =MCPR and (b)M =MK .",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison between the bound Bk(n), valid for all primitive NZ sets, and rtk(M) for (a) M =MCPR and (b)M =MK .",
            "categories": "['cs.DM cs.CL math.CO']",
            "figure_id": "1903.10421v2-Figure2-1",
            "image_path": "1903.10421v2-Figure2-1.png",
            "instance_id": "c761edc9786ba13d94837611f3aa14c6",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "For which value of  'n' is M equal to MCPR?",
            "reference_answer": "4"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The value of 'n' for which \\( M = M_{CPR} \\) is 4.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Comparison between the bound Bk(n), valid for all primitive NZ sets, and rtk(M) for (a) M =MCPR and (b)M =MK .",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison between the bound Bk(n), valid for all primitive NZ sets, and rtk(M) for (a) M =MCPR and (b)M =MK .",
            "categories": "['cs.DM cs.CL math.CO']",
            "figure_id": "1903.10421v2-Figure2-1",
            "image_path": "1903.10421v2-Figure2-1.png",
            "instance_id": "2d5af3644696a0102a3b0c86f5b4dd84",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "In Figure 2(a), does the dashed blue line representing the upper bound Bk(4) reach a value greater than 15?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Comparison between the bound Bk(n), valid for all primitive NZ sets, and rtk(M) for (a) M =MCPR and (b)M =MK .",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison between the bound Bk(n), valid for all primitive NZ sets, and rtk(M) for (a) M =MCPR and (b)M =MK .",
            "categories": "['cs.DM cs.CL math.CO']",
            "figure_id": "1903.10421v2-Figure2-1",
            "image_path": "1903.10421v2-Figure2-1.png",
            "instance_id": "5eb38e3980bf330012eb1aeb224c5009",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the 'exact value rtk' ever reach a value of 20 in Kari primitive set?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Left plot"
                    },
                    {
                        "B": "Right plot"
                    },
                    {
                        "C": "Both of the plots"
                    },
                    {
                        "D": "Neither of the plots"
                    }
                ],
                "caption": "Figure 2: Comparison between the bound Bk(n), valid for all primitive NZ sets, and rtk(M) for (a) M =MCPR and (b)M =MK .",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison between the bound Bk(n), valid for all primitive NZ sets, and rtk(M) for (a) M =MCPR and (b)M =MK .",
            "categories": "['cs.DM cs.CL math.CO']",
            "figure_id": "1903.10421v2-Figure2-1",
            "image_path": "1903.10421v2-Figure2-1.png",
            "instance_id": "0b778f0e891dff60df72468e35c8d836",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "In which of the following plots does the blue line reach a value more than 20?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The line in (a) reaches a higher maximum value than the line in (b)."
                    },
                    {
                        "B": "Both lines show a stepwise increase in value."
                    },
                    {
                        "C": "Both line reach a value greater than 0"
                    },
                    {
                        "D": "Neither of the lines are increasing"
                    }
                ],
                "caption": "Figure 2: Comparison between the bound Bk(n), valid for all primitive NZ sets, and rtk(M) for (a) M =MCPR and (b)M =MK .",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison between the bound Bk(n), valid for all primitive NZ sets, and rtk(M) for (a) M =MCPR and (b)M =MK .",
            "categories": "['cs.DM cs.CL math.CO']",
            "figure_id": "1903.10421v2-Figure2-1",
            "image_path": "1903.10421v2-Figure2-1.png",
            "instance_id": "c246603064d963bcebf3e16eab8e6814",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "In Figure 2, considering line representing 'Exact value of rtk' in both subfigures (a) and (b), which statements are incorrect?",
            "reference_answer": "A,D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ACD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Comparison between the bound Bk(n), valid for all primitive NZ sets, and rtk(M) for (a) M =MCPR and (b)M =MK .",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison between the bound Bk(n), valid for all primitive NZ sets, and rtk(M) for (a) M =MCPR and (b)M =MK .",
            "categories": "['cs.DM cs.CL math.CO']",
            "figure_id": "1903.10421v2-Figure2-1",
            "image_path": "1903.10421v2-Figure2-1.png",
            "instance_id": "7e13c11d8201cd8f7615268d50ca0615",
            "qa_pair_type": "unanswerable",
            "question": "What is the value of 'exact value of rtk' at k = 9 for M = MCPR and n = 10?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6. Precision vs Recall (left) and ROC curve (True Positive Rate vs False Positive Rate) (right) plots of the proposed models trained with the different inputs, the LSTM and random scores.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6. Precision vs Recall (left) and ROC curve (True Positive Rate vs False Positive Rate) (right) plots of the proposed models trained with the different inputs, the LSTM and random scores.",
            "categories": "['cs.CV cs.CL']",
            "figure_id": "1910.03814v1-Figure6-1",
            "image_path": "1910.03814v1-Figure6-1.png",
            "instance_id": "0e1b5b29ecdaed6e7d18bed1a495fa2a",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of the True Positive Rate for the black line at a False Positive Rate of 0.5?",
            "reference_answer": "0.4 - 0.6"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6. Precision vs Recall (left) and ROC curve (True Positive Rate vs False Positive Rate) (right) plots of the proposed models trained with the different inputs, the LSTM and random scores.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6. Precision vs Recall (left) and ROC curve (True Positive Rate vs False Positive Rate) (right) plots of the proposed models trained with the different inputs, the LSTM and random scores.",
            "categories": "['cs.CV cs.CL']",
            "figure_id": "1910.03814v1-Figure6-1",
            "image_path": "1910.03814v1-Figure6-1.png",
            "instance_id": "a0518c7a4c203ebd5fe558ea5f6a487f",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What are the names of the different models trained?",
            "reference_answer": "FCM - I, FCM - ALL, LSTM, TKM - All, Random, SCM - All, FCM - TT,IT"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The different models trained are:\n\n1. FCM - I\n2. FCM - ALL\n3. LSTM\n4. TKM - All\n5. Random\n6. SCM - All\n7. FCM - TT,IT",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6. Precision vs Recall (left) and ROC curve (True Positive Rate vs False Positive Rate) (right) plots of the proposed models trained with the different inputs, the LSTM and random scores.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6. Precision vs Recall (left) and ROC curve (True Positive Rate vs False Positive Rate) (right) plots of the proposed models trained with the different inputs, the LSTM and random scores.",
            "categories": "['cs.CV cs.CL']",
            "figure_id": "1910.03814v1-Figure6-1",
            "image_path": "1910.03814v1-Figure6-1.png",
            "instance_id": "bb58c96c479dc1cb4eee24bbbe1c95cd",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the red line in the bottom plot represent the LSTM model?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6. Precision vs Recall (left) and ROC curve (True Positive Rate vs False Positive Rate) (right) plots of the proposed models trained with the different inputs, the LSTM and random scores.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6. Precision vs Recall (left) and ROC curve (True Positive Rate vs False Positive Rate) (right) plots of the proposed models trained with the different inputs, the LSTM and random scores.",
            "categories": "['cs.CV cs.CL']",
            "figure_id": "1910.03814v1-Figure6-1",
            "image_path": "1910.03814v1-Figure6-1.png",
            "instance_id": "e5dfb05875d89ef0d98d5c00829b9c4b",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the precision of the LSTM model at 1.0 Recall more than 0.4?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Red"
                    },
                    {
                        "B": "Green"
                    },
                    {
                        "C": "Black"
                    },
                    {
                        "D": "Blue"
                    }
                ],
                "caption": "Figure 6. Precision vs Recall (left) and ROC curve (True Positive Rate vs False Positive Rate) (right) plots of the proposed models trained with the different inputs, the LSTM and random scores.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6. Precision vs Recall (left) and ROC curve (True Positive Rate vs False Positive Rate) (right) plots of the proposed models trained with the different inputs, the LSTM and random scores.",
            "categories": "['cs.CV cs.CL']",
            "figure_id": "1910.03814v1-Figure6-1",
            "image_path": "1910.03814v1-Figure6-1.png",
            "instance_id": "dd8e37f4f0a13dbe1dc2604d0d83fb51",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line in the bottom plot represents 'Random'?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "LSTM"
                    },
                    {
                        "B": "TKM"
                    },
                    {
                        "C": "FCM"
                    },
                    {
                        "D": "SCM"
                    }
                ],
                "caption": "Figure 6. Precision vs Recall (left) and ROC curve (True Positive Rate vs False Positive Rate) (right) plots of the proposed models trained with the different inputs, the LSTM and random scores.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6. Precision vs Recall (left) and ROC curve (True Positive Rate vs False Positive Rate) (right) plots of the proposed models trained with the different inputs, the LSTM and random scores.",
            "categories": "['cs.CV cs.CL']",
            "figure_id": "1910.03814v1-Figure6-1",
            "image_path": "1910.03814v1-Figure6-1.png",
            "instance_id": "aad56075214f592762563ee88b33a284",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which model(s) were trained using the 'All' inputs?",
            "reference_answer": "BCD"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ABCD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6. Precision vs Recall (left) and ROC curve (True Positive Rate vs False Positive Rate) (right) plots of the proposed models trained with the different inputs, the LSTM and random scores.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6. Precision vs Recall (left) and ROC curve (True Positive Rate vs False Positive Rate) (right) plots of the proposed models trained with the different inputs, the LSTM and random scores.",
            "categories": "['cs.CV cs.CL']",
            "figure_id": "1910.03814v1-Figure6-1",
            "image_path": "1910.03814v1-Figure6-1.png",
            "instance_id": "4da77f3319fd5ffcec33556883792d68",
            "qa_pair_type": "unanswerable",
            "question": "What is the F1 score for each model?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Representation similarity evolvement during the learning course, NAT (or AT) denotes the baseline of representation similarity between two baselines NAT (or AT) models with different initialization seeds. NATAT denotes the representation similarity between NAT and AT encoder. Best viewed in color.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Representation similarity evolvement during the learning course, NAT (or AT) denotes the baseline of representation similarity between two baselines NAT (or AT) models with different initialization seeds. NATAT denotes the representation similarity between NAT and AT encoder. Best viewed in color.",
            "categories": "['cs.CL']",
            "figure_id": "2010.12868v1-Figure1-1",
            "image_path": "2010.12868v1-Figure1-1.png",
            "instance_id": "1c674ccc15db7300c634e9456d82b914",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of the green line at 250 training steps?",
            "reference_answer": "0.60 - 0.65"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Representation similarity evolvement during the learning course, NAT (or AT) denotes the baseline of representation similarity between two baselines NAT (or AT) models with different initialization seeds. NATAT denotes the representation similarity between NAT and AT encoder. Best viewed in color.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Representation similarity evolvement during the learning course, NAT (or AT) denotes the baseline of representation similarity between two baselines NAT (or AT) models with different initialization seeds. NATAT denotes the representation similarity between NAT and AT encoder. Best viewed in color.",
            "categories": "['cs.CL']",
            "figure_id": "2010.12868v1-Figure1-1",
            "image_path": "2010.12868v1-Figure1-1.png",
            "instance_id": "3fb9bdcd24264f6b87bf739f08d44d87",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "At approximately which training step does the representation similarity of the AT encoder reach its maximum?",
            "reference_answer": "300"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Representation similarity evolvement during the learning course, NAT (or AT) denotes the baseline of representation similarity between two baselines NAT (or AT) models with different initialization seeds. NATAT denotes the representation similarity between NAT and AT encoder. Best viewed in color.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Representation similarity evolvement during the learning course, NAT (or AT) denotes the baseline of representation similarity between two baselines NAT (or AT) models with different initialization seeds. NATAT denotes the representation similarity between NAT and AT encoder. Best viewed in color.",
            "categories": "['cs.CL']",
            "figure_id": "2010.12868v1-Figure1-1",
            "image_path": "2010.12868v1-Figure1-1.png",
            "instance_id": "c00051518397d5f1bbdee7b7a38e3452",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the blue line representing NAT similarity reach a value greater than 0.65?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the blue line representing NAT similarity reaches a value greater than 0.65.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Representation similarity evolvement during the learning course, NAT (or AT) denotes the baseline of representation similarity between two baselines NAT (or AT) models with different initialization seeds. NATAT denotes the representation similarity between NAT and AT encoder. Best viewed in color.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Representation similarity evolvement during the learning course, NAT (or AT) denotes the baseline of representation similarity between two baselines NAT (or AT) models with different initialization seeds. NATAT denotes the representation similarity between NAT and AT encoder. Best viewed in color.",
            "categories": "['cs.CL']",
            "figure_id": "2010.12868v1-Figure1-1",
            "image_path": "2010.12868v1-Figure1-1.png",
            "instance_id": "2037b3c1dab435099c77e8e25ace67aa",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the representation similarity between NAT and AT encoder (NAT-AT) reach a plateau during the learning course?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the representation similarity between NAT and AT encoder (NAT-AT) appears to reach a plateau during the learning course, as indicated by the leveling off of the red line in the graph.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Blue line"
                    },
                    {
                        "B": "Green line"
                    },
                    {
                        "C": "Red line"
                    },
                    {
                        "D": "All of the above"
                    }
                ],
                "caption": "Figure 1: Representation similarity evolvement during the learning course, NAT (or AT) denotes the baseline of representation similarity between two baselines NAT (or AT) models with different initialization seeds. NATAT denotes the representation similarity between NAT and AT encoder. Best viewed in color.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Representation similarity evolvement during the learning course, NAT (or AT) denotes the baseline of representation similarity between two baselines NAT (or AT) models with different initialization seeds. NATAT denotes the representation similarity between NAT and AT encoder. Best viewed in color.",
            "categories": "['cs.CL']",
            "figure_id": "2010.12868v1-Figure1-1",
            "image_path": "2010.12868v1-Figure1-1.png",
            "instance_id": "d883a0546dfcb40216ea0d36d3d92ae1",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line has the highest similarity value around 250 training steps?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "NAT"
                    },
                    {
                        "B": "AT"
                    },
                    {
                        "C": "NAT-AT"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 1: Representation similarity evolvement during the learning course, NAT (or AT) denotes the baseline of representation similarity between two baselines NAT (or AT) models with different initialization seeds. NATAT denotes the representation similarity between NAT and AT encoder. Best viewed in color.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Representation similarity evolvement during the learning course, NAT (or AT) denotes the baseline of representation similarity between two baselines NAT (or AT) models with different initialization seeds. NATAT denotes the representation similarity between NAT and AT encoder. Best viewed in color.",
            "categories": "['cs.CL']",
            "figure_id": "2010.12868v1-Figure1-1",
            "image_path": "2010.12868v1-Figure1-1.png",
            "instance_id": "340bc592e76ede04875c119a21f7a59a",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following start from a lower similarity score?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Representation similarity evolvement during the learning course, NAT (or AT) denotes the baseline of representation similarity between two baselines NAT (or AT) models with different initialization seeds. NATAT denotes the representation similarity between NAT and AT encoder. Best viewed in color.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Representation similarity evolvement during the learning course, NAT (or AT) denotes the baseline of representation similarity between two baselines NAT (or AT) models with different initialization seeds. NATAT denotes the representation similarity between NAT and AT encoder. Best viewed in color.",
            "categories": "['cs.CL']",
            "figure_id": "2010.12868v1-Figure1-1",
            "image_path": "2010.12868v1-Figure1-1.png",
            "instance_id": "047590e18c8ed5007d19968b9bb9b223",
            "qa_pair_type": "unanswerable",
            "question": "Which dataset is used for training the NAT models?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Training dialogs vs. \u2206P , where \u2206P is the fraction of test dialogs where HCNs produced longer initial correct sequences of system actions than the rules, minus the fraction where rules produced longer initial correct sequences than the HCNs. \u201cembed\u201d indicates whether utterance embeddings were included; \u201csampled\u201d indicates whether dialogs sampled from the rule-based controller were included in the training set.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Training dialogs vs. \u2206P , where \u2206P is the fraction of test dialogs where HCNs produced longer initial correct sequences of system actions than the rules, minus the fraction where rules produced longer initial correct sequences than the HCNs. \u201cembed\u201d indicates whether utterance embeddings were included; \u201csampled\u201d indicates whether dialogs sampled from the rule-based controller were included in the training set.",
            "categories": "['cs.AI cs.CL']",
            "figure_id": "1702.03274v2-Figure3-1",
            "image_path": "1702.03274v2-Figure3-1.png",
            "instance_id": "2ad71987e445de2331cbeaea28ad6764",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of \u2206P for the dashed line without markers at 10 labeled supervised learning training dialogs in the right graph?",
            "reference_answer": "-10 - 0"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Training dialogs vs. \u2206P , where \u2206P is the fraction of test dialogs where HCNs produced longer initial correct sequences of system actions than the rules, minus the fraction where rules produced longer initial correct sequences than the HCNs. \u201cembed\u201d indicates whether utterance embeddings were included; \u201csampled\u201d indicates whether dialogs sampled from the rule-based controller were included in the training set.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Training dialogs vs. \u2206P , where \u2206P is the fraction of test dialogs where HCNs produced longer initial correct sequences of system actions than the rules, minus the fraction where rules produced longer initial correct sequences than the HCNs. \u201cembed\u201d indicates whether utterance embeddings were included; \u201csampled\u201d indicates whether dialogs sampled from the rule-based controller were included in the training set.",
            "categories": "['cs.AI cs.CL']",
            "figure_id": "1702.03274v2-Figure3-1",
            "image_path": "1702.03274v2-Figure3-1.png",
            "instance_id": "b22dd4f39df50e4c68d168428f3b85f0",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What are the different training dialogs compared in figure 3?",
            "reference_answer": "HCN+embed+samples, HCN+samples, HCN+embed, HCN"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The different training dialogs compared in the figure are:\n\n1. HCN+embed+sampled\n2. HCN+sampled\n3. HCN+embed\n4. HCN",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Training dialogs vs. \u2206P , where \u2206P is the fraction of test dialogs where HCNs produced longer initial correct sequences of system actions than the rules, minus the fraction where rules produced longer initial correct sequences than the HCNs. \u201cembed\u201d indicates whether utterance embeddings were included; \u201csampled\u201d indicates whether dialogs sampled from the rule-based controller were included in the training set.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Training dialogs vs. \u2206P , where \u2206P is the fraction of test dialogs where HCNs produced longer initial correct sequences of system actions than the rules, minus the fraction where rules produced longer initial correct sequences than the HCNs. \u201cembed\u201d indicates whether utterance embeddings were included; \u201csampled\u201d indicates whether dialogs sampled from the rule-based controller were included in the training set.",
            "categories": "['cs.AI cs.CL']",
            "figure_id": "1702.03274v2-Figure3-1",
            "image_path": "1702.03274v2-Figure3-1.png",
            "instance_id": "be29f88f80e1827ce6b4526167dc5ac8",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the dashed line representing HCN+sampled consistently have a higher value than the solid line representing HCN in the left graph?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. In the left graph, the dashed line representing HCN+sampled consistently has a higher value than the solid line representing HCN.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Training dialogs vs. \u2206P , where \u2206P is the fraction of test dialogs where HCNs produced longer initial correct sequences of system actions than the rules, minus the fraction where rules produced longer initial correct sequences than the HCNs. \u201cembed\u201d indicates whether utterance embeddings were included; \u201csampled\u201d indicates whether dialogs sampled from the rule-based controller were included in the training set.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Training dialogs vs. \u2206P , where \u2206P is the fraction of test dialogs where HCNs produced longer initial correct sequences of system actions than the rules, minus the fraction where rules produced longer initial correct sequences than the HCNs. \u201cembed\u201d indicates whether utterance embeddings were included; \u201csampled\u201d indicates whether dialogs sampled from the rule-based controller were included in the training set.",
            "categories": "['cs.AI cs.CL']",
            "figure_id": "1702.03274v2-Figure3-1",
            "image_path": "1702.03274v2-Figure3-1.png",
            "instance_id": "0f9c1c2a5da9db3ce60b0869ee36319e",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the inclusion of utterance embeddings always result in a higher \u2206P compared to not including them?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Solid line"
                    },
                    {
                        "B": "Dashed line"
                    },
                    {
                        "C": "Solid line with circle markers"
                    },
                    {
                        "D": "Dashed line with circle markers"
                    }
                ],
                "caption": "Figure 3: Training dialogs vs. \u2206P , where \u2206P is the fraction of test dialogs where HCNs produced longer initial correct sequences of system actions than the rules, minus the fraction where rules produced longer initial correct sequences than the HCNs. \u201cembed\u201d indicates whether utterance embeddings were included; \u201csampled\u201d indicates whether dialogs sampled from the rule-based controller were included in the training set.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Training dialogs vs. \u2206P , where \u2206P is the fraction of test dialogs where HCNs produced longer initial correct sequences of system actions than the rules, minus the fraction where rules produced longer initial correct sequences than the HCNs. \u201cembed\u201d indicates whether utterance embeddings were included; \u201csampled\u201d indicates whether dialogs sampled from the rule-based controller were included in the training set.",
            "categories": "['cs.AI cs.CL']",
            "figure_id": "1702.03274v2-Figure3-1",
            "image_path": "1702.03274v2-Figure3-1.png",
            "instance_id": "daae5fc9e1dfb2068b6a7f8d3b4ec12e",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following lines reach a delta P value more than 0% before 10 labeled supervised learning training dialogs?",
            "reference_answer": "C,D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "HCN+embed+sampled"
                    },
                    {
                        "B": "HCN+sampled"
                    },
                    {
                        "C": "HCN+embed"
                    },
                    {
                        "D": "HCN"
                    }
                ],
                "caption": "Figure 3: Training dialogs vs. \u2206P , where \u2206P is the fraction of test dialogs where HCNs produced longer initial correct sequences of system actions than the rules, minus the fraction where rules produced longer initial correct sequences than the HCNs. \u201cembed\u201d indicates whether utterance embeddings were included; \u201csampled\u201d indicates whether dialogs sampled from the rule-based controller were included in the training set.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Training dialogs vs. \u2206P , where \u2206P is the fraction of test dialogs where HCNs produced longer initial correct sequences of system actions than the rules, minus the fraction where rules produced longer initial correct sequences than the HCNs. \u201cembed\u201d indicates whether utterance embeddings were included; \u201csampled\u201d indicates whether dialogs sampled from the rule-based controller were included in the training set.",
            "categories": "['cs.AI cs.CL']",
            "figure_id": "1702.03274v2-Figure3-1",
            "image_path": "1702.03274v2-Figure3-1.png",
            "instance_id": "0ca72d9ba37dd1179863a1c82d76b13e",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "In the \"Can't access account\" domain figure, which of the following represents the performance of HCNs that were trained using utterance embeddings but not sampled dialogs?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Training dialogs vs. \u2206P , where \u2206P is the fraction of test dialogs where HCNs produced longer initial correct sequences of system actions than the rules, minus the fraction where rules produced longer initial correct sequences than the HCNs. \u201cembed\u201d indicates whether utterance embeddings were included; \u201csampled\u201d indicates whether dialogs sampled from the rule-based controller were included in the training set.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Training dialogs vs. \u2206P , where \u2206P is the fraction of test dialogs where HCNs produced longer initial correct sequences of system actions than the rules, minus the fraction where rules produced longer initial correct sequences than the HCNs. \u201cembed\u201d indicates whether utterance embeddings were included; \u201csampled\u201d indicates whether dialogs sampled from the rule-based controller were included in the training set.",
            "categories": "['cs.AI cs.CL']",
            "figure_id": "1702.03274v2-Figure3-1",
            "image_path": "1702.03274v2-Figure3-1.png",
            "instance_id": "486e8f241703707a019f2a3c08dbc7f6",
            "qa_pair_type": "unanswerable",
            "question": "What is the performance of the rule-based controller for 'Forgot password' domain when it has been trained on 150 labeled dialogs? ",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Impact of few-shot size K on NELL dataset.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Impact of few-shot size K on NELL dataset.",
            "categories": "['cs.CL']",
            "figure_id": "2010.09638v1-Figure3-1",
            "image_path": "2010.09638v1-Figure3-1.png",
            "instance_id": "455d1254501a686d3a103e634b2c21c3",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the dark blue line at K = 4 for the bottom figure?",
            "reference_answer": "0.4"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Impact of few-shot size K on NELL dataset.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Impact of few-shot size K on NELL dataset.",
            "categories": "['cs.CL']",
            "figure_id": "2010.09638v1-Figure3-1",
            "image_path": "2010.09638v1-Figure3-1.png",
            "instance_id": "bea6d16e65509b8e7594f2511b0a2e24",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the MRR value for MetaR method at K=6?",
            "reference_answer": "0.22 - 0.26"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Impact of few-shot size K on NELL dataset.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Impact of few-shot size K on NELL dataset.",
            "categories": "['cs.CL']",
            "figure_id": "2010.09638v1-Figure3-1",
            "image_path": "2010.09638v1-Figure3-1.png",
            "instance_id": "193eb9f2121c734a912b4df63e6dce2f",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the value of Hits@10 for the blue line decrease between the value of K=3 and K=4?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Impact of few-shot size K on NELL dataset.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Impact of few-shot size K on NELL dataset.",
            "categories": "['cs.CL']",
            "figure_id": "2010.09638v1-Figure3-1",
            "image_path": "2010.09638v1-Figure3-1.png",
            "instance_id": "804ae9b89aaa5e996d244afcb89cd4ab",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the value of MRR mostly increase as K increases for the MetaR method?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the value of MRR mostly increases as K increases for the MetaR method.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Green line"
                    },
                    {
                        "B": "Grey line"
                    },
                    {
                        "C": "Yellow line"
                    },
                    {
                        "D": "Light blue line"
                    }
                ],
                "caption": "Figure 3: Impact of few-shot size K on NELL dataset.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Impact of few-shot size K on NELL dataset.",
            "categories": "['cs.CL']",
            "figure_id": "2010.09638v1-Figure3-1",
            "image_path": "2010.09638v1-Figure3-1.png",
            "instance_id": "8f8a2882e1ef670f22cf226fa866c423",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line has the lowest MRR value for K = 4?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Gmatching(Max P)"
                    },
                    {
                        "B": "Gmatching(Mean)"
                    },
                    {
                        "C": "MetaR"
                    },
                    {
                        "D": "FAAN"
                    }
                ],
                "caption": "Figure 3: Impact of few-shot size K on NELL dataset.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Impact of few-shot size K on NELL dataset.",
            "categories": "['cs.CL']",
            "figure_id": "2010.09638v1-Figure3-1",
            "image_path": "2010.09638v1-Figure3-1.png",
            "instance_id": "71cde3700d9a5f9d07e6480651ecd7f5",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following methods achieve a Hits@10 value more than 0.35?",
            "reference_answer": "C,D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Impact of few-shot size K on NELL dataset.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Impact of few-shot size K on NELL dataset.",
            "categories": "['cs.CL']",
            "figure_id": "2010.09638v1-Figure3-1",
            "image_path": "2010.09638v1-Figure3-1.png",
            "instance_id": "9fb29f3a59874cd2293a4c02293545f5",
            "qa_pair_type": "unanswerable",
            "question": "What is accuracy on the NELL dataset for the Gmatching(Max P) method at K=5?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Performance of ALBERT with PET/iPET and GPT-3 on SuperGLUE for 32 training examples. ALBERT with PET/iPET outperforms GPT-3 even though it has three orders of magnitude fewer parameters.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Performance of ALBERT with PET/iPET and GPT-3 on SuperGLUE for 32 training examples. ALBERT with PET/iPET outperforms GPT-3 even though it has three orders of magnitude fewer parameters.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "2009.07118v1-Figure1-1",
            "image_path": "2009.07118v1-Figure1-1.png",
            "instance_id": "ebdcf91105119c9662ff9723db399446",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the SuperGLUE performance of the blue line for 100,000 million parameters?",
            "reference_answer": "70 - 80"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Performance of ALBERT with PET/iPET and GPT-3 on SuperGLUE for 32 training examples. ALBERT with PET/iPET outperforms GPT-3 even though it has three orders of magnitude fewer parameters.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Performance of ALBERT with PET/iPET and GPT-3 on SuperGLUE for 32 training examples. ALBERT with PET/iPET outperforms GPT-3 even though it has three orders of magnitude fewer parameters.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "2009.07118v1-Figure1-1",
            "image_path": "2009.07118v1-Figure1-1.png",
            "instance_id": "07a946e130e68d90f0f8d8275f9813c9",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "Which model has the highest SuperGLUE performance?",
            "reference_answer": "iPET"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "GPT-3",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Performance of ALBERT with PET/iPET and GPT-3 on SuperGLUE for 32 training examples. ALBERT with PET/iPET outperforms GPT-3 even though it has three orders of magnitude fewer parameters.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Performance of ALBERT with PET/iPET and GPT-3 on SuperGLUE for 32 training examples. ALBERT with PET/iPET outperforms GPT-3 even though it has three orders of magnitude fewer parameters.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "2009.07118v1-Figure1-1",
            "image_path": "2009.07118v1-Figure1-1.png",
            "instance_id": "742f16970bc19920e10b0b65fd501e98",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the blue line representing GPT-3 performance have a steeper slope in the first two datapoints points compared to the last two datapoints?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Performance of ALBERT with PET/iPET and GPT-3 on SuperGLUE for 32 training examples. ALBERT with PET/iPET outperforms GPT-3 even though it has three orders of magnitude fewer parameters.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Performance of ALBERT with PET/iPET and GPT-3 on SuperGLUE for 32 training examples. ALBERT with PET/iPET outperforms GPT-3 even though it has three orders of magnitude fewer parameters.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "2009.07118v1-Figure1-1",
            "image_path": "2009.07118v1-Figure1-1.png",
            "instance_id": "680c9984a0ad4b8dcdc818f7f4eab78e",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does GPT-3 scores the highest ever SuperGLUE performance?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. Based on the graph, GPT-3 scores the highest SuperGLUE performance compared to the other models presented.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "It scores the lowest SuperGLUE performance at one point."
                    },
                    {
                        "B": "It has the highest number of parameters at one point."
                    },
                    {
                        "C": "It has the lowest number of parameters at one point."
                    },
                    {
                        "D": "It is represented by the smallest circle."
                    }
                ],
                "caption": "Figure 1: Performance of ALBERT with PET/iPET and GPT-3 on SuperGLUE for 32 training examples. ALBERT with PET/iPET outperforms GPT-3 even though it has three orders of magnitude fewer parameters.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Performance of ALBERT with PET/iPET and GPT-3 on SuperGLUE for 32 training examples. ALBERT with PET/iPET outperforms GPT-3 even though it has three orders of magnitude fewer parameters.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "2009.07118v1-Figure1-1",
            "image_path": "2009.07118v1-Figure1-1.png",
            "instance_id": "b8e5f9f2a0b548711e55a6ae7456591b",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following is true about the blue line representing GPT-3 in the figure?",
            "reference_answer": "A,B,C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "BC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "65"
                    },
                    {
                        "B": "75"
                    },
                    {
                        "C": "85"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 1: Performance of ALBERT with PET/iPET and GPT-3 on SuperGLUE for 32 training examples. ALBERT with PET/iPET outperforms GPT-3 even though it has three orders of magnitude fewer parameters.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Performance of ALBERT with PET/iPET and GPT-3 on SuperGLUE for 32 training examples. ALBERT with PET/iPET outperforms GPT-3 even though it has three orders of magnitude fewer parameters.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "2009.07118v1-Figure1-1",
            "image_path": "2009.07118v1-Figure1-1.png",
            "instance_id": "14123355497db3e5a3d55a5aa639e2bb",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following is the performance of GPT-3 at around 10000M parameters?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Performance of ALBERT with PET/iPET and GPT-3 on SuperGLUE for 32 training examples. ALBERT with PET/iPET outperforms GPT-3 even though it has three orders of magnitude fewer parameters.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Performance of ALBERT with PET/iPET and GPT-3 on SuperGLUE for 32 training examples. ALBERT with PET/iPET outperforms GPT-3 even though it has three orders of magnitude fewer parameters.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "2009.07118v1-Figure1-1",
            "image_path": "2009.07118v1-Figure1-1.png",
            "instance_id": "4fd4a7f15cb2b9298ec78d9284e53791",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific training data used for ALBERT with PET/iPET in this figure?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 15: HRG model size as the subgraph size s and the number of subgraph samples k varies. The model size grows linearly with k and s.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 15: HRG model size as the subgraph size s and the number of subgraph samples k varies. The model size grows linearly with k and s.",
            "categories": "['cs.SI cs.CL']",
            "figure_id": "1608.03192v1-Figure15-1",
            "image_path": "1608.03192v1-Figure15-1.png",
            "instance_id": "47338d9b6d039c421d639a2240b7a9a1",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate model size of the line with white square markers when the subgraph size is 500?",
            "reference_answer": "5000"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 15: HRG model size as the subgraph size s and the number of subgraph samples k varies. The model size grows linearly with k and s.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 15: HRG model size as the subgraph size s and the number of subgraph samples k varies. The model size grows linearly with k and s.",
            "categories": "['cs.SI cs.CL']",
            "figure_id": "1608.03192v1-Figure15-1",
            "image_path": "1608.03192v1-Figure15-1.png",
            "instance_id": "d1febf2f9b66e864326005a30736812d",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "Which number of subgraph samples for HRG reaches the highest model size?",
            "reference_answer": "32"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 15: HRG model size as the subgraph size s and the number of subgraph samples k varies. The model size grows linearly with k and s.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 15: HRG model size as the subgraph size s and the number of subgraph samples k varies. The model size grows linearly with k and s.",
            "categories": "['cs.SI cs.CL']",
            "figure_id": "1608.03192v1-Figure15-1",
            "image_path": "1608.03192v1-Figure15-1.png",
            "instance_id": "a9903cbef17bc88bddd26ebb5d482922",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the model size for the line with star markers greater than the model size for the line with diamond markers at a subgraph size of 300?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 15: HRG model size as the subgraph size s and the number of subgraph samples k varies. The model size grows linearly with k and s.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 15: HRG model size as the subgraph size s and the number of subgraph samples k varies. The model size grows linearly with k and s.",
            "categories": "['cs.SI cs.CL']",
            "figure_id": "1608.03192v1-Figure15-1",
            "image_path": "1608.03192v1-Figure15-1.png",
            "instance_id": "f20ac4acadfe6829ee414aef759396f3",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the HRG model with 1 subgraph sample have the highest model size?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Circle"
                    },
                    {
                        "B": "Star"
                    },
                    {
                        "C": "Square"
                    },
                    {
                        "D": "Triangle"
                    }
                ],
                "caption": "Figure 15: HRG model size as the subgraph size s and the number of subgraph samples k varies. The model size grows linearly with k and s.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 15: HRG model size as the subgraph size s and the number of subgraph samples k varies. The model size grows linearly with k and s.",
            "categories": "['cs.SI cs.CL']",
            "figure_id": "1608.03192v1-Figure15-1",
            "image_path": "1608.03192v1-Figure15-1.png",
            "instance_id": "533c0f60a986146b23a4d49d8774b298",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following line styles represent the model size with 32 samples?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "1"
                    },
                    {
                        "B": "2"
                    },
                    {
                        "C": "4"
                    },
                    {
                        "D": "8"
                    }
                ],
                "caption": "Figure 15: HRG model size as the subgraph size s and the number of subgraph samples k varies. The model size grows linearly with k and s.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 15: HRG model size as the subgraph size s and the number of subgraph samples k varies. The model size grows linearly with k and s.",
            "categories": "['cs.SI cs.CL']",
            "figure_id": "1608.03192v1-Figure15-1",
            "image_path": "1608.03192v1-Figure15-1.png",
            "instance_id": "fa5f977f2919a1f65998e18d8e73bede",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following number of subgraph samples for the HRG model has the smallest model size?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ABCD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 15: HRG model size as the subgraph size s and the number of subgraph samples k varies. The model size grows linearly with k and s.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 15: HRG model size as the subgraph size s and the number of subgraph samples k varies. The model size grows linearly with k and s.",
            "categories": "['cs.SI cs.CL']",
            "figure_id": "1608.03192v1-Figure15-1",
            "image_path": "1608.03192v1-Figure15-1.png",
            "instance_id": "1c5d0768d38955dcaf25b728c5ff3048",
            "qa_pair_type": "unanswerable",
            "question": "What is the computational complexity of the HRG model with respect to the subgraph size and the number of subgraph samples?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Normalized signal and saliency norms for the input and inference LSTMs (forward) of ESIM-50 for three examples. The bottom (top) three rows show the signals of the input (inference) LSTM. Each row shows one of the three gates (input, forget and output).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Normalized signal and saliency norms for the input and inference LSTMs (forward) of ESIM-50 for three examples. The bottom (top) three rows show the signals of the input (inference) LSTM. Each row shows one of the three gates (input, forget and output).",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "1808.03894v1-Figure3-1",
            "image_path": "1808.03894v1-Figure3-1.png",
            "instance_id": "2133af4e0aaef19fa8e8de607ae69b28",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the red dashed line corresponding to the word \"family\" in the top row of the middle column?",
            "reference_answer": "1"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Normalized signal and saliency norms for the input and inference LSTMs (forward) of ESIM-50 for three examples. The bottom (top) three rows show the signals of the input (inference) LSTM. Each row shows one of the three gates (input, forget and output).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Normalized signal and saliency norms for the input and inference LSTMs (forward) of ESIM-50 for three examples. The bottom (top) three rows show the signals of the input (inference) LSTM. Each row shows one of the three gates (input, forget and output).",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "1808.03894v1-Figure3-1",
            "image_path": "1808.03894v1-Figure3-1.png",
            "instance_id": "b13ea28d27be8e06e642caa9d0e5fc26",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the exact example shown for the neutral sample?",
            "reference_answer": "A kid is having fun in a garden with her family"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Normalized signal and saliency norms for the input and inference LSTMs (forward) of ESIM-50 for three examples. The bottom (top) three rows show the signals of the input (inference) LSTM. Each row shows one of the three gates (input, forget and output).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Normalized signal and saliency norms for the input and inference LSTMs (forward) of ESIM-50 for three examples. The bottom (top) three rows show the signals of the input (inference) LSTM. Each row shows one of the three gates (input, forget and output).",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "1808.03894v1-Figure3-1",
            "image_path": "1808.03894v1-Figure3-1.png",
            "instance_id": "4127cb4e9904dbfc94cf93349de27fba",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the blue line for the \"forget\" gate of the input LSTM always lower than the red line for the same gate in the middle subplot?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Normalized signal and saliency norms for the input and inference LSTMs (forward) of ESIM-50 for three examples. The bottom (top) three rows show the signals of the input (inference) LSTM. Each row shows one of the three gates (input, forget and output).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Normalized signal and saliency norms for the input and inference LSTMs (forward) of ESIM-50 for three examples. The bottom (top) three rows show the signals of the input (inference) LSTM. Each row shows one of the three gates (input, forget and output).",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "1808.03894v1-Figure3-1",
            "image_path": "1808.03894v1-Figure3-1.png",
            "instance_id": "0795128f727cad0a951718fb1e87c114",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the saliency vector norm always have a lower value than the vector norm in the output gate of the input LSTM before the word 'in' in the neutral sample?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Left"
                    },
                    {
                        "B": "Right"
                    },
                    {
                        "C": "Center"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 3: Normalized signal and saliency norms for the input and inference LSTMs (forward) of ESIM-50 for three examples. The bottom (top) three rows show the signals of the input (inference) LSTM. Each row shows one of the three gates (input, forget and output).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Normalized signal and saliency norms for the input and inference LSTMs (forward) of ESIM-50 for three examples. The bottom (top) three rows show the signals of the input (inference) LSTM. Each row shows one of the three gates (input, forget and output).",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "1808.03894v1-Figure3-1",
            "image_path": "1808.03894v1-Figure3-1.png",
            "instance_id": "15f066fea2582d849d4fd62067fd4430",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which graph is titled 'Entailment Sample'?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Inference LSTM - output gate"
                    },
                    {
                        "B": "Inference LSTM - forget gate"
                    },
                    {
                        "C": "Input LSTM - output gate"
                    },
                    {
                        "D": "Input LSTM - forget gate"
                    }
                ],
                "caption": "Figure 3: Normalized signal and saliency norms for the input and inference LSTMs (forward) of ESIM-50 for three examples. The bottom (top) three rows show the signals of the input (inference) LSTM. Each row shows one of the three gates (input, forget and output).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Normalized signal and saliency norms for the input and inference LSTMs (forward) of ESIM-50 for three examples. The bottom (top) three rows show the signals of the input (inference) LSTM. Each row shows one of the three gates (input, forget and output).",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "1808.03894v1-Figure3-1",
            "image_path": "1808.03894v1-Figure3-1.png",
            "instance_id": "5c3fb78c9a8f3f05e006d0765c69c65b",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following gates approximately reach a value of 1 for the vector norm for 'nap' in the contradiction sample?",
            "reference_answer": "A,B,C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Normalized signal and saliency norms for the input and inference LSTMs (forward) of ESIM-50 for three examples. The bottom (top) three rows show the signals of the input (inference) LSTM. Each row shows one of the three gates (input, forget and output).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Normalized signal and saliency norms for the input and inference LSTMs (forward) of ESIM-50 for three examples. The bottom (top) three rows show the signals of the input (inference) LSTM. Each row shows one of the three gates (input, forget and output).",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "1808.03894v1-Figure3-1",
            "image_path": "1808.03894v1-Figure3-1.png",
            "instance_id": "2ad4383297631b4875a12bdc98c1bfae",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific task that the ESIM-50 model was trained on?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Accuracy with varying graph density.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Accuracy with varying graph density.",
            "categories": "nan",
            "figure_id": "2020.acl-main.31.pdf-Figure5",
            "image_path": "2020.acl-main.31.pdf-Figure5.png",
            "instance_id": "89b8998b1932f14eb914baa1f8428e1f",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the dashed orange line at a window size of 7 in the right subplot?",
            "reference_answer": "15"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Accuracy with varying graph density.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Accuracy with varying graph density.",
            "categories": "nan",
            "figure_id": "2020.acl-main.31.pdf-Figure5",
            "image_path": "2020.acl-main.31.pdf-Figure5.png",
            "instance_id": "449ddea697791a10ed35b55bd7fc8a2d",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the maximum density value shown for the figure labelled (b)?",
            "reference_answer": "15"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Accuracy with varying graph density.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Accuracy with varying graph density.",
            "categories": "nan",
            "figure_id": "2020.acl-main.31.pdf-Figure5",
            "image_path": "2020.acl-main.31.pdf-Figure5.png",
            "instance_id": "e4e895192143bda9cc51c927716a00ce",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the blue line representing accuracy reach its highest point at the window size of 3 in the left subplot?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, the blue line representing accuracy does not reach its highest point at the window size of 3 in the left subplot; it continues to increase and reaches its highest point at window size 5.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Accuracy with varying graph density.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Accuracy with varying graph density.",
            "categories": "nan",
            "figure_id": "2020.acl-main.31.pdf-Figure5",
            "image_path": "2020.acl-main.31.pdf-Figure5.png",
            "instance_id": "57237933103e3480da190e6fe76203e7",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does accuracy always increase as graph density increases?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "1"
                    },
                    {
                        "B": "3"
                    },
                    {
                        "C": "5"
                    },
                    {
                        "D": "7"
                    }
                ],
                "caption": "Figure 5: Accuracy with varying graph density.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Accuracy with varying graph density.",
            "categories": "nan",
            "figure_id": "2020.acl-main.31.pdf-Figure5",
            "image_path": "2020.acl-main.31.pdf-Figure5.png",
            "instance_id": "4a7b7f20f5521f28583e2601cc4699aa",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following Window Sizes have the highest Accuracy on the blue line in the figure labelled (b)?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "BC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "MR"
                    },
                    {
                        "B": "Ohsumed"
                    },
                    {
                        "C": "XR"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 5: Accuracy with varying graph density.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Accuracy with varying graph density.",
            "categories": "nan",
            "figure_id": "2020.acl-main.31.pdf-Figure5",
            "image_path": "2020.acl-main.31.pdf-Figure5.png",
            "instance_id": "c2e899cd722b196c5424d162f4eacb36",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following reach a density level more than 12?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Accuracy with varying graph density.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Accuracy with varying graph density.",
            "categories": "nan",
            "figure_id": "2020.acl-main.31.pdf-Figure5",
            "image_path": "2020.acl-main.31.pdf-Figure5.png",
            "instance_id": "4c2ec2c25a6a1d11062c01efc85a77fb",
            "qa_pair_type": "unanswerable",
            "question": "What is the accuracy for the Ohsumed method with a window size of 9?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Performance Comparisons of Character and Character-Morphological Embeddings During Training and Validation.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Performance Comparisons of Character and Character-Morphological Embeddings During Training and Validation.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2005.07692v2-Figure5-1",
            "image_path": "2005.07692v2-Figure5-1.png",
            "instance_id": "99caba2996d13d13a271b484f6ba4672",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of the solid dark black line at epoch e31?",
            "reference_answer": "0.900 - 0.925"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Performance Comparisons of Character and Character-Morphological Embeddings During Training and Validation.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Performance Comparisons of Character and Character-Morphological Embeddings During Training and Validation.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2005.07692v2-Figure5-1",
            "image_path": "2005.07692v2-Figure5-1.png",
            "instance_id": "a16ac3de9dd4254b4641e719254f211a",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the training F1-Measure at epoch e50 for Char + MorphChar Embeddings?",
            "reference_answer": "More than 0.975"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Performance Comparisons of Character and Character-Morphological Embeddings During Training and Validation.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Performance Comparisons of Character and Character-Morphological Embeddings During Training and Validation.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2005.07692v2-Figure5-1",
            "image_path": "2005.07692v2-Figure5-1.png",
            "instance_id": "7bb78e91e6b97f64a669a0a05c4817b0",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the solid black line representing 'Char + MorphChar Embeddings val' consistently increase across all epochs?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, the solid black line representing 'Char + MorphChar Embeddings val' does not consistently increase across all epochs. It remains relatively stable and does not show a clear upward trend throughout the epochs.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Performance Comparisons of Character and Character-Morphological Embeddings During Training and Validation.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Performance Comparisons of Character and Character-Morphological Embeddings During Training and Validation.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2005.07692v2-Figure5-1",
            "image_path": "2005.07692v2-Figure5-1.png",
            "instance_id": "ceec9813b70cb2eac2054ed254cd2bef",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the performance of \"Char + MorphChar Embeddings tr\" exceed the performance of \"Char Embeddings tr\" for all epochs?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Dashed line"
                    },
                    {
                        "B": "Solid line"
                    },
                    {
                        "C": "Dotted line"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Performance Comparisons of Character and Character-Morphological Embeddings During Training and Validation.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Performance Comparisons of Character and Character-Morphological Embeddings During Training and Validation.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2005.07692v2-Figure5-1",
            "image_path": "2005.07692v2-Figure5-1.png",
            "instance_id": "60a7baa7b0045ade1398bf40103805f3",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line represents the training performance for 'Char + MorphChar Embeddings'?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Char Embeddings tr"
                    },
                    {
                        "B": "Char Embeddings val"
                    },
                    {
                        "C": "Char + MorphChar Embeddings tr"
                    },
                    {
                        "D": "Char + MorphChar Embeddings val"
                    }
                ],
                "caption": "Performance Comparisons of Character and Character-Morphological Embeddings During Training and Validation.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Performance Comparisons of Character and Character-Morphological Embeddings During Training and Validation.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2005.07692v2-Figure5-1",
            "image_path": "2005.07692v2-Figure5-1.png",
            "instance_id": "28976f1c35d2104f1fbd2e27a9d86363",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the models achieves the best performance at the end of training?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Performance Comparisons of Character and Character-Morphological Embeddings During Training and Validation.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Performance Comparisons of Character and Character-Morphological Embeddings During Training and Validation.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2005.07692v2-Figure5-1",
            "image_path": "2005.07692v2-Figure5-1.png",
            "instance_id": "718bbe51d0ccbfa7f1a9b515aca7a62d",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific dataset used for the training and validation in this experiment?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "FIG. 4: (Color online) Evolution of the average shortest path length L(N) for growing word-adjacency networks created from the original (black) and randomly reshuffled (red) literary texts (the same ones as in Fig. 2). The curves representing L(N) for the original texts were averaged over 22-30 different pieces of each text (depending on a text\u2019s length), while for the surrogate texts they were averaged over 20 independent realizations of text reshuffling. Error bars denote standard error of the mean. Note that qualitatively similar shape of the curves for both kinds of data is by no means surprising: the word-frequency statistics is one of the key factors that exert influence on topology of the word-adjacency networks and this statistics is invariant under text randomization.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIG. 4: (Color online) Evolution of the average shortest path length L(N) for growing word-adjacency networks created from the original (black) and randomly reshuffled (red) literary texts (the same ones as in Fig. 2). The curves representing L(N) for the original texts were averaged over 22-30 different pieces of each text (depending on a text\u2019s length), while for the surrogate texts they were averaged over 20 independent realizations of text reshuffling. Error bars denote standard error of the mean. Note that qualitatively similar shape of the curves for both kinds of data is by no means surprising: the word-frequency statistics is one of the key factors that exert influence on topology of the word-adjacency networks and this statistics is invariant under text randomization.",
            "categories": "['cs.CL physics.soc-ph']",
            "figure_id": "1409.4714v2-Figure4-1",
            "image_path": "1409.4714v2-Figure4-1.png",
            "instance_id": "857fff4c574f345982822c524955a9a6",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of L(N) for the black line in 'Der Zauberberg' (DE) when N is approximately 100?",
            "reference_answer": "5 - 6"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "FIG. 4: (Color online) Evolution of the average shortest path length L(N) for growing word-adjacency networks created from the original (black) and randomly reshuffled (red) literary texts (the same ones as in Fig. 2). The curves representing L(N) for the original texts were averaged over 22-30 different pieces of each text (depending on a text\u2019s length), while for the surrogate texts they were averaged over 20 independent realizations of text reshuffling. Error bars denote standard error of the mean. Note that qualitatively similar shape of the curves for both kinds of data is by no means surprising: the word-frequency statistics is one of the key factors that exert influence on topology of the word-adjacency networks and this statistics is invariant under text randomization.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIG. 4: (Color online) Evolution of the average shortest path length L(N) for growing word-adjacency networks created from the original (black) and randomly reshuffled (red) literary texts (the same ones as in Fig. 2). The curves representing L(N) for the original texts were averaged over 22-30 different pieces of each text (depending on a text\u2019s length), while for the surrogate texts they were averaged over 20 independent realizations of text reshuffling. Error bars denote standard error of the mean. Note that qualitatively similar shape of the curves for both kinds of data is by no means surprising: the word-frequency statistics is one of the key factors that exert influence on topology of the word-adjacency networks and this statistics is invariant under text randomization.",
            "categories": "['cs.CL physics.soc-ph']",
            "figure_id": "1409.4714v2-Figure4-1",
            "image_path": "1409.4714v2-Figure4-1.png",
            "instance_id": "0851061ed75cfd6bb774ebf0e8bbe693",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the approximate maximum average shortest path length for the original texts in panel (a)?",
            "reference_answer": "5"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "FIG. 4: (Color online) Evolution of the average shortest path length L(N) for growing word-adjacency networks created from the original (black) and randomly reshuffled (red) literary texts (the same ones as in Fig. 2). The curves representing L(N) for the original texts were averaged over 22-30 different pieces of each text (depending on a text\u2019s length), while for the surrogate texts they were averaged over 20 independent realizations of text reshuffling. Error bars denote standard error of the mean. Note that qualitatively similar shape of the curves for both kinds of data is by no means surprising: the word-frequency statistics is one of the key factors that exert influence on topology of the word-adjacency networks and this statistics is invariant under text randomization.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIG. 4: (Color online) Evolution of the average shortest path length L(N) for growing word-adjacency networks created from the original (black) and randomly reshuffled (red) literary texts (the same ones as in Fig. 2). The curves representing L(N) for the original texts were averaged over 22-30 different pieces of each text (depending on a text\u2019s length), while for the surrogate texts they were averaged over 20 independent realizations of text reshuffling. Error bars denote standard error of the mean. Note that qualitatively similar shape of the curves for both kinds of data is by no means surprising: the word-frequency statistics is one of the key factors that exert influence on topology of the word-adjacency networks and this statistics is invariant under text randomization.",
            "categories": "['cs.CL physics.soc-ph']",
            "figure_id": "1409.4714v2-Figure4-1",
            "image_path": "1409.4714v2-Figure4-1.png",
            "instance_id": "bcb9cde63ff1eb86243da2090dc6c512",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the red curve in the top right graph have a lower value at the point where the horizontal axis is labeled 1000 than the black curve in the same graph?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the red curve in the top right graph (La Comedie humaine) has a lower value at the point where the horizontal axis is labeled 1000 than the black curve.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "FIG. 4: (Color online) Evolution of the average shortest path length L(N) for growing word-adjacency networks created from the original (black) and randomly reshuffled (red) literary texts (the same ones as in Fig. 2). The curves representing L(N) for the original texts were averaged over 22-30 different pieces of each text (depending on a text\u2019s length), while for the surrogate texts they were averaged over 20 independent realizations of text reshuffling. Error bars denote standard error of the mean. Note that qualitatively similar shape of the curves for both kinds of data is by no means surprising: the word-frequency statistics is one of the key factors that exert influence on topology of the word-adjacency networks and this statistics is invariant under text randomization.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIG. 4: (Color online) Evolution of the average shortest path length L(N) for growing word-adjacency networks created from the original (black) and randomly reshuffled (red) literary texts (the same ones as in Fig. 2). The curves representing L(N) for the original texts were averaged over 22-30 different pieces of each text (depending on a text\u2019s length), while for the surrogate texts they were averaged over 20 independent realizations of text reshuffling. Error bars denote standard error of the mean. Note that qualitatively similar shape of the curves for both kinds of data is by no means surprising: the word-frequency statistics is one of the key factors that exert influence on topology of the word-adjacency networks and this statistics is invariant under text randomization.",
            "categories": "['cs.CL physics.soc-ph']",
            "figure_id": "1409.4714v2-Figure4-1",
            "image_path": "1409.4714v2-Figure4-1.png",
            "instance_id": "e2b38719df2cf34c302372a3be502ab6",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Was the average shortest path length L(N) calculated for the original texts have a maximum value lower than the maximum value of the randomly reshuffled texts in panel e?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Top left graph"
                    },
                    {
                        "B": "Top right graph"
                    },
                    {
                        "C": "Middle left graph"
                    },
                    {
                        "D": "All of the above"
                    }
                ],
                "caption": "FIG. 4: (Color online) Evolution of the average shortest path length L(N) for growing word-adjacency networks created from the original (black) and randomly reshuffled (red) literary texts (the same ones as in Fig. 2). The curves representing L(N) for the original texts were averaged over 22-30 different pieces of each text (depending on a text\u2019s length), while for the surrogate texts they were averaged over 20 independent realizations of text reshuffling. Error bars denote standard error of the mean. Note that qualitatively similar shape of the curves for both kinds of data is by no means surprising: the word-frequency statistics is one of the key factors that exert influence on topology of the word-adjacency networks and this statistics is invariant under text randomization.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIG. 4: (Color online) Evolution of the average shortest path length L(N) for growing word-adjacency networks created from the original (black) and randomly reshuffled (red) literary texts (the same ones as in Fig. 2). The curves representing L(N) for the original texts were averaged over 22-30 different pieces of each text (depending on a text\u2019s length), while for the surrogate texts they were averaged over 20 independent realizations of text reshuffling. Error bars denote standard error of the mean. Note that qualitatively similar shape of the curves for both kinds of data is by no means surprising: the word-frequency statistics is one of the key factors that exert influence on topology of the word-adjacency networks and this statistics is invariant under text randomization.",
            "categories": "['cs.CL physics.soc-ph']",
            "figure_id": "1409.4714v2-Figure4-1",
            "image_path": "1409.4714v2-Figure4-1.png",
            "instance_id": "f884ca0fcf29ffa86591a465dca3d0ce",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following subplots have red lines that reach above 5?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Ulysses"
                    },
                    {
                        "B": "La Comedie humaine"
                    },
                    {
                        "C": "Anna Karenina"
                    },
                    {
                        "D": "Trylogia"
                    }
                ],
                "caption": "FIG. 4: (Color online) Evolution of the average shortest path length L(N) for growing word-adjacency networks created from the original (black) and randomly reshuffled (red) literary texts (the same ones as in Fig. 2). The curves representing L(N) for the original texts were averaged over 22-30 different pieces of each text (depending on a text\u2019s length), while for the surrogate texts they were averaged over 20 independent realizations of text reshuffling. Error bars denote standard error of the mean. Note that qualitatively similar shape of the curves for both kinds of data is by no means surprising: the word-frequency statistics is one of the key factors that exert influence on topology of the word-adjacency networks and this statistics is invariant under text randomization.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIG. 4: (Color online) Evolution of the average shortest path length L(N) for growing word-adjacency networks created from the original (black) and randomly reshuffled (red) literary texts (the same ones as in Fig. 2). The curves representing L(N) for the original texts were averaged over 22-30 different pieces of each text (depending on a text\u2019s length), while for the surrogate texts they were averaged over 20 independent realizations of text reshuffling. Error bars denote standard error of the mean. Note that qualitatively similar shape of the curves for both kinds of data is by no means surprising: the word-frequency statistics is one of the key factors that exert influence on topology of the word-adjacency networks and this statistics is invariant under text randomization.",
            "categories": "['cs.CL physics.soc-ph']",
            "figure_id": "1409.4714v2-Figure4-1",
            "image_path": "1409.4714v2-Figure4-1.png",
            "instance_id": "d551d5886122a369cdb16cbeee17a151",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following texts are shown in figure 4?",
            "reference_answer": "A,B,C,D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ABCD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "FIG. 4: (Color online) Evolution of the average shortest path length L(N) for growing word-adjacency networks created from the original (black) and randomly reshuffled (red) literary texts (the same ones as in Fig. 2). The curves representing L(N) for the original texts were averaged over 22-30 different pieces of each text (depending on a text\u2019s length), while for the surrogate texts they were averaged over 20 independent realizations of text reshuffling. Error bars denote standard error of the mean. Note that qualitatively similar shape of the curves for both kinds of data is by no means surprising: the word-frequency statistics is one of the key factors that exert influence on topology of the word-adjacency networks and this statistics is invariant under text randomization.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIG. 4: (Color online) Evolution of the average shortest path length L(N) for growing word-adjacency networks created from the original (black) and randomly reshuffled (red) literary texts (the same ones as in Fig. 2). The curves representing L(N) for the original texts were averaged over 22-30 different pieces of each text (depending on a text\u2019s length), while for the surrogate texts they were averaged over 20 independent realizations of text reshuffling. Error bars denote standard error of the mean. Note that qualitatively similar shape of the curves for both kinds of data is by no means surprising: the word-frequency statistics is one of the key factors that exert influence on topology of the word-adjacency networks and this statistics is invariant under text randomization.",
            "categories": "['cs.CL physics.soc-ph']",
            "figure_id": "1409.4714v2-Figure4-1",
            "image_path": "1409.4714v2-Figure4-1.png",
            "instance_id": "baa53fec54e2534322061eed96f82b23",
            "qa_pair_type": "unanswerable",
            "question": "What is the exact value of L(N) for Don Quixote at N=100?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Results for experiments with balanced datasets",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Results for experiments with balanced datasets",
            "categories": "['cs.LG cs.CL stat.ML']",
            "figure_id": "2006.05561v2-Figure3-1",
            "image_path": "2006.05561v2-Figure3-1.png",
            "instance_id": "f913f85c8b72650e3f9d3fba3de34f96",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate maximum value of the light blue line labelled on the leftmost graph?",
            "reference_answer": "70"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Results for experiments with balanced datasets",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Results for experiments with balanced datasets",
            "categories": "['cs.LG cs.CL stat.ML']",
            "figure_id": "2006.05561v2-Figure3-1",
            "image_path": "2006.05561v2-Figure3-1.png",
            "instance_id": "fdd6f998a05a9d159c020fcd32010da4",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "How many different entities are compared in graph (c)?",
            "reference_answer": "5"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Results for experiments with balanced datasets",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Results for experiments with balanced datasets",
            "categories": "['cs.LG cs.CL stat.ML']",
            "figure_id": "2006.05561v2-Figure3-1",
            "image_path": "2006.05561v2-Figure3-1.png",
            "instance_id": "09ad79ce3092b690887fe363d71b894d",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the red line with label 'all' in the figure labeled (a) reach a value above 70?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Results for experiments with balanced datasets",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Results for experiments with balanced datasets",
            "categories": "['cs.LG cs.CL stat.ML']",
            "figure_id": "2006.05561v2-Figure3-1",
            "image_path": "2006.05561v2-Figure3-1.png",
            "instance_id": "2fc67d1eb74982a7469719ccc1c096c3",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does MTL-1k reach a fscore more than 20?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Red"
                    },
                    {
                        "B": "Yellow"
                    },
                    {
                        "C": "Black"
                    },
                    {
                        "D": "Blue"
                    }
                ],
                "caption": "Figure 3: Results for experiments with balanced datasets",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Results for experiments with balanced datasets",
            "categories": "['cs.LG cs.CL stat.ML']",
            "figure_id": "2006.05561v2-Figure3-1",
            "image_path": "2006.05561v2-Figure3-1.png",
            "instance_id": "7649909f96075f9a2df6cd44af121e4c",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line in the leftmost graph represents the STL method?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "AMI = 1"
                    },
                    {
                        "B": "AMI = 0.8"
                    },
                    {
                        "C": "AMI = 0.6"
                    },
                    {
                        "D": "AMI = 0.43"
                    }
                ],
                "caption": "Figure 3: Results for experiments with balanced datasets",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Results for experiments with balanced datasets",
            "categories": "['cs.LG cs.CL stat.ML']",
            "figure_id": "2006.05561v2-Figure3-1",
            "image_path": "2006.05561v2-Figure3-1.png",
            "instance_id": "81108f96b618ee0f917afd7b161e6c34",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following reach a fscore more than 0.5 in graph (c)?",
            "reference_answer": "A,B,C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ABCD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Results for experiments with balanced datasets",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Results for experiments with balanced datasets",
            "categories": "['cs.LG cs.CL stat.ML']",
            "figure_id": "2006.05561v2-Figure3-1",
            "image_path": "2006.05561v2-Figure3-1.png",
            "instance_id": "e0db996b9be78de06e9212242e3a515b",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific experimental design of the study represented in Figure 3?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5. Comparison of mBERT\u2019s sentence representations by averaging word embeddings in each layer in the BUCC task.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5. Comparison of mBERT\u2019s sentence representations by averaging word embeddings in each layer in the BUCC task.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2003.11080v5-Figure5-1",
            "image_path": "2003.11080v5-Figure5-1.png",
            "instance_id": "1b67288bc1aa3b25eae0c168e7ba567e",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the F1 score for the light orange line at layer L8?",
            "reference_answer": "50 - 60"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5. Comparison of mBERT\u2019s sentence representations by averaging word embeddings in each layer in the BUCC task.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5. Comparison of mBERT\u2019s sentence representations by averaging word embeddings in each layer in the BUCC task.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2003.11080v5-Figure5-1",
            "image_path": "2003.11080v5-Figure5-1.png",
            "instance_id": "f1bd75b0a99c82015a52daed9daea0dc",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "Which sentence representation scores the highest F1 score at L3?",
            "reference_answer": "fr"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5. Comparison of mBERT\u2019s sentence representations by averaging word embeddings in each layer in the BUCC task.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5. Comparison of mBERT\u2019s sentence representations by averaging word embeddings in each layer in the BUCC task.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2003.11080v5-Figure5-1",
            "image_path": "2003.11080v5-Figure5-1.png",
            "instance_id": "5ddcca70103044e0e374ea82bfea0650",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the orange line representing 'ru' reach its highest value at the 'L8' label on the horizontal axis?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, the orange line representing 'ru' does not reach its highest value at the 'L8' label; it reaches its highest value at the 'L9' label.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5. Comparison of mBERT\u2019s sentence representations by averaging word embeddings in each layer in the BUCC task.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5. Comparison of mBERT\u2019s sentence representations by averaging word embeddings in each layer in the BUCC task.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2003.11080v5-Figure5-1",
            "image_path": "2003.11080v5-Figure5-1.png",
            "instance_id": "8dd0fae94e854b88a11dc1b5646260ca",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the 'ru' line achieve the highest F1 score at any point in the figure?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Dark orange line"
                    },
                    {
                        "B": "Yellow line"
                    },
                    {
                        "C": "Purple line"
                    },
                    {
                        "D": "Light orange line"
                    }
                ],
                "caption": "Figure 5. Comparison of mBERT\u2019s sentence representations by averaging word embeddings in each layer in the BUCC task.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5. Comparison of mBERT\u2019s sentence representations by averaging word embeddings in each layer in the BUCC task.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2003.11080v5-Figure5-1",
            "image_path": "2003.11080v5-Figure5-1.png",
            "instance_id": "19bd88e2da104a4edfd5fbee9e6cc6d5",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line(s) reach a F1 score value lower than 20 regardless of the layer?",
            "reference_answer": "A,B,C,D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A B C D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "de"
                    },
                    {
                        "B": "fr"
                    },
                    {
                        "C": "zh"
                    },
                    {
                        "D": "ru"
                    }
                ],
                "caption": "Figure 5. Comparison of mBERT\u2019s sentence representations by averaging word embeddings in each layer in the BUCC task.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5. Comparison of mBERT\u2019s sentence representations by averaging word embeddings in each layer in the BUCC task.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2003.11080v5-Figure5-1",
            "image_path": "2003.11080v5-Figure5-1.png",
            "instance_id": "b5b592ddef93f16938eae17e0612db86",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following show the highest F1 score in the BUCC task at layer L12?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5. Comparison of mBERT\u2019s sentence representations by averaging word embeddings in each layer in the BUCC task.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5. Comparison of mBERT\u2019s sentence representations by averaging word embeddings in each layer in the BUCC task.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2003.11080v5-Figure5-1",
            "image_path": "2003.11080v5-Figure5-1.png",
            "instance_id": "49dfa59274ee3eea40d1bf933d7c4240",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific task the BUCC task refers to in the context of this graph?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: The accumulated attention weights of documents tokens on RAM T and CMR on Case 1 in Fig. 3. We only show top tokens in both methods here.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The accumulated attention weights of documents tokens on RAM T and CMR on Case 1 in Fig. 3. We only show top tokens in both methods here.",
            "categories": "nan",
            "figure_id": "2020.acl-main.61.pdf-Figure4",
            "image_path": "2020.acl-main.61.pdf-Figure4.png",
            "instance_id": "439df80402e847ed32a097aafcea5b2b",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the highest attention weights value of the red line?",
            "reference_answer": "More than 0.30"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: The accumulated attention weights of documents tokens on RAM T and CMR on Case 1 in Fig. 3. We only show top tokens in both methods here.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The accumulated attention weights of documents tokens on RAM T and CMR on Case 1 in Fig. 3. We only show top tokens in both methods here.",
            "categories": "nan",
            "figure_id": "2020.acl-main.61.pdf-Figure4",
            "image_path": "2020.acl-main.61.pdf-Figure4.png",
            "instance_id": "bcac0a9ff74163f44f6d93460e54f608",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "Which method has the highest attention weight for the word 'of'?",
            "reference_answer": "CMR"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "CMR",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: The accumulated attention weights of documents tokens on RAM T and CMR on Case 1 in Fig. 3. We only show top tokens in both methods here.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The accumulated attention weights of documents tokens on RAM T and CMR on Case 1 in Fig. 3. We only show top tokens in both methods here.",
            "categories": "nan",
            "figure_id": "2020.acl-main.61.pdf-Figure4",
            "image_path": "2020.acl-main.61.pdf-Figure4.png",
            "instance_id": "d82e9bc632a60ec7b7fc038ac9f99200",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the blue line higher than the red line at the point labelled 'to'?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: The accumulated attention weights of documents tokens on RAM T and CMR on Case 1 in Fig. 3. We only show top tokens in both methods here.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The accumulated attention weights of documents tokens on RAM T and CMR on Case 1 in Fig. 3. We only show top tokens in both methods here.",
            "categories": "nan",
            "figure_id": "2020.acl-main.61.pdf-Figure4",
            "image_path": "2020.acl-main.61.pdf-Figure4.png",
            "instance_id": "4bcd348106dc18ff34611e76161d9f85",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the attention weight of the token 'of' higher in RAM.T than in CMR?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, the attention weight of the token 'of' is not higher in RAM.T than in CMR.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "the"
                    },
                    {
                        "B": "of"
                    },
                    {
                        "C": "<PAD>"
                    },
                    {
                        "D": "season"
                    }
                ],
                "caption": "Figure 4: The accumulated attention weights of documents tokens on RAM T and CMR on Case 1 in Fig. 3. We only show top tokens in both methods here.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The accumulated attention weights of documents tokens on RAM T and CMR on Case 1 in Fig. 3. We only show top tokens in both methods here.",
            "categories": "nan",
            "figure_id": "2020.acl-main.61.pdf-Figure4",
            "image_path": "2020.acl-main.61.pdf-Figure4.png",
            "instance_id": "8aec7cbe37e92f2231e22cf1ffabeda3",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following has the highest attention weight for the method shown in red line?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "BC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "RAM_T"
                    },
                    {
                        "B": "CMR"
                    },
                    {
                        "C": "Both"
                    },
                    {
                        "D": "Neither"
                    }
                ],
                "caption": "Figure 4: The accumulated attention weights of documents tokens on RAM T and CMR on Case 1 in Fig. 3. We only show top tokens in both methods here.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The accumulated attention weights of documents tokens on RAM T and CMR on Case 1 in Fig. 3. We only show top tokens in both methods here.",
            "categories": "nan",
            "figure_id": "2020.acl-main.61.pdf-Figure4",
            "image_path": "2020.acl-main.61.pdf-Figure4.png",
            "instance_id": "31f14aa11f11ce09556cfa79a3fc50cf",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following methods show a higher attention weight for the word 'premier'?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: The accumulated attention weights of documents tokens on RAM T and CMR on Case 1 in Fig. 3. We only show top tokens in both methods here.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The accumulated attention weights of documents tokens on RAM T and CMR on Case 1 in Fig. 3. We only show top tokens in both methods here.",
            "categories": "nan",
            "figure_id": "2020.acl-main.61.pdf-Figure4",
            "image_path": "2020.acl-main.61.pdf-Figure4.png",
            "instance_id": "9a0303af99ee2124d40f7397ced48955",
            "qa_pair_type": "unanswerable",
            "question": "What is the value of the CMR attention weight for the token 'football'?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: Plot of percentage performance change against answer length under AddSent2Opt-Shuffle Attack. Correlation Coefficient: MCScript: 0.7693, RACE-M: -0.4048.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Plot of percentage performance change against answer length under AddSent2Opt-Shuffle Attack. Correlation Coefficient: MCScript: 0.7693, RACE-M: -0.4048.",
            "categories": "['cs.CL']",
            "figure_id": "1910.12391v1-Figure7-1",
            "image_path": "1910.12391v1-Figure7-1.png",
            "instance_id": "28984acce5688d0d2dd808e7ec1fd660",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the exact value of the orange line at answer length 9?",
            "reference_answer": "-46.6"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The exact value of the orange line (MCScript) at answer length 9 is -25.6.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: Plot of percentage performance change against answer length under AddSent2Opt-Shuffle Attack. Correlation Coefficient: MCScript: 0.7693, RACE-M: -0.4048.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Plot of percentage performance change against answer length under AddSent2Opt-Shuffle Attack. Correlation Coefficient: MCScript: 0.7693, RACE-M: -0.4048.",
            "categories": "['cs.CL']",
            "figure_id": "1910.12391v1-Figure7-1",
            "image_path": "1910.12391v1-Figure7-1.png",
            "instance_id": "f33963036dbf1083b5cd565b87d4ff93",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the exact percentage performance change for RACE-M at answer length 1?",
            "reference_answer": "-12.4"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The exact percentage performance change for RACE-M at answer length 1 is -12.4%.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: Plot of percentage performance change against answer length under AddSent2Opt-Shuffle Attack. Correlation Coefficient: MCScript: 0.7693, RACE-M: -0.4048.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Plot of percentage performance change against answer length under AddSent2Opt-Shuffle Attack. Correlation Coefficient: MCScript: 0.7693, RACE-M: -0.4048.",
            "categories": "['cs.CL']",
            "figure_id": "1910.12391v1-Figure7-1",
            "image_path": "1910.12391v1-Figure7-1.png",
            "instance_id": "b8ad650195e6b1ab549d0b0997d35b65",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the value of the orange line at an answer length of 9 higher than the value of the blue line at the same answer length?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, the value of the orange line (MCScript) at an answer length of 9 is lower than the value of the blue line (RACE-M) at the same answer length.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: Plot of percentage performance change against answer length under AddSent2Opt-Shuffle Attack. Correlation Coefficient: MCScript: 0.7693, RACE-M: -0.4048.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Plot of percentage performance change against answer length under AddSent2Opt-Shuffle Attack. Correlation Coefficient: MCScript: 0.7693, RACE-M: -0.4048.",
            "categories": "['cs.CL']",
            "figure_id": "1910.12391v1-Figure7-1",
            "image_path": "1910.12391v1-Figure7-1.png",
            "instance_id": "ac082e37c75cdfd4e5ae517b8db0ee52",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the percentage performance change for MCScript lower than that of RACE-M?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Blue line"
                    },
                    {
                        "B": "Orange line"
                    },
                    {
                        "C": "Both lines have the same value at answer length 10."
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 7: Plot of percentage performance change against answer length under AddSent2Opt-Shuffle Attack. Correlation Coefficient: MCScript: 0.7693, RACE-M: -0.4048.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Plot of percentage performance change against answer length under AddSent2Opt-Shuffle Attack. Correlation Coefficient: MCScript: 0.7693, RACE-M: -0.4048.",
            "categories": "['cs.CL']",
            "figure_id": "1910.12391v1-Figure7-1",
            "image_path": "1910.12391v1-Figure7-1.png",
            "instance_id": "dd070ef96921144fa85ca85c4d69f0b7",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line in the plot has the highest value at answer length 10?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "-23.9"
                    },
                    {
                        "B": "-11.9"
                    },
                    {
                        "C": "-29.2"
                    },
                    {
                        "D": "-25.5"
                    }
                ],
                "caption": "Figure 7: Plot of percentage performance change against answer length under AddSent2Opt-Shuffle Attack. Correlation Coefficient: MCScript: 0.7693, RACE-M: -0.4048.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Plot of percentage performance change against answer length under AddSent2Opt-Shuffle Attack. Correlation Coefficient: MCScript: 0.7693, RACE-M: -0.4048.",
            "categories": "['cs.CL']",
            "figure_id": "1910.12391v1-Figure7-1",
            "image_path": "1910.12391v1-Figure7-1.png",
            "instance_id": "3dbb7ff698b325e75b65a8fca7227b91",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following is the lowest performance change value recorded for RACE-M?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: Plot of percentage performance change against answer length under AddSent2Opt-Shuffle Attack. Correlation Coefficient: MCScript: 0.7693, RACE-M: -0.4048.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Plot of percentage performance change against answer length under AddSent2Opt-Shuffle Attack. Correlation Coefficient: MCScript: 0.7693, RACE-M: -0.4048.",
            "categories": "['cs.CL']",
            "figure_id": "1910.12391v1-Figure7-1",
            "image_path": "1910.12391v1-Figure7-1.png",
            "instance_id": "0f42d8e3122b8dda54afe1bbe03cd71b",
            "qa_pair_type": "unanswerable",
            "question": "What is the exact training loss of the MCScript under AddSent2Opt-Shuffle Attack at answer length 9? ",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: ROUGE-1 on Gigaword test set with respect to the number of training examples. ABS+ is a baseline method from Rush et al. (2015) using attention. The x-axis is in log scale.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: ROUGE-1 on Gigaword test set with respect to the number of training examples. ABS+ is a baseline method from Rush et al. (2015) using attention. The x-axis is in log scale.",
            "categories": "['cs.CL']",
            "figure_id": "1908.08206v1-Figure3-1",
            "image_path": "1908.08206v1-Figure3-1.png",
            "instance_id": "3e26cc290f3fd18bfcdd8821aa247762",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the ROUGE-1 score of the blue line at 10,000 training examples?",
            "reference_answer": "20 - 25"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: ROUGE-1 on Gigaword test set with respect to the number of training examples. ABS+ is a baseline method from Rush et al. (2015) using attention. The x-axis is in log scale.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: ROUGE-1 on Gigaword test set with respect to the number of training examples. ABS+ is a baseline method from Rush et al. (2015) using attention. The x-axis is in log scale.",
            "categories": "['cs.CL']",
            "figure_id": "1908.08206v1-Figure3-1",
            "image_path": "1908.08206v1-Figure3-1.png",
            "instance_id": "b7440cd39570978ab0217692f62de9f4",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "How many different methods are displayed in figure 3?",
            "reference_answer": "3"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "There are three different methods displayed in figure 3: \n\n1. PoDA w/o pre-training\n2. PoDA\n3. ABS+",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: ROUGE-1 on Gigaword test set with respect to the number of training examples. ABS+ is a baseline method from Rush et al. (2015) using attention. The x-axis is in log scale.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: ROUGE-1 on Gigaword test set with respect to the number of training examples. ABS+ is a baseline method from Rush et al. (2015) using attention. The x-axis is in log scale.",
            "categories": "['cs.CL']",
            "figure_id": "1908.08206v1-Figure3-1",
            "image_path": "1908.08206v1-Figure3-1.png",
            "instance_id": "09c856c9478b4108ba6bdf5a9cbf3627",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the blue line representing 'PoDA w/o pre-training' consistently higher than the red line representing 'PoDA'?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: ROUGE-1 on Gigaword test set with respect to the number of training examples. ABS+ is a baseline method from Rush et al. (2015) using attention. The x-axis is in log scale.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: ROUGE-1 on Gigaword test set with respect to the number of training examples. ABS+ is a baseline method from Rush et al. (2015) using attention. The x-axis is in log scale.",
            "categories": "['cs.CL']",
            "figure_id": "1908.08206v1-Figure3-1",
            "image_path": "1908.08206v1-Figure3-1.png",
            "instance_id": "092c2bd972ce6f7200e41866bb54fa6a",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the ROUGE-1 score of the PoDA method with pre-training exceed 30 for the largest number of training examples?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The blue line"
                    },
                    {
                        "B": "The red line"
                    },
                    {
                        "C": "Both lines represent methods that use pre-training"
                    },
                    {
                        "D": "Neither line represents a method that uses pre-training"
                    }
                ],
                "caption": "Figure 3: ROUGE-1 on Gigaword test set with respect to the number of training examples. ABS+ is a baseline method from Rush et al. (2015) using attention. The x-axis is in log scale.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: ROUGE-1 on Gigaword test set with respect to the number of training examples. ABS+ is a baseline method from Rush et al. (2015) using attention. The x-axis is in log scale.",
            "categories": "['cs.CL']",
            "figure_id": "1908.08206v1-Figure3-1",
            "image_path": "1908.08206v1-Figure3-1.png",
            "instance_id": "0cf8ca5d00f3433ca31b296c761ce313",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line represents the method that does not use pre-training?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "40"
                    },
                    {
                        "B": "35"
                    },
                    {
                        "C": "30"
                    },
                    {
                        "D": "25"
                    }
                ],
                "caption": "Figure 3: ROUGE-1 on Gigaword test set with respect to the number of training examples. ABS+ is a baseline method from Rush et al. (2015) using attention. The x-axis is in log scale.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: ROUGE-1 on Gigaword test set with respect to the number of training examples. ABS+ is a baseline method from Rush et al. (2015) using attention. The x-axis is in log scale.",
            "categories": "['cs.CL']",
            "figure_id": "1908.08206v1-Figure3-1",
            "image_path": "1908.08206v1-Figure3-1.png",
            "instance_id": "5398244ce808479b7c0224a02362a8b1",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the highest ROGUE-1 value for the PoDA method?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: ROUGE-1 on Gigaword test set with respect to the number of training examples. ABS+ is a baseline method from Rush et al. (2015) using attention. The x-axis is in log scale.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: ROUGE-1 on Gigaword test set with respect to the number of training examples. ABS+ is a baseline method from Rush et al. (2015) using attention. The x-axis is in log scale.",
            "categories": "['cs.CL']",
            "figure_id": "1908.08206v1-Figure3-1",
            "image_path": "1908.08206v1-Figure3-1.png",
            "instance_id": "00824180630506197a04e7324f40af4c",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific implementation of the ABS+ baseline method used in this experiment?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Convergence of training entropy. The entropy value has been converted to its logarithm.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Convergence of training entropy. The entropy value has been converted to its logarithm.",
            "categories": "['cs.CL cs.AI cs.LG cs.NE']",
            "figure_id": "1506.00195v1-Figure2-1",
            "image_path": "1506.00195v1-Figure2-1.png",
            "instance_id": "99b315515a85fe0ba7ba1b2739bbe0d7",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the training entropy for the green line at epoch 20?",
            "reference_answer": "-7 - -6"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Convergence of training entropy. The entropy value has been converted to its logarithm.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Convergence of training entropy. The entropy value has been converted to its logarithm.",
            "categories": "['cs.CL cs.AI cs.LG cs.NE']",
            "figure_id": "1506.00195v1-Figure2-1",
            "image_path": "1506.00195v1-Figure2-1.png",
            "instance_id": "f36402939a1b3024c233ea053121de21",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the model with the lowest training entropy at epoch 40?",
            "reference_answer": "RNN-EM"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The model with the lowest training entropy at epoch 40 is RNN-EM.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Convergence of training entropy. The entropy value has been converted to its logarithm.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Convergence of training entropy. The entropy value has been converted to its logarithm.",
            "categories": "['cs.CL cs.AI cs.LG cs.NE']",
            "figure_id": "1506.00195v1-Figure2-1",
            "image_path": "1506.00195v1-Figure2-1.png",
            "instance_id": "8146188b49710c2a6c2b9fa49f915c4a",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the green line labeled 'RNN-EM' show a higher entropy value than the dotted line labeled 'simple RNN' at Epoch 10?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Convergence of training entropy. The entropy value has been converted to its logarithm.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Convergence of training entropy. The entropy value has been converted to its logarithm.",
            "categories": "['cs.CL cs.AI cs.LG cs.NE']",
            "figure_id": "1506.00195v1-Figure2-1",
            "image_path": "1506.00195v1-Figure2-1.png",
            "instance_id": "486ba14e14b5133b527989a79e3ce900",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the training entropy for the simple RNN converge to a higher value than the training entropy of the LSTM?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the training entropy for the simple RNN converges to a higher value than the training entropy of the LSTM.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Green solid line"
                    },
                    {
                        "B": "Blue solid line"
                    },
                    {
                        "C": "Red solid line"
                    },
                    {
                        "D": "Black dotted line"
                    }
                ],
                "caption": "Figure 2: Convergence of training entropy. The entropy value has been converted to its logarithm.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Convergence of training entropy. The entropy value has been converted to its logarithm.",
            "categories": "['cs.CL cs.AI cs.LG cs.NE']",
            "figure_id": "1506.00195v1-Figure2-1",
            "image_path": "1506.00195v1-Figure2-1.png",
            "instance_id": "241018e0752525e2b8ea48a28022289c",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following describes the line representing simple RNN?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "RNN-EM"
                    },
                    {
                        "B": "GRNN"
                    },
                    {
                        "C": "LSTM"
                    },
                    {
                        "D": "simple RNN"
                    }
                ],
                "caption": "Figure 2: Convergence of training entropy. The entropy value has been converted to its logarithm.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Convergence of training entropy. The entropy value has been converted to its logarithm.",
            "categories": "['cs.CL cs.AI cs.LG cs.NE']",
            "figure_id": "1506.00195v1-Figure2-1",
            "image_path": "1506.00195v1-Figure2-1.png",
            "instance_id": "353f7af6daa5c6560e17502997f995fb",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following represents the highest entropy value after 40 epochs?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Convergence of training entropy. The entropy value has been converted to its logarithm.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Convergence of training entropy. The entropy value has been converted to its logarithm.",
            "categories": "['cs.CL cs.AI cs.LG cs.NE']",
            "figure_id": "1506.00195v1-Figure2-1",
            "image_path": "1506.00195v1-Figure2-1.png",
            "instance_id": "76d11093f0694feeba7123436fd66ba6",
            "qa_pair_type": "unanswerable",
            "question": "What is the value of the entropy for RNN-EM at epoch 60?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Validation results when retraining a classifier on a frozen hypothesis encoder (cHypoth, retrained) compared to our methods (cNLI), the adversarial hypothesisonly classifier (cHypoth, in AdvCls), majority baseline, a random frozen encoder, and a hypothesis-only model.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Validation results when retraining a classifier on a frozen hypothesis encoder (cHypoth, retrained) compared to our methods (cNLI), the adversarial hypothesisonly classifier (cHypoth, in AdvCls), majority baseline, a random frozen encoder, and a hypothesis-only model.",
            "categories": "['cs.CL']",
            "figure_id": "1907.04389v1-Figure1-1",
            "image_path": "1907.04389v1-Figure1-1.png",
            "instance_id": "64635099642ce4569cc91383be689f01",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the accuracy of the green line at the third data point in the top graph?",
            "reference_answer": "60 - 70"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Validation results when retraining a classifier on a frozen hypothesis encoder (cHypoth, retrained) compared to our methods (cNLI), the adversarial hypothesisonly classifier (cHypoth, in AdvCls), majority baseline, a random frozen encoder, and a hypothesis-only model.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Validation results when retraining a classifier on a frozen hypothesis encoder (cHypoth, retrained) compared to our methods (cNLI), the adversarial hypothesisonly classifier (cHypoth, in AdvCls), majority baseline, a random frozen encoder, and a hypothesis-only model.",
            "categories": "['cs.CL']",
            "figure_id": "1907.04389v1-Figure1-1",
            "image_path": "1907.04389v1-Figure1-1.png",
            "instance_id": "b817fcd9e0197bcaab241de1a1f0746b",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is approximately the highest value of cNLI in graph (b)?",
            "reference_answer": "80"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "In graph (b), the highest value of \\( cNLI \\) is approximately 80.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Validation results when retraining a classifier on a frozen hypothesis encoder (cHypoth, retrained) compared to our methods (cNLI), the adversarial hypothesisonly classifier (cHypoth, in AdvCls), majority baseline, a random frozen encoder, and a hypothesis-only model.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Validation results when retraining a classifier on a frozen hypothesis encoder (cHypoth, retrained) compared to our methods (cNLI), the adversarial hypothesisonly classifier (cHypoth, in AdvCls), majority baseline, a random frozen encoder, and a hypothesis-only model.",
            "categories": "['cs.CL']",
            "figure_id": "1907.04389v1-Figure1-1",
            "image_path": "1907.04389v1-Figure1-1.png",
            "instance_id": "1f03fde238f15358119911a6b21df218",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the accuracy of the blue line at the value of 0.4, 0.4 for 'lambda Loss, lambda Enc' lower than the accuracy of the green line at the same value?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the accuracy of the blue line at the value of 0.4, 0.4 is lower than the accuracy of the green line at the same value.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Validation results when retraining a classifier on a frozen hypothesis encoder (cHypoth, retrained) compared to our methods (cNLI), the adversarial hypothesisonly classifier (cHypoth, in AdvCls), majority baseline, a random frozen encoder, and a hypothesis-only model.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Validation results when retraining a classifier on a frozen hypothesis encoder (cHypoth, retrained) compared to our methods (cNLI), the adversarial hypothesisonly classifier (cHypoth, in AdvCls), majority baseline, a random frozen encoder, and a hypothesis-only model.",
            "categories": "['cs.CL']",
            "figure_id": "1907.04389v1-Figure1-1",
            "image_path": "1907.04389v1-Figure1-1.png",
            "instance_id": "f09a038c79748cccc7b090b242247504",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the 'cNLI' method and the 'cHypoth, retrained' method have the same accuracy at 0.4, 1 for 'lambda Loss, lambda Enc' in graph (b)?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, at 0.4, 1 for 'lambda Loss, lambda Enc' in graph (b), the 'cNLI' method and the 'cHypoth, retrained' method have the same accuracy.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Green line"
                    },
                    {
                        "B": "Blue line"
                    },
                    {
                        "C": "Black horizontal line (Hyp Only)"
                    },
                    {
                        "D": "Black horizontal line (Majority)"
                    }
                ],
                "caption": "Figure 1: Validation results when retraining a classifier on a frozen hypothesis encoder (cHypoth, retrained) compared to our methods (cNLI), the adversarial hypothesisonly classifier (cHypoth, in AdvCls), majority baseline, a random frozen encoder, and a hypothesis-only model.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Validation results when retraining a classifier on a frozen hypothesis encoder (cHypoth, retrained) compared to our methods (cNLI), the adversarial hypothesisonly classifier (cHypoth, in AdvCls), majority baseline, a random frozen encoder, and a hypothesis-only model.",
            "categories": "['cs.CL']",
            "figure_id": "1907.04389v1-Figure1-1",
            "image_path": "1907.04389v1-Figure1-1.png",
            "instance_id": "c2ab935a1ade7df5d526f7509f2bb5d6",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "In the bottom figure, which of the four lines has the highest accuracy for the value of the x-axis equal to 0.1, 0.1?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "cHypoth, retrained"
                    },
                    {
                        "B": "cHypoth"
                    },
                    {
                        "C": "Random"
                    },
                    {
                        "D": "Adversarial Attack"
                    }
                ],
                "caption": "Figure 1: Validation results when retraining a classifier on a frozen hypothesis encoder (cHypoth, retrained) compared to our methods (cNLI), the adversarial hypothesisonly classifier (cHypoth, in AdvCls), majority baseline, a random frozen encoder, and a hypothesis-only model.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Validation results when retraining a classifier on a frozen hypothesis encoder (cHypoth, retrained) compared to our methods (cNLI), the adversarial hypothesisonly classifier (cHypoth, in AdvCls), majority baseline, a random frozen encoder, and a hypothesis-only model.",
            "categories": "['cs.CL']",
            "figure_id": "1907.04389v1-Figure1-1",
            "image_path": "1907.04389v1-Figure1-1.png",
            "instance_id": "9b0c46dd93c5d9627bc94da1483f1a24",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of these is not a method depicted in Figure 1?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Validation results when retraining a classifier on a frozen hypothesis encoder (cHypoth, retrained) compared to our methods (cNLI), the adversarial hypothesisonly classifier (cHypoth, in AdvCls), majority baseline, a random frozen encoder, and a hypothesis-only model.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Validation results when retraining a classifier on a frozen hypothesis encoder (cHypoth, retrained) compared to our methods (cNLI), the adversarial hypothesisonly classifier (cHypoth, in AdvCls), majority baseline, a random frozen encoder, and a hypothesis-only model.",
            "categories": "['cs.CL']",
            "figure_id": "1907.04389v1-Figure1-1",
            "image_path": "1907.04389v1-Figure1-1.png",
            "instance_id": "61ae907eb287ed3b9590dbcfe68b8e44",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific dataset used for training and validation?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 4. PER on different amounts of cross-lingual data using a full network end-to-end adaptation (retraining).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 4. PER on different amounts of cross-lingual data using a full network end-to-end adaptation (retraining).",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "1802.07420v2-Figure4-1",
            "image_path": "1802.07420v2-Figure4-1.png",
            "instance_id": "262e121f64f74a66d03d56e0151afbe1",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of the green line with circle markers at 50% on the x-axis?",
            "reference_answer": "40 - 50"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 4. PER on different amounts of cross-lingual data using a full network end-to-end adaptation (retraining).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 4. PER on different amounts of cross-lingual data using a full network end-to-end adaptation (retraining).",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "1802.07420v2-Figure4-1",
            "image_path": "1802.07420v2-Figure4-1.png",
            "instance_id": "03ecb03710abcc19576b5813cee47401",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the highest amount of training data used for full network adaptation according to figure 4?",
            "reference_answer": "50%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 4. PER on different amounts of cross-lingual data using a full network end-to-end adaptation (retraining).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 4. PER on different amounts of cross-lingual data using a full network end-to-end adaptation (retraining).",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "1802.07420v2-Figure4-1",
            "image_path": "1802.07420v2-Figure4-1.png",
            "instance_id": "9196f4490e7d39be1821b4408182bf7f",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the green line represent the phoneme error rate for Tamil?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the green line represents the phoneme error rate for Tamil.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 4. PER on different amounts of cross-lingual data using a full network end-to-end adaptation (retraining).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 4. PER on different amounts of cross-lingual data using a full network end-to-end adaptation (retraining).",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "1802.07420v2-Figure4-1",
            "image_path": "1802.07420v2-Figure4-1.png",
            "instance_id": "6a6c6920a3bc46aa412c878c07faf16d",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the phoneme error rate (PER) increase as the percentage of cross-lingual training data increases for all languages?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, the phoneme error rate (PER) does not increase as the percentage of cross-lingual training data increases for all languages. In fact, the PER generally decreases with an increase in the percentage of training data for the languages shown in the graph.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The blue line"
                    },
                    {
                        "B": "The green line"
                    },
                    {
                        "C": "The orange line"
                    },
                    {
                        "D": "The purple line"
                    }
                ],
                "caption": "Fig. 4. PER on different amounts of cross-lingual data using a full network end-to-end adaptation (retraining).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 4. PER on different amounts of cross-lingual data using a full network end-to-end adaptation (retraining).",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "1802.07420v2-Figure4-1",
            "image_path": "1802.07420v2-Figure4-1.png",
            "instance_id": "78e320d9c2d01b4f9052bdf9d52cac5d",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line in the figure is associated with the language Tamil?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Amharic"
                    },
                    {
                        "B": "Swahili"
                    },
                    {
                        "C": "Tamil"
                    },
                    {
                        "D": "Kurmanji"
                    }
                ],
                "caption": "Fig. 4. PER on different amounts of cross-lingual data using a full network end-to-end adaptation (retraining).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 4. PER on different amounts of cross-lingual data using a full network end-to-end adaptation (retraining).",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "1802.07420v2-Figure4-1",
            "image_path": "1802.07420v2-Figure4-1.png",
            "instance_id": "27bf8c3d8fd6a738ad9d61d0936a1a5e",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which language(s) have a higher phoneme error rate (PER) when using a full network adaptation compared to using a monolingual model on 100% data?",
            "reference_answer": "A,B,C,D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ABCD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 4. PER on different amounts of cross-lingual data using a full network end-to-end adaptation (retraining).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 4. PER on different amounts of cross-lingual data using a full network end-to-end adaptation (retraining).",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "1802.07420v2-Figure4-1",
            "image_path": "1802.07420v2-Figure4-1.png",
            "instance_id": "ac08e909b22c315d6766dfa604757263",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific type of machine learning used for this 'Full Network Adaptation' model?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Elementary trees for the verb read with negation didnt in its extended projection. The semantic tree does not contain the negation; it is a separate tree.",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Elementary trees for the verb read with negation didnt in its extended projection. The semantic tree does not contain the negation; it is a separate tree.",
            "categories": "nan",
            "figure_id": "W12-4626.pdf-Figure5",
            "image_path": "W12-4626.pdf-Figure5.png",
            "instance_id": "79b087aceaef9a2ff75ae302f3c37e71",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the right child of 't' in the middle tree?",
            "reference_answer": "<e, t>"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The right child of 't' in the middle tree is \u3008e,t\u3009.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Elementary trees for the verb read with negation didnt in its extended projection. The semantic tree does not contain the negation; it is a separate tree.",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Elementary trees for the verb read with negation didnt in its extended projection. The semantic tree does not contain the negation; it is a separate tree.",
            "categories": "nan",
            "figure_id": "W12-4626.pdf-Figure5",
            "image_path": "W12-4626.pdf-Figure5.png",
            "instance_id": "83f4d6773ab474ba154f87d3b04b5e73",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What are the total number of nodes in the negation tree?",
            "reference_answer": "3"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Elementary trees for the verb read with negation didnt in its extended projection. The semantic tree does not contain the negation; it is a separate tree.",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Elementary trees for the verb read with negation didnt in its extended projection. The semantic tree does not contain the negation; it is a separate tree.",
            "categories": "nan",
            "figure_id": "W12-4626.pdf-Figure5",
            "image_path": "W12-4626.pdf-Figure5.png",
            "instance_id": "65188e2a32bb6742e07d7c3706a60297",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the 'negation tree' positioned to the right of the 'semantic tree' in the figure?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the 'negation tree' is positioned to the right of the 'semantic tree' in the figure.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Elementary trees for the verb read with negation didnt in its extended projection. The semantic tree does not contain the negation; it is a separate tree.",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Elementary trees for the verb read with negation didnt in its extended projection. The semantic tree does not contain the negation; it is a separate tree.",
            "categories": "nan",
            "figure_id": "W12-4626.pdf-Figure5",
            "image_path": "W12-4626.pdf-Figure5.png",
            "instance_id": "27589ff530336ee1b7d236f5bcae2062",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the semantic tree in Figure 5 include the negation 'didn't'?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the semantic tree does reflect the negation 'didn't' through its structure, as it represents negation in the context of the sentence.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The syntax tree is located to the left, and it is a branching tree structure."
                    },
                    {
                        "B": "The negation tree is positioned to the right, and it is a triangular tree structure."
                    },
                    {
                        "C": "The semantic tree is in the center, and it has a multi-level branching structure."
                    },
                    {
                        "D": "All of the above"
                    }
                ],
                "caption": "Figure 5: Elementary trees for the verb read with negation didnt in its extended projection. The semantic tree does not contain the negation; it is a separate tree.",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Elementary trees for the verb read with negation didnt in its extended projection. The semantic tree does not contain the negation; it is a separate tree.",
            "categories": "nan",
            "figure_id": "W12-4626.pdf-Figure5",
            "image_path": "W12-4626.pdf-Figure5.png",
            "instance_id": "b60b4006d4baaf3037d8e0a0a70e79c6",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Considering the position and shape of the trees in Figure 5, which statements are correct?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ACD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The semantic tree includes the negation 'didn't'."
                    },
                    {
                        "B": "The figure shows three separate trees: syntax, semantic, and negation."
                    },
                    {
                        "C": "The negation 'didn't' is represented in the syntax tree."
                    },
                    {
                        "D": "The verb 'read' appears in both the syntax and semantic trees."
                    }
                ],
                "caption": "Figure 5: Elementary trees for the verb read with negation didnt in its extended projection. The semantic tree does not contain the negation; it is a separate tree.",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Elementary trees for the verb read with negation didnt in its extended projection. The semantic tree does not contain the negation; it is a separate tree.",
            "categories": "nan",
            "figure_id": "W12-4626.pdf-Figure5",
            "image_path": "W12-4626.pdf-Figure5.png",
            "instance_id": "abd1b92678c6f33498dbb5d4d46d6cb6",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "According to Figure 5 and its caption, which of the following statements are true?",
            "reference_answer": "BCD"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "BCDA",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Elementary trees for the verb read with negation didnt in its extended projection. The semantic tree does not contain the negation; it is a separate tree.",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Elementary trees for the verb read with negation didnt in its extended projection. The semantic tree does not contain the negation; it is a separate tree.",
            "categories": "nan",
            "figure_id": "W12-4626.pdf-Figure5",
            "image_path": "W12-4626.pdf-Figure5.png",
            "instance_id": "e08ffd65247a889d88853ec2a976228b",
            "qa_pair_type": "unanswerable",
            "question": "What is the grammatical function of DP2 in the syntax tree?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: AE+NN+Weighted-Learning",
                "compound": false,
                "figure_type": "Neural Networks",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: AE+NN+Weighted-Learning",
            "categories": "nan",
            "figure_id": "Y18-1005.pdf-Figure1",
            "image_path": "Y18-1005.pdf-Figure1.png",
            "instance_id": "5d884192b1803fa88a3534bf0cd41a34",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the color of the arrow pointing from the encoded input to the NN box?",
            "reference_answer": "Blue"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The color of the arrow pointing from the encoded input to the NN box is blue.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: AE+NN+Weighted-Learning",
                "compound": false,
                "figure_type": "Neural Networks",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: AE+NN+Weighted-Learning",
            "categories": "nan",
            "figure_id": "Y18-1005.pdf-Figure1",
            "image_path": "Y18-1005.pdf-Figure1.png",
            "instance_id": "63cb6f70fa19da463e58b5464da8d42b",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "Which variable denotes 'weight'?",
            "reference_answer": "w"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The variable that denotes 'weight' is \\( w \\).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: AE+NN+Weighted-Learning",
                "compound": false,
                "figure_type": "Neural Networks",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: AE+NN+Weighted-Learning",
            "categories": "nan",
            "figure_id": "Y18-1005.pdf-Figure1",
            "image_path": "Y18-1005.pdf-Figure1.png",
            "instance_id": "3c1726402d862b6c866135b8ca8a84b1",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the red arrow pointing to the NN box?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, the red arrow is not pointing to the NN box.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: AE+NN+Weighted-Learning",
                "compound": false,
                "figure_type": "Neural Networks",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: AE+NN+Weighted-Learning",
            "categories": "nan",
            "figure_id": "Y18-1005.pdf-Figure1",
            "image_path": "Y18-1005.pdf-Figure1.png",
            "instance_id": "43ec790f30da118593fd9fc55145bf09",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the Autoencoder block connected to 'label'?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Left"
                    },
                    {
                        "B": "Right"
                    },
                    {
                        "C": "Up"
                    },
                    {
                        "D": "Down"
                    }
                ],
                "caption": "Figure 1: AE+NN+Weighted-Learning",
                "compound": false,
                "figure_type": "Neural Networks",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: AE+NN+Weighted-Learning",
            "categories": "nan",
            "figure_id": "Y18-1005.pdf-Figure1",
            "image_path": "Y18-1005.pdf-Figure1.png",
            "instance_id": "5a38f0b1235d5d0e3898db855c0d17ea",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What is the direction of the arrow labeled W2?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "xs"
                    },
                    {
                        "B": "encoded xs"
                    },
                    {
                        "C": "y'"
                    },
                    {
                        "D": "y"
                    }
                ],
                "caption": "Figure 1: AE+NN+Weighted-Learning",
                "compound": false,
                "figure_type": "Neural Networks",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: AE+NN+Weighted-Learning",
            "categories": "nan",
            "figure_id": "Y18-1005.pdf-Figure1",
            "image_path": "Y18-1005.pdf-Figure1.png",
            "instance_id": "1cd3a04820fd9088d946f4985d5ec454",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the output of the NN block?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "BC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: AE+NN+Weighted-Learning",
                "compound": false,
                "figure_type": "Neural Networks",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: AE+NN+Weighted-Learning",
            "categories": "nan",
            "figure_id": "Y18-1005.pdf-Figure1",
            "image_path": "Y18-1005.pdf-Figure1.png",
            "instance_id": "477e9891f85f275c124fe28def4b53d3",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific type of neural network used in the AE+NN+Weighted-Learning architecture shown in Figure 1?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Generation of concentrated modification structure",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Generation of concentrated modification structure",
            "categories": "nan",
            "figure_id": "Y05-1028.pdf-Figure5",
            "image_path": "Y05-1028.pdf-Figure5.png",
            "instance_id": "bfd7cc7386c1cf2cae6b473e0c31e01d",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the label of the triangle directly below the 'AND' label in the lower-right structure in tree 'c'?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The label of the triangle directly below the 'AND' label in the lower-right structure in tree 'c' is 'A'.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Generation of concentrated modification structure",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Generation of concentrated modification structure",
            "categories": "nan",
            "figure_id": "Y05-1028.pdf-Figure5",
            "image_path": "Y05-1028.pdf-Figure5.png",
            "instance_id": "65a9a757a7a9651485693bb166284a2e",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "How many 'B1' blocks are in tree 'b'?",
            "reference_answer": "2"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "There is one 'B1' block in tree 'b'.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Generation of concentrated modification structure",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Generation of concentrated modification structure",
            "categories": "nan",
            "figure_id": "Y05-1028.pdf-Figure5",
            "image_path": "Y05-1028.pdf-Figure5.png",
            "instance_id": "d54dc950644b3e4a030156f9790596ae",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the shape of the 'Lambda' symbol above the 'AND' node in the rightmost structure of the image a triangle?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the shape of the 'Lambda' symbol above the 'AND' node in the rightmost structure of the image is a triangle.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Generation of concentrated modification structure",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Generation of concentrated modification structure",
            "categories": "nan",
            "figure_id": "Y05-1028.pdf-Figure5",
            "image_path": "Y05-1028.pdf-Figure5.png",
            "instance_id": "237f16f84120241e635bc60447aac0c4",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the figure contain structures labeled as 'upper unit structure' and 'lower unit structure'?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The figure contains structures labeled as 'upper unit structure' and 'lower unit structure'.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "AND"
                    },
                    {
                        "B": "OR"
                    },
                    {
                        "C": "A"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 5: Generation of concentrated modification structure",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Generation of concentrated modification structure",
            "categories": "nan",
            "figure_id": "Y05-1028.pdf-Figure5",
            "image_path": "Y05-1028.pdf-Figure5.png",
            "instance_id": "e52c2af882025c2956f54c9f1896c09d",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following are directly connected to 'or' from the bottom in tree 'a'?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "upper unit structure"
                    },
                    {
                        "B": "lower unit structure"
                    },
                    {
                        "C": "bottom unit structure"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 5: Generation of concentrated modification structure",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Generation of concentrated modification structure",
            "categories": "nan",
            "figure_id": "Y05-1028.pdf-Figure5",
            "image_path": "Y05-1028.pdf-Figure5.png",
            "instance_id": "150c40a4513ff43d356b6485206c0ff8",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following structures are included in the generation of concentrated modification structure?",
            "reference_answer": "A,B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Generation of concentrated modification structure",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Generation of concentrated modification structure",
            "categories": "nan",
            "figure_id": "Y05-1028.pdf-Figure5",
            "image_path": "Y05-1028.pdf-Figure5.png",
            "instance_id": "bb0641475b9830f2994e8fa7821d0db8",
            "qa_pair_type": "unanswerable",
            "question": "What is the type of concentrated modification structure depicted in Figure 5?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Multimodal architecture",
                "compound": false,
                "figure_type": "Architecture Diagram",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Multimodal architecture",
            "categories": "nan",
            "figure_id": "C00-1054.pdf-Figure1",
            "image_path": "C00-1054.pdf-Figure1.png",
            "instance_id": "ce93a64cbe9a9fd7045599bef9421a74",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the name of the component directly below UI, to the right?",
            "reference_answer": "Gesture Recognizer"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The component directly below UI, to the right, is called Gesture Recognizer.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Multimodal architecture",
                "compound": false,
                "figure_type": "Architecture Diagram",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Multimodal architecture",
            "categories": "nan",
            "figure_id": "C00-1054.pdf-Figure1",
            "image_path": "C00-1054.pdf-Figure1.png",
            "instance_id": "400ac90e5ad9c089b3f4a6db4ef38576",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "How many blocks does figure 1 have?",
            "reference_answer": "5"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The figure has five blocks.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Multimodal architecture",
                "compound": false,
                "figure_type": "Architecture Diagram",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Multimodal architecture",
            "categories": "nan",
            "figure_id": "C00-1054.pdf-Figure1",
            "image_path": "C00-1054.pdf-Figure1.png",
            "instance_id": "c2733052e0720d2f60ee0d73381ef43a",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the UI component have direct arrows pointing to the Backend component?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, the UI component does not have direct arrows pointing to the Backend component.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Multimodal architecture",
                "compound": false,
                "figure_type": "Architecture Diagram",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Multimodal architecture",
            "categories": "nan",
            "figure_id": "C00-1054.pdf-Figure1",
            "image_path": "C00-1054.pdf-Figure1.png",
            "instance_id": "c51d808a10aeae0f3aefaa539c01be35",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the UI connected to the ASR component?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the UI is connected to the ASR component.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "ASR"
                    },
                    {
                        "B": "Gesture Recognizer"
                    },
                    {
                        "C": "Backend"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 1: Multimodal architecture",
                "compound": false,
                "figure_type": "Architecture Diagram",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Multimodal architecture",
            "categories": "nan",
            "figure_id": "C00-1054.pdf-Figure1",
            "image_path": "C00-1054.pdf-Figure1.png",
            "instance_id": "8a8dbd755aa684d81d52be69e5f52fca",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following components is connected to the left of UI?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "UI"
                    },
                    {
                        "B": "ASR"
                    },
                    {
                        "C": "Gesture Recognizer"
                    },
                    {
                        "D": "Backend"
                    }
                ],
                "caption": "Figure 1: Multimodal architecture",
                "compound": false,
                "figure_type": "Architecture Diagram",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Multimodal architecture",
            "categories": "nan",
            "figure_id": "C00-1054.pdf-Figure1",
            "image_path": "C00-1054.pdf-Figure1.png",
            "instance_id": "53ea2e2ba45a59da5f7b3dc7509408e6",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following components interact directly with the Multimodal Parser/Understander?",
            "reference_answer": "B,C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "BC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Multimodal architecture",
                "compound": false,
                "figure_type": "Architecture Diagram",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Multimodal architecture",
            "categories": "nan",
            "figure_id": "C00-1054.pdf-Figure1",
            "image_path": "C00-1054.pdf-Figure1.png",
            "instance_id": "eba7f3ab37ac358d551d5813ddd1f212",
            "qa_pair_type": "unanswerable",
            "question": "What machine learning algorithm is used for the ASR component in the multimodal architecture?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Visualization of the first two eigenvectors of style matrices on four subcorpora with ratings ranging in 1, 2, 4, 5, collected from Yelp review dataset. The reviews with higher rating are more positive in attitude and vice versa.",
                "compound": false,
                "figure_type": "Vector plot",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Visualization of the first two eigenvectors of style matrices on four subcorpora with ratings ranging in 1, 2, 4, 5, collected from Yelp review dataset. The reviews with higher rating are more positive in attitude and vice versa.",
            "categories": "['cs.CL']",
            "figure_id": "1908.05947v1-Figure1-1",
            "image_path": "1908.05947v1-Figure1-1.png",
            "instance_id": "3bc87daeadc8453b4fc748ff5d94c80e",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the color of the arrow representing a rating of 1?",
            "reference_answer": "Blue"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The color of the arrow representing a rating of 1 is blue.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Visualization of the first two eigenvectors of style matrices on four subcorpora with ratings ranging in 1, 2, 4, 5, collected from Yelp review dataset. The reviews with higher rating are more positive in attitude and vice versa.",
                "compound": false,
                "figure_type": "Vector plot",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Visualization of the first two eigenvectors of style matrices on four subcorpora with ratings ranging in 1, 2, 4, 5, collected from Yelp review dataset. The reviews with higher rating are more positive in attitude and vice versa.",
            "categories": "['cs.CL']",
            "figure_id": "1908.05947v1-Figure1-1",
            "image_path": "1908.05947v1-Figure1-1.png",
            "instance_id": "054739ff6511d700f52efbb09714b7d5",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "Which rating has the strongest positive attitude?",
            "reference_answer": "Rating 5"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The rating with the strongest positive attitude is Rating 5.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Visualization of the first two eigenvectors of style matrices on four subcorpora with ratings ranging in 1, 2, 4, 5, collected from Yelp review dataset. The reviews with higher rating are more positive in attitude and vice versa.",
                "compound": false,
                "figure_type": "Vector plot",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Visualization of the first two eigenvectors of style matrices on four subcorpora with ratings ranging in 1, 2, 4, 5, collected from Yelp review dataset. The reviews with higher rating are more positive in attitude and vice versa.",
            "categories": "['cs.CL']",
            "figure_id": "1908.05947v1-Figure1-1",
            "image_path": "1908.05947v1-Figure1-1.png",
            "instance_id": "12c4b53bba0c8a5595f248e7479d1880",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the arrow representing Rating 1 positioned in the same direction as the arrow representing Rating 5?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Visualization of the first two eigenvectors of style matrices on four subcorpora with ratings ranging in 1, 2, 4, 5, collected from Yelp review dataset. The reviews with higher rating are more positive in attitude and vice versa.",
                "compound": false,
                "figure_type": "Vector plot",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Visualization of the first two eigenvectors of style matrices on four subcorpora with ratings ranging in 1, 2, 4, 5, collected from Yelp review dataset. The reviews with higher rating are more positive in attitude and vice versa.",
            "categories": "['cs.CL']",
            "figure_id": "1908.05947v1-Figure1-1",
            "image_path": "1908.05947v1-Figure1-1.png",
            "instance_id": "e9017d1b329b7fe80dcc14c3b927ba87",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is 1.0 the maximum z1 value shown in figure 1's x-axis?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, 1.0 is the maximum z1 value shown in the figure's x-axis.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The arrow labeled 'weak negative'"
                    },
                    {
                        "B": "The arrow labeled 'weak positive'"
                    },
                    {
                        "C": "The arrow labeled 'strong positive'"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 1: Visualization of the first two eigenvectors of style matrices on four subcorpora with ratings ranging in 1, 2, 4, 5, collected from Yelp review dataset. The reviews with higher rating are more positive in attitude and vice versa.",
                "compound": false,
                "figure_type": "Vector plot",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Visualization of the first two eigenvectors of style matrices on four subcorpora with ratings ranging in 1, 2, 4, 5, collected from Yelp review dataset. The reviews with higher rating are more positive in attitude and vice versa.",
            "categories": "['cs.CL']",
            "figure_id": "1908.05947v1-Figure1-1",
            "image_path": "1908.05947v1-Figure1-1.png",
            "instance_id": "317e9d2301b63db82347c05561fb8e5b",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which arrow is the closest in direction to the arrow labeled 'strong negative'?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Rating 1"
                    },
                    {
                        "B": "Rating 2"
                    },
                    {
                        "C": "Rating 4"
                    },
                    {
                        "D": "Rating 5"
                    }
                ],
                "caption": "Figure 1: Visualization of the first two eigenvectors of style matrices on four subcorpora with ratings ranging in 1, 2, 4, 5, collected from Yelp review dataset. The reviews with higher rating are more positive in attitude and vice versa.",
                "compound": false,
                "figure_type": "Vector plot",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Visualization of the first two eigenvectors of style matrices on four subcorpora with ratings ranging in 1, 2, 4, 5, collected from Yelp review dataset. The reviews with higher rating are more positive in attitude and vice versa.",
            "categories": "['cs.CL']",
            "figure_id": "1908.05947v1-Figure1-1",
            "image_path": "1908.05947v1-Figure1-1.png",
            "instance_id": "4f1034d7d92e8964c6604f7f47fc8501",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following rating corresponds to 'weak negative'?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Visualization of the first two eigenvectors of style matrices on four subcorpora with ratings ranging in 1, 2, 4, 5, collected from Yelp review dataset. The reviews with higher rating are more positive in attitude and vice versa.",
                "compound": false,
                "figure_type": "Vector plot",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Visualization of the first two eigenvectors of style matrices on four subcorpora with ratings ranging in 1, 2, 4, 5, collected from Yelp review dataset. The reviews with higher rating are more positive in attitude and vice versa.",
            "categories": "['cs.CL']",
            "figure_id": "1908.05947v1-Figure1-1",
            "image_path": "1908.05947v1-Figure1-1.png",
            "instance_id": "4bd98bbba6dbac3c57ddf4a795006044",
            "qa_pair_type": "unanswerable",
            "question": "What specific phrases were used to generate the style matrix for rating 4?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: Shared Sub-Task C, training data instance share (IND, GRP and OTH)",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Shared Sub-Task C, training data instance share (IND, GRP and OTH)",
            "categories": "nan",
            "figure_id": "S19-2097.pdf-Figure7",
            "image_path": "S19-2097.pdf-Figure7.png",
            "instance_id": "860f64f3cb49e72aae8347b64eed785c",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What percentage of the pie chart is represented by the grey section?",
            "reference_answer": "27.7%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "27.7%",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: Shared Sub-Task C, training data instance share (IND, GRP and OTH)",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Shared Sub-Task C, training data instance share (IND, GRP and OTH)",
            "categories": "nan",
            "figure_id": "S19-2097.pdf-Figure7",
            "image_path": "S19-2097.pdf-Figure7.png",
            "instance_id": "da0f387e345151f98a9f44316c099287",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What percentage of the training data instance share is represented by GRP?",
            "reference_answer": "27.7%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "27.7%",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: Shared Sub-Task C, training data instance share (IND, GRP and OTH)",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Shared Sub-Task C, training data instance share (IND, GRP and OTH)",
            "categories": "nan",
            "figure_id": "S19-2097.pdf-Figure7",
            "image_path": "S19-2097.pdf-Figure7.png",
            "instance_id": "ddf417d80997e48612ca2f12d98d7ed1",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the red slice of the pie chart larger than the gray slice?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The red slice is 62.1%, while the gray slice is 27.7%.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: Shared Sub-Task C, training data instance share (IND, GRP and OTH)",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Shared Sub-Task C, training data instance share (IND, GRP and OTH)",
            "categories": "nan",
            "figure_id": "S19-2097.pdf-Figure7",
            "image_path": "S19-2097.pdf-Figure7.png",
            "instance_id": "41e209a19b9b4de6ed007039cad2d774",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the percentage of IND lower than the combined percentage of GRP and OTH?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Red"
                    },
                    {
                        "B": "Gray"
                    },
                    {
                        "C": "Light yellow"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 7: Shared Sub-Task C, training data instance share (IND, GRP and OTH)",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Shared Sub-Task C, training data instance share (IND, GRP and OTH)",
            "categories": "nan",
            "figure_id": "S19-2097.pdf-Figure7",
            "image_path": "S19-2097.pdf-Figure7.png",
            "instance_id": "ebaa4aef18987d56edba21f75f7839dd",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following pie chart slices represent the training data instance share for OTH?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "IND"
                    },
                    {
                        "B": "GRP"
                    },
                    {
                        "C": "OTH"
                    },
                    {
                        "D": "IND and GRP"
                    }
                ],
                "caption": "Figure 7: Shared Sub-Task C, training data instance share (IND, GRP and OTH)",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Shared Sub-Task C, training data instance share (IND, GRP and OTH)",
            "categories": "nan",
            "figure_id": "S19-2097.pdf-Figure7",
            "image_path": "S19-2097.pdf-Figure7.png",
            "instance_id": "e09a7692fd0ad926ffcbe6a743968cf2",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following categories represent more than 50% of the data instance share? ",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: Shared Sub-Task C, training data instance share (IND, GRP and OTH)",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Shared Sub-Task C, training data instance share (IND, GRP and OTH)",
            "categories": "nan",
            "figure_id": "S19-2097.pdf-Figure7",
            "image_path": "S19-2097.pdf-Figure7.png",
            "instance_id": "25c1c401a5cb96b0cbd80cbb2c19d9d9",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific type of sub-task C?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Ratio of sarcasm over the dialects.",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Ratio of sarcasm over the dialects.",
            "categories": "nan",
            "figure_id": "2020.osact-1.5.pdf-Figure1",
            "image_path": "2020.osact-1.5.pdf-Figure1.png",
            "instance_id": "0ea7a75af1fe217eb1c935c85926fe44",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the percentage of sarcasm in the \"Maghreb\" dialect shown in grey?",
            "reference_answer": "38%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The percentage of sarcasm in the \"Maghreb\" dialect shown in grey is 38%.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Ratio of sarcasm over the dialects.",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Ratio of sarcasm over the dialects.",
            "categories": "nan",
            "figure_id": "2020.osact-1.5.pdf-Figure1",
            "image_path": "2020.osact-1.5.pdf-Figure1.png",
            "instance_id": "1cf26ef29bb8d871ed3d164460b7ed07",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the percentage of sarcasm in Egypt?",
            "reference_answer": "34%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The percentage of sarcasm in Egypt is 34%.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Ratio of sarcasm over the dialects.",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Ratio of sarcasm over the dialects.",
            "categories": "nan",
            "figure_id": "2020.osact-1.5.pdf-Figure1",
            "image_path": "2020.osact-1.5.pdf-Figure1.png",
            "instance_id": "fcbabcb28d0cc02d253ba7b1025764d2",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the gray segment labeled 'MSA, Sarcastic' smaller than the blue segment for Maghreb?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the gray segment labeled 'MSA, Sarcastic' (9%) is smaller than the blue segment for Maghreb (38%).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Ratio of sarcasm over the dialects.",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Ratio of sarcasm over the dialects.",
            "categories": "nan",
            "figure_id": "2020.osact-1.5.pdf-Figure1",
            "image_path": "2020.osact-1.5.pdf-Figure1.png",
            "instance_id": "7961f8be16b7764174b60ff5fe0c76b0",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the percentage of sarcasm in Levant higher than that of Gulf?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The percentage of sarcasm in Levant is 21%, which is higher than the 24% in Gulf.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "MSA"
                    },
                    {
                        "B": "Levant"
                    },
                    {
                        "C": "Egypt"
                    },
                    {
                        "D": "Maghreb"
                    }
                ],
                "caption": "Figure 1: Ratio of sarcasm over the dialects.",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Ratio of sarcasm over the dialects.",
            "categories": "nan",
            "figure_id": "2020.osact-1.5.pdf-Figure1",
            "image_path": "2020.osact-1.5.pdf-Figure1.png",
            "instance_id": "3dcaabaa2c99bf2f697c6c76d6be514f",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following regions has the highest percentage of sarcasm represented in grey?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Levant"
                    },
                    {
                        "B": "MSA"
                    },
                    {
                        "C": "Maghreb"
                    },
                    {
                        "D": "Gulf"
                    }
                ],
                "caption": "Figure 1: Ratio of sarcasm over the dialects.",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Ratio of sarcasm over the dialects.",
            "categories": "nan",
            "figure_id": "2020.osact-1.5.pdf-Figure1",
            "image_path": "2020.osact-1.5.pdf-Figure1.png",
            "instance_id": "308d9e8f3a8b1f7c5721c752cf703e8a",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following regions has the lowest ratio of sarcasm?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Ratio of sarcasm over the dialects.",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Ratio of sarcasm over the dialects.",
            "categories": "nan",
            "figure_id": "2020.osact-1.5.pdf-Figure1",
            "image_path": "2020.osact-1.5.pdf-Figure1.png",
            "instance_id": "f36f2cbc78b5b18aee29c1769fd4aacb",
            "qa_pair_type": "unanswerable",
            "question": "What is the ratio of sarcasm over the dialects in the year 2019?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3. Structure of FCGMM",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3. Structure of FCGMM",
            "categories": "nan",
            "figure_id": "O04-3005.pdf-Figure3",
            "image_path": "O04-3005.pdf-Figure3.png",
            "instance_id": "31d0036642c95cdd5993fd64b36e23ff",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "How many boxes are labeled 'Extract LPCC'?",
            "reference_answer": "3"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "There are L boxes labeled 'Extract LPCC'.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3. Structure of FCGMM",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3. Structure of FCGMM",
            "categories": "nan",
            "figure_id": "O04-3005.pdf-Figure3",
            "image_path": "O04-3005.pdf-Figure3.png",
            "instance_id": "e67d55c6999a5216cd53ee55b2a98d64",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the input to Wavelet Transform Decomposition?",
            "reference_answer": "Input Speech Signals"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The input to Wavelet Transform Decomposition is \"Input Speech Signals.\"",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3. Structure of FCGMM",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3. Structure of FCGMM",
            "categories": "nan",
            "figure_id": "O04-3005.pdf-Figure3",
            "image_path": "O04-3005.pdf-Figure3.png",
            "instance_id": "9f93d54ed0cd8380de825039fcb3ccb8",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the 'Extract LPCC' box present only once in the diagram?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, the 'Extract LPCC' box is present multiple times in the diagram.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3. Structure of FCGMM",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3. Structure of FCGMM",
            "categories": "nan",
            "figure_id": "O04-3005.pdf-Figure3",
            "image_path": "O04-3005.pdf-Figure3.png",
            "instance_id": "68536d9235e196a392eeac962ac1e0ae",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is LPCC extracted from both full-band and sub-bands?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Wavelet Transform Decomposition"
                    },
                    {
                        "B": "Input Speech Signals"
                    },
                    {
                        "C": "Subband-1"
                    },
                    {
                        "D": "Extract LPCC"
                    }
                ],
                "caption": "Figure 3. Structure of FCGMM",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3. Structure of FCGMM",
            "categories": "nan",
            "figure_id": "O04-3005.pdf-Figure3",
            "image_path": "O04-3005.pdf-Figure3.png",
            "instance_id": "2f9bdc2700c9e737fa9bb1a292248027",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which block(s) are directly connected (incoming and outgoing) to the Full-band block?",
            "reference_answer": "A,D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Wavelet Transform Decomposition"
                    },
                    {
                        "B": "Extract LPCC"
                    },
                    {
                        "C": "Feature Recombination"
                    },
                    {
                        "D": "GMM"
                    }
                ],
                "caption": "Figure 3. Structure of FCGMM",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3. Structure of FCGMM",
            "categories": "nan",
            "figure_id": "O04-3005.pdf-Figure3",
            "image_path": "O04-3005.pdf-Figure3.png",
            "instance_id": "9ee80becedaa718c818bdd2146593b77",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the final step in the structure of FCGMM?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "CD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3. Structure of FCGMM",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3. Structure of FCGMM",
            "categories": "nan",
            "figure_id": "O04-3005.pdf-Figure3",
            "image_path": "O04-3005.pdf-Figure3.png",
            "instance_id": "ec20a9fcc7fb400bd5722f3cca304a86",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific type of wavelet transform used in the FCGMM structure?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Lexical Units Attention Model.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Lexical Units Attention Model.",
            "categories": "nan",
            "figure_id": "2020.acl-main.83.pdf-Figure1",
            "image_path": "2020.acl-main.83.pdf-Figure1.png",
            "instance_id": "d4d6edef8d501003982d1f58fc9b83fb",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "How many blue squares with circles are present in the Lexical Units Attention Model?",
            "reference_answer": "3"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "There are four blue squares with circles present in the Lexical Units Attention Model.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Lexical Units Attention Model.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Lexical Units Attention Model.",
            "categories": "nan",
            "figure_id": "2020.acl-main.83.pdf-Figure1",
            "image_path": "2020.acl-main.83.pdf-Figure1.png",
            "instance_id": "8575fa51f06b6f7c07efb4778c29b6ef",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the final output of the Lexical Units Attention Model?",
            "reference_answer": "Fm"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Lexical Units Attention Model.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Lexical Units Attention Model.",
            "categories": "nan",
            "figure_id": "2020.acl-main.83.pdf-Figure1",
            "image_path": "2020.acl-main.83.pdf-Figure1.png",
            "instance_id": "158eddfc6bf619e7be14d2f3a0889bb3",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Are there more blue squares than green squares in the image?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, there are more blue squares than green squares in the image.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Lexical Units Attention Model.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Lexical Units Attention Model.",
            "categories": "nan",
            "figure_id": "2020.acl-main.83.pdf-Figure1",
            "image_path": "2020.acl-main.83.pdf-Figure1.png",
            "instance_id": "108659625ea4228b277a4ab2d7c14f74",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the Lexical Units Attention Model involve a convolution mechanism?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "LU1"
                    },
                    {
                        "B": "LU2"
                    },
                    {
                        "C": "LUn-1"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 1: Lexical Units Attention Model.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Lexical Units Attention Model.",
            "categories": "nan",
            "figure_id": "2020.acl-main.83.pdf-Figure1",
            "image_path": "2020.acl-main.83.pdf-Figure1.png",
            "instance_id": "4a18dbe4cb2d041b7fee94a508f031bb",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the blue boxes labeled with 'LU' has a connecting arrow pointing to the box labeled 'Fm'?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "F_m"
                    },
                    {
                        "B": "LU_1"
                    },
                    {
                        "C": "att"
                    },
                    {
                        "D": "t^F_m"
                    }
                ],
                "caption": "Figure 1: Lexical Units Attention Model.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Lexical Units Attention Model.",
            "categories": "nan",
            "figure_id": "2020.acl-main.83.pdf-Figure1",
            "image_path": "2020.acl-main.83.pdf-Figure1.png",
            "instance_id": "55dce6baaffbd1b9f09885586e8d636e",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following are components of the Lexical Units Attention Model?",
            "reference_answer": "['A', 'B', 'C', 'D']"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ABCD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Lexical Units Attention Model.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Lexical Units Attention Model.",
            "categories": "nan",
            "figure_id": "2020.acl-main.83.pdf-Figure1",
            "image_path": "2020.acl-main.83.pdf-Figure1.png",
            "instance_id": "8f469ca22749d2a0296e5193a1092ad8",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific mathematical function used in the attention mechanism labeled 'att' in Figure 1: Lexical Units Attention Model?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: The structure of Q-network. It chooses a unlabeled subset from {U1, U2, ..., UK} at each time step. The state representation is computed according to the two classifiers N -class probability distribution on the representative example Si of each subset Ui.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: The structure of Q-network. It chooses a unlabeled subset from {U1, U2, ..., UK} at each time step. The state representation is computed according to the two classifiers N -class probability distribution on the representative example Si of each subset Ui.",
            "categories": "nan",
            "figure_id": "N18-1113.pdf-Figure3",
            "image_path": "N18-1113.pdf-Figure3.png",
            "instance_id": "fa5a2fd9a94d4bbe789650561da7cb30",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "How many green circles are there in the second row from the bottom?",
            "reference_answer": "9"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "There are three green circles in the second row from the bottom.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: The structure of Q-network. It chooses a unlabeled subset from {U1, U2, ..., UK} at each time step. The state representation is computed according to the two classifiers N -class probability distribution on the representative example Si of each subset Ui.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: The structure of Q-network. It chooses a unlabeled subset from {U1, U2, ..., UK} at each time step. The state representation is computed according to the two classifiers N -class probability distribution on the representative example Si of each subset Ui.",
            "categories": "nan",
            "figure_id": "N18-1113.pdf-Figure3",
            "image_path": "N18-1113.pdf-Figure3.png",
            "instance_id": "0e69aa0b8b03671b53c3062d3f06a84d",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the dimension of Q-values shown in figure 3?",
            "reference_answer": "K"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The dimension of Q-values shown in the figure is K.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: The structure of Q-network. It chooses a unlabeled subset from {U1, U2, ..., UK} at each time step. The state representation is computed according to the two classifiers N -class probability distribution on the representative example Si of each subset Ui.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: The structure of Q-network. It chooses a unlabeled subset from {U1, U2, ..., UK} at each time step. The state representation is computed according to the two classifiers N -class probability distribution on the representative example Si of each subset Ui.",
            "categories": "nan",
            "figure_id": "N18-1113.pdf-Figure3",
            "image_path": "N18-1113.pdf-Figure3.png",
            "instance_id": "b8533c3fc064b179b552503ad1bb2285",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Are the green circles connected to the blue circles by black arrows?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the green circles are connected to the blue circles by black arrows.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: The structure of Q-network. It chooses a unlabeled subset from {U1, U2, ..., UK} at each time step. The state representation is computed according to the two classifiers N -class probability distribution on the representative example Si of each subset Ui.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: The structure of Q-network. It chooses a unlabeled subset from {U1, U2, ..., UK} at each time step. The state representation is computed according to the two classifiers N -class probability distribution on the representative example Si of each subset Ui.",
            "categories": "nan",
            "figure_id": "N18-1113.pdf-Figure3",
            "image_path": "N18-1113.pdf-Figure3.png",
            "instance_id": "07a642e0d2e24761496b7e0a3b41d5fd",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is 'Q-keys' the output of 'Q-network'?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Blue circles"
                    },
                    {
                        "B": "Green circles"
                    },
                    {
                        "C": "Pink circles"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 3: The structure of Q-network. It chooses a unlabeled subset from {U1, U2, ..., UK} at each time step. The state representation is computed according to the two classifiers N -class probability distribution on the representative example Si of each subset Ui.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: The structure of Q-network. It chooses a unlabeled subset from {U1, U2, ..., UK} at each time step. The state representation is computed according to the two classifiers N -class probability distribution on the representative example Si of each subset Ui.",
            "categories": "nan",
            "figure_id": "N18-1113.pdf-Figure3",
            "image_path": "N18-1113.pdf-Figure3.png",
            "instance_id": "45dfcbf33b73122ddbf47d1db017285c",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following are direct inputs to the Q-network?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Two classifiers"
                    },
                    {
                        "B": "Q-keys"
                    },
                    {
                        "C": "Q-values"
                    },
                    {
                        "D": "Class probability distribution"
                    }
                ],
                "caption": "Figure 3: The structure of Q-network. It chooses a unlabeled subset from {U1, U2, ..., UK} at each time step. The state representation is computed according to the two classifiers N -class probability distribution on the representative example Si of each subset Ui.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: The structure of Q-network. It chooses a unlabeled subset from {U1, U2, ..., UK} at each time step. The state representation is computed according to the two classifiers N -class probability distribution on the representative example Si of each subset Ui.",
            "categories": "nan",
            "figure_id": "N18-1113.pdf-Figure3",
            "image_path": "N18-1113.pdf-Figure3.png",
            "instance_id": "e7e2e0bc6ef6b9070413935082c285de",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the output of the Q-network?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ACD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: The structure of Q-network. It chooses a unlabeled subset from {U1, U2, ..., UK} at each time step. The state representation is computed according to the two classifiers N -class probability distribution on the representative example Si of each subset Ui.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: The structure of Q-network. It chooses a unlabeled subset from {U1, U2, ..., UK} at each time step. The state representation is computed according to the two classifiers N -class probability distribution on the representative example Si of each subset Ui.",
            "categories": "nan",
            "figure_id": "N18-1113.pdf-Figure3",
            "image_path": "N18-1113.pdf-Figure3.png",
            "instance_id": "ef5b3142cdf8eaed14edc8c7259e5f1e",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific value of K in the image?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Illustration of the dual learning system of Logician and Orator.",
                "compound": false,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Illustration of the dual learning system of Logician and Orator.",
            "categories": "nan",
            "figure_id": "D18-1236.pdf-Figure1",
            "image_path": "D18-1236.pdf-Figure1.png",
            "instance_id": "44258bb6594671d710f5b263a857e837",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the label of the circle that has a dashed arrow pointing to the right?",
            "reference_answer": "{Sj}"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The label of the circle that has a dashed arrow pointing to the right is {F_i}.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Illustration of the dual learning system of Logician and Orator.",
                "compound": false,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Illustration of the dual learning system of Logician and Orator.",
            "categories": "nan",
            "figure_id": "D18-1236.pdf-Figure1",
            "image_path": "D18-1236.pdf-Figure1.png",
            "instance_id": "d13bbc6be43ed7d6ac1121ac7f64b12b",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "How many nodes are depicted in figure 1?",
            "reference_answer": "4"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "There are 6 nodes depicted in the figure.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Illustration of the dual learning system of Logician and Orator.",
                "compound": false,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Illustration of the dual learning system of Logician and Orator.",
            "categories": "nan",
            "figure_id": "D18-1236.pdf-Figure1",
            "image_path": "D18-1236.pdf-Figure1.png",
            "instance_id": "ac86e27436740193f7aa3a99ff2707b4",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Are the arrows representing the 'Logician' relationships between 'S' and '{F_i}'  solid?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, the arrows representing the 'Logician' relationships between 'S' and '{F_i}' are dashed, not solid.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Illustration of the dual learning system of Logician and Orator.",
                "compound": false,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Illustration of the dual learning system of Logician and Orator.",
            "categories": "nan",
            "figure_id": "D18-1236.pdf-Figure1",
            "image_path": "D18-1236.pdf-Figure1.png",
            "instance_id": "61ae618af3814be06da5bcd7a636f250",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the dual learning system of Logician and Orator involve two separate feedback loops?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "S -> {F_i}"
                    },
                    {
                        "B": "{S_j} -> F"
                    },
                    {
                        "C": "{F_i} -> {S_j}"
                    },
                    {
                        "D": "F -> {F_i}"
                    }
                ],
                "caption": "Figure 1: Illustration of the dual learning system of Logician and Orator.",
                "compound": false,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Illustration of the dual learning system of Logician and Orator.",
            "categories": "nan",
            "figure_id": "D18-1236.pdf-Figure1",
            "image_path": "D18-1236.pdf-Figure1.png",
            "instance_id": "cfe2712c98a9b7b29405d7702b516cb1",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following arrows are represented by a dashed line?",
            "reference_answer": "B,D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "S -> F"
                    },
                    {
                        "B": "{Sj} -> F"
                    },
                    {
                        "C": "S -> {Fi}"
                    },
                    {
                        "D": "{Sj} -> {Fi}"
                    }
                ],
                "caption": "Figure 1: Illustration of the dual learning system of Logician and Orator.",
                "compound": false,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Illustration of the dual learning system of Logician and Orator.",
            "categories": "nan",
            "figure_id": "D18-1236.pdf-Figure1",
            "image_path": "D18-1236.pdf-Figure1.png",
            "instance_id": "adc377501cb796b48776c97c482aabff",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following does not have a connection between them?",
            "reference_answer": "A,D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "BD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Illustration of the dual learning system of Logician and Orator.",
                "compound": false,
                "figure_type": "graph",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Illustration of the dual learning system of Logician and Orator.",
            "categories": "nan",
            "figure_id": "D18-1236.pdf-Figure1",
            "image_path": "D18-1236.pdf-Figure1.png",
            "instance_id": "019be9c1cfad63cd0db59a09e22bb682",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific value of the reward function R_2(F, S_j) in the Orator learning system?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Histogram of the ratio of the decoding steps needed to generate a sentence with tree-based decoding with respect to sequential generation.",
                "compound": false,
                "figure_type": "histogram",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Histogram of the ratio of the decoding steps needed to generate a sentence with tree-based decoding with respect to sequential generation.",
            "categories": "['cs.CL']",
            "figure_id": "2004.02211v2-Figure6-1",
            "image_path": "2004.02211v2-Figure6-1.png",
            "instance_id": "1218699bb9c083b623bee9db52a7ea4c",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the x-value at the gray bars representing the 'ideal binary tree' reach a maximum?",
            "reference_answer": "0.1 - 0.2"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Histogram of the ratio of the decoding steps needed to generate a sentence with tree-based decoding with respect to sequential generation.",
                "compound": false,
                "figure_type": "histogram",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Histogram of the ratio of the decoding steps needed to generate a sentence with tree-based decoding with respect to sequential generation.",
            "categories": "['cs.CL']",
            "figure_id": "2004.02211v2-Figure6-1",
            "image_path": "2004.02211v2-Figure6-1.png",
            "instance_id": "3684c3a0355c01e7611c7f9d8a399455",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What are the three different types of tree decoding methods shown in the histogram?",
            "reference_answer": "Binarized tree, non-binarized tree, ideal binary tree"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The three different types of tree decoding methods shown in the histogram are:\n\n1. Binarized tree (indicated by the solid purple line)\n2. Non-binarized tree (indicated by the dashed red line)\n3. Ideal binary tree (indicated by the gray histogram bars)",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Histogram of the ratio of the decoding steps needed to generate a sentence with tree-based decoding with respect to sequential generation.",
                "compound": false,
                "figure_type": "histogram",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Histogram of the ratio of the decoding steps needed to generate a sentence with tree-based decoding with respect to sequential generation.",
            "categories": "['cs.CL']",
            "figure_id": "2004.02211v2-Figure6-1",
            "image_path": "2004.02211v2-Figure6-1.png",
            "instance_id": "8e8baf6b3aa23f64ff99c9c4409cdbba",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the tallest bar in the histogram gray in color?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, the tallest bar in the histogram is not gray; it is part of the binarized tree shown in purple.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Histogram of the ratio of the decoding steps needed to generate a sentence with tree-based decoding with respect to sequential generation.",
                "compound": false,
                "figure_type": "histogram",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Histogram of the ratio of the decoding steps needed to generate a sentence with tree-based decoding with respect to sequential generation.",
            "categories": "['cs.CL']",
            "figure_id": "2004.02211v2-Figure6-1",
            "image_path": "2004.02211v2-Figure6-1.png",
            "instance_id": "bfe73e739146433ed914b3120e0b3743",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the binarized tree have a higher ratio of decoding steps with respect to sequential decoding than the ideal binary tree?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the binarized tree has a higher ratio of decoding steps with respect to sequential decoding than the ideal binary tree.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The red dashed histogram"
                    },
                    {
                        "B": "The purple solid histogram"
                    },
                    {
                        "C": "The grey histogram"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 6: Histogram of the ratio of the decoding steps needed to generate a sentence with tree-based decoding with respect to sequential generation.",
                "compound": false,
                "figure_type": "histogram",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Histogram of the ratio of the decoding steps needed to generate a sentence with tree-based decoding with respect to sequential generation.",
            "categories": "['cs.CL']",
            "figure_id": "2004.02211v2-Figure6-1",
            "image_path": "2004.02211v2-Figure6-1.png",
            "instance_id": "6696bb28a749ba56ac8a1810130ef1f5",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which histogram has the most bars that are taller than the rest of the bars in their respective histograms?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Binarized tree"
                    },
                    {
                        "B": "Non-binarized tree"
                    },
                    {
                        "C": "Ideal binary tree"
                    },
                    {
                        "D": "Both binarized and non-binarized trees"
                    }
                ],
                "caption": "Figure 6: Histogram of the ratio of the decoding steps needed to generate a sentence with tree-based decoding with respect to sequential generation.",
                "compound": false,
                "figure_type": "histogram",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Histogram of the ratio of the decoding steps needed to generate a sentence with tree-based decoding with respect to sequential generation.",
            "categories": "['cs.CL']",
            "figure_id": "2004.02211v2-Figure6-1",
            "image_path": "2004.02211v2-Figure6-1.png",
            "instance_id": "f8922895b5aa64b4f710bf250e3379c1",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which type of tree has the highest ratio of tree-based decoding steps with respect to sequential decoding?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Histogram of the ratio of the decoding steps needed to generate a sentence with tree-based decoding with respect to sequential generation.",
                "compound": false,
                "figure_type": "histogram",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Histogram of the ratio of the decoding steps needed to generate a sentence with tree-based decoding with respect to sequential generation.",
            "categories": "['cs.CL']",
            "figure_id": "2004.02211v2-Figure6-1",
            "image_path": "2004.02211v2-Figure6-1.png",
            "instance_id": "d928a3b96297afaae62272cff1b90304",
            "qa_pair_type": "unanswerable",
            "question": "What is the average ratio of the decoding steps needed to generate a sentence with tree-based decoding with respect to sequential generation for the binarized tree?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4. Accuracy measurements of two LDA models and a 2000-500-250-125-10 DBN.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4. Accuracy measurements of two LDA models and a 2000-500-250-125-10 DBN.",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1501.04325v1-Figure4-1",
            "image_path": "1501.04325v1-Figure4-1.png",
            "instance_id": "7472ffa021062636ed4cd1011df1e196",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate accuracy of the red line, DBN model, with 1 neighbor?",
            "reference_answer": "68%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4. Accuracy measurements of two LDA models and a 2000-500-250-125-10 DBN.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4. Accuracy measurements of two LDA models and a 2000-500-250-125-10 DBN.",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1501.04325v1-Figure4-1",
            "image_path": "1501.04325v1-Figure4-1.png",
            "instance_id": "d0a08cc652f3582a24419edd83280bcd",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What are the two dimensional topic distributions for LDA models?",
            "reference_answer": "12 and 150"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The two dimensional topic distributions for LDA models in the graph are:\n\n1. **12-dimensional topic distribution**\n2. **150-dimensional topic distribution**",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4. Accuracy measurements of two LDA models and a 2000-500-250-125-10 DBN.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4. Accuracy measurements of two LDA models and a 2000-500-250-125-10 DBN.",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1501.04325v1-Figure4-1",
            "image_path": "1501.04325v1-Figure4-1.png",
            "instance_id": "0f71d03fd2960c73927a24d2a6e48346",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the green line representing LDA 12-dimensional topic distribution have a higher accuracy value than the purple line representing LDA 150-dimensional topic distribution at the Neighbors value of 3?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. At the Neighbors value of 3, the green line (LDA 12-dimensional topic distribution) has a higher accuracy value than the purple line (LDA 150-dimensional topic distribution).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4. Accuracy measurements of two LDA models and a 2000-500-250-125-10 DBN.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4. Accuracy measurements of two LDA models and a 2000-500-250-125-10 DBN.",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1501.04325v1-Figure4-1",
            "image_path": "1501.04325v1-Figure4-1.png",
            "instance_id": "9051f5651c47c1c200c8cf61c2e12263",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the accuracy of the 150-dimensional LDA model consistently decrease as the number of neighbors increases?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The accuracy of the 150-dimensional LDA model consistently decreases as the number of neighbors increases.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Green"
                    },
                    {
                        "B": "Purple"
                    },
                    {
                        "C": "Red"
                    },
                    {
                        "D": "Purple and Green"
                    }
                ],
                "caption": "Figure 4. Accuracy measurements of two LDA models and a 2000-500-250-125-10 DBN.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4. Accuracy measurements of two LDA models and a 2000-500-250-125-10 DBN.",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1501.04325v1-Figure4-1",
            "image_path": "1501.04325v1-Figure4-1.png",
            "instance_id": "ac515f625843a2cb439e5ae0505ba62e",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the lines in the graph are below 60% accuracy when the value on the x-axis is 1?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "LDA 12-dimensional topic distribution"
                    },
                    {
                        "B": "LDA 150-dimensional topic distribution"
                    },
                    {
                        "C": "DBN 2000-500-250-125-10"
                    },
                    {
                        "D": "All models achieve the same accuracy"
                    }
                ],
                "caption": "Figure 4. Accuracy measurements of two LDA models and a 2000-500-250-125-10 DBN.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4. Accuracy measurements of two LDA models and a 2000-500-250-125-10 DBN.",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1501.04325v1-Figure4-1",
            "image_path": "1501.04325v1-Figure4-1.png",
            "instance_id": "a7c135728b29853dca2f8b1441880210",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following models achieves the highest accuracy when the number of neighbors is 1?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4. Accuracy measurements of two LDA models and a 2000-500-250-125-10 DBN.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4. Accuracy measurements of two LDA models and a 2000-500-250-125-10 DBN.",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1501.04325v1-Figure4-1",
            "image_path": "1501.04325v1-Figure4-1.png",
            "instance_id": "349ba75a1513aa2c8a476db4e9894b93",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific type of accuracy measurement used for each model in Figure 4?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Some metrics on mini datasets, where ATTOrder represents ATTOrderNet; Prt-Net represents LSTM+PtrNet, where V-Ptr-Net stands for Variant-LSTM+PtrNet.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Some metrics on mini datasets, where ATTOrder represents ATTOrderNet; Prt-Net represents LSTM+PtrNet, where V-Ptr-Net stands for Variant-LSTM+PtrNet.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2006.03221v1-Figure1-1",
            "image_path": "2006.03221v1-Figure1-1.png",
            "instance_id": "44dd3f237726f3036a95436d48225395",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the maximum value for the green line in the plot labeled 'Accuracy' in the second panel?",
            "reference_answer": "approximately 0.6"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Some metrics on mini datasets, where ATTOrder represents ATTOrderNet; Prt-Net represents LSTM+PtrNet, where V-Ptr-Net stands for Variant-LSTM+PtrNet.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Some metrics on mini datasets, where ATTOrder represents ATTOrderNet; Prt-Net represents LSTM+PtrNet, where V-Ptr-Net stands for Variant-LSTM+PtrNet.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2006.03221v1-Figure1-1",
            "image_path": "2006.03221v1-Figure1-1.png",
            "instance_id": "db5d1d50a2a378e80343f302cf741595",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "In the first plot \"(a) Results of WLCS-w on arXiv\" which models were used?",
            "reference_answer": "ATTOrder, Ptr-Net, SE-Graph, V-Ptr-Net"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The models used in the first plot \"(a) Results of WLCS-w on arXiv\" are:\n\n- Attender\n- PT-Net\n- SR-Graph\n- VP-Net",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Some metrics on mini datasets, where ATTOrder represents ATTOrderNet; Prt-Net represents LSTM+PtrNet, where V-Ptr-Net stands for Variant-LSTM+PtrNet.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Some metrics on mini datasets, where ATTOrder represents ATTOrderNet; Prt-Net represents LSTM+PtrNet, where V-Ptr-Net stands for Variant-LSTM+PtrNet.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2006.03221v1-Figure1-1",
            "image_path": "2006.03221v1-Figure1-1.png",
            "instance_id": "5bbbd6eb59ec9bcc555130fabf03356a",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "In the fourth graph (titled 'Accuracy'), is the green line representing 'SF-Graph' consistently higher than the orange line representing 'Ptr-Net'?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Some metrics on mini datasets, where ATTOrder represents ATTOrderNet; Prt-Net represents LSTM+PtrNet, where V-Ptr-Net stands for Variant-LSTM+PtrNet.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Some metrics on mini datasets, where ATTOrder represents ATTOrderNet; Prt-Net represents LSTM+PtrNet, where V-Ptr-Net stands for Variant-LSTM+PtrNet.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2006.03221v1-Figure1-1",
            "image_path": "2006.03221v1-Figure1-1.png",
            "instance_id": "20477c75daf70f528e34d4757c72ed8d",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does ATTOrderNet show a consistently better performance than LSTM+PtrNet on all mini datasets?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Red"
                    },
                    {
                        "B": "Green"
                    },
                    {
                        "C": "Blue"
                    },
                    {
                        "D": "Orange"
                    }
                ],
                "caption": "Figure 1: Some metrics on mini datasets, where ATTOrder represents ATTOrderNet; Prt-Net represents LSTM+PtrNet, where V-Ptr-Net stands for Variant-LSTM+PtrNet.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Some metrics on mini datasets, where ATTOrder represents ATTOrderNet; Prt-Net represents LSTM+PtrNet, where V-Ptr-Net stands for Variant-LSTM+PtrNet.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2006.03221v1-Figure1-1",
            "image_path": "2006.03221v1-Figure1-1.png",
            "instance_id": "194effb6d16511b7e7b755a8cb89ed5c",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line in the second graph represents 'V-Ptr-Net'?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "ATTOrder"
                    },
                    {
                        "B": "Ptr-Net"
                    },
                    {
                        "C": "SE-Graph"
                    },
                    {
                        "D": "V-Ptr-Net"
                    }
                ],
                "caption": "Figure 1: Some metrics on mini datasets, where ATTOrder represents ATTOrderNet; Prt-Net represents LSTM+PtrNet, where V-Ptr-Net stands for Variant-LSTM+PtrNet.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Some metrics on mini datasets, where ATTOrder represents ATTOrderNet; Prt-Net represents LSTM+PtrNet, where V-Ptr-Net stands for Variant-LSTM+PtrNet.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2006.03221v1-Figure1-1",
            "image_path": "2006.03221v1-Figure1-1.png",
            "instance_id": "5963bd14ea69b99dde587bad2ef31ef7",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following models achieves the highest WLCS-1 score on the Economist dataset with a set size of 10?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Some metrics on mini datasets, where ATTOrder represents ATTOrderNet; Prt-Net represents LSTM+PtrNet, where V-Ptr-Net stands for Variant-LSTM+PtrNet.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Some metrics on mini datasets, where ATTOrder represents ATTOrderNet; Prt-Net represents LSTM+PtrNet, where V-Ptr-Net stands for Variant-LSTM+PtrNet.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2006.03221v1-Figure1-1",
            "image_path": "2006.03221v1-Figure1-1.png",
            "instance_id": "cd18134e3c6fabd3e4bfeaaebc15ebaf",
            "qa_pair_type": "unanswerable",
            "question": "What is the maximum accuracy achieved by ATTOrderNet on the Economist dataset?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: BLEU score loss vs. maximum number of unknown words in source and target sentence when translating with the RNNenc model with and without segmentation.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: BLEU score loss vs. maximum number of unknown words in source and target sentence when translating with the RNNenc model with and without segmentation.",
            "categories": "['cs.CL cs.LG cs.NE stat.ML']",
            "figure_id": "1409.1257v2-Figure2-1",
            "image_path": "1409.1257v2-Figure2-1.png",
            "instance_id": "e6d27eba14126d7864397ec816ee6ea2",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of BLEU score decrease for the RNNenc model without segmentation, solid line,  at 4 unknown words?",
            "reference_answer": "approximately -7"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The value of BLEU score decrease for the RNNenc model without segmentation (solid line) at 4 unknown words is approximately -6.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: BLEU score loss vs. maximum number of unknown words in source and target sentence when translating with the RNNenc model with and without segmentation.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: BLEU score loss vs. maximum number of unknown words in source and target sentence when translating with the RNNenc model with and without segmentation.",
            "categories": "['cs.CL cs.LG cs.NE stat.ML']",
            "figure_id": "1409.1257v2-Figure2-1",
            "image_path": "1409.1257v2-Figure2-1.png",
            "instance_id": "1be27d9ff404ca5b2c8b7305c776f909",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the maximum value of BLEU score decrease when translating with the RNNenc model without segmentation?",
            "reference_answer": "between -8 and -9"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: BLEU score loss vs. maximum number of unknown words in source and target sentence when translating with the RNNenc model with and without segmentation.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: BLEU score loss vs. maximum number of unknown words in source and target sentence when translating with the RNNenc model with and without segmentation.",
            "categories": "['cs.CL cs.LG cs.NE stat.ML']",
            "figure_id": "1409.1257v2-Figure2-1",
            "image_path": "1409.1257v2-Figure2-1.png",
            "instance_id": "fe9664f241330fb89cda63832031875d",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the dashed line representing 'With segm.' have a consistently higher BLEU score decrease than the solid line representing 'Without segm.'?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the dashed line representing 'With segm.' consistently has a higher BLEU score decrease than the solid line representing 'Without segm.' throughout the range of the x-axis.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: BLEU score loss vs. maximum number of unknown words in source and target sentence when translating with the RNNenc model with and without segmentation.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: BLEU score loss vs. maximum number of unknown words in source and target sentence when translating with the RNNenc model with and without segmentation.",
            "categories": "['cs.CL cs.LG cs.NE stat.ML']",
            "figure_id": "1409.1257v2-Figure2-1",
            "image_path": "1409.1257v2-Figure2-1.png",
            "instance_id": "be5c20561e2b1260bf8a4000cf263c6f",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the BLEU score decrease more rapidly with segmentation than without segmentation?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the BLEU score decreases more rapidly with segmentation than without segmentation, as indicated by the steeper slope of the line labeled \"Without segm.\" compared to the line labeled \"With segm.\" in the graph.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Solid line"
                    },
                    {
                        "B": "Dashed line"
                    },
                    {
                        "C": "Both lines"
                    },
                    {
                        "D": "Neither line"
                    }
                ],
                "caption": "Figure 2: BLEU score loss vs. maximum number of unknown words in source and target sentence when translating with the RNNenc model with and without segmentation.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: BLEU score loss vs. maximum number of unknown words in source and target sentence when translating with the RNNenc model with and without segmentation.",
            "categories": "['cs.CL cs.LG cs.NE stat.ML']",
            "figure_id": "1409.1257v2-Figure2-1",
            "image_path": "1409.1257v2-Figure2-1.png",
            "instance_id": "82a3d687d8f68afdde1e38966accf17d",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line represents the BLEU score loss with segmentation?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "With segmentation"
                    },
                    {
                        "B": "Without segmentation"
                    },
                    {
                        "C": "Both models"
                    },
                    {
                        "D": "Neither model"
                    }
                ],
                "caption": "Figure 2: BLEU score loss vs. maximum number of unknown words in source and target sentence when translating with the RNNenc model with and without segmentation.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: BLEU score loss vs. maximum number of unknown words in source and target sentence when translating with the RNNenc model with and without segmentation.",
            "categories": "['cs.CL cs.LG cs.NE stat.ML']",
            "figure_id": "1409.1257v2-Figure2-1",
            "image_path": "1409.1257v2-Figure2-1.png",
            "instance_id": "be17dca4e0894b09eeeeab51de4f0944",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which model has a BLEU score decrease closer to -5 when the maximum number of unknown words in the source and target sentence is 4?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: BLEU score loss vs. maximum number of unknown words in source and target sentence when translating with the RNNenc model with and without segmentation.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: BLEU score loss vs. maximum number of unknown words in source and target sentence when translating with the RNNenc model with and without segmentation.",
            "categories": "['cs.CL cs.LG cs.NE stat.ML']",
            "figure_id": "1409.1257v2-Figure2-1",
            "image_path": "1409.1257v2-Figure2-1.png",
            "instance_id": "a6db9ae1f0721be0f7258ebb13d3157d",
            "qa_pair_type": "unanswerable",
            "question": "What is the dataset used for this experiment on the RNNenc model, and how does it affect the results?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Comparison of rankers trained on extended datasets",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison of rankers trained on extended datasets",
            "categories": "['cs.CL']",
            "figure_id": "1811.00967v1-Figure2-1",
            "image_path": "1811.00967v1-Figure2-1.png",
            "instance_id": "610bb6f9f9c7e9e7fa27240c0dd0f182",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the precision@1 value of the orange line at the trainset size of 7.10^5?",
            "reference_answer": "approximately 0.73"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Comparison of rankers trained on extended datasets",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison of rankers trained on extended datasets",
            "categories": "['cs.CL']",
            "figure_id": "1811.00967v1-Figure2-1",
            "image_path": "1811.00967v1-Figure2-1.png",
            "instance_id": "500d927149e8cb55354dbeab1ffbea2e",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the precision for the Neural@rating ranker (baseline) in all trainset sizes?",
            "reference_answer": "between 0.8 and 0.9"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Comparison of rankers trained on extended datasets",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison of rankers trained on extended datasets",
            "categories": "['cs.CL']",
            "figure_id": "1811.00967v1-Figure2-1",
            "image_path": "1811.00967v1-Figure2-1.png",
            "instance_id": "54f441e2724373bb4b31e4bad376a394",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the orange line representing 'VV@length' have a higher value than the red line representing 'Neural@length' at the trainset size of 9e5?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Comparison of rankers trained on extended datasets",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison of rankers trained on extended datasets",
            "categories": "['cs.CL']",
            "figure_id": "1811.00967v1-Figure2-1",
            "image_path": "1811.00967v1-Figure2-1.png",
            "instance_id": "ab0fe38024c70a3b3a8d935ba22c9637",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the precision of the Neural@rating model consistently higher than the precision of the VW@length model?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Red line with squares"
                    },
                    {
                        "B": "Blue line with dashes"
                    },
                    {
                        "C": "Orange line with triangles"
                    },
                    {
                        "D": "Green line with dashes"
                    }
                ],
                "caption": "Figure 2: Comparison of rankers trained on extended datasets",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison of rankers trained on extended datasets",
            "categories": "['cs.CL']",
            "figure_id": "1811.00967v1-Figure2-1",
            "image_path": "1811.00967v1-Figure2-1.png",
            "instance_id": "88dc60755dfd359122b23d0cea0e2d67",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the lines represents 'VW@rating (baseline)'?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Neural@rating (baseline)"
                    },
                    {
                        "B": "VW@rating (baseline)"
                    },
                    {
                        "C": "Neural@length"
                    },
                    {
                        "D": "VW@length"
                    }
                ],
                "caption": "Figure 2: Comparison of rankers trained on extended datasets",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison of rankers trained on extended datasets",
            "categories": "['cs.CL']",
            "figure_id": "1811.00967v1-Figure2-1",
            "image_path": "1811.00967v1-Figure2-1.png",
            "instance_id": "351d578c34f431f4d6ef150f6ade9ec2",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following rankers have a consistent precision value across all trainset sizes?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Comparison of rankers trained on extended datasets",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison of rankers trained on extended datasets",
            "categories": "['cs.CL']",
            "figure_id": "1811.00967v1-Figure2-1",
            "image_path": "1811.00967v1-Figure2-1.png",
            "instance_id": "6c531570e55a6541d7354d79afc3becb",
            "qa_pair_type": "unanswerable",
            "question": "How is precision@1 calcualted, and how does it affect the results?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Precision@1 measures the proportion of true positive results in the top prediction made by a model. It is calculated as:\n\n\\[\n\\text{Precision@1} = \\frac{\\text{Number of relevant items retrieved in top 1}}{\\text{Total items retrieved in top 1}}\n\\]\n\nIn this case, a relevant item is one that is correct for the query or need.\n\n**Impact on Results:**\n- A high precision@1 indicates that the model is effectively retrieving the most relevant item for the given input, which suggests better performance.\n- Low precision@1 may indicate that the model often makes incorrect top predictions, signaling areas for improvement in model training or feature selection.\n- The graph shows how different models perform as the training set size increases, helping to identify which approach yields better precision at varying dataset sizes.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Influence of \u03bb in Eq. (11).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Influence of \u03bb in Eq. (11).",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1905.01963v1-Figure5-1",
            "image_path": "1905.01963v1-Figure5-1.png",
            "instance_id": "3c76a8d4d7ab270ee5f0222f0dc05c3e",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of the blue line at \u03bb = 1.5 for the UPUC dataset?",
            "reference_answer": "approximately 0.87"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Influence of \u03bb in Eq. (11).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Influence of \u03bb in Eq. (11).",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1905.01963v1-Figure5-1",
            "image_path": "1905.01963v1-Figure5-1.png",
            "instance_id": "57ef8495af039fc4bd5a49edc788cfe1",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What are the metrics being used in Figure 5?",
            "reference_answer": "Precision, Recall, Fscore"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The metrics being used in Figure 5 are Precision, Recall, and F-score.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Influence of \u03bb in Eq. (11).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Influence of \u03bb in Eq. (11).",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1905.01963v1-Figure5-1",
            "image_path": "1905.01963v1-Figure5-1.png",
            "instance_id": "0c5485515274c438e85dc2ef80ad3160",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the blue line representing 'Precision' in the left graph reach a value above 0.89?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the blue line representing 'Precision' in the left graph reaches a value above 0.89.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Influence of \u03bb in Eq. (11).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Influence of \u03bb in Eq. (11).",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1905.01963v1-Figure5-1",
            "image_path": "1905.01963v1-Figure5-1.png",
            "instance_id": "bcb1f79a33bd8bc5d11bcc59d0c38c5a",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does Fscore in the left plot is consistently higher than the Fscore in the right plot?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Precision"
                    },
                    {
                        "B": "Recall"
                    },
                    {
                        "C": "Fscore"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 5: Influence of \u03bb in Eq. (11).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Influence of \u03bb in Eq. (11).",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1905.01963v1-Figure5-1",
            "image_path": "1905.01963v1-Figure5-1.png",
            "instance_id": "a7196450d8c9af5fd4f4778e96b769e1",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line presents the lowest value at  \u03bb=0 in UPUC dataset?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Yes"
                    },
                    {
                        "B": "No"
                    },
                    {
                        "C": "Fscore"
                    },
                    {
                        "D": "none of the above"
                    }
                ],
                "caption": "Figure 5: Influence of \u03bb in Eq. (11).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Influence of \u03bb in Eq. (11).",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1905.01963v1-Figure5-1",
            "image_path": "1905.01963v1-Figure5-1.png",
            "instance_id": "94708cc0940d4c406059709da5e60398",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which line is the highest at its peak in the figure labeled (a)?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Influence of \u03bb in Eq. (11).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Influence of \u03bb in Eq. (11).",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1905.01963v1-Figure5-1",
            "image_path": "1905.01963v1-Figure5-1.png",
            "instance_id": "b19fd7402eaf4a427883234601f6785f",
            "qa_pair_type": "unanswerable",
            "question": "What is the optimal value of \u03bb for the MSRA dataset, and how is it presented in the figure?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: ROUGE-L and full METEOR scores on adversarial samples, where n irrelevant sentences are inserted into original test articles. Our models (shared decoder for NYT, shared+MHA for CNN/DM) are sturdier against irrelevant information than seq2seq and pointer-generator.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: ROUGE-L and full METEOR scores on adversarial samples, where n irrelevant sentences are inserted into original test articles. Our models (shared decoder for NYT, shared+MHA for CNN/DM) are sturdier against irrelevant information than seq2seq and pointer-generator.",
            "categories": "['cs.CL']",
            "figure_id": "1810.06065v1-Figure3-1",
            "image_path": "1810.06065v1-Figure3-1.png",
            "instance_id": "7c9d04430466522a970218f39b7975e4",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of ROUGE-L score for red line ('Ours' model) when 4 irrelevant sentences are added to the CNN/DM dataset?",
            "reference_answer": "32"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: ROUGE-L and full METEOR scores on adversarial samples, where n irrelevant sentences are inserted into original test articles. Our models (shared decoder for NYT, shared+MHA for CNN/DM) are sturdier against irrelevant information than seq2seq and pointer-generator.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: ROUGE-L and full METEOR scores on adversarial samples, where n irrelevant sentences are inserted into original test articles. Our models (shared decoder for NYT, shared+MHA for CNN/DM) are sturdier against irrelevant information than seq2seq and pointer-generator.",
            "categories": "['cs.CL']",
            "figure_id": "1810.06065v1-Figure3-1",
            "image_path": "1810.06065v1-Figure3-1.png",
            "instance_id": "a0952935cd59da13f20ba3ae7163feda",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the score for the 'Ours' model when 2 irrelevant sentences are inserted into the CNN/DM articles in the METEOR evaluation?",
            "reference_answer": "approximately 16.5"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: ROUGE-L and full METEOR scores on adversarial samples, where n irrelevant sentences are inserted into original test articles. Our models (shared decoder for NYT, shared+MHA for CNN/DM) are sturdier against irrelevant information than seq2seq and pointer-generator.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: ROUGE-L and full METEOR scores on adversarial samples, where n irrelevant sentences are inserted into original test articles. Our models (shared decoder for NYT, shared+MHA for CNN/DM) are sturdier against irrelevant information than seq2seq and pointer-generator.",
            "categories": "['cs.CL']",
            "figure_id": "1810.06065v1-Figure3-1",
            "image_path": "1810.06065v1-Figure3-1.png",
            "instance_id": "8490d243f612be0c472eb5d23bf02d76",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the red line in the first graph (CNN/DM ROUGE-L)  have a higher value at n=0 than the green line in the same graph?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the red line (Ours) in the first graph (CNN/DM ROUGE-L) has a higher value at n=0 than the green line (Seq2seq).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: ROUGE-L and full METEOR scores on adversarial samples, where n irrelevant sentences are inserted into original test articles. Our models (shared decoder for NYT, shared+MHA for CNN/DM) are sturdier against irrelevant information than seq2seq and pointer-generator.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: ROUGE-L and full METEOR scores on adversarial samples, where n irrelevant sentences are inserted into original test articles. Our models (shared decoder for NYT, shared+MHA for CNN/DM) are sturdier against irrelevant information than seq2seq and pointer-generator.",
            "categories": "['cs.CL']",
            "figure_id": "1810.06065v1-Figure3-1",
            "image_path": "1810.06065v1-Figure3-1.png",
            "instance_id": "ecd6a27835d242e2c80a11a82977c1e6",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Do 'Ours' model perform better than seq2seq model in the (d) NYT METEOR plot?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, in the (d) NYT METEOR plot, the 'Ours' model performs better than the seq2seq model.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Green"
                    },
                    {
                        "B": "Red"
                    },
                    {
                        "C": "Blue"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 3: ROUGE-L and full METEOR scores on adversarial samples, where n irrelevant sentences are inserted into original test articles. Our models (shared decoder for NYT, shared+MHA for CNN/DM) are sturdier against irrelevant information than seq2seq and pointer-generator.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: ROUGE-L and full METEOR scores on adversarial samples, where n irrelevant sentences are inserted into original test articles. Our models (shared decoder for NYT, shared+MHA for CNN/DM) are sturdier against irrelevant information than seq2seq and pointer-generator.",
            "categories": "['cs.CL']",
            "figure_id": "1810.06065v1-Figure3-1",
            "image_path": "1810.06065v1-Figure3-1.png",
            "instance_id": "86db13a5dd083ba7373b19cecbce56c1",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line in the (d) NYT METEOR plot represents the \"pointer-generator\" model?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "seq2seq and pointer-generator"
                    },
                    {
                        "B": "shared decoder for NYT and shared+MHA for CNN/DM"
                    },
                    {
                        "C": "Both A and B"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 3: ROUGE-L and full METEOR scores on adversarial samples, where n irrelevant sentences are inserted into original test articles. Our models (shared decoder for NYT, shared+MHA for CNN/DM) are sturdier against irrelevant information than seq2seq and pointer-generator.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: ROUGE-L and full METEOR scores on adversarial samples, where n irrelevant sentences are inserted into original test articles. Our models (shared decoder for NYT, shared+MHA for CNN/DM) are sturdier against irrelevant information than seq2seq and pointer-generator.",
            "categories": "['cs.CL']",
            "figure_id": "1810.06065v1-Figure3-1",
            "image_path": "1810.06065v1-Figure3-1.png",
            "instance_id": "714de617f36e1e0acc1b47bbb93dbc39",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "In the (b) CNN/DM METEOR plot, which model has consistently the lowest scores?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: ROUGE-L and full METEOR scores on adversarial samples, where n irrelevant sentences are inserted into original test articles. Our models (shared decoder for NYT, shared+MHA for CNN/DM) are sturdier against irrelevant information than seq2seq and pointer-generator.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: ROUGE-L and full METEOR scores on adversarial samples, where n irrelevant sentences are inserted into original test articles. Our models (shared decoder for NYT, shared+MHA for CNN/DM) are sturdier against irrelevant information than seq2seq and pointer-generator.",
            "categories": "['cs.CL']",
            "figure_id": "1810.06065v1-Figure3-1",
            "image_path": "1810.06065v1-Figure3-1.png",
            "instance_id": "9d8189db7617d80c2b9430033f643e89",
            "qa_pair_type": "unanswerable",
            "question": "How was ROUGE-L calculated, and how does it affect the results?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 15: Effect of Fine-Tuning Objective on fixed size data: SQUAD. Showing P@10.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 15: Effect of Fine-Tuning Objective on fixed size data: SQUAD. Showing P@10.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2010.09313v1-Figure15-1",
            "image_path": "2010.09313v1-Figure15-1.png",
            "instance_id": "add8ae33391fe9b2b720cf15a30dfb1a",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the red line at the x-axis value of 18 in the fourth graph?",
            "reference_answer": "14"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 15: Effect of Fine-Tuning Objective on fixed size data: SQUAD. Showing P@10.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 15: Effect of Fine-Tuning Objective on fixed size data: SQUAD. Showing P@10.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2010.09313v1-Figure15-1",
            "image_path": "2010.09313v1-Figure15-1.png",
            "instance_id": "2611f017187562b952eac3eba2e54536",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "In subplot (b), what is the  P@10 value for 'QA-SQuAD-2' with value 5 in the x-axis?",
            "reference_answer": "approximately 10"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 15: Effect of Fine-Tuning Objective on fixed size data: SQUAD. Showing P@10.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 15: Effect of Fine-Tuning Objective on fixed size data: SQUAD. Showing P@10.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2010.09313v1-Figure15-1",
            "image_path": "2010.09313v1-Figure15-1.png",
            "instance_id": "4bcf27419d6e7cc923acccc4e64714b2",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the red line (QA-SQuAD-2) consistently higher than the purple line (MLM-SQuAD) in the plot labeled (a) ConceptNet?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. In the plot labeled (a) ConceptNet, the red line (QA-SQuAD-2) is consistently higher than the purple line (MLM-SQuAD).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 15: Effect of Fine-Tuning Objective on fixed size data: SQUAD. Showing P@10.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 15: Effect of Fine-Tuning Objective on fixed size data: SQUAD. Showing P@10.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2010.09313v1-Figure15-1",
            "image_path": "2010.09313v1-Figure15-1.png",
            "instance_id": "01d245b41c14ed837b36f2b75f031981",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "In the left plot, is the MLM-SQuAD line lower than the QA-SQuAD-2 line with x-axis between 0 and 5?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, in the left plot (ConceptNet), the MLM-SQuAD line is lower than the QA-SQuAD-2 line between x-axis values of 0 and 5.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "(a) ConceptNet"
                    },
                    {
                        "B": "(b) T-REX"
                    },
                    {
                        "C": "(c) Squad"
                    },
                    {
                        "D": "(d) Google-RE"
                    }
                ],
                "caption": "Figure 15: Effect of Fine-Tuning Objective on fixed size data: SQUAD. Showing P@10.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 15: Effect of Fine-Tuning Objective on fixed size data: SQUAD. Showing P@10.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2010.09313v1-Figure15-1",
            "image_path": "2010.09313v1-Figure15-1.png",
            "instance_id": "1bb25e01eff69bf37a03cc483eebd381",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the graphs shows the highest maximum value of P@10 for purple line?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Precision"
                    },
                    {
                        "B": "Recall"
                    },
                    {
                        "C": "F1-Score"
                    },
                    {
                        "D": "P@10"
                    }
                ],
                "caption": "Figure 15: Effect of Fine-Tuning Objective on fixed size data: SQUAD. Showing P@10.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 15: Effect of Fine-Tuning Objective on fixed size data: SQUAD. Showing P@10.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2010.09313v1-Figure15-1",
            "image_path": "2010.09313v1-Figure15-1.png",
            "instance_id": "91c78f851bb59a577f2a68dda56df305",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which is the maximum value for the P@10 in the y-axis in subplot (d)?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 15: Effect of Fine-Tuning Objective on fixed size data: SQUAD. Showing P@10.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 15: Effect of Fine-Tuning Objective on fixed size data: SQUAD. Showing P@10.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2010.09313v1-Figure15-1",
            "image_path": "2010.09313v1-Figure15-1.png",
            "instance_id": "6af6c94e9ffc25f0e138b8cde1298199",
            "qa_pair_type": "unanswerable",
            "question": "What is the fine-tuning objective used for the QA-SQuAD-2 data in Figure 15, and how does it affect the results?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 1. Annotated examples\u2019 densities by three user groups: the individuals, the teammates, and the largest team; the highlighted region corresponds to the interval between 50 and 350 examples.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 1. Annotated examples\u2019 densities by three user groups: the individuals, the teammates, and the largest team; the highlighted region corresponds to the interval between 50 and 350 examples.",
            "categories": "['cs.SI cs.CL']",
            "figure_id": "1408.4245v2-Figure1-1",
            "image_path": "1408.4245v2-Figure1-1.png",
            "instance_id": "2c830f024f3396173cf2be00b82a37d3",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate density value of the green dashed line at 50 annotated examples?",
            "reference_answer": "0.005"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 1. Annotated examples\u2019 densities by three user groups: the individuals, the teammates, and the largest team; the highlighted region corresponds to the interval between 50 and 350 examples.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 1. Annotated examples\u2019 densities by three user groups: the individuals, the teammates, and the largest team; the highlighted region corresponds to the interval between 50 and 350 examples.",
            "categories": "['cs.SI cs.CL']",
            "figure_id": "1408.4245v2-Figure1-1",
            "image_path": "1408.4245v2-Figure1-1.png",
            "instance_id": "5ed05ecdc1413c2e4a9707b3ca4ea807",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the highest density value for the 'Largest Team'?",
            "reference_answer": "between 0 and 0.005"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 1. Annotated examples\u2019 densities by three user groups: the individuals, the teammates, and the largest team; the highlighted region corresponds to the interval between 50 and 350 examples.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 1. Annotated examples\u2019 densities by three user groups: the individuals, the teammates, and the largest team; the highlighted region corresponds to the interval between 50 and 350 examples.",
            "categories": "['cs.SI cs.CL']",
            "figure_id": "1408.4245v2-Figure1-1",
            "image_path": "1408.4245v2-Figure1-1.png",
            "instance_id": "0cd8c92652b75d130bb0edafafc2c438",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the density value of the green dashed line higher than the red line at the number of annotated examples equal to 100?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 1. Annotated examples\u2019 densities by three user groups: the individuals, the teammates, and the largest team; the highlighted region corresponds to the interval between 50 and 350 examples.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 1. Annotated examples\u2019 densities by three user groups: the individuals, the teammates, and the largest team; the highlighted region corresponds to the interval between 50 and 350 examples.",
            "categories": "['cs.SI cs.CL']",
            "figure_id": "1408.4245v2-Figure1-1",
            "image_path": "1408.4245v2-Figure1-1.png",
            "instance_id": "aea56b371f804926eef7d4350cc010f1",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the density of annotated examples higher for the individuals than for the teammates with annotated examples between 200 and 300?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Red solid"
                    },
                    {
                        "B": "Blue dashed"
                    },
                    {
                        "C": "Green dashed"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Fig. 1. Annotated examples\u2019 densities by three user groups: the individuals, the teammates, and the largest team; the highlighted region corresponds to the interval between 50 and 350 examples.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 1. Annotated examples\u2019 densities by three user groups: the individuals, the teammates, and the largest team; the highlighted region corresponds to the interval between 50 and 350 examples.",
            "categories": "['cs.SI cs.CL']",
            "figure_id": "1408.4245v2-Figure1-1",
            "image_path": "1408.4245v2-Figure1-1.png",
            "instance_id": "bda7844bfbb0f3b59f901da8afd35035",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line represents the \u2018Largest Team\u2019 group? ",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Individuals"
                    },
                    {
                        "B": "Teammates"
                    },
                    {
                        "C": "Largest Team"
                    },
                    {
                        "D": "All user groups have similar density"
                    }
                ],
                "caption": "Fig. 1. Annotated examples\u2019 densities by three user groups: the individuals, the teammates, and the largest team; the highlighted region corresponds to the interval between 50 and 350 examples.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 1. Annotated examples\u2019 densities by three user groups: the individuals, the teammates, and the largest team; the highlighted region corresponds to the interval between 50 and 350 examples.",
            "categories": "['cs.SI cs.CL']",
            "figure_id": "1408.4245v2-Figure1-1",
            "image_path": "1408.4245v2-Figure1-1.png",
            "instance_id": "f98a4e405f1bc7210f51dcd3395c0486",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which user group has a higher density between 100 and 350 examples?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "BC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 1. Annotated examples\u2019 densities by three user groups: the individuals, the teammates, and the largest team; the highlighted region corresponds to the interval between 50 and 350 examples.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 1. Annotated examples\u2019 densities by three user groups: the individuals, the teammates, and the largest team; the highlighted region corresponds to the interval between 50 and 350 examples.",
            "categories": "['cs.SI cs.CL']",
            "figure_id": "1408.4245v2-Figure1-1",
            "image_path": "1408.4245v2-Figure1-1.png",
            "instance_id": "f600a5a0a717bf95fa26a33440f57a67",
            "qa_pair_type": "unanswerable",
            "question": "What is the number of examples annotated by individuals in the range of 50 to 350 and how does it affect the results?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 6: Top-k accuracies of target object selection given a spoken instruction.",
                "compound": false,
                "figure_type": "Scatter Plot",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 6: Top-k accuracies of target object selection given a spoken instruction.",
            "categories": "['cs.RO cs.CL']",
            "figure_id": "1710.06280v2-Figure6-1",
            "image_path": "1710.06280v2-Figure6-1.png",
            "instance_id": "cee8e011b8db03fc1e76b4f5498e6e66",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the top-k accuracy at K=1?",
            "reference_answer": "87%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The approximate value of the top-k accuracy at K=1 is around 95%.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 6: Top-k accuracies of target object selection given a spoken instruction.",
                "compound": false,
                "figure_type": "Scatter Plot",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 6: Top-k accuracies of target object selection given a spoken instruction.",
            "categories": "['cs.RO cs.CL']",
            "figure_id": "1710.06280v2-Figure6-1",
            "image_path": "1710.06280v2-Figure6-1.png",
            "instance_id": "844b2054a9bfa5989d95be58fc3881fd",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the value of K at which the top-k accuracy is approximately 98%?",
            "reference_answer": "between 7 and 9 "
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The value of K at which the top-k accuracy is approximately 98% is around 6.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 6: Top-k accuracies of target object selection given a spoken instruction.",
                "compound": false,
                "figure_type": "Scatter Plot",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 6: Top-k accuracies of target object selection given a spoken instruction.",
            "categories": "['cs.RO cs.CL']",
            "figure_id": "1710.06280v2-Figure6-1",
            "image_path": "1710.06280v2-Figure6-1.png",
            "instance_id": "6517930cd659a9ac90799277b796fdb7",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Do the blue circles in the graph show a decreasing trend of top-k accuracy as the value of K increases?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, the blue circles in the graph do not show a decreasing trend of top-k accuracy as the value of K increases. In fact, the trend appears to be stable or slightly increasing.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 6: Top-k accuracies of target object selection given a spoken instruction.",
                "compound": false,
                "figure_type": "Scatter Plot",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 6: Top-k accuracies of target object selection given a spoken instruction.",
            "categories": "['cs.RO cs.CL']",
            "figure_id": "1710.06280v2-Figure6-1",
            "image_path": "1710.06280v2-Figure6-1.png",
            "instance_id": "ae4b24ccffe65b3dafa4ac051462d62c",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the top-k accuracy increase when the k values are between 1 and 8?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the top-k accuracy increases as the k values increase from 1 to 8.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "99"
                    },
                    {
                        "B": "98"
                    },
                    {
                        "C": "97"
                    },
                    {
                        "D": "100"
                    }
                ],
                "caption": "Fig. 6: Top-k accuracies of target object selection given a spoken instruction.",
                "compound": false,
                "figure_type": "Scatter Plot",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 6: Top-k accuracies of target object selection given a spoken instruction.",
            "categories": "['cs.RO cs.CL']",
            "figure_id": "1710.06280v2-Figure6-1",
            "image_path": "1710.06280v2-Figure6-1.png",
            "instance_id": "b91a48e1a0efffe0470f5e4447de1d54",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What is the color of the points?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Yes"
                    },
                    {
                        "B": "No"
                    },
                    {
                        "C": "Sometimes"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Fig. 6: Top-k accuracies of target object selection given a spoken instruction.",
                "compound": false,
                "figure_type": "Scatter Plot",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 6: Top-k accuracies of target object selection given a spoken instruction.",
            "categories": "['cs.RO cs.CL']",
            "figure_id": "1710.06280v2-Figure6-1",
            "image_path": "1710.06280v2-Figure6-1.png",
            "instance_id": "3061e39b270edc2f6795c6e7280a5065",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the approximate value of the point positioned at K=10?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 6: Top-k accuracies of target object selection given a spoken instruction.",
                "compound": false,
                "figure_type": "Scatter Plot",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 6: Top-k accuracies of target object selection given a spoken instruction.",
            "categories": "['cs.RO cs.CL']",
            "figure_id": "1710.06280v2-Figure6-1",
            "image_path": "1710.06280v2-Figure6-1.png",
            "instance_id": "cec86f2472b50be2d143b2b0c7b64c2c",
            "qa_pair_type": "unanswerable",
            "question": "What is the spoken instruction used in this experiment to achieve the shown top-k accuracy values and how does it affect the results?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5.1: Baseline (BPE) vs Combined (SST\u2013CCG) NMT Systems for EN\u2013FR, evaluated on the newstest2013.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5.1: Baseline (BPE) vs Combined (SST\u2013CCG) NMT Systems for EN\u2013FR, evaluated on the newstest2013.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2003.14324v1-Figure5.1-1",
            "image_path": "2003.14324v1-Figure5.1-1.png",
            "instance_id": "b819beb97228105bfb0174d1148f0cf7",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of the blue line at 160,000 iterations?",
            "reference_answer": "between 20 and 25"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5.1: Baseline (BPE) vs Combined (SST\u2013CCG) NMT Systems for EN\u2013FR, evaluated on the newstest2013.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5.1: Baseline (BPE) vs Combined (SST\u2013CCG) NMT Systems for EN\u2013FR, evaluated on the newstest2013.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2003.14324v1-Figure5.1-1",
            "image_path": "2003.14324v1-Figure5.1-1.png",
            "instance_id": "2010eea6a1ea256b1dd0432b8dbef3ff",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "Which system, BPE or SST\u2013CCG, performs better at the final iteration?",
            "reference_answer": "SST\u2013CCG"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "SST\u2013CCG performs better at the final iteration.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5.1: Baseline (BPE) vs Combined (SST\u2013CCG) NMT Systems for EN\u2013FR, evaluated on the newstest2013.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5.1: Baseline (BPE) vs Combined (SST\u2013CCG) NMT Systems for EN\u2013FR, evaluated on the newstest2013.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2003.14324v1-Figure5.1-1",
            "image_path": "2003.14324v1-Figure5.1-1.png",
            "instance_id": "4330558a6b18a778b7016bbfcae23cb1",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the blue line representing BPE reach a higher value than the orange line representing SST CCG at the iteration point of 100,000?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the blue line representing BPE reaches a higher value than the orange line representing SST CCG at the iteration point of 100,000.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5.1: Baseline (BPE) vs Combined (SST\u2013CCG) NMT Systems for EN\u2013FR, evaluated on the newstest2013.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5.1: Baseline (BPE) vs Combined (SST\u2013CCG) NMT Systems for EN\u2013FR, evaluated on the newstest2013.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2003.14324v1-Figure5.1-1",
            "image_path": "2003.14324v1-Figure5.1-1.png",
            "instance_id": "9e69ff8fe166cff8f6c54fe804145c4d",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the Combined (SST\u2013CCG) NMT system consistently outperform the Baseline (BPE) system?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "blue line"
                    },
                    {
                        "B": "red line"
                    },
                    {
                        "C": "red dashed line"
                    },
                    {
                        "D": "blue dashed line"
                    }
                ],
                "caption": "Figure 5.1: Baseline (BPE) vs Combined (SST\u2013CCG) NMT Systems for EN\u2013FR, evaluated on the newstest2013.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5.1: Baseline (BPE) vs Combined (SST\u2013CCG) NMT Systems for EN\u2013FR, evaluated on the newstest2013.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2003.14324v1-Figure5.1-1",
            "image_path": "2003.14324v1-Figure5.1-1.png",
            "instance_id": "2a970e0c63b7a6a2f320708f5912872f",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line represents the 'SST CCG' system?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "BPE"
                    },
                    {
                        "B": "SST-CCG"
                    },
                    {
                        "C": "Both BPE and SST-CCG"
                    },
                    {
                        "D": "Neither BPE nor SST-CCG"
                    }
                ],
                "caption": "Figure 5.1: Baseline (BPE) vs Combined (SST\u2013CCG) NMT Systems for EN\u2013FR, evaluated on the newstest2013.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5.1: Baseline (BPE) vs Combined (SST\u2013CCG) NMT Systems for EN\u2013FR, evaluated on the newstest2013.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2003.14324v1-Figure5.1-1",
            "image_path": "2003.14324v1-Figure5.1-1.png",
            "instance_id": "abb8e82f7d8f7726ac14df276715edea",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following NMT systems achieved a BLEU score of 20 at a specific number of iterations?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5.1: Baseline (BPE) vs Combined (SST\u2013CCG) NMT Systems for EN\u2013FR, evaluated on the newstest2013.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5.1: Baseline (BPE) vs Combined (SST\u2013CCG) NMT Systems for EN\u2013FR, evaluated on the newstest2013.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2003.14324v1-Figure5.1-1",
            "image_path": "2003.14324v1-Figure5.1-1.png",
            "instance_id": "4beb3a28712ed2832fd0337c6cf9a1a4",
            "qa_pair_type": "unanswerable",
            "question": "What are the training data sizes for the BPE and SST\u2013CCG NMT systems?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4. Accuracy of correct predictions of tth token given all prefix reference tokens on NQG dev set. Colored regions represents 95% confidence interval obtained using standard bootstrapping. Without exposure bias, token prediction accuracy stays relatively stable across lengths.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4. Accuracy of correct predictions of tth token given all prefix reference tokens on NQG dev set. Colored regions represents 95% confidence interval obtained using standard bootstrapping. Without exposure bias, token prediction accuracy stays relatively stable across lengths.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2009.07839v1-Figure4-1",
            "image_path": "2009.07839v1-Figure4-1.png",
            "instance_id": "a104f3b00dd5d9b4adbcc7035202ff64",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the highest average accuracy of the green line?",
            "reference_answer": "between 0.4 and 0.5"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4. Accuracy of correct predictions of tth token given all prefix reference tokens on NQG dev set. Colored regions represents 95% confidence interval obtained using standard bootstrapping. Without exposure bias, token prediction accuracy stays relatively stable across lengths.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4. Accuracy of correct predictions of tth token given all prefix reference tokens on NQG dev set. Colored regions represents 95% confidence interval obtained using standard bootstrapping. Without exposure bias, token prediction accuracy stays relatively stable across lengths.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2009.07839v1-Figure4-1",
            "image_path": "2009.07839v1-Figure4-1.png",
            "instance_id": "509889159cbc2acf5aa927936f80b811",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the number of time-steps for MLE with 0.3 accuracy?",
            "reference_answer": "15"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4. Accuracy of correct predictions of tth token given all prefix reference tokens on NQG dev set. Colored regions represents 95% confidence interval obtained using standard bootstrapping. Without exposure bias, token prediction accuracy stays relatively stable across lengths.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4. Accuracy of correct predictions of tth token given all prefix reference tokens on NQG dev set. Colored regions represents 95% confidence interval obtained using standard bootstrapping. Without exposure bias, token prediction accuracy stays relatively stable across lengths.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2009.07839v1-Figure4-1",
            "image_path": "2009.07839v1-Figure4-1.png",
            "instance_id": "f8fd4080b6f97cffb008b30f6fa0ee73",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the green line represent GOLD-s?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the green line represents GOLD-s.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4. Accuracy of correct predictions of tth token given all prefix reference tokens on NQG dev set. Colored regions represents 95% confidence interval obtained using standard bootstrapping. Without exposure bias, token prediction accuracy stays relatively stable across lengths.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4. Accuracy of correct predictions of tth token given all prefix reference tokens on NQG dev set. Colored regions represents 95% confidence interval obtained using standard bootstrapping. Without exposure bias, token prediction accuracy stays relatively stable across lengths.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2009.07839v1-Figure4-1",
            "image_path": "2009.07839v1-Figure4-1.png",
            "instance_id": "7676c9b22fa78b8332bd2f982b599f1e",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the MLE and GOLD-s have an average accuracy of approximatley 0.3 with time-step= 15?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Blue"
                    },
                    {
                        "B": "Green"
                    },
                    {
                        "C": "Red"
                    },
                    {
                        "D": "Black"
                    }
                ],
                "caption": "Figure 4. Accuracy of correct predictions of tth token given all prefix reference tokens on NQG dev set. Colored regions represents 95% confidence interval obtained using standard bootstrapping. Without exposure bias, token prediction accuracy stays relatively stable across lengths.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4. Accuracy of correct predictions of tth token given all prefix reference tokens on NQG dev set. Colored regions represents 95% confidence interval obtained using standard bootstrapping. Without exposure bias, token prediction accuracy stays relatively stable across lengths.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2009.07839v1-Figure4-1",
            "image_path": "2009.07839v1-Figure4-1.png",
            "instance_id": "9e029070c95f8d17d0b722d4d244e7cf",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What is the color of the line representing MLE?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "0.1, 0.2, 0.3, 0.4, 0.7"
                    },
                    {
                        "B": "0.1, 0.2, 0.3, 0.4"
                    },
                    {
                        "C": "0.1, 0.2, 0.3, 0.4, 0.5, 0.6"
                    },
                    {
                        "D": "0.1, 0.2, 0.3, 0.4, 0.8"
                    }
                ],
                "caption": "Figure 4. Accuracy of correct predictions of tth token given all prefix reference tokens on NQG dev set. Colored regions represents 95% confidence interval obtained using standard bootstrapping. Without exposure bias, token prediction accuracy stays relatively stable across lengths.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4. Accuracy of correct predictions of tth token given all prefix reference tokens on NQG dev set. Colored regions represents 95% confidence interval obtained using standard bootstrapping. Without exposure bias, token prediction accuracy stays relatively stable across lengths.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2009.07839v1-Figure4-1",
            "image_path": "2009.07839v1-Figure4-1.png",
            "instance_id": "f99492d65c165254e7a6b504ac018573",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What are all possible values for average accuracy in y-axis?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4. Accuracy of correct predictions of tth token given all prefix reference tokens on NQG dev set. Colored regions represents 95% confidence interval obtained using standard bootstrapping. Without exposure bias, token prediction accuracy stays relatively stable across lengths.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4. Accuracy of correct predictions of tth token given all prefix reference tokens on NQG dev set. Colored regions represents 95% confidence interval obtained using standard bootstrapping. Without exposure bias, token prediction accuracy stays relatively stable across lengths.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2009.07839v1-Figure4-1",
            "image_path": "2009.07839v1-Figure4-1.png",
            "instance_id": "d1494351ee25d614ec2f60660655883b",
            "qa_pair_type": "unanswerable",
            "question": "What specific NLP task is the accuracy being measured for in this figure?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Parallel sentence retrieval accuracy after Procrustes alignment of monolingual BERT models.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Parallel sentence retrieval accuracy after Procrustes alignment of monolingual BERT models.",
            "categories": "['cs.CL']",
            "figure_id": "1911.01464v3-Figure6-1",
            "image_path": "1911.01464v3-Figure6-1.png",
            "instance_id": "2c4601603b5bb74fe7f764c83fb3ccda",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the accuracy of the en-ru pair at layer 4 using the LASER model?",
            "reference_answer": "between 90 and 100"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Parallel sentence retrieval accuracy after Procrustes alignment of monolingual BERT models.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Parallel sentence retrieval accuracy after Procrustes alignment of monolingual BERT models.",
            "categories": "['cs.CL']",
            "figure_id": "1911.01464v3-Figure6-1",
            "image_path": "1911.01464v3-Figure6-1.png",
            "instance_id": "3ba50e5f9b4b38ae75aee036b96109af",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the accuracy of the en-fr pair with the BERT model at the 7th layer?",
            "reference_answer": "approximately 55"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Parallel sentence retrieval accuracy after Procrustes alignment of monolingual BERT models.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Parallel sentence retrieval accuracy after Procrustes alignment of monolingual BERT models.",
            "categories": "['cs.CL']",
            "figure_id": "1911.01464v3-Figure6-1",
            "image_path": "1911.01464v3-Figure6-1.png",
            "instance_id": "a9c8944e76b897f5a254b7420a4b91c2",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the red line represent the accuracy of the en-fr model?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the red line represents the accuracy of the en-fr model.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Parallel sentence retrieval accuracy after Procrustes alignment of monolingual BERT models.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Parallel sentence retrieval accuracy after Procrustes alignment of monolingual BERT models.",
            "categories": "['cs.CL']",
            "figure_id": "1911.01464v3-Figure6-1",
            "image_path": "1911.01464v3-Figure6-1.png",
            "instance_id": "359bb2cad249c214c97281ed3bb15817",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the retrieval accuracy for the en-fr pair using BERT consistently higher than the retrieval accuracy for the en-fr pair using LASER?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": " red and blue"
                    },
                    {
                        "B": "blue and purple"
                    },
                    {
                        "C": "red and purple"
                    },
                    {
                        "D": "green and purple"
                    }
                ],
                "caption": "Figure 6: Parallel sentence retrieval accuracy after Procrustes alignment of monolingual BERT models.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Parallel sentence retrieval accuracy after Procrustes alignment of monolingual BERT models.",
            "categories": "['cs.CL']",
            "figure_id": "1911.01464v3-Figure6-1",
            "image_path": "1911.01464v3-Figure6-1.png",
            "instance_id": "d80861f9111d518e35c5de956ca3a770",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the lines show a consistently decreasing accuracy trend for the BERT model between layers 0 and 6?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "en-fr"
                    },
                    {
                        "B": "en-de"
                    },
                    {
                        "C": "en-ru"
                    },
                    {
                        "D": "en-zh"
                    }
                ],
                "caption": "Figure 6: Parallel sentence retrieval accuracy after Procrustes alignment of monolingual BERT models.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Parallel sentence retrieval accuracy after Procrustes alignment of monolingual BERT models.",
            "categories": "['cs.CL']",
            "figure_id": "1911.01464v3-Figure6-1",
            "image_path": "1911.01464v3-Figure6-1.png",
            "instance_id": "884fdcb8ff3621dca688e4140a23c783",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which language pair shows the highest retrieval accuracy for the LASER model?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Parallel sentence retrieval accuracy after Procrustes alignment of monolingual BERT models.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Parallel sentence retrieval accuracy after Procrustes alignment of monolingual BERT models.",
            "categories": "['cs.CL']",
            "figure_id": "1911.01464v3-Figure6-1",
            "image_path": "1911.01464v3-Figure6-1.png",
            "instance_id": "36096d26612da7f1854c9029860efa3b",
            "qa_pair_type": "unanswerable",
            "question": "Considering pairs for BERT and LASER, what does the graph tell us about the success of the task?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Average F1 scores as a function of time, approximated using the number of previous comments quantized in increments of 20.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Average F1 scores as a function of time, approximated using the number of previous comments quantized in increments of 20.",
            "categories": "['cs.CL']",
            "figure_id": "1704.02080v1-Figure4-1",
            "image_path": "1704.02080v1-Figure4-1.png",
            "instance_id": "e8d6b943df0873f0fe91ebb00a0e1f3f",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate F1 average of the red line in the 'askwomen' subplot at a time of 100?",
            "reference_answer": "between 45 and 50 "
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Average F1 scores as a function of time, approximated using the number of previous comments quantized in increments of 20.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Average F1 scores as a function of time, approximated using the number of previous comments quantized in increments of 20.",
            "categories": "['cs.CL']",
            "figure_id": "1704.02080v1-Figure4-1",
            "image_path": "1704.02080v1-Figure4-1.png",
            "instance_id": "bb235e1d6e7af38e4862644504d6b9c4",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the maximum value of F1 average represented in 'politics'?",
            "reference_answer": "75"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Average F1 scores as a function of time, approximated using the number of previous comments quantized in increments of 20.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Average F1 scores as a function of time, approximated using the number of previous comments quantized in increments of 20.",
            "categories": "['cs.CL']",
            "figure_id": "1704.02080v1-Figure4-1",
            "image_path": "1704.02080v1-Figure4-1.png",
            "instance_id": "6b79f864c8ad63ca3b29a7bd09bf778b",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the red line consistently above the yellow line in the 'askwomen' plot?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, the red line is not consistently above the yellow line in the 'askwomen' plot.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Average F1 scores as a function of time, approximated using the number of previous comments quantized in increments of 20.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Average F1 scores as a function of time, approximated using the number of previous comments quantized in increments of 20.",
            "categories": "['cs.CL']",
            "figure_id": "1704.02080v1-Figure4-1",
            "image_path": "1704.02080v1-Figure4-1.png",
            "instance_id": "44d0bd940f76e88d571f26479a73a68c",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the F1 average score for 'node-independent' decrease consistently over time for the 'askmen' category?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the F1 average score for 'node-independent' decreases consistently over time for the 'askmen' category.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "askwomen"
                    },
                    {
                        "B": "askmen"
                    },
                    {
                        "C": "politics"
                    },
                    {
                        "D": "All of the above"
                    }
                ],
                "caption": "Figure 4: Average F1 scores as a function of time, approximated using the number of previous comments quantized in increments of 20.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Average F1 scores as a function of time, approximated using the number of previous comments quantized in increments of 20.",
            "categories": "['cs.CL']",
            "figure_id": "1704.02080v1-Figure4-1",
            "image_path": "1704.02080v1-Figure4-1.png",
            "instance_id": "9f6ed8f7120541cf9fad98d7c072c3ef",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which graph depicts a more consistent F1 average for the yellow line?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "askwomen and askmen"
                    },
                    {
                        "B": "politics, askwomen and askmen"
                    },
                    {
                        "C": "politics and askwomen"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 4: Average F1 scores as a function of time, approximated using the number of previous comments quantized in increments of 20.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Average F1 scores as a function of time, approximated using the number of previous comments quantized in increments of 20.",
            "categories": "['cs.CL']",
            "figure_id": "1704.02080v1-Figure4-1",
            "image_path": "1704.02080v1-Figure4-1.png",
            "instance_id": "c5774e1a9e8aa9525c49eccec2ad6154",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which are the names of the subplots?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Average F1 scores as a function of time, approximated using the number of previous comments quantized in increments of 20.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Average F1 scores as a function of time, approximated using the number of previous comments quantized in increments of 20.",
            "categories": "['cs.CL']",
            "figure_id": "1704.02080v1-Figure4-1",
            "image_path": "1704.02080v1-Figure4-1.png",
            "instance_id": "d7280eb955ff85b1b8c380d5b91bdc35",
            "qa_pair_type": "unanswerable",
            "question": "What is the methodology used to determine the F1 scores for each of the three subreddits, askwomen, askmen, and politics?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5. Precision recall curves for sentence ranking (blue curves are the PALE LAGER model). Like in [30], we find that our unsupervised method achieves performance close to that of a fully-supervised Maximum Entropy classifier. However, we also report that our semi-supervised method matches the performance of the maxent classifier, and our fully supervised method outperforms maximum entropy classification significantly. In terms of Mean Average Precision, Maxent = 0.82 (fully-supervised), PALE LAGER = 0.76 (unsupervised), 0.81 (semi-supervised), 0.87 (fully-supervised).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5. Precision recall curves for sentence ranking (blue curves are the PALE LAGER model). Like in [30], we find that our unsupervised method achieves performance close to that of a fully-supervised Maximum Entropy classifier. However, we also report that our semi-supervised method matches the performance of the maxent classifier, and our fully supervised method outperforms maximum entropy classification significantly. In terms of Mean Average Precision, Maxent = 0.82 (fully-supervised), PALE LAGER = 0.76 (unsupervised), 0.81 (semi-supervised), 0.87 (fully-supervised).",
            "categories": "['cs.CL cs.IR cs.LG']",
            "figure_id": "1210.3926v2-Figure5-1",
            "image_path": "1210.3926v2-Figure5-1.png",
            "instance_id": "34fcc24cfee71329ce0161567e365878",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of the recall at which the blue curve for the 'feel' category reaches its highest precision value?",
            "reference_answer": "approximately 0.1"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5. Precision recall curves for sentence ranking (blue curves are the PALE LAGER model). Like in [30], we find that our unsupervised method achieves performance close to that of a fully-supervised Maximum Entropy classifier. However, we also report that our semi-supervised method matches the performance of the maxent classifier, and our fully supervised method outperforms maximum entropy classification significantly. In terms of Mean Average Precision, Maxent = 0.82 (fully-supervised), PALE LAGER = 0.76 (unsupervised), 0.81 (semi-supervised), 0.87 (fully-supervised).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5. Precision recall curves for sentence ranking (blue curves are the PALE LAGER model). Like in [30], we find that our unsupervised method achieves performance close to that of a fully-supervised Maximum Entropy classifier. However, we also report that our semi-supervised method matches the performance of the maxent classifier, and our fully supervised method outperforms maximum entropy classification significantly. In terms of Mean Average Precision, Maxent = 0.82 (fully-supervised), PALE LAGER = 0.76 (unsupervised), 0.81 (semi-supervised), 0.87 (fully-supervised).",
            "categories": "['cs.CL cs.IR cs.LG']",
            "figure_id": "1210.3926v2-Figure5-1",
            "image_path": "1210.3926v2-Figure5-1.png",
            "instance_id": "ef3c31d8778dcd93c29084c8166df9ab",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "Which metrics were used to evaluate the models?",
            "reference_answer": "Precision and Recall"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The metrics used to evaluate the models are Precision and Recall, as indicated by the graph labels and layout.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5. Precision recall curves for sentence ranking (blue curves are the PALE LAGER model). Like in [30], we find that our unsupervised method achieves performance close to that of a fully-supervised Maximum Entropy classifier. However, we also report that our semi-supervised method matches the performance of the maxent classifier, and our fully supervised method outperforms maximum entropy classification significantly. In terms of Mean Average Precision, Maxent = 0.82 (fully-supervised), PALE LAGER = 0.76 (unsupervised), 0.81 (semi-supervised), 0.87 (fully-supervised).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5. Precision recall curves for sentence ranking (blue curves are the PALE LAGER model). Like in [30], we find that our unsupervised method achieves performance close to that of a fully-supervised Maximum Entropy classifier. However, we also report that our semi-supervised method matches the performance of the maxent classifier, and our fully supervised method outperforms maximum entropy classification significantly. In terms of Mean Average Precision, Maxent = 0.82 (fully-supervised), PALE LAGER = 0.76 (unsupervised), 0.81 (semi-supervised), 0.87 (fully-supervised).",
            "categories": "['cs.CL cs.IR cs.LG']",
            "figure_id": "1210.3926v2-Figure5-1",
            "image_path": "1210.3926v2-Figure5-1.png",
            "instance_id": "cb11663188d60e67b9b64769c06e85c1",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the blue curve consistently higher than the red curver in the third subplot?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the blue curve is consistently higher than the red curve in the third subplot (smell).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5. Precision recall curves for sentence ranking (blue curves are the PALE LAGER model). Like in [30], we find that our unsupervised method achieves performance close to that of a fully-supervised Maximum Entropy classifier. However, we also report that our semi-supervised method matches the performance of the maxent classifier, and our fully supervised method outperforms maximum entropy classification significantly. In terms of Mean Average Precision, Maxent = 0.82 (fully-supervised), PALE LAGER = 0.76 (unsupervised), 0.81 (semi-supervised), 0.87 (fully-supervised).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5. Precision recall curves for sentence ranking (blue curves are the PALE LAGER model). Like in [30], we find that our unsupervised method achieves performance close to that of a fully-supervised Maximum Entropy classifier. However, we also report that our semi-supervised method matches the performance of the maxent classifier, and our fully supervised method outperforms maximum entropy classification significantly. In terms of Mean Average Precision, Maxent = 0.82 (fully-supervised), PALE LAGER = 0.76 (unsupervised), 0.81 (semi-supervised), 0.87 (fully-supervised).",
            "categories": "['cs.CL cs.IR cs.LG']",
            "figure_id": "1210.3926v2-Figure5-1",
            "image_path": "1210.3926v2-Figure5-1.png",
            "instance_id": "82dcffe43a0a2914efdf79565911815c",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the fully supervised PALE LAGER model achieve a higher Mean Average Precision than the unsupervised model for all senses?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The fully supervised PALE LAGER model achieves a higher Mean Average Precision than the unsupervised model for all senses displayed (feel, look, smell, taste, overall).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "green"
                    },
                    {
                        "B": "blue"
                    },
                    {
                        "C": "light blue"
                    },
                    {
                        "D": "red"
                    }
                ],
                "caption": "Figure 5. Precision recall curves for sentence ranking (blue curves are the PALE LAGER model). Like in [30], we find that our unsupervised method achieves performance close to that of a fully-supervised Maximum Entropy classifier. However, we also report that our semi-supervised method matches the performance of the maxent classifier, and our fully supervised method outperforms maximum entropy classification significantly. In terms of Mean Average Precision, Maxent = 0.82 (fully-supervised), PALE LAGER = 0.76 (unsupervised), 0.81 (semi-supervised), 0.87 (fully-supervised).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5. Precision recall curves for sentence ranking (blue curves are the PALE LAGER model). Like in [30], we find that our unsupervised method achieves performance close to that of a fully-supervised Maximum Entropy classifier. However, we also report that our semi-supervised method matches the performance of the maxent classifier, and our fully supervised method outperforms maximum entropy classification significantly. In terms of Mean Average Precision, Maxent = 0.82 (fully-supervised), PALE LAGER = 0.76 (unsupervised), 0.81 (semi-supervised), 0.87 (fully-supervised).",
            "categories": "['cs.CL cs.IR cs.LG']",
            "figure_id": "1210.3926v2-Figure5-1",
            "image_path": "1210.3926v2-Figure5-1.png",
            "instance_id": "f2bdcbb297ec42531ded37a6f75b07b3",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which is  line represents the Maxent classifier?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "feel, smell, jump"
                    },
                    {
                        "B": "feel, smell, look, taste and overall"
                    },
                    {
                        "C": "feel, smell, and look "
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 5. Precision recall curves for sentence ranking (blue curves are the PALE LAGER model). Like in [30], we find that our unsupervised method achieves performance close to that of a fully-supervised Maximum Entropy classifier. However, we also report that our semi-supervised method matches the performance of the maxent classifier, and our fully supervised method outperforms maximum entropy classification significantly. In terms of Mean Average Precision, Maxent = 0.82 (fully-supervised), PALE LAGER = 0.76 (unsupervised), 0.81 (semi-supervised), 0.87 (fully-supervised).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5. Precision recall curves for sentence ranking (blue curves are the PALE LAGER model). Like in [30], we find that our unsupervised method achieves performance close to that of a fully-supervised Maximum Entropy classifier. However, we also report that our semi-supervised method matches the performance of the maxent classifier, and our fully supervised method outperforms maximum entropy classification significantly. In terms of Mean Average Precision, Maxent = 0.82 (fully-supervised), PALE LAGER = 0.76 (unsupervised), 0.81 (semi-supervised), 0.87 (fully-supervised).",
            "categories": "['cs.CL cs.IR cs.LG']",
            "figure_id": "1210.3926v2-Figure5-1",
            "image_path": "1210.3926v2-Figure5-1.png",
            "instance_id": "c72323fe8987144949a1a1b9014af200",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the name of all subplots?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5. Precision recall curves for sentence ranking (blue curves are the PALE LAGER model). Like in [30], we find that our unsupervised method achieves performance close to that of a fully-supervised Maximum Entropy classifier. However, we also report that our semi-supervised method matches the performance of the maxent classifier, and our fully supervised method outperforms maximum entropy classification significantly. In terms of Mean Average Precision, Maxent = 0.82 (fully-supervised), PALE LAGER = 0.76 (unsupervised), 0.81 (semi-supervised), 0.87 (fully-supervised).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5. Precision recall curves for sentence ranking (blue curves are the PALE LAGER model). Like in [30], we find that our unsupervised method achieves performance close to that of a fully-supervised Maximum Entropy classifier. However, we also report that our semi-supervised method matches the performance of the maxent classifier, and our fully supervised method outperforms maximum entropy classification significantly. In terms of Mean Average Precision, Maxent = 0.82 (fully-supervised), PALE LAGER = 0.76 (unsupervised), 0.81 (semi-supervised), 0.87 (fully-supervised).",
            "categories": "['cs.CL cs.IR cs.LG']",
            "figure_id": "1210.3926v2-Figure5-1",
            "image_path": "1210.3926v2-Figure5-1.png",
            "instance_id": "452321e025887c8cec6a857d5f525c70",
            "qa_pair_type": "unanswerable",
            "question": "What is the AUC of the PALE LAGER model for 'feel' and 'smell' when using a fully-supervised training method?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The AUC of the PL (fully-supervised) model for 'feel' is 0.90, and for 'smell', it is 0.86.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 2: Average number of words hourly",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2: Average number of words hourly",
            "categories": "['cs.CL']",
            "figure_id": "1711.04115v1-Figure2-1",
            "image_path": "1711.04115v1-Figure2-1.png",
            "instance_id": "74901585837f105320ea5df2f37a6745",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate number of words at approximately hour 2 for the red line?",
            "reference_answer": "between 16.5 and 17"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 2: Average number of words hourly",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2: Average number of words hourly",
            "categories": "['cs.CL']",
            "figure_id": "1711.04115v1-Figure2-1",
            "image_path": "1711.04115v1-Figure2-1.png",
            "instance_id": "39fe78cf936b41fbd5cd234f6bcc2561",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the value when nb_words is at its peak?",
            "reference_answer": "18.5"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 2: Average number of words hourly",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2: Average number of words hourly",
            "categories": "['cs.CL']",
            "figure_id": "1711.04115v1-Figure2-1",
            "image_path": "1711.04115v1-Figure2-1.png",
            "instance_id": "2c3e548da18665a9b52b875f4780f10f",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Considering the red line, does the average number of words at hour 7 exceed the average number of words at hour 10?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 2: Average number of words hourly",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2: Average number of words hourly",
            "categories": "['cs.CL']",
            "figure_id": "1711.04115v1-Figure2-1",
            "image_path": "1711.04115v1-Figure2-1.png",
            "instance_id": "8f74fa7c000158ae647c211ece16861e",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the average number of words per hour at hour 21 higher than the average number of words per hour at hour 1?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Hour 8"
                    },
                    {
                        "B": "Hour 10"
                    },
                    {
                        "C": "Hour 21"
                    },
                    {
                        "D": "Hour 8 and Hour 21"
                    }
                ],
                "caption": "Fig. 2: Average number of words hourly",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2: Average number of words hourly",
            "categories": "['cs.CL']",
            "figure_id": "1711.04115v1-Figure2-1",
            "image_path": "1711.04115v1-Figure2-1.png",
            "instance_id": "7a6cd23499bb9c5e5b9ce6a586460b88",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which hours have the highest average number of words, according to the red line?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "16 to 19 "
                    },
                    {
                        "B": "16 to 21"
                    },
                    {
                        "C": "16 to 23"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Fig. 2: Average number of words hourly",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2: Average number of words hourly",
            "categories": "['cs.CL']",
            "figure_id": "1711.04115v1-Figure2-1",
            "image_path": "1711.04115v1-Figure2-1.png",
            "instance_id": "5805bb0cc0b90fae3f951c78bd2d6807",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which is the range of the average number of words?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 2: Average number of words hourly",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2: Average number of words hourly",
            "categories": "['cs.CL']",
            "figure_id": "1711.04115v1-Figure2-1",
            "image_path": "1711.04115v1-Figure2-1.png",
            "instance_id": "48b708942690a6e4af1dcfdbb491d02f",
            "qa_pair_type": "unanswerable",
            "question": "What is the standard deviation of the average number of words hourly?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Ablation training curves on simplest variant of RTFM. Individual runs are in light colours. Average win rates are in bold, dark lines.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Ablation training curves on simplest variant of RTFM. Individual runs are in light colours. Average win rates are in bold, dark lines.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "1910.08210v5-Figure4-1",
            "image_path": "1910.08210v5-Figure4-1.png",
            "instance_id": "697d21b65acd33dd987658b80e77c75b",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the win rate of the blue dark line at 4 million frames?",
            "reference_answer": "approximately 0.8"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Ablation training curves on simplest variant of RTFM. Individual runs are in light colours. Average win rates are in bold, dark lines.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Ablation training curves on simplest variant of RTFM. Individual runs are in light colours. Average win rates are in bold, dark lines.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "1910.08210v5-Figure4-1",
            "image_path": "1910.08210v5-Figure4-1.png",
            "instance_id": "cbe3aa9f3d7f5dd758a223704975f426",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the maximum win rate for the 'no_goal_attn' variant?",
            "reference_answer": "approximately 0.60"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Ablation training curves on simplest variant of RTFM. Individual runs are in light colours. Average win rates are in bold, dark lines.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Ablation training curves on simplest variant of RTFM. Individual runs are in light colours. Average win rates are in bold, dark lines.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "1910.08210v5-Figure4-1",
            "image_path": "1910.08210v5-Figure4-1.png",
            "instance_id": "e2ca3136167e163dd77390eb22288a09",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the dark blue line higher than the purple line?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Ablation training curves on simplest variant of RTFM. Individual runs are in light colours. Average win rates are in bold, dark lines.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Ablation training curves on simplest variant of RTFM. Individual runs are in light colours. Average win rates are in bold, dark lines.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "1910.08210v5-Figure4-1",
            "image_path": "1910.08210v5-Figure4-1.png",
            "instance_id": "0f60beb79fa233ee5b5f1384ef1f8fd8",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Are the average win rates between 0 and 100%?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the average win rates are between 0 and 100%.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The dark red line."
                    },
                    {
                        "B": "The orange line."
                    },
                    {
                        "C": "The dark brown line."
                    },
                    {
                        "D": "The light blue line."
                    }
                ],
                "caption": "Figure 4: Ablation training curves on simplest variant of RTFM. Individual runs are in light colours. Average win rates are in bold, dark lines.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Ablation training curves on simplest variant of RTFM. Individual runs are in light colours. Average win rates are in bold, dark lines.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "1910.08210v5-Figure4-1",
            "image_path": "1910.08210v5-Figure4-1.png",
            "instance_id": "1287ea4bfe5b7799bc991096c0ac6957",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line represents the average win rate for the 'no_text_mod' variant?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "exp"
                    },
                    {
                        "B": "no_goal_attn"
                    },
                    {
                        "C": "film"
                    },
                    {
                        "D": "conv"
                    }
                ],
                "caption": "Figure 4: Ablation training curves on simplest variant of RTFM. Individual runs are in light colours. Average win rates are in bold, dark lines.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Ablation training curves on simplest variant of RTFM. Individual runs are in light colours. Average win rates are in bold, dark lines.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "1910.08210v5-Figure4-1",
            "image_path": "1910.08210v5-Figure4-1.png",
            "instance_id": "ed8d1aa86041217e4e52aa4a6c65d75c",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following variants were trained with ablation on the simplest version of RTFM?",
            "reference_answer": "A,B,C,D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Ablation training curves on simplest variant of RTFM. Individual runs are in light colours. Average win rates are in bold, dark lines.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Ablation training curves on simplest variant of RTFM. Individual runs are in light colours. Average win rates are in bold, dark lines.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "1910.08210v5-Figure4-1",
            "image_path": "1910.08210v5-Figure4-1.png",
            "instance_id": "3c41d30a614c72450025715059fb7a1e",
            "qa_pair_type": "unanswerable",
            "question": "What do the ablation training curves of all elements tell us about the RTFM?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: The mutual information between an input token and a representation of this token at each layer.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: The mutual information between an input token and a representation of this token at each layer.",
            "categories": "['cs.CL']",
            "figure_id": "1909.01380v1-Figure1-1",
            "image_path": "1909.01380v1-Figure1-1.png",
            "instance_id": "465b06ee223597d98b17feaef3692022",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of the red line at layer 6?",
            "reference_answer": "4"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: The mutual information between an input token and a representation of this token at each layer.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: The mutual information between an input token and a representation of this token at each layer.",
            "categories": "['cs.CL']",
            "figure_id": "1909.01380v1-Figure1-1",
            "image_path": "1909.01380v1-Figure1-1.png",
            "instance_id": "b12d045ce77a6e3a6f6a896db3ea5f9a",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What are the three different tasks being compared in this figure?",
            "reference_answer": "MT, LM, MLM"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The three different tasks being compared in this figure are: MT (Machine Translation), LM (Language Modeling), and MLM (Masked Language Modeling).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: The mutual information between an input token and a representation of this token at each layer.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: The mutual information between an input token and a representation of this token at each layer.",
            "categories": "['cs.CL']",
            "figure_id": "1909.01380v1-Figure1-1",
            "image_path": "1909.01380v1-Figure1-1.png",
            "instance_id": "59468e3c94c93d8875d1900950c3e56d",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the mutual information decrease as the layer number increases for the blue solid line?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the mutual information decreases as the layer number increases for the blue solid line.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: The mutual information between an input token and a representation of this token at each layer.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: The mutual information between an input token and a representation of this token at each layer.",
            "categories": "['cs.CL']",
            "figure_id": "1909.01380v1-Figure1-1",
            "image_path": "1909.01380v1-Figure1-1.png",
            "instance_id": "582c157d763f02ea08f0afa5fa5764cb",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the mutual information value for the LM approximately 5.5 at layer 0?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "blue line"
                    },
                    {
                        "B": "red line"
                    },
                    {
                        "C": "orange line "
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 1: The mutual information between an input token and a representation of this token at each layer.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: The mutual information between an input token and a representation of this token at each layer.",
            "categories": "['cs.CL']",
            "figure_id": "1909.01380v1-Figure1-1",
            "image_path": "1909.01380v1-Figure1-1.png",
            "instance_id": "6e99f91d4a42af2be52494ffe379ab27",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line has the highest value at layer 6?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "MT, LM, MLM"
                    },
                    {
                        "B": "MT, LM"
                    },
                    {
                        "C": "LM, MLM"
                    },
                    {
                        "D": "MT, MLM"
                    }
                ],
                "caption": "Figure 1: The mutual information between an input token and a representation of this token at each layer.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: The mutual information between an input token and a representation of this token at each layer.",
            "categories": "['cs.CL']",
            "figure_id": "1909.01380v1-Figure1-1",
            "image_path": "1909.01380v1-Figure1-1.png",
            "instance_id": "e66d0dbfa2b5e2931547b362584ea47a",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which tasks have a mutual information value of approximately 5.2 for layer 0?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: The mutual information between an input token and a representation of this token at each layer.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: The mutual information between an input token and a representation of this token at each layer.",
            "categories": "['cs.CL']",
            "figure_id": "1909.01380v1-Figure1-1",
            "image_path": "1909.01380v1-Figure1-1.png",
            "instance_id": "f922ff017b5754dc06ca4434bb5aa0e6",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific task that each line in the graph represents, and how does this information relate to the overall trend of the mutual information?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The specific tasks represented by each line in the graph are as follows:\n\n- Blue line: MT (Machine Translation)\n- Red line: LM (Language Modeling)\n- Orange line: MLM (Masked Language Modeling)\n\nRegarding the overall trend of mutual information, as the number of layers increases, mutual information tends to decrease for all three tasks. This indicates that deeper layers are associated with a reduction in the mutual information between the layer representations and the source tokens. The blue line (MT) retains the highest mutual information, followed by LM and then MLM, suggesting that different tasks interact differently with layer representations as depth increases.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2. Rouge-L validation scores.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2. Rouge-L validation scores.",
            "categories": "['cs.CL']",
            "figure_id": "2004.12495v1-Figure2-1",
            "image_path": "2004.12495v1-Figure2-1.png",
            "instance_id": "be926f468e7a9c4b453c7516c7c1b444",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the Rouge-L score for the green line at epoch 5?",
            "reference_answer": "between 0.30 and 0.35"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2. Rouge-L validation scores.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2. Rouge-L validation scores.",
            "categories": "['cs.CL']",
            "figure_id": "2004.12495v1-Figure2-1",
            "image_path": "2004.12495v1-Figure2-1.png",
            "instance_id": "d6d64281e1fddf95567efb209548e74c",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the Rouge L for the bpe-based at all epochs?",
            "reference_answer": "between 0.50 and above 0.55"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2. Rouge-L validation scores.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2. Rouge-L validation scores.",
            "categories": "['cs.CL']",
            "figure_id": "2004.12495v1-Figure2-1",
            "image_path": "2004.12495v1-Figure2-1.png",
            "instance_id": "bf26a9c18586a7793e29f4683d03d3e5",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the green line is always higher than the red line?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2. Rouge-L validation scores.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2. Rouge-L validation scores.",
            "categories": "['cs.CL']",
            "figure_id": "2004.12495v1-Figure2-1",
            "image_path": "2004.12495v1-Figure2-1.png",
            "instance_id": "b3b1d22a655b60563394155852d1cdfa",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the 'lvt + fre' model achieve a higher Rouge-L score than the 'baseline' model at epoch 4?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the 'lvt + fre' model achieves a higher Rouge-L score than the 'baseline' model at epoch 4.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "blue"
                    },
                    {
                        "B": "orange"
                    },
                    {
                        "C": "green"
                    },
                    {
                        "D": "red"
                    }
                ],
                "caption": "Figure 2. Rouge-L validation scores.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2. Rouge-L validation scores.",
            "categories": "['cs.CL']",
            "figure_id": "2004.12495v1-Figure2-1",
            "image_path": "2004.12495v1-Figure2-1.png",
            "instance_id": "4e03c6cf36510ed2940ccc56b744a30e",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line represents the baseline model?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "bpe-based"
                    },
                    {
                        "B": "baseline"
                    },
                    {
                        "C": "lvt + fre"
                    },
                    {
                        "D": "fre-f2h"
                    }
                ],
                "caption": "Figure 2. Rouge-L validation scores.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2. Rouge-L validation scores.",
            "categories": "['cs.CL']",
            "figure_id": "2004.12495v1-Figure2-1",
            "image_path": "2004.12495v1-Figure2-1.png",
            "instance_id": "25250b73c1a9262e62c330c73fe7607d",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following models achieve a Rouge-L score of 0.35 at the 10th epoch?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A B C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2. Rouge-L validation scores.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2. Rouge-L validation scores.",
            "categories": "['cs.CL']",
            "figure_id": "2004.12495v1-Figure2-1",
            "image_path": "2004.12495v1-Figure2-1.png",
            "instance_id": "cf512c0db3dffdba10145999b8318cc9",
            "qa_pair_type": "unanswerable",
            "question": "What is the dataset used for this Rouge-L validation and how does it affect the results?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Developmental experimental results of our model on EmoryNLP by varying the values of T .",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Developmental experimental results of our model on EmoryNLP by varying the values of T .",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2003.01478v2-Figure4-1",
            "image_path": "2003.01478v2-Figure4-1.png",
            "instance_id": "d62b935f4ec336940aa4834a535a21c6",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of T when the blue line with crosses reaches its highest point?",
            "reference_answer": "3"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The blue line with crosses reaches its highest point at T = 3.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Developmental experimental results of our model on EmoryNLP by varying the values of T .",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Developmental experimental results of our model on EmoryNLP by varying the values of T .",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2003.01478v2-Figure4-1",
            "image_path": "2003.01478v2-Figure4-1.png",
            "instance_id": "0e8043f6c26a437e1d214a7ebde0bc46",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the highest value of the F1 score for CER on EmoryNLP?",
            "reference_answer": "39"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Developmental experimental results of our model on EmoryNLP by varying the values of T .",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Developmental experimental results of our model on EmoryNLP by varying the values of T .",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2003.01478v2-Figure4-1",
            "image_path": "2003.01478v2-Figure4-1.png",
            "instance_id": "459aa3d239462501f31aa0965e94a195",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the blue line always higher than the orange line?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, the blue line is not always higher than the orange line.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Developmental experimental results of our model on EmoryNLP by varying the values of T .",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Developmental experimental results of our model on EmoryNLP by varying the values of T .",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2003.01478v2-Figure4-1",
            "image_path": "2003.01478v2-Figure4-1.png",
            "instance_id": "c0caf2c2c0510b8b018b41075e925fa1",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the EmoryNLP model have a higher F1 score for CER on EmoryNLP than the MELD model for all values of T?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The blue line with crosses"
                    },
                    {
                        "B": "The orange line with crosses"
                    },
                    {
                        "C": "Both the blue and orange lines"
                    },
                    {
                        "D": "Neither of the lines"
                    }
                ],
                "caption": "Figure 4: Developmental experimental results of our model on EmoryNLP by varying the values of T .",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Developmental experimental results of our model on EmoryNLP by varying the values of T .",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2003.01478v2-Figure4-1",
            "image_path": "2003.01478v2-Figure4-1.png",
            "instance_id": "ab3458ad3aa728688b59061ff414b27b",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following lines represents the EmoryNLP?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "between 59 and 60"
                    },
                    {
                        "B": "between 58 and 59"
                    },
                    {
                        "C": "between 53 and 55"
                    },
                    {
                        "D": "All of the above"
                    }
                ],
                "caption": "Figure 4: Developmental experimental results of our model on EmoryNLP by varying the values of T .",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Developmental experimental results of our model on EmoryNLP by varying the values of T .",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2003.01478v2-Figure4-1",
            "image_path": "2003.01478v2-Figure4-1.png",
            "instance_id": "d2c006f52568535739d95bfa3bbc0c2e",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the highest F1 score achieved on MELD?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Developmental experimental results of our model on EmoryNLP by varying the values of T .",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Developmental experimental results of our model on EmoryNLP by varying the values of T .",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2003.01478v2-Figure4-1",
            "image_path": "2003.01478v2-Figure4-1.png",
            "instance_id": "acc181158a7eea66aef754cc5df9e80d",
            "qa_pair_type": "unanswerable",
            "question": "What is the difference between EmoryNLP and MELD methids?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: The comparison of Spearman Correlations to the KORE gold standard of different graph-based methods from each DBpedia dataset with redirects",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: The comparison of Spearman Correlations to the KORE gold standard of different graph-based methods from each DBpedia dataset with redirects",
            "categories": "['cs.CL cs.IR']",
            "figure_id": "1812.05001v1-Figure7-1",
            "image_path": "1812.05001v1-Figure7-1.png",
            "instance_id": "16c542f1ff1bc2fddc7efa0b1a758d9a",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the blue line in 2009?",
            "reference_answer": "between 0.5 and 0.6"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: The comparison of Spearman Correlations to the KORE gold standard of different graph-based methods from each DBpedia dataset with redirects",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: The comparison of Spearman Correlations to the KORE gold standard of different graph-based methods from each DBpedia dataset with redirects",
            "categories": "['cs.CL cs.IR']",
            "figure_id": "1812.05001v1-Figure7-1",
            "image_path": "1812.05001v1-Figure7-1.png",
            "instance_id": "e5c465df94371d0d2d0488dd96718e1c",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "Which graph-based method has the highest Spearman correlation in 2011?",
            "reference_answer": "Ext Jaccard RD (I+O)"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: The comparison of Spearman Correlations to the KORE gold standard of different graph-based methods from each DBpedia dataset with redirects",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: The comparison of Spearman Correlations to the KORE gold standard of different graph-based methods from each DBpedia dataset with redirects",
            "categories": "['cs.CL cs.IR']",
            "figure_id": "1812.05001v1-Figure7-1",
            "image_path": "1812.05001v1-Figure7-1.png",
            "instance_id": "e29d6e352173b4ae6b8994eb30be3593",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the orange line with circles has a higher Spearman Correlation in 2010 than the purple line with crosses?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: The comparison of Spearman Correlations to the KORE gold standard of different graph-based methods from each DBpedia dataset with redirects",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: The comparison of Spearman Correlations to the KORE gold standard of different graph-based methods from each DBpedia dataset with redirects",
            "categories": "['cs.CL cs.IR']",
            "figure_id": "1812.05001v1-Figure7-1",
            "image_path": "1812.05001v1-Figure7-1.png",
            "instance_id": "b060e413958092fa16e59719aa2b4d5c",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the Jaccard (O)\u2019s spearman correlation  always bellow the other methods in all years?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "orange line with circles"
                    },
                    {
                        "B": "red line with squares "
                    },
                    {
                        "C": "blue line with diamonds"
                    },
                    {
                        "D": "All of the above "
                    }
                ],
                "caption": "Figure 7: The comparison of Spearman Correlations to the KORE gold standard of different graph-based methods from each DBpedia dataset with redirects",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: The comparison of Spearman Correlations to the KORE gold standard of different graph-based methods from each DBpedia dataset with redirects",
            "categories": "['cs.CL cs.IR']",
            "figure_id": "1812.05001v1-Figure7-1",
            "image_path": "1812.05001v1-Figure7-1.png",
            "instance_id": "b3f9ba1f7b256557c06f2becf67986a1",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the line graphs reach a value of 0.7 or higher?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "2007"
                    },
                    {
                        "B": "2005"
                    },
                    {
                        "C": "2016"
                    },
                    {
                        "D": "2010"
                    }
                ],
                "caption": "Figure 7: The comparison of Spearman Correlations to the KORE gold standard of different graph-based methods from each DBpedia dataset with redirects",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: The comparison of Spearman Correlations to the KORE gold standard of different graph-based methods from each DBpedia dataset with redirects",
            "categories": "['cs.CL cs.IR']",
            "figure_id": "1812.05001v1-Figure7-1",
            "image_path": "1812.05001v1-Figure7-1.png",
            "instance_id": "9aa719bcbc41dc66807e1602abfa0c33",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "In which year are all methods higher than 0.5 in the y-axis?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: The comparison of Spearman Correlations to the KORE gold standard of different graph-based methods from each DBpedia dataset with redirects",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: The comparison of Spearman Correlations to the KORE gold standard of different graph-based methods from each DBpedia dataset with redirects",
            "categories": "['cs.CL cs.IR']",
            "figure_id": "1812.05001v1-Figure7-1",
            "image_path": "1812.05001v1-Figure7-1.png",
            "instance_id": "0d5f5f108be80e8a27630221153a245b",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific DBpedia dataset used for this analysis and how does it compare to other datasets in terms of graph-based methods?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Model accuracy on the e-SNLI dataset when using different percentages of tokens as rationales. The attention model values are obtained using different thresholds \u03bb to clip the attention weights while the values for our exact-k model correspond to k = 1, 2, 3, 4.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Model accuracy on the e-SNLI dataset when using different percentages of tokens as rationales. The attention model values are obtained using different thresholds \u03bb to clip the attention weights while the values for our exact-k model correspond to k = 1, 2, 3, 4.",
            "categories": "['cs.LG cs.CL stat.ML']",
            "figure_id": "2005.13111v1-Figure6-1",
            "image_path": "2005.13111v1-Figure6-1.png",
            "instance_id": "213f5113954519e75e771a281fabd130",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the model accuracy of the red line at 35% token selected?",
            "reference_answer": "between 79% and 85%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Model accuracy on the e-SNLI dataset when using different percentages of tokens as rationales. The attention model values are obtained using different thresholds \u03bb to clip the attention weights while the values for our exact-k model correspond to k = 1, 2, 3, 4.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Model accuracy on the e-SNLI dataset when using different percentages of tokens as rationales. The attention model values are obtained using different thresholds \u03bb to clip the attention weights while the values for our exact-k model correspond to k = 1, 2, 3, 4.",
            "categories": "['cs.LG cs.CL stat.ML']",
            "figure_id": "2005.13111v1-Figure6-1",
            "image_path": "2005.13111v1-Figure6-1.png",
            "instance_id": "2507cdb3a35a322a0abd87ae967e426f",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the model accuracy for the Attention model when 35% of tokens are used as rationales?",
            "reference_answer": "approximately 72%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Model accuracy on the e-SNLI dataset when using different percentages of tokens as rationales. The attention model values are obtained using different thresholds \u03bb to clip the attention weights while the values for our exact-k model correspond to k = 1, 2, 3, 4.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Model accuracy on the e-SNLI dataset when using different percentages of tokens as rationales. The attention model values are obtained using different thresholds \u03bb to clip the attention weights while the values for our exact-k model correspond to k = 1, 2, 3, 4.",
            "categories": "['cs.LG cs.CL stat.ML']",
            "figure_id": "2005.13111v1-Figure6-1",
            "image_path": "2005.13111v1-Figure6-1.png",
            "instance_id": "6ef3c469d298194e0d38423c89fc022d",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the accuracy of the red line decrease as the percentage of tokens selected increases?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Model accuracy on the e-SNLI dataset when using different percentages of tokens as rationales. The attention model values are obtained using different thresholds \u03bb to clip the attention weights while the values for our exact-k model correspond to k = 1, 2, 3, 4.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Model accuracy on the e-SNLI dataset when using different percentages of tokens as rationales. The attention model values are obtained using different thresholds \u03bb to clip the attention weights while the values for our exact-k model correspond to k = 1, 2, 3, 4.",
            "categories": "['cs.LG cs.CL stat.ML']",
            "figure_id": "2005.13111v1-Figure6-1",
            "image_path": "2005.13111v1-Figure6-1.png",
            "instance_id": "1b9a4c695ed026a5409790c7bd41bd6b",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the model accuracy for the Attention model consistently increase with the percentage of tokens selected?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Red line"
                    },
                    {
                        "B": "Blue line"
                    },
                    {
                        "C": "Green line"
                    },
                    {
                        "D": "Yellow line"
                    }
                ],
                "caption": "Figure 6: Model accuracy on the e-SNLI dataset when using different percentages of tokens as rationales. The attention model values are obtained using different thresholds \u03bb to clip the attention weights while the values for our exact-k model correspond to k = 1, 2, 3, 4.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Model accuracy on the e-SNLI dataset when using different percentages of tokens as rationales. The attention model values are obtained using different thresholds \u03bb to clip the attention weights while the values for our exact-k model correspond to k = 1, 2, 3, 4.",
            "categories": "['cs.LG cs.CL stat.ML']",
            "figure_id": "2005.13111v1-Figure6-1",
            "image_path": "2005.13111v1-Figure6-1.png",
            "instance_id": "57ef1b0959207cfceb3a4876e1e7ad59",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line represents the 'Attention (T=0.1)' model?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Attention"
                    },
                    {
                        "B": "Attention (T=0.1)"
                    },
                    {
                        "C": "Attention (T=0.01)"
                    },
                    {
                        "D": "OT (exact k)"
                    }
                ],
                "caption": "Figure 6: Model accuracy on the e-SNLI dataset when using different percentages of tokens as rationales. The attention model values are obtained using different thresholds \u03bb to clip the attention weights while the values for our exact-k model correspond to k = 1, 2, 3, 4.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Model accuracy on the e-SNLI dataset when using different percentages of tokens as rationales. The attention model values are obtained using different thresholds \u03bb to clip the attention weights while the values for our exact-k model correspond to k = 1, 2, 3, 4.",
            "categories": "['cs.LG cs.CL stat.ML']",
            "figure_id": "2005.13111v1-Figure6-1",
            "image_path": "2005.13111v1-Figure6-1.png",
            "instance_id": "c22aef5822e2684a08116745ef01783e",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which model has the highest accuracy using 15% of tokens?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Model accuracy on the e-SNLI dataset when using different percentages of tokens as rationales. The attention model values are obtained using different thresholds \u03bb to clip the attention weights while the values for our exact-k model correspond to k = 1, 2, 3, 4.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Model accuracy on the e-SNLI dataset when using different percentages of tokens as rationales. The attention model values are obtained using different thresholds \u03bb to clip the attention weights while the values for our exact-k model correspond to k = 1, 2, 3, 4.",
            "categories": "['cs.LG cs.CL stat.ML']",
            "figure_id": "2005.13111v1-Figure6-1",
            "image_path": "2005.13111v1-Figure6-1.png",
            "instance_id": "97896b4d971d0b3bd64826d92eeaccc8",
            "qa_pair_type": "unanswerable",
            "question": "What are the specific values of \u03bb used to obtain the attention model values for different thresholds and how do they affect the results?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "FIG. 2: Heaps law for monkey books with different sizes of the alphabet, in log-log scale. The full curves from top to bottom gives the N(M) for alphabets of length m = 4, 2, and 1, respectively. According to Eq.(7) the N(M) should for m = 4, and 2 follows Heaps power laws with the exponents 0.86 and 0.63, respectively, and the corresponding broken lines show that these predictions are borne out to excellent precision. For m = 1, Eq.(7) predicts that N(M) instead should be proportional to lnM , since \u03b3 \u2212 1 = 0. The corresponding broken curve again shows an excellent agreement.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIG. 2: Heaps law for monkey books with different sizes of the alphabet, in log-log scale. The full curves from top to bottom gives the N(M) for alphabets of length m = 4, 2, and 1, respectively. According to Eq.(7) the N(M) should for m = 4, and 2 follows Heaps power laws with the exponents 0.86 and 0.63, respectively, and the corresponding broken lines show that these predictions are borne out to excellent precision. For m = 1, Eq.(7) predicts that N(M) instead should be proportional to lnM , since \u03b3 \u2212 1 = 0. The corresponding broken curve again shows an excellent agreement.",
            "categories": "['physics.data-an cond-mat.stat-mech cs.CL cs.IR physics.soc-ph']",
            "figure_id": "1103.2681v1-Figure2-1",
            "image_path": "1103.2681v1-Figure2-1.png",
            "instance_id": "2c82941b228c3466e9a21fb12532efce",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of N(M) for the gray line with M=10^1?",
            "reference_answer": "between 10^0 and 10^1"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "FIG. 2: Heaps law for monkey books with different sizes of the alphabet, in log-log scale. The full curves from top to bottom gives the N(M) for alphabets of length m = 4, 2, and 1, respectively. According to Eq.(7) the N(M) should for m = 4, and 2 follows Heaps power laws with the exponents 0.86 and 0.63, respectively, and the corresponding broken lines show that these predictions are borne out to excellent precision. For m = 1, Eq.(7) predicts that N(M) instead should be proportional to lnM , since \u03b3 \u2212 1 = 0. The corresponding broken curve again shows an excellent agreement.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIG. 2: Heaps law for monkey books with different sizes of the alphabet, in log-log scale. The full curves from top to bottom gives the N(M) for alphabets of length m = 4, 2, and 1, respectively. According to Eq.(7) the N(M) should for m = 4, and 2 follows Heaps power laws with the exponents 0.86 and 0.63, respectively, and the corresponding broken lines show that these predictions are borne out to excellent precision. For m = 1, Eq.(7) predicts that N(M) instead should be proportional to lnM , since \u03b3 \u2212 1 = 0. The corresponding broken curve again shows an excellent agreement.",
            "categories": "['physics.data-an cond-mat.stat-mech cs.CL cs.IR physics.soc-ph']",
            "figure_id": "1103.2681v1-Figure2-1",
            "image_path": "1103.2681v1-Figure2-1.png",
            "instance_id": "8c93d649f47933d7c7a354da2fe95982",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the value of the x-axis for the m=4 line when the y-axis=10^4?",
            "reference_answer": "10^5"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "To find the value of the x-axis (M) for the m=4 line when the y-axis (N(M)) equals \\(10^4\\), you can visually inspect the graph. \n\nThe m=4 line intersects the horizontal line at \\(N(M) = 10^4\\) around \\(M \\approx 10^5\\). \n\nSo the value of the x-axis for the m=4 line when the y-axis equals \\(10^4\\) is approximately \\(10^5\\).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "FIG. 2: Heaps law for monkey books with different sizes of the alphabet, in log-log scale. The full curves from top to bottom gives the N(M) for alphabets of length m = 4, 2, and 1, respectively. According to Eq.(7) the N(M) should for m = 4, and 2 follows Heaps power laws with the exponents 0.86 and 0.63, respectively, and the corresponding broken lines show that these predictions are borne out to excellent precision. For m = 1, Eq.(7) predicts that N(M) instead should be proportional to lnM , since \u03b3 \u2212 1 = 0. The corresponding broken curve again shows an excellent agreement.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIG. 2: Heaps law for monkey books with different sizes of the alphabet, in log-log scale. The full curves from top to bottom gives the N(M) for alphabets of length m = 4, 2, and 1, respectively. According to Eq.(7) the N(M) should for m = 4, and 2 follows Heaps power laws with the exponents 0.86 and 0.63, respectively, and the corresponding broken lines show that these predictions are borne out to excellent precision. For m = 1, Eq.(7) predicts that N(M) instead should be proportional to lnM , since \u03b3 \u2212 1 = 0. The corresponding broken curve again shows an excellent agreement.",
            "categories": "['physics.data-an cond-mat.stat-mech cs.CL cs.IR physics.soc-ph']",
            "figure_id": "1103.2681v1-Figure2-1",
            "image_path": "1103.2681v1-Figure2-1.png",
            "instance_id": "5f801c3efa5f3c26f3d98e7e359049e1",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the blue line consistently higher than the gray line?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "FIG. 2: Heaps law for monkey books with different sizes of the alphabet, in log-log scale. The full curves from top to bottom gives the N(M) for alphabets of length m = 4, 2, and 1, respectively. According to Eq.(7) the N(M) should for m = 4, and 2 follows Heaps power laws with the exponents 0.86 and 0.63, respectively, and the corresponding broken lines show that these predictions are borne out to excellent precision. For m = 1, Eq.(7) predicts that N(M) instead should be proportional to lnM , since \u03b3 \u2212 1 = 0. The corresponding broken curve again shows an excellent agreement.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIG. 2: Heaps law for monkey books with different sizes of the alphabet, in log-log scale. The full curves from top to bottom gives the N(M) for alphabets of length m = 4, 2, and 1, respectively. According to Eq.(7) the N(M) should for m = 4, and 2 follows Heaps power laws with the exponents 0.86 and 0.63, respectively, and the corresponding broken lines show that these predictions are borne out to excellent precision. For m = 1, Eq.(7) predicts that N(M) instead should be proportional to lnM , since \u03b3 \u2212 1 = 0. The corresponding broken curve again shows an excellent agreement.",
            "categories": "['physics.data-an cond-mat.stat-mech cs.CL cs.IR physics.soc-ph']",
            "figure_id": "1103.2681v1-Figure2-1",
            "image_path": "1103.2681v1-Figure2-1.png",
            "instance_id": "495985d061b20416c95d00b7d45509c3",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the m=1 line is always lower than m=4 and m=2 starting at M=10^1?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the \\( m=1 \\) line is always lower than both the \\( m=2 \\) and \\( m=4 \\) lines starting at \\( M = 10^1 \\).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "blue"
                    },
                    {
                        "B": "green"
                    },
                    {
                        "C": "grey"
                    },
                    {
                        "D": "dashed black"
                    }
                ],
                "caption": "FIG. 2: Heaps law for monkey books with different sizes of the alphabet, in log-log scale. The full curves from top to bottom gives the N(M) for alphabets of length m = 4, 2, and 1, respectively. According to Eq.(7) the N(M) should for m = 4, and 2 follows Heaps power laws with the exponents 0.86 and 0.63, respectively, and the corresponding broken lines show that these predictions are borne out to excellent precision. For m = 1, Eq.(7) predicts that N(M) instead should be proportional to lnM , since \u03b3 \u2212 1 = 0. The corresponding broken curve again shows an excellent agreement.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIG. 2: Heaps law for monkey books with different sizes of the alphabet, in log-log scale. The full curves from top to bottom gives the N(M) for alphabets of length m = 4, 2, and 1, respectively. According to Eq.(7) the N(M) should for m = 4, and 2 follows Heaps power laws with the exponents 0.86 and 0.63, respectively, and the corresponding broken lines show that these predictions are borne out to excellent precision. For m = 1, Eq.(7) predicts that N(M) instead should be proportional to lnM , since \u03b3 \u2212 1 = 0. The corresponding broken curve again shows an excellent agreement.",
            "categories": "['physics.data-an cond-mat.stat-mech cs.CL cs.IR physics.soc-ph']",
            "figure_id": "1103.2681v1-Figure2-1",
            "image_path": "1103.2681v1-Figure2-1.png",
            "instance_id": "318b963aea889f8522fdd9dae5643e1d",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line corresponds to the equation \"\u221d lnM\"?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "m = 1"
                    },
                    {
                        "B": "m = 0"
                    },
                    {
                        "C": "m = 3"
                    },
                    {
                        "D": "m = 1, m = 2, m = 4"
                    }
                ],
                "caption": "FIG. 2: Heaps law for monkey books with different sizes of the alphabet, in log-log scale. The full curves from top to bottom gives the N(M) for alphabets of length m = 4, 2, and 1, respectively. According to Eq.(7) the N(M) should for m = 4, and 2 follows Heaps power laws with the exponents 0.86 and 0.63, respectively, and the corresponding broken lines show that these predictions are borne out to excellent precision. For m = 1, Eq.(7) predicts that N(M) instead should be proportional to lnM , since \u03b3 \u2212 1 = 0. The corresponding broken curve again shows an excellent agreement.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIG. 2: Heaps law for monkey books with different sizes of the alphabet, in log-log scale. The full curves from top to bottom gives the N(M) for alphabets of length m = 4, 2, and 1, respectively. According to Eq.(7) the N(M) should for m = 4, and 2 follows Heaps power laws with the exponents 0.86 and 0.63, respectively, and the corresponding broken lines show that these predictions are borne out to excellent precision. For m = 1, Eq.(7) predicts that N(M) instead should be proportional to lnM , since \u03b3 \u2212 1 = 0. The corresponding broken curve again shows an excellent agreement.",
            "categories": "['physics.data-an cond-mat.stat-mech cs.CL cs.IR physics.soc-ph']",
            "figure_id": "1103.2681v1-Figure2-1",
            "image_path": "1103.2681v1-Figure2-1.png",
            "instance_id": "cb560852b36bff8e270c1be9d410a981",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following values of *m* are presented in the plot?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "FIG. 2: Heaps law for monkey books with different sizes of the alphabet, in log-log scale. The full curves from top to bottom gives the N(M) for alphabets of length m = 4, 2, and 1, respectively. According to Eq.(7) the N(M) should for m = 4, and 2 follows Heaps power laws with the exponents 0.86 and 0.63, respectively, and the corresponding broken lines show that these predictions are borne out to excellent precision. For m = 1, Eq.(7) predicts that N(M) instead should be proportional to lnM , since \u03b3 \u2212 1 = 0. The corresponding broken curve again shows an excellent agreement.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIG. 2: Heaps law for monkey books with different sizes of the alphabet, in log-log scale. The full curves from top to bottom gives the N(M) for alphabets of length m = 4, 2, and 1, respectively. According to Eq.(7) the N(M) should for m = 4, and 2 follows Heaps power laws with the exponents 0.86 and 0.63, respectively, and the corresponding broken lines show that these predictions are borne out to excellent precision. For m = 1, Eq.(7) predicts that N(M) instead should be proportional to lnM , since \u03b3 \u2212 1 = 0. The corresponding broken curve again shows an excellent agreement.",
            "categories": "['physics.data-an cond-mat.stat-mech cs.CL cs.IR physics.soc-ph']",
            "figure_id": "1103.2681v1-Figure2-1",
            "image_path": "1103.2681v1-Figure2-1.png",
            "instance_id": "c93b96481988511c5d26c39db0755fd5",
            "qa_pair_type": "unanswerable",
            "question": "What are the values of the parameters used in Eq. (7) for the alphabet size m = 4 and how do they influence the results?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8 Precision-recall curves for the temporally-scoped relation extraction task. We compare our approach with three different settings of the prior (yellow, orange, red) and CCG (blue). The solid lines denote our parser\u2019s performance when using a grammar that models the morphology of verbs, whereas the dashed lines are produced when our parser is trained with a grammar that does not model verb morphology. The uniform prior places equal probability mass on all semantic statements. The \u201ctype-correct\u201d prior places higher mass (+4 in log probability) on semantic statements with subject and object types that agree with the domain and range of the relation predicate. The \u201cknowledge base prior\u201d is similar to the type-correct prior, except that it additionally places higher probability mass on semantic statements that correspond to true beliefs in the NELL knowledge base (additional +4 in log probability).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8 Precision-recall curves for the temporally-scoped relation extraction task. We compare our approach with three different settings of the prior (yellow, orange, red) and CCG (blue). The solid lines denote our parser\u2019s performance when using a grammar that models the morphology of verbs, whereas the dashed lines are produced when our parser is trained with a grammar that does not model verb morphology. The uniform prior places equal probability mass on all semantic statements. The \u201ctype-correct\u201d prior places higher mass (+4 in log probability) on semantic statements with subject and object types that agree with the domain and range of the relation predicate. The \u201cknowledge base prior\u201d is similar to the type-correct prior, except that it additionally places higher probability mass on semantic statements that correspond to true beliefs in the NELL knowledge base (additional +4 in log probability).",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1606.06361v1-Figure8-1",
            "image_path": "1606.06361v1-Figure8-1.png",
            "instance_id": "2075703a98a1dcb9c64e19fc1532b437",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate precision of the orange solid line at a recall value of 0.6?",
            "reference_answer": "approximately 0.98"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8 Precision-recall curves for the temporally-scoped relation extraction task. We compare our approach with three different settings of the prior (yellow, orange, red) and CCG (blue). The solid lines denote our parser\u2019s performance when using a grammar that models the morphology of verbs, whereas the dashed lines are produced when our parser is trained with a grammar that does not model verb morphology. The uniform prior places equal probability mass on all semantic statements. The \u201ctype-correct\u201d prior places higher mass (+4 in log probability) on semantic statements with subject and object types that agree with the domain and range of the relation predicate. The \u201cknowledge base prior\u201d is similar to the type-correct prior, except that it additionally places higher probability mass on semantic statements that correspond to true beliefs in the NELL knowledge base (additional +4 in log probability).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8 Precision-recall curves for the temporally-scoped relation extraction task. We compare our approach with three different settings of the prior (yellow, orange, red) and CCG (blue). The solid lines denote our parser\u2019s performance when using a grammar that models the morphology of verbs, whereas the dashed lines are produced when our parser is trained with a grammar that does not model verb morphology. The uniform prior places equal probability mass on all semantic statements. The \u201ctype-correct\u201d prior places higher mass (+4 in log probability) on semantic statements with subject and object types that agree with the domain and range of the relation predicate. The \u201cknowledge base prior\u201d is similar to the type-correct prior, except that it additionally places higher probability mass on semantic statements that correspond to true beliefs in the NELL knowledge base (additional +4 in log probability).",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1606.06361v1-Figure8-1",
            "image_path": "1606.06361v1-Figure8-1.png",
            "instance_id": "1a8351965a28d3dde08570e570d274ae",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the maximum possible precision value in the y-axis?",
            "reference_answer": "100%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The maximum possible precision value in the y-axis is 1.00.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8 Precision-recall curves for the temporally-scoped relation extraction task. We compare our approach with three different settings of the prior (yellow, orange, red) and CCG (blue). The solid lines denote our parser\u2019s performance when using a grammar that models the morphology of verbs, whereas the dashed lines are produced when our parser is trained with a grammar that does not model verb morphology. The uniform prior places equal probability mass on all semantic statements. The \u201ctype-correct\u201d prior places higher mass (+4 in log probability) on semantic statements with subject and object types that agree with the domain and range of the relation predicate. The \u201cknowledge base prior\u201d is similar to the type-correct prior, except that it additionally places higher probability mass on semantic statements that correspond to true beliefs in the NELL knowledge base (additional +4 in log probability).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8 Precision-recall curves for the temporally-scoped relation extraction task. We compare our approach with three different settings of the prior (yellow, orange, red) and CCG (blue). The solid lines denote our parser\u2019s performance when using a grammar that models the morphology of verbs, whereas the dashed lines are produced when our parser is trained with a grammar that does not model verb morphology. The uniform prior places equal probability mass on all semantic statements. The \u201ctype-correct\u201d prior places higher mass (+4 in log probability) on semantic statements with subject and object types that agree with the domain and range of the relation predicate. The \u201cknowledge base prior\u201d is similar to the type-correct prior, except that it additionally places higher probability mass on semantic statements that correspond to true beliefs in the NELL knowledge base (additional +4 in log probability).",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1606.06361v1-Figure8-1",
            "image_path": "1606.06361v1-Figure8-1.png",
            "instance_id": "e574c0d963457e5c23f17a4efed46271",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the red dashed line reach a precision value of between 98% and 100% at any point?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the red dashed line reaches a precision value of between 98% and 100% at one point.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8 Precision-recall curves for the temporally-scoped relation extraction task. We compare our approach with three different settings of the prior (yellow, orange, red) and CCG (blue). The solid lines denote our parser\u2019s performance when using a grammar that models the morphology of verbs, whereas the dashed lines are produced when our parser is trained with a grammar that does not model verb morphology. The uniform prior places equal probability mass on all semantic statements. The \u201ctype-correct\u201d prior places higher mass (+4 in log probability) on semantic statements with subject and object types that agree with the domain and range of the relation predicate. The \u201cknowledge base prior\u201d is similar to the type-correct prior, except that it additionally places higher probability mass on semantic statements that correspond to true beliefs in the NELL knowledge base (additional +4 in log probability).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8 Precision-recall curves for the temporally-scoped relation extraction task. We compare our approach with three different settings of the prior (yellow, orange, red) and CCG (blue). The solid lines denote our parser\u2019s performance when using a grammar that models the morphology of verbs, whereas the dashed lines are produced when our parser is trained with a grammar that does not model verb morphology. The uniform prior places equal probability mass on all semantic statements. The \u201ctype-correct\u201d prior places higher mass (+4 in log probability) on semantic statements with subject and object types that agree with the domain and range of the relation predicate. The \u201cknowledge base prior\u201d is similar to the type-correct prior, except that it additionally places higher probability mass on semantic statements that correspond to true beliefs in the NELL knowledge base (additional +4 in log probability).",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1606.06361v1-Figure8-1",
            "image_path": "1606.06361v1-Figure8-1.png",
            "instance_id": "a0b5b90cd8d85d5c8c4bdddf886d6970",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the CCG has the lowest precision value at recall between 0.6 and 0.8?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The CCG line is below the other lines in terms of precision within the recall range of 0.6 to 0.8.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "yellow dashed line"
                    },
                    {
                        "B": "yellow solid line"
                    },
                    {
                        "C": "Blue dashed line"
                    },
                    {
                        "D": "Blue solid line"
                    }
                ],
                "caption": "Figure 8 Precision-recall curves for the temporally-scoped relation extraction task. We compare our approach with three different settings of the prior (yellow, orange, red) and CCG (blue). The solid lines denote our parser\u2019s performance when using a grammar that models the morphology of verbs, whereas the dashed lines are produced when our parser is trained with a grammar that does not model verb morphology. The uniform prior places equal probability mass on all semantic statements. The \u201ctype-correct\u201d prior places higher mass (+4 in log probability) on semantic statements with subject and object types that agree with the domain and range of the relation predicate. The \u201cknowledge base prior\u201d is similar to the type-correct prior, except that it additionally places higher probability mass on semantic statements that correspond to true beliefs in the NELL knowledge base (additional +4 in log probability).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8 Precision-recall curves for the temporally-scoped relation extraction task. We compare our approach with three different settings of the prior (yellow, orange, red) and CCG (blue). The solid lines denote our parser\u2019s performance when using a grammar that models the morphology of verbs, whereas the dashed lines are produced when our parser is trained with a grammar that does not model verb morphology. The uniform prior places equal probability mass on all semantic statements. The \u201ctype-correct\u201d prior places higher mass (+4 in log probability) on semantic statements with subject and object types that agree with the domain and range of the relation predicate. The \u201cknowledge base prior\u201d is similar to the type-correct prior, except that it additionally places higher probability mass on semantic statements that correspond to true beliefs in the NELL knowledge base (additional +4 in log probability).",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1606.06361v1-Figure8-1",
            "image_path": "1606.06361v1-Figure8-1.png",
            "instance_id": "d807fa021b8846aab2bf779d9e08bbc5",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line represents the performance of the parser using a grammar that does not model verb morphology named uniform prior?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "uniform prior"
                    },
                    {
                        "B": "type-correct prior"
                    },
                    {
                        "C": "knowledge base prior"
                    },
                    {
                        "D": "CCG"
                    }
                ],
                "caption": "Figure 8 Precision-recall curves for the temporally-scoped relation extraction task. We compare our approach with three different settings of the prior (yellow, orange, red) and CCG (blue). The solid lines denote our parser\u2019s performance when using a grammar that models the morphology of verbs, whereas the dashed lines are produced when our parser is trained with a grammar that does not model verb morphology. The uniform prior places equal probability mass on all semantic statements. The \u201ctype-correct\u201d prior places higher mass (+4 in log probability) on semantic statements with subject and object types that agree with the domain and range of the relation predicate. The \u201cknowledge base prior\u201d is similar to the type-correct prior, except that it additionally places higher probability mass on semantic statements that correspond to true beliefs in the NELL knowledge base (additional +4 in log probability).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8 Precision-recall curves for the temporally-scoped relation extraction task. We compare our approach with three different settings of the prior (yellow, orange, red) and CCG (blue). The solid lines denote our parser\u2019s performance when using a grammar that models the morphology of verbs, whereas the dashed lines are produced when our parser is trained with a grammar that does not model verb morphology. The uniform prior places equal probability mass on all semantic statements. The \u201ctype-correct\u201d prior places higher mass (+4 in log probability) on semantic statements with subject and object types that agree with the domain and range of the relation predicate. The \u201cknowledge base prior\u201d is similar to the type-correct prior, except that it additionally places higher probability mass on semantic statements that correspond to true beliefs in the NELL knowledge base (additional +4 in log probability).",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1606.06361v1-Figure8-1",
            "image_path": "1606.06361v1-Figure8-1.png",
            "instance_id": "42ef4adc8141193b3ed2ff643bb42cff",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which prior has the highest precision with verb morphology grammar and a recall of 0.6?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8 Precision-recall curves for the temporally-scoped relation extraction task. We compare our approach with three different settings of the prior (yellow, orange, red) and CCG (blue). The solid lines denote our parser\u2019s performance when using a grammar that models the morphology of verbs, whereas the dashed lines are produced when our parser is trained with a grammar that does not model verb morphology. The uniform prior places equal probability mass on all semantic statements. The \u201ctype-correct\u201d prior places higher mass (+4 in log probability) on semantic statements with subject and object types that agree with the domain and range of the relation predicate. The \u201cknowledge base prior\u201d is similar to the type-correct prior, except that it additionally places higher probability mass on semantic statements that correspond to true beliefs in the NELL knowledge base (additional +4 in log probability).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8 Precision-recall curves for the temporally-scoped relation extraction task. We compare our approach with three different settings of the prior (yellow, orange, red) and CCG (blue). The solid lines denote our parser\u2019s performance when using a grammar that models the morphology of verbs, whereas the dashed lines are produced when our parser is trained with a grammar that does not model verb morphology. The uniform prior places equal probability mass on all semantic statements. The \u201ctype-correct\u201d prior places higher mass (+4 in log probability) on semantic statements with subject and object types that agree with the domain and range of the relation predicate. The \u201cknowledge base prior\u201d is similar to the type-correct prior, except that it additionally places higher probability mass on semantic statements that correspond to true beliefs in the NELL knowledge base (additional +4 in log probability).",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1606.06361v1-Figure8-1",
            "image_path": "1606.06361v1-Figure8-1.png",
            "instance_id": "ebd0a9b487d8856b453f7b24bdee3eed",
            "qa_pair_type": "unanswerable",
            "question": "What is the average precision for the type-correct prior when the parser is trained with a grammar that models verb morphology?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Precision@Recall for the attention models on the CNN validation data.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Precision@Recall for the attention models on the CNN validation data.",
            "categories": "['cs.CL cs.AI cs.NE']",
            "figure_id": "1506.03340v3-Figure2-1",
            "image_path": "1506.03340v3-Figure2-1.png",
            "instance_id": "3d4d70b85ee0bcb3d15c726936a9ded1",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of the blue line at a recall of 20%?",
            "reference_answer": "approximately 74%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Precision@Recall for the attention models on the CNN validation data.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Precision@Recall for the attention models on the CNN validation data.",
            "categories": "['cs.CL cs.AI cs.NE']",
            "figure_id": "1506.03340v3-Figure2-1",
            "image_path": "1506.03340v3-Figure2-1.png",
            "instance_id": "e88080fb2edddc32957635a1f4db78e7",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the maximum recall value?",
            "reference_answer": "100%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Precision@Recall for the attention models on the CNN validation data.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Precision@Recall for the attention models on the CNN validation data.",
            "categories": "['cs.CL cs.AI cs.NE']",
            "figure_id": "1506.03340v3-Figure2-1",
            "image_path": "1506.03340v3-Figure2-1.png",
            "instance_id": "e879c0bc98bb8f224527937a47f1cf45",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the blue line higher than the orange line  at a recall of 50%?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the blue line (Uniform) is higher than the orange line (Impatient Reader) at a recall of 50%.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Precision@Recall for the attention models on the CNN validation data.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Precision@Recall for the attention models on the CNN validation data.",
            "categories": "['cs.CL cs.AI cs.NE']",
            "figure_id": "1506.03340v3-Figure2-1",
            "image_path": "1506.03340v3-Figure2-1.png",
            "instance_id": "4ac617b9cb8afaa916bdf717d7ad95cc",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the precision of the Attentive Reader always lower than that of the Impatient Reader?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Red"
                    },
                    {
                        "B": "Blue"
                    },
                    {
                        "C": "Orange"
                    },
                    {
                        "D": "Green"
                    }
                ],
                "caption": "Figure 2: Precision@Recall for the attention models on the CNN validation data.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Precision@Recall for the attention models on the CNN validation data.",
            "categories": "['cs.CL cs.AI cs.NE']",
            "figure_id": "1506.03340v3-Figure2-1",
            "image_path": "1506.03340v3-Figure2-1.png",
            "instance_id": "3de5c7365d042859772a007120cd8b9b",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What is the color of the line representing 'Impatient Reader'?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Uniform, Impatient Reader"
                    },
                    {
                        "B": "Uniform, Attentive Reader, Impatient Reader"
                    },
                    {
                        "C": "Attentive Reader, Impatient Reader"
                    },
                    {
                        "D": "Uniform, Attentive Reader"
                    }
                ],
                "caption": "Figure 2: Precision@Recall for the attention models on the CNN validation data.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Precision@Recall for the attention models on the CNN validation data.",
            "categories": "['cs.CL cs.AI cs.NE']",
            "figure_id": "1506.03340v3-Figure2-1",
            "image_path": "1506.03340v3-Figure2-1.png",
            "instance_id": "57d8858bfdf501808cf2a97a0b740312",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which models are presented in the figure?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Precision@Recall for the attention models on the CNN validation data.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Precision@Recall for the attention models on the CNN validation data.",
            "categories": "['cs.CL cs.AI cs.NE']",
            "figure_id": "1506.03340v3-Figure2-1",
            "image_path": "1506.03340v3-Figure2-1.png",
            "instance_id": "7d0c2c06694607e9054ab6346fe45761",
            "qa_pair_type": "unanswerable",
            "question": "What is the average Precision@Recall value for each attention model and what does it tell us about the performance?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Acc@10 on ranges of different query length. The number of queries in each range is 672, 3, 609, 21, 113, 31, 013, 14, 684, 5, 803, 2, 316 and 1, 448 respectively.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Acc@10 on ranges of different query length. The number of queries in each range is 672, 3, 609, 21, 113, 31, 013, 14, 684, 5, 803, 2, 316 and 1, 448 respectively.",
            "categories": "['cs.CL cs.AI cs.IR']",
            "figure_id": "1912.08441v2-Figure5-1",
            "image_path": "1912.08441v2-Figure5-1.png",
            "instance_id": "25c86dacea18c0bf921c0b0265ae998f",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of the green line at the \"11-15\" range?",
            "reference_answer": "between 0 and 0.1"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Acc@10 on ranges of different query length. The number of queries in each range is 672, 3, 609, 21, 113, 31, 013, 14, 684, 5, 803, 2, 316 and 1, 448 respectively.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Acc@10 on ranges of different query length. The number of queries in each range is 672, 3, 609, 21, 113, 31, 013, 14, 684, 5, 803, 2, 316 and 1, 448 respectively.",
            "categories": "['cs.CL cs.AI cs.IR']",
            "figure_id": "1912.08441v2-Figure5-1",
            "image_path": "1912.08441v2-Figure5-1.png",
            "instance_id": "99b16a31618f07cae7629a728c55c657",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the length of queries for Multi-channel with acc@10 of 0.4?",
            "reference_answer": "1-2"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The length of queries for Multi-channel with Acc@10 of 0.4 is 1-2.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Acc@10 on ranges of different query length. The number of queries in each range is 672, 3, 609, 21, 113, 31, 013, 14, 684, 5, 803, 2, 316 and 1, 448 respectively.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Acc@10 on ranges of different query length. The number of queries in each range is 672, 3, 609, 21, 113, 31, 013, 14, 684, 5, 803, 2, 316 and 1, 448 respectively.",
            "categories": "['cs.CL cs.AI cs.IR']",
            "figure_id": "1912.08441v2-Figure5-1",
            "image_path": "1912.08441v2-Figure5-1.png",
            "instance_id": "2e4681f981e2a9249df5083ac90e5347",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the green line consistently above the red line?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, the green line (RNN) is not consistently above the red line (SuperSense). In several instances, especially for longer query lengths, the red line is above the green line.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Acc@10 on ranges of different query length. The number of queries in each range is 672, 3, 609, 21, 113, 31, 013, 14, 684, 5, 803, 2, 316 and 1, 448 respectively.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Acc@10 on ranges of different query length. The number of queries in each range is 672, 3, 609, 21, 113, 31, 013, 14, 684, 5, 803, 2, 316 and 1, 448 respectively.",
            "categories": "['cs.CL cs.AI cs.IR']",
            "figure_id": "1912.08441v2-Figure5-1",
            "image_path": "1912.08441v2-Figure5-1.png",
            "instance_id": "46313fa9c091fffaa5dd1fe08eaf7a79",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the Acc@10 in the range of 0 to 0.5?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the Acc@10 is in the range of 0 to 0.5.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "blue "
                    },
                    {
                        "B": "red"
                    },
                    {
                        "C": "green"
                    },
                    {
                        "D": "purple"
                    }
                ],
                "caption": "Figure 5: Acc@10 on ranges of different query length. The number of queries in each range is 672, 3, 609, 21, 113, 31, 013, 14, 684, 5, 803, 2, 316 and 1, 448 respectively.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Acc@10 on ranges of different query length. The number of queries in each range is 672, 3, 609, 21, 113, 31, 013, 14, 684, 5, 803, 2, 316 and 1, 448 respectively.",
            "categories": "['cs.CL cs.AI cs.IR']",
            "figure_id": "1912.08441v2-Figure5-1",
            "image_path": "1912.08441v2-Figure5-1.png",
            "instance_id": "fa578c4251f72175774ecb22e9c5d420",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line is the highest for the query length range of 6-10?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Multi-Channel, BiLSTM, and BOW"
                    },
                    {
                        "B": "Multi-Channel, BiLSTM, andWord2Vec"
                    },
                    {
                        "C": "Multi-Channel, SVM, and Log Regression"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 5: Acc@10 on ranges of different query length. The number of queries in each range is 672, 3, 609, 21, 113, 31, 013, 14, 684, 5, 803, 2, 316 and 1, 448 respectively.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Acc@10 on ranges of different query length. The number of queries in each range is 672, 3, 609, 21, 113, 31, 013, 14, 684, 5, 803, 2, 316 and 1, 448 respectively.",
            "categories": "['cs.CL cs.AI cs.IR']",
            "figure_id": "1912.08441v2-Figure5-1",
            "image_path": "1912.08441v2-Figure5-1.png",
            "instance_id": "809348c682e0506f88f8fb297a31b14b",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What are three methods presented in the plot?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Acc@10 on ranges of different query length. The number of queries in each range is 672, 3, 609, 21, 113, 31, 013, 14, 684, 5, 803, 2, 316 and 1, 448 respectively.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Acc@10 on ranges of different query length. The number of queries in each range is 672, 3, 609, 21, 113, 31, 013, 14, 684, 5, 803, 2, 316 and 1, 448 respectively.",
            "categories": "['cs.CL cs.AI cs.IR']",
            "figure_id": "1912.08441v2-Figure5-1",
            "image_path": "1912.08441v2-Figure5-1.png",
            "instance_id": "1100d1243e8834d72fb222b55894e4c9",
            "qa_pair_type": "unanswerable",
            "question": "What is the dataset used in the study presented in Figure 5 and how does it affect acc@10 results?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: The above graphs show that as the dialogue session count increases for both the Photoshop SPARQL (left) and Web-Analytics SQL (right) dataset, the accuracy also increases. The y-axis of each graph marks the accuracy, while the x-axis marks the number of dialogue sessions for each dataset.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: The above graphs show that as the dialogue session count increases for both the Photoshop SPARQL (left) and Web-Analytics SQL (right) dataset, the accuracy also increases. The y-axis of each graph marks the accuracy, while the x-axis marks the number of dialogue sessions for each dataset.",
            "categories": "['cs.CL']",
            "figure_id": "2006.00591v2-Figure6-1",
            "image_path": "2006.00591v2-Figure6-1.png",
            "instance_id": "71f28a22cdd7628fdf65dd6130dba982",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the accuracy value for the left graph at 100 dialogue sessions?",
            "reference_answer": "0.6"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: The above graphs show that as the dialogue session count increases for both the Photoshop SPARQL (left) and Web-Analytics SQL (right) dataset, the accuracy also increases. The y-axis of each graph marks the accuracy, while the x-axis marks the number of dialogue sessions for each dataset.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: The above graphs show that as the dialogue session count increases for both the Photoshop SPARQL (left) and Web-Analytics SQL (right) dataset, the accuracy also increases. The y-axis of each graph marks the accuracy, while the x-axis marks the number of dialogue sessions for each dataset.",
            "categories": "['cs.CL']",
            "figure_id": "2006.00591v2-Figure6-1",
            "image_path": "2006.00591v2-Figure6-1.png",
            "instance_id": "128034ab2c4ec8289e13168d82b18f7a",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the highest accuracy value of the dialogue session count SPARQL?",
            "reference_answer": "70%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: The above graphs show that as the dialogue session count increases for both the Photoshop SPARQL (left) and Web-Analytics SQL (right) dataset, the accuracy also increases. The y-axis of each graph marks the accuracy, while the x-axis marks the number of dialogue sessions for each dataset.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: The above graphs show that as the dialogue session count increases for both the Photoshop SPARQL (left) and Web-Analytics SQL (right) dataset, the accuracy also increases. The y-axis of each graph marks the accuracy, while the x-axis marks the number of dialogue sessions for each dataset.",
            "categories": "['cs.CL']",
            "figure_id": "2006.00591v2-Figure6-1",
            "image_path": "2006.00591v2-Figure6-1.png",
            "instance_id": "19a2173f76a79cc6d0256fea5e62b9e7",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the highest accuracy value for the rightmost plot between 70% and 80%?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The highest accuracy value for the rightmost plot is between 70% and 80%.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: The above graphs show that as the dialogue session count increases for both the Photoshop SPARQL (left) and Web-Analytics SQL (right) dataset, the accuracy also increases. The y-axis of each graph marks the accuracy, while the x-axis marks the number of dialogue sessions for each dataset.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: The above graphs show that as the dialogue session count increases for both the Photoshop SPARQL (left) and Web-Analytics SQL (right) dataset, the accuracy also increases. The y-axis of each graph marks the accuracy, while the x-axis marks the number of dialogue sessions for each dataset.",
            "categories": "['cs.CL']",
            "figure_id": "2006.00591v2-Figure6-1",
            "image_path": "2006.00591v2-Figure6-1.png",
            "instance_id": "6d5b5664e599c0129a2e3ae7954d8ae0",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the x-axis values for SPARQL plot are between 0 ad 250?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the x-axis values for the SPARQL plot are between 0 and 250.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "50%"
                    },
                    {
                        "B": "60%"
                    },
                    {
                        "C": "70%"
                    },
                    {
                        "D": "80%"
                    }
                ],
                "caption": "Figure 6: The above graphs show that as the dialogue session count increases for both the Photoshop SPARQL (left) and Web-Analytics SQL (right) dataset, the accuracy also increases. The y-axis of each graph marks the accuracy, while the x-axis marks the number of dialogue sessions for each dataset.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: The above graphs show that as the dialogue session count increases for both the Photoshop SPARQL (left) and Web-Analytics SQL (right) dataset, the accuracy also increases. The y-axis of each graph marks the accuracy, while the x-axis marks the number of dialogue sessions for each dataset.",
            "categories": "['cs.CL']",
            "figure_id": "2006.00591v2-Figure6-1",
            "image_path": "2006.00591v2-Figure6-1.png",
            "instance_id": "15f89bc3587bd98d846c4d143e4e163b",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What is the maximum accuracy value shown for both datasets in the yaxis?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "10 to 20"
                    },
                    {
                        "B": "20 to 200"
                    },
                    {
                        "C": "40 to 100"
                    },
                    {
                        "D": "0 to 160"
                    }
                ],
                "caption": "Figure 6: The above graphs show that as the dialogue session count increases for both the Photoshop SPARQL (left) and Web-Analytics SQL (right) dataset, the accuracy also increases. The y-axis of each graph marks the accuracy, while the x-axis marks the number of dialogue sessions for each dataset.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: The above graphs show that as the dialogue session count increases for both the Photoshop SPARQL (left) and Web-Analytics SQL (right) dataset, the accuracy also increases. The y-axis of each graph marks the accuracy, while the x-axis marks the number of dialogue sessions for each dataset.",
            "categories": "['cs.CL']",
            "figure_id": "2006.00591v2-Figure6-1",
            "image_path": "2006.00591v2-Figure6-1.png",
            "instance_id": "822c0fe290dd7480b996aac96ec91251",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the range of possible values in x-axis for the SQL plot?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: The above graphs show that as the dialogue session count increases for both the Photoshop SPARQL (left) and Web-Analytics SQL (right) dataset, the accuracy also increases. The y-axis of each graph marks the accuracy, while the x-axis marks the number of dialogue sessions for each dataset.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: The above graphs show that as the dialogue session count increases for both the Photoshop SPARQL (left) and Web-Analytics SQL (right) dataset, the accuracy also increases. The y-axis of each graph marks the accuracy, while the x-axis marks the number of dialogue sessions for each dataset.",
            "categories": "['cs.CL']",
            "figure_id": "2006.00591v2-Figure6-1",
            "image_path": "2006.00591v2-Figure6-1.png",
            "instance_id": "c34b543b62136b8b2d6eba12a22ebd62",
            "qa_pair_type": "unanswerable",
            "question": "What is the accuracy rate for the Web-Analytics SQL dataset at 100 dialogue sessions and how is it similar to that one of the Photoshop SPARQL?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Performance of strong and weak training with different amount of training data.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Performance of strong and weak training with different amount of training data.",
            "categories": "['cs.LG cs.AI cs.CL cs.SD']",
            "figure_id": "1609.08441v2-Figure2-1",
            "image_path": "1609.08441v2-Figure2-1.png",
            "instance_id": "35dc8ac38780e87975b1371cf6ac7a42",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of the green line at 500 speakers?",
            "reference_answer": "approximately 2.5"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Performance of strong and weak training with different amount of training data.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Performance of strong and weak training with different amount of training data.",
            "categories": "['cs.LG cs.AI cs.CL cs.SD']",
            "figure_id": "1609.08441v2-Figure2-1",
            "image_path": "1609.08441v2-Figure2-1.png",
            "instance_id": "e46fb865250d7c87df5a6333c95b43b3",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the training method with the lowest EER at 2000 speakers?",
            "reference_answer": "Strong Training"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Performance of strong and weak training with different amount of training data.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Performance of strong and weak training with different amount of training data.",
            "categories": "['cs.LG cs.AI cs.CL cs.SD']",
            "figure_id": "1609.08441v2-Figure2-1",
            "image_path": "1609.08441v2-Figure2-1.png",
            "instance_id": "67a5be5817e257a1bce36337d6e8a6b1",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the green line consistently have a lower EER value than the red dashed line ?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the green line consistently has a lower EER value than the red dashed line across the range of speakers presented in the graph.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Performance of strong and weak training with different amount of training data.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Performance of strong and weak training with different amount of training data.",
            "categories": "['cs.LG cs.AI cs.CL cs.SD']",
            "figure_id": "1609.08441v2-Figure2-1",
            "image_path": "1609.08441v2-Figure2-1.png",
            "instance_id": "98d8ca677728ad7b82f5c093028f6b0c",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the performance of the strong training method improve with an increase in the number of speakers?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the performance of the strong training method improves with an increase in the number of speakers, as indicated by the decrease in the EER (%) in the graph.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Green solid line"
                    },
                    {
                        "B": "Blue dashed line"
                    },
                    {
                        "C": "Red dashed line"
                    },
                    {
                        "D": "Pink dotted line"
                    }
                ],
                "caption": "Figure 2: Performance of strong and weak training with different amount of training data.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Performance of strong and weak training with different amount of training data.",
            "categories": "['cs.LG cs.AI cs.CL cs.SD']",
            "figure_id": "1609.08441v2-Figure2-1",
            "image_path": "1609.08441v2-Figure2-1.png",
            "instance_id": "d54b3a9c5f1bcd6b316e47d48c2f7dce",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line represents 'Weak Training-mix'?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Strong Training, Weak Training-mix, Weak Training-customer, Weak Training-service"
                    },
                    {
                        "B": "Strong Training, Weak Training-customer, Weak Training-service"
                    },
                    {
                        "C": "Weak Training-mix, Weak Training-customer, Weak Training-service"
                    },
                    {
                        "D": "Strong Training, Weak Training-mix, Weak Training-customer"
                    }
                ],
                "caption": "Figure 2: Performance of strong and weak training with different amount of training data.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Performance of strong and weak training with different amount of training data.",
            "categories": "['cs.LG cs.AI cs.CL cs.SD']",
            "figure_id": "1609.08441v2-Figure2-1",
            "image_path": "1609.08441v2-Figure2-1.png",
            "instance_id": "890319a1896e06b6192b278c6f181b0a",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which training types are included in the figure?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Performance of strong and weak training with different amount of training data.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Performance of strong and weak training with different amount of training data.",
            "categories": "['cs.LG cs.AI cs.CL cs.SD']",
            "figure_id": "1609.08441v2-Figure2-1",
            "image_path": "1609.08441v2-Figure2-1.png",
            "instance_id": "0c28a076235553570f7b96533f934c1e",
            "qa_pair_type": "unanswerable",
            "question": "How is the EER value calculated?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: Workload runtime using indexes recommended under various time budgets. Using a query2vec compression scheme, the indexes recommended resulted in improved runtimes under all time budgets over 3 minutes. Under 3 minutes, our method does not finish, and we default to producing no index recommendations. Surprisingly, the recommendations for the uncompressed workload results in worse runtimes under tight time budgets before converging at higher time budgets. These results show that syntax-based workload compression as a pre-processing can improve the performance of index recommenders.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Workload runtime using indexes recommended under various time budgets. Using a query2vec compression scheme, the indexes recommended resulted in improved runtimes under all time budgets over 3 minutes. Under 3 minutes, our method does not finish, and we default to producing no index recommendations. Surprisingly, the recommendations for the uncompressed workload results in worse runtimes under tight time budgets before converging at higher time budgets. These results show that syntax-based workload compression as a pre-processing can improve the performance of index recommenders.",
            "categories": "['cs.DB cs.CL']",
            "figure_id": "1801.05613v2-Figure7-1",
            "image_path": "1801.05613v2-Figure7-1.png",
            "instance_id": "3aded2da527d0d1bbbdfbd87cae30268",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the runtime for the blue line at a time budget of 5 minutes?",
            "reference_answer": "between 800 and 1000"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: Workload runtime using indexes recommended under various time budgets. Using a query2vec compression scheme, the indexes recommended resulted in improved runtimes under all time budgets over 3 minutes. Under 3 minutes, our method does not finish, and we default to producing no index recommendations. Surprisingly, the recommendations for the uncompressed workload results in worse runtimes under tight time budgets before converging at higher time budgets. These results show that syntax-based workload compression as a pre-processing can improve the performance of index recommenders.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Workload runtime using indexes recommended under various time budgets. Using a query2vec compression scheme, the indexes recommended resulted in improved runtimes under all time budgets over 3 minutes. Under 3 minutes, our method does not finish, and we default to producing no index recommendations. Surprisingly, the recommendations for the uncompressed workload results in worse runtimes under tight time budgets before converging at higher time budgets. These results show that syntax-based workload compression as a pre-processing can improve the performance of index recommenders.",
            "categories": "['cs.DB cs.CL']",
            "figure_id": "1801.05613v2-Figure7-1",
            "image_path": "1801.05613v2-Figure7-1.png",
            "instance_id": "0cdf9e4df33ad155cb6d52d060e3777f",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the method with the highest total execution time?",
            "reference_answer": "SQL Server"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The method with the highest total execution time is \"SQL Server.\"",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: Workload runtime using indexes recommended under various time budgets. Using a query2vec compression scheme, the indexes recommended resulted in improved runtimes under all time budgets over 3 minutes. Under 3 minutes, our method does not finish, and we default to producing no index recommendations. Surprisingly, the recommendations for the uncompressed workload results in worse runtimes under tight time budgets before converging at higher time budgets. These results show that syntax-based workload compression as a pre-processing can improve the performance of index recommenders.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Workload runtime using indexes recommended under various time budgets. Using a query2vec compression scheme, the indexes recommended resulted in improved runtimes under all time budgets over 3 minutes. Under 3 minutes, our method does not finish, and we default to producing no index recommendations. Surprisingly, the recommendations for the uncompressed workload results in worse runtimes under tight time budgets before converging at higher time budgets. These results show that syntax-based workload compression as a pre-processing can improve the performance of index recommenders.",
            "categories": "['cs.DB cs.CL']",
            "figure_id": "1801.05613v2-Figure7-1",
            "image_path": "1801.05613v2-Figure7-1.png",
            "instance_id": "c5f5ce090dd33517b87264ad5844c019",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the red line show a higher runtime than the green line at a time budget of 5 minutes?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: Workload runtime using indexes recommended under various time budgets. Using a query2vec compression scheme, the indexes recommended resulted in improved runtimes under all time budgets over 3 minutes. Under 3 minutes, our method does not finish, and we default to producing no index recommendations. Surprisingly, the recommendations for the uncompressed workload results in worse runtimes under tight time budgets before converging at higher time budgets. These results show that syntax-based workload compression as a pre-processing can improve the performance of index recommenders.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Workload runtime using indexes recommended under various time budgets. Using a query2vec compression scheme, the indexes recommended resulted in improved runtimes under all time budgets over 3 minutes. Under 3 minutes, our method does not finish, and we default to producing no index recommendations. Surprisingly, the recommendations for the uncompressed workload results in worse runtimes under tight time budgets before converging at higher time budgets. These results show that syntax-based workload compression as a pre-processing can improve the performance of index recommenders.",
            "categories": "['cs.DB cs.CL']",
            "figure_id": "1801.05613v2-Figure7-1",
            "image_path": "1801.05613v2-Figure7-1.png",
            "instance_id": "ee989b8726cf16b110224c35f0f9d457",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the 'doc2vecOnSQL' method consistently produce a faster runtime than the 'SQL Server' method?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "purple "
                    },
                    {
                        "B": "red"
                    },
                    {
                        "C": "blue"
                    },
                    {
                        "D": "green"
                    }
                ],
                "caption": "Figure 7: Workload runtime using indexes recommended under various time budgets. Using a query2vec compression scheme, the indexes recommended resulted in improved runtimes under all time budgets over 3 minutes. Under 3 minutes, our method does not finish, and we default to producing no index recommendations. Surprisingly, the recommendations for the uncompressed workload results in worse runtimes under tight time budgets before converging at higher time budgets. These results show that syntax-based workload compression as a pre-processing can improve the performance of index recommenders.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Workload runtime using indexes recommended under various time budgets. Using a query2vec compression scheme, the indexes recommended resulted in improved runtimes under all time budgets over 3 minutes. Under 3 minutes, our method does not finish, and we default to producing no index recommendations. Surprisingly, the recommendations for the uncompressed workload results in worse runtimes under tight time budgets before converging at higher time budgets. These results show that syntax-based workload compression as a pre-processing can improve the performance of index recommenders.",
            "categories": "['cs.DB cs.CL']",
            "figure_id": "1801.05613v2-Figure7-1",
            "image_path": "1801.05613v2-Figure7-1.png",
            "instance_id": "b6ae6d0836579a47498f2ac017ee4879",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line starts at 1200 seconds?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "1 to 20"
                    },
                    {
                        "B": "1 to 15"
                    },
                    {
                        "C": "15 to 60"
                    },
                    {
                        "D": "1 to 9 "
                    }
                ],
                "caption": "Figure 7: Workload runtime using indexes recommended under various time budgets. Using a query2vec compression scheme, the indexes recommended resulted in improved runtimes under all time budgets over 3 minutes. Under 3 minutes, our method does not finish, and we default to producing no index recommendations. Surprisingly, the recommendations for the uncompressed workload results in worse runtimes under tight time budgets before converging at higher time budgets. These results show that syntax-based workload compression as a pre-processing can improve the performance of index recommenders.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Workload runtime using indexes recommended under various time budgets. Using a query2vec compression scheme, the indexes recommended resulted in improved runtimes under all time budgets over 3 minutes. Under 3 minutes, our method does not finish, and we default to producing no index recommendations. Surprisingly, the recommendations for the uncompressed workload results in worse runtimes under tight time budgets before converging at higher time budgets. These results show that syntax-based workload compression as a pre-processing can improve the performance of index recommenders.",
            "categories": "['cs.DB cs.CL']",
            "figure_id": "1801.05613v2-Figure7-1",
            "image_path": "1801.05613v2-Figure7-1.png",
            "instance_id": "fc40023059729ccfb28aa9d1fdd79c0b",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the range of values presented in the x-axis?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: Workload runtime using indexes recommended under various time budgets. Using a query2vec compression scheme, the indexes recommended resulted in improved runtimes under all time budgets over 3 minutes. Under 3 minutes, our method does not finish, and we default to producing no index recommendations. Surprisingly, the recommendations for the uncompressed workload results in worse runtimes under tight time budgets before converging at higher time budgets. These results show that syntax-based workload compression as a pre-processing can improve the performance of index recommenders.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Workload runtime using indexes recommended under various time budgets. Using a query2vec compression scheme, the indexes recommended resulted in improved runtimes under all time budgets over 3 minutes. Under 3 minutes, our method does not finish, and we default to producing no index recommendations. Surprisingly, the recommendations for the uncompressed workload results in worse runtimes under tight time budgets before converging at higher time budgets. These results show that syntax-based workload compression as a pre-processing can improve the performance of index recommenders.",
            "categories": "['cs.DB cs.CL']",
            "figure_id": "1801.05613v2-Figure7-1",
            "image_path": "1801.05613v2-Figure7-1.png",
            "instance_id": "fcbc8e3c2192ea094e59d7b7d9a40ebe",
            "qa_pair_type": "unanswerable",
            "question": "What is the workload used in this experiment and how does its size affect the performance of the index recommenders?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Performance of the model on images from the CelebA dataset when the asking-agent has four images, two rounds of question-answer are performed and with a vocabulary of eight and sixteen words available. The dashed grey lines represents the baseline performance where the asking-agent guesses randomly.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Performance of the model on images from the CelebA dataset when the asking-agent has four images, two rounds of question-answer are performed and with a vocabulary of eight and sixteen words available. The dashed grey lines represents the baseline performance where the asking-agent guesses randomly.",
            "categories": "['cs.AI cs.CL cs.LG cs.MA']",
            "figure_id": "1611.03218v4-Figure5-1",
            "image_path": "1611.03218v4-Figure5-1.png",
            "instance_id": "0efcf2b228cd26d1be646db5a36d7669",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the performance of the green line at 50k episodes?",
            "reference_answer": "0.68"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Performance of the model on images from the CelebA dataset when the asking-agent has four images, two rounds of question-answer are performed and with a vocabulary of eight and sixteen words available. The dashed grey lines represents the baseline performance where the asking-agent guesses randomly.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Performance of the model on images from the CelebA dataset when the asking-agent has four images, two rounds of question-answer are performed and with a vocabulary of eight and sixteen words available. The dashed grey lines represents the baseline performance where the asking-agent guesses randomly.",
            "categories": "['cs.AI cs.CL cs.LG cs.MA']",
            "figure_id": "1611.03218v4-Figure5-1",
            "image_path": "1611.03218v4-Figure5-1.png",
            "instance_id": "0b4f06a59bfdec2b324d841a398b2fbb",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the range of episodes?",
            "reference_answer": "0 to 50k"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The range of episodes is from 0 to 50,000 (0 to 50k).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Performance of the model on images from the CelebA dataset when the asking-agent has four images, two rounds of question-answer are performed and with a vocabulary of eight and sixteen words available. The dashed grey lines represents the baseline performance where the asking-agent guesses randomly.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Performance of the model on images from the CelebA dataset when the asking-agent has four images, two rounds of question-answer are performed and with a vocabulary of eight and sixteen words available. The dashed grey lines represents the baseline performance where the asking-agent guesses randomly.",
            "categories": "['cs.AI cs.CL cs.LG cs.MA']",
            "figure_id": "1611.03218v4-Figure5-1",
            "image_path": "1611.03218v4-Figure5-1.png",
            "instance_id": "b9ffbbfb5ed286b860955ef4dcbf4aa7",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the performance of the green line consistently exceed the performance of the red line throughout the training process?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, the performance of the green line does not consistently exceed the performance of the red line throughout the training process.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Performance of the model on images from the CelebA dataset when the asking-agent has four images, two rounds of question-answer are performed and with a vocabulary of eight and sixteen words available. The dashed grey lines represents the baseline performance where the asking-agent guesses randomly.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Performance of the model on images from the CelebA dataset when the asking-agent has four images, two rounds of question-answer are performed and with a vocabulary of eight and sixteen words available. The dashed grey lines represents the baseline performance where the asking-agent guesses randomly.",
            "categories": "['cs.AI cs.CL cs.LG cs.MA']",
            "figure_id": "1611.03218v4-Figure5-1",
            "image_path": "1611.03218v4-Figure5-1.png",
            "instance_id": "4c43fe16f3d70dec17469345b0f7ae69",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the model's performance improve with a larger vocabulary?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the model's performance improves with a larger vocabulary, as indicated by the higher performance levels observed for 16 words compared to 8 words over the episodes.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The red line"
                    },
                    {
                        "B": "The grey dashed line"
                    },
                    {
                        "C": "The blue line"
                    },
                    {
                        "D": "The green line"
                    }
                ],
                "caption": "Figure 5: Performance of the model on images from the CelebA dataset when the asking-agent has four images, two rounds of question-answer are performed and with a vocabulary of eight and sixteen words available. The dashed grey lines represents the baseline performance where the asking-agent guesses randomly.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Performance of the model on images from the CelebA dataset when the asking-agent has four images, two rounds of question-answer are performed and with a vocabulary of eight and sixteen words available. The dashed grey lines represents the baseline performance where the asking-agent guesses randomly.",
            "categories": "['cs.AI cs.CL cs.LG cs.MA']",
            "figure_id": "1611.03218v4-Figure5-1",
            "image_path": "1611.03218v4-Figure5-1.png",
            "instance_id": "4bd00a4bb343aac862613a5482682213",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line in the plot represents the model performance when a vocabulary of sixteen words was used?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "between 2 and 10"
                    },
                    {
                        "B": "between 2 and 4"
                    },
                    {
                        "C": "between 1 and 2"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 5: Performance of the model on images from the CelebA dataset when the asking-agent has four images, two rounds of question-answer are performed and with a vocabulary of eight and sixteen words available. The dashed grey lines represents the baseline performance where the asking-agent guesses randomly.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Performance of the model on images from the CelebA dataset when the asking-agent has four images, two rounds of question-answer are performed and with a vocabulary of eight and sixteen words available. The dashed grey lines represents the baseline performance where the asking-agent guesses randomly.",
            "categories": "['cs.AI cs.CL cs.LG cs.MA']",
            "figure_id": "1611.03218v4-Figure5-1",
            "image_path": "1611.03218v4-Figure5-1.png",
            "instance_id": "4455ebeff78e72b7d492202b90264a24",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the baseline performance of the asking-agent?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Performance of the model on images from the CelebA dataset when the asking-agent has four images, two rounds of question-answer are performed and with a vocabulary of eight and sixteen words available. The dashed grey lines represents the baseline performance where the asking-agent guesses randomly.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Performance of the model on images from the CelebA dataset when the asking-agent has four images, two rounds of question-answer are performed and with a vocabulary of eight and sixteen words available. The dashed grey lines represents the baseline performance where the asking-agent guesses randomly.",
            "categories": "['cs.AI cs.CL cs.LG cs.MA']",
            "figure_id": "1611.03218v4-Figure5-1",
            "image_path": "1611.03218v4-Figure5-1.png",
            "instance_id": "163988d1029af5a952d0acdab2c09e51",
            "qa_pair_type": "unanswerable",
            "question": "What is the average performance of the model when using a vocabulary of eight words after 25,000 episodes?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: A dependency syntax tree example",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: A dependency syntax tree example",
            "categories": "nan",
            "figure_id": "2020.lrec-1.865.pdf-Figure4",
            "image_path": "2020.lrec-1.865.pdf-Figure4.png",
            "instance_id": "5a79cd6b97ac75b0e0a6be1ab30670c0",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the color of the rectangular boxes containing the grammatical information in the lower left corner of Figure 4?",
            "reference_answer": "Light teal"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The color of the rectangular boxes containing the grammatical information in the lower left corner of the image is pink.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: A dependency syntax tree example",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: A dependency syntax tree example",
            "categories": "nan",
            "figure_id": "2020.lrec-1.865.pdf-Figure4",
            "image_path": "2020.lrec-1.865.pdf-Figure4.png",
            "instance_id": "5b49db3b3512036342dce3e9fff3166e",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the grammatical function of the word 'obloze' according to the provided dependency syntax tree?",
            "reference_answer": "Adv"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The grammatical function of the word 'obloze' according to the provided dependency syntax tree is that it functions as an adverb (Adv).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: A dependency syntax tree example",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: A dependency syntax tree example",
            "categories": "nan",
            "figure_id": "2020.lrec-1.865.pdf-Figure4",
            "image_path": "2020.lrec-1.865.pdf-Figure4.png",
            "instance_id": "c254c1757fcdb9a99ce95f08bf49d87c",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Are all the rectangular boxes in the dependency syntax tree the same size?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: A dependency syntax tree example",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: A dependency syntax tree example",
            "categories": "nan",
            "figure_id": "2020.lrec-1.865.pdf-Figure4",
            "image_path": "2020.lrec-1.865.pdf-Figure4.png",
            "instance_id": "a5fd157fb82b189be51c4fd52d4bb391",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the label of the root node #?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "It is cyan and rectangular "
                    },
                    {
                        "B": "It is red and circle"
                    },
                    {
                        "C": "It is yellow and circle"
                    },
                    {
                        "D": "It is red and rectangular"
                    }
                ],
                "caption": "Figure 4: A dependency syntax tree example",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: A dependency syntax tree example",
            "categories": "nan",
            "figure_id": "2020.lrec-1.865.pdf-Figure4",
            "image_path": "2020.lrec-1.865.pdf-Figure4.png",
            "instance_id": "bb6d615682a900cbe431e00177b26afd",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Considering the provided dependency syntax tree, which of the following options correctly describe the visual attributes of the node 'obloze' (sky)?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Subject"
                    },
                    {
                        "B": "Adverb"
                    },
                    {
                        "C": "Object"
                    },
                    {
                        "D": "Predicate"
                    }
                ],
                "caption": "Figure 4: A dependency syntax tree example",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: A dependency syntax tree example",
            "categories": "nan",
            "figure_id": "2020.lrec-1.865.pdf-Figure4",
            "image_path": "2020.lrec-1.865.pdf-Figure4.png",
            "instance_id": "d283eadd1fcc3e9ebcb3bace22e7ef40",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "According to the provided dependency syntax tree, which of the following grammatical roles are assigned to the word 'sebou'?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: A dependency syntax tree example",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: A dependency syntax tree example",
            "categories": "nan",
            "figure_id": "2020.lrec-1.865.pdf-Figure4",
            "image_path": "2020.lrec-1.865.pdf-Figure4.png",
            "instance_id": "0233a3748c6d58498419e0cb731d683c",
            "qa_pair_type": "unanswerable",
            "question": "How was the dependency syntax tree created?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "FIGURE 4 : Retrieving Inheritance patterns and Supertags from a Hypertag",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIGURE 4 : Retrieving Inheritance patterns and Supertags from a Hypertag",
            "categories": "nan",
            "figure_id": "C00-1065.pdf-Figure4",
            "image_path": "C00-1065.pdf-Figure4.png",
            "instance_id": "6da2a33810dcbd0e52cae78616cd7567",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "Which two elements are directly connected with gray lines to Dimension 2?",
            "reference_answer": "no-redistrib. and a-obj-empty"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The two elements that are directly connected with gray lines to Dimension 2 are \"\u00e0-obj-empty\" and \"no-redistrib.\"",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "FIGURE 4 : Retrieving Inheritance patterns and Supertags from a Hypertag",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIGURE 4 : Retrieving Inheritance patterns and Supertags from a Hypertag",
            "categories": "nan",
            "figure_id": "C00-1065.pdf-Figure4",
            "image_path": "C00-1065.pdf-Figure4.png",
            "instance_id": "a9ea43dcd2439e8ec6449508e88296da",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "How many Supertags correspond to inheritance patterns?",
            "reference_answer": "7"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "FIGURE 4 : Retrieving Inheritance patterns and Supertags from a Hypertag",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIGURE 4 : Retrieving Inheritance patterns and Supertags from a Hypertag",
            "categories": "nan",
            "figure_id": "C00-1065.pdf-Figure4",
            "image_path": "C00-1065.pdf-Figure4.png",
            "instance_id": "d98656b39f50a34ce76d0c65b690709b",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Are there any black lines connecting the dimension 3 label 'nom-invert' to beta4?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, there are black lines connecting the dimension 3 label 'nom-invert' to beta 4.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "FIGURE 4 : Retrieving Inheritance patterns and Supertags from a Hypertag",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIGURE 4 : Retrieving Inheritance patterns and Supertags from a Hypertag",
            "categories": "nan",
            "figure_id": "C00-1065.pdf-Figure4",
            "image_path": "C00-1065.pdf-Figure4.png",
            "instance_id": "6948eed879894eac2a5aee08cf9a653d",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Are there any supertags corresponding to inheritance patterns that do not have a corresponding tree?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, there are supertags corresponding to inheritance patterns that do not have a corresponding tree, as indicated by the branches labeled \"No Corresponding tree.\"",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "\u03b13, \u03b24, \u03b25, \u03b26, \u03b27"
                    },
                    {
                        "B": "\u03b11, \u03b12, \u03b25, \u03b24"
                    },
                    {
                        "C": "\u03b11, \u03b12, \u03b24, \u03b13, \u03b26"
                    },
                    {
                        "D": "\u03b11, \u03b12, \u03b24, \u03b13, \u03b27"
                    }
                ],
                "caption": "FIGURE 4 : Retrieving Inheritance patterns and Supertags from a Hypertag",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIGURE 4 : Retrieving Inheritance patterns and Supertags from a Hypertag",
            "categories": "nan",
            "figure_id": "C00-1065.pdf-Figure4",
            "image_path": "C00-1065.pdf-Figure4.png",
            "instance_id": "da1507e504eec64c65b87d05ec5a0590",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following supertags are directly connected with black solid lines to the node 'no-redistrib.' under Dimension 2?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "1"
                    },
                    {
                        "B": "2"
                    },
                    {
                        "C": "3"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "FIGURE 4 : Retrieving Inheritance patterns and Supertags from a Hypertag",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIGURE 4 : Retrieving Inheritance patterns and Supertags from a Hypertag",
            "categories": "nan",
            "figure_id": "C00-1065.pdf-Figure4",
            "image_path": "C00-1065.pdf-Figure4.png",
            "instance_id": "515e7145e2ab806038dd722c596aa708",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "How many dimensions are presented?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "FIGURE 4 : Retrieving Inheritance patterns and Supertags from a Hypertag",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIGURE 4 : Retrieving Inheritance patterns and Supertags from a Hypertag",
            "categories": "nan",
            "figure_id": "C00-1065.pdf-Figure4",
            "image_path": "C00-1065.pdf-Figure4.png",
            "instance_id": "45a7a853ea1a709d460bb76513743335",
            "qa_pair_type": "unanswerable",
            "question": "What is the linguistic phenomenon represented by the supertag 'B5' and what does it tell us about the hypertags?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8: Vocalic triangle, for the three degrees of articulation, estimated on the sentences generated by the HMM-based synthesizer. Dispersion ellipses are also indicated.",
                "compound": false,
                "figure_type": "Other",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: Vocalic triangle, for the three degrees of articulation, estimated on the sentences generated by the HMM-based synthesizer. Dispersion ellipses are also indicated.",
            "categories": "['eess.AS cs.CL']",
            "figure_id": "2006.04136v1-Figure8-1",
            "image_path": "2006.04136v1-Figure8-1.png",
            "instance_id": "97b6f8a7fc6b6f73729a52c57c1b8b03",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the shape of the dispersion ellipse for the sound /i/ in the 'Hypo' condition?",
            "reference_answer": "Oval"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8: Vocalic triangle, for the three degrees of articulation, estimated on the sentences generated by the HMM-based synthesizer. Dispersion ellipses are also indicated.",
                "compound": false,
                "figure_type": "Other",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: Vocalic triangle, for the three degrees of articulation, estimated on the sentences generated by the HMM-based synthesizer. Dispersion ellipses are also indicated.",
            "categories": "['eess.AS cs.CL']",
            "figure_id": "2006.04136v1-Figure8-1",
            "image_path": "2006.04136v1-Figure8-1.png",
            "instance_id": "c958bc3988f6ab0d5ec8f6f1624fe469",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What are the three degrees presented in the plot?",
            "reference_answer": "Hyper, Neutral, Hypo"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The three degrees presented in the plot are Hyper, Neutral, and Hypo.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8: Vocalic triangle, for the three degrees of articulation, estimated on the sentences generated by the HMM-based synthesizer. Dispersion ellipses are also indicated.",
                "compound": false,
                "figure_type": "Other",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: Vocalic triangle, for the three degrees of articulation, estimated on the sentences generated by the HMM-based synthesizer. Dispersion ellipses are also indicated.",
            "categories": "['eess.AS cs.CL']",
            "figure_id": "2006.04136v1-Figure8-1",
            "image_path": "2006.04136v1-Figure8-1.png",
            "instance_id": "5ac5b411e99faa98f23eb9e8a25450c2",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the dashed circle for /a/ have a F1(Hz) between 600 and 700?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8: Vocalic triangle, for the three degrees of articulation, estimated on the sentences generated by the HMM-based synthesizer. Dispersion ellipses are also indicated.",
                "compound": false,
                "figure_type": "Other",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: Vocalic triangle, for the three degrees of articulation, estimated on the sentences generated by the HMM-based synthesizer. Dispersion ellipses are also indicated.",
            "categories": "['eess.AS cs.CL']",
            "figure_id": "2006.04136v1-Figure8-1",
            "image_path": "2006.04136v1-Figure8-1.png",
            "instance_id": "57f140ea589835b5e7b9ddd27089bab2",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Are the F2 values between 500 and 2300?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Solid"
                    },
                    {
                        "B": "Dashed"
                    },
                    {
                        "C": "Dotted"
                    },
                    {
                        "D": "Both dashed and dotted"
                    }
                ],
                "caption": "Figure 8: Vocalic triangle, for the three degrees of articulation, estimated on the sentences generated by the HMM-based synthesizer. Dispersion ellipses are also indicated.",
                "compound": false,
                "figure_type": "Other",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: Vocalic triangle, for the three degrees of articulation, estimated on the sentences generated by the HMM-based synthesizer. Dispersion ellipses are also indicated.",
            "categories": "['eess.AS cs.CL']",
            "figure_id": "2006.04136v1-Figure8-1",
            "image_path": "2006.04136v1-Figure8-1.png",
            "instance_id": "b1e1b91b5cc99384fedd883c46016102",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which lines represent the \"Hypo\" condition in the vocalic triangle?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Hyper, Neutral, Hypo"
                    },
                    {
                        "B": "High, Mid, Low"
                    },
                    {
                        "C": "Front, Central, Back"
                    },
                    {
                        "D": "Round, Unround"
                    }
                ],
                "caption": "Figure 8: Vocalic triangle, for the three degrees of articulation, estimated on the sentences generated by the HMM-based synthesizer. Dispersion ellipses are also indicated.",
                "compound": false,
                "figure_type": "Other",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: Vocalic triangle, for the three degrees of articulation, estimated on the sentences generated by the HMM-based synthesizer. Dispersion ellipses are also indicated.",
            "categories": "['eess.AS cs.CL']",
            "figure_id": "2006.04136v1-Figure8-1",
            "image_path": "2006.04136v1-Figure8-1.png",
            "instance_id": "c11bbc595bc7abf5962beffbbbeb4da5",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What vocals are presented in the triangle?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8: Vocalic triangle, for the three degrees of articulation, estimated on the sentences generated by the HMM-based synthesizer. Dispersion ellipses are also indicated.",
                "compound": false,
                "figure_type": "Other",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: Vocalic triangle, for the three degrees of articulation, estimated on the sentences generated by the HMM-based synthesizer. Dispersion ellipses are also indicated.",
            "categories": "['eess.AS cs.CL']",
            "figure_id": "2006.04136v1-Figure8-1",
            "image_path": "2006.04136v1-Figure8-1.png",
            "instance_id": "c6fa036893f8db78586d617b1479cb2d",
            "qa_pair_type": "unanswerable",
            "question": "How are the degrees of articulation defined and what do they tell us about the vocals?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The degrees of articulation in the provided diagram refer to different qualities of vowel sounds based on their formant frequencies (F1 and F2). \n\n1. **Hyper articulation**: This is characterized by exaggerated clarity in the production of vowels. It typically involves higher formant values, which could lead to clearer distinctions between vowel sounds.\n\n2. **Neutral articulation**: This represents a more standard or typical production of vowels, sitting between the extremes of hyper and hypo articulation.\n\n3. **Hypo articulation**: This indicates less distinct production of vowel sounds, often leading to a blending of qualities and reduced clarity in their pronunciation.\n\nThese degrees of articulation tell us about how vowels can change in clarity and distinction depending on factors such as speech context, speaker intent, and audience perception. They highlight the variability in vocal production that affects communication effectiveness.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1. Percentage of participants (not) familiar with flooding",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1. Percentage of participants (not) familiar with flooding",
            "categories": "nan",
            "figure_id": "2020.eamt-1.2.pdf-Figure1",
            "image_path": "2020.eamt-1.2.pdf-Figure1.png",
            "instance_id": "72f02db45fbd9a1ab00cd22df8e4b9da",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What percentage of participants is located on the right side of the pie chart?",
            "reference_answer": "42%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, 44%, and I don't know, 14% are located on the right side of the pie chart. To find the total percentage on the right side, add these two values:\n\n44% + 14% = 58%\n\nSo, 58% of participants are located on the right side of the pie chart.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1. Percentage of participants (not) familiar with flooding",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1. Percentage of participants (not) familiar with flooding",
            "categories": "nan",
            "figure_id": "2020.eamt-1.2.pdf-Figure1",
            "image_path": "2020.eamt-1.2.pdf-Figure1.png",
            "instance_id": "ffc0f579075dcd4ea49f1f2fb648e5a9",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What percentage of participants responded I don't know?",
            "reference_answer": "14%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "14%",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1. Percentage of participants (not) familiar with flooding",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1. Percentage of participants (not) familiar with flooding",
            "categories": "nan",
            "figure_id": "2020.eamt-1.2.pdf-Figure1",
            "image_path": "2020.eamt-1.2.pdf-Figure1.png",
            "instance_id": "13c4056c6c02f5c8d3e70d523fc284a8",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the percentage of participants who answered \"Yes\" to the question larger than the percentage who answered \"No\"?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1. Percentage of participants (not) familiar with flooding",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1. Percentage of participants (not) familiar with flooding",
            "categories": "nan",
            "figure_id": "2020.eamt-1.2.pdf-Figure1",
            "image_path": "2020.eamt-1.2.pdf-Figure1.png",
            "instance_id": "e94b814ec9d240651948cbf0ad6791ca",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the plot present 3 different types of answers?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The plot presents three different types of answers: \"Yes,\" \"No,\" and \"I don't know.\"",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "right slice"
                    },
                    {
                        "B": "top left slice"
                    },
                    {
                        "C": "buttom left slice"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 1. Percentage of participants (not) familiar with flooding",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1. Percentage of participants (not) familiar with flooding",
            "categories": "nan",
            "figure_id": "2020.eamt-1.2.pdf-Figure1",
            "image_path": "2020.eamt-1.2.pdf-Figure1.png",
            "instance_id": "efa0bf813f5e51187620271939db7b38",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following slices of the pie chart represent participants who were familiar with flooding?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "44%"
                    },
                    {
                        "B": "14%"
                    },
                    {
                        "C": "42%"
                    },
                    {
                        "D": "56%"
                    }
                ],
                "caption": "Figure 1. Percentage of participants (not) familiar with flooding",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1. Percentage of participants (not) familiar with flooding",
            "categories": "nan",
            "figure_id": "2020.eamt-1.2.pdf-Figure1",
            "image_path": "2020.eamt-1.2.pdf-Figure1.png",
            "instance_id": "1282cbab35e4c3c5f1a9aaa24204aab9",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What percentage of participants are familiar with flooding?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1. Percentage of participants (not) familiar with flooding",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1. Percentage of participants (not) familiar with flooding",
            "categories": "nan",
            "figure_id": "2020.eamt-1.2.pdf-Figure1",
            "image_path": "2020.eamt-1.2.pdf-Figure1.png",
            "instance_id": "37bf0e00af8d005b02e0602b720b7362",
            "qa_pair_type": "unanswerable",
            "question": "What is the average age of the participants in this survey and how does it influence the results?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Select results from our survey.",
                "compound": true,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Select results from our survey.",
            "categories": "nan",
            "figure_id": "2020.acl-main.506.pdf-Figure3",
            "image_path": "2020.acl-main.506.pdf-Figure3.png",
            "instance_id": "bcba950cfa716d864971a74646eb69e6",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What slice presents the percentage of participants who answered yes to the question on the top right plot?",
            "reference_answer": "blue"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The slice that presents the percentage of participants who answered yes to the question on the top right plot is 52.7%.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Select results from our survey.",
                "compound": true,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Select results from our survey.",
            "categories": "nan",
            "figure_id": "2020.acl-main.506.pdf-Figure3",
            "image_path": "2020.acl-main.506.pdf-Figure3.png",
            "instance_id": "4b4e7e1325e11d0623fab170c5c058fb",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What percentage of respondents know the definition of Bayes Factor?",
            "reference_answer": "21.8%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "78.2%",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Select results from our survey.",
                "compound": true,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Select results from our survey.",
            "categories": "nan",
            "figure_id": "2020.acl-main.506.pdf-Figure3",
            "image_path": "2020.acl-main.506.pdf-Figure3.png",
            "instance_id": "21f09c528b7f98bcaf5487db3452b5d5",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the blue section of the pie chart in the bottom left corner smaller than the blue section of the pie chart in the top left corner?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Select results from our survey.",
                "compound": true,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Select results from our survey.",
            "categories": "nan",
            "figure_id": "2020.acl-main.506.pdf-Figure3",
            "image_path": "2020.acl-main.506.pdf-Figure3.png",
            "instance_id": "2db4c120003122c7cfa87870f582f0b2",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Did a majority of respondents know the definition of \"Bayes Factor\"?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Top left"
                    },
                    {
                        "B": "Top right"
                    },
                    {
                        "C": "Bottom left"
                    },
                    {
                        "D": "Bottom right"
                    }
                ],
                "caption": "Figure 3: Select results from our survey.",
                "compound": true,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Select results from our survey.",
            "categories": "nan",
            "figure_id": "2020.acl-main.506.pdf-Figure3",
            "image_path": "2020.acl-main.506.pdf-Figure3.png",
            "instance_id": "e36fed7081f702f62095b989fdd03dc6",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which pie chart represents the question 'Have you heard about \"Bayesian Hypothesis Testing\"?'",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Have you heard about 'Bayesian Hypothesis Testing'?"
                    },
                    {
                        "B": "Do you know the definition of 'Bayes Factor'?"
                    },
                    {
                        "C": "I have used 'hypothesis testing' in the past"
                    },
                    {
                        "D": "Do you know the definition of 'Highest Density Interval'?"
                    }
                ],
                "caption": "Figure 3: Select results from our survey.",
                "compound": true,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Select results from our survey.",
            "categories": "nan",
            "figure_id": "2020.acl-main.506.pdf-Figure3",
            "image_path": "2020.acl-main.506.pdf-Figure3.png",
            "instance_id": "1f0821e4e47dc43aadb4c0218d3e7f3e",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "In the survey results, which of the following questions had a response option of 'Don't remember'?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Select results from our survey.",
                "compound": true,
                "figure_type": "pie chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Select results from our survey.",
            "categories": "nan",
            "figure_id": "2020.acl-main.506.pdf-Figure3",
            "image_path": "2020.acl-main.506.pdf-Figure3.png",
            "instance_id": "652d1930bda9689c76ab877c3158f87f",
            "qa_pair_type": "unanswerable",
            "question": "What is the total number of respondents to the survey and how does it affect the results?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: State transition map of interaction in PHOTON. States with darker background are the end states that can receive user reply, and switch to INIT state automatically. The bottom part is the system response templates in each end state.",
                "compound": true,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: State transition map of interaction in PHOTON. States with darker background are the end states that can receive user reply, and switch to INIT state automatically. The bottom part is the system response templates in each end state.",
            "categories": "nan",
            "figure_id": "2020.acl-demos.24.pdf-Figure2",
            "image_path": "2020.acl-demos.24.pdf-Figure2.png",
            "instance_id": "997ec5d56966cb71dc328e950c973556",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "Which squares in the diagram have the darkest background?",
            "reference_answer": "CONFIRM_CORRECTION, INIT, NEED_REPHRASE, INVALID_QUERY, CONFIRM_RESULT"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The squares with the darkest background in the diagram are:\n\n- INIT\n- INVALID_QUERY\n\n",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: State transition map of interaction in PHOTON. States with darker background are the end states that can receive user reply, and switch to INIT state automatically. The bottom part is the system response templates in each end state.",
                "compound": true,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: State transition map of interaction in PHOTON. States with darker background are the end states that can receive user reply, and switch to INIT state automatically. The bottom part is the system response templates in each end state.",
            "categories": "nan",
            "figure_id": "2020.acl-demos.24.pdf-Figure2",
            "image_path": "2020.acl-demos.24.pdf-Figure2.png",
            "instance_id": "0f923c5fecc08f511c493af288cdda79",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the starting state?",
            "reference_answer": "INIT"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The starting state is \"INIT.\"",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: State transition map of interaction in PHOTON. States with darker background are the end states that can receive user reply, and switch to INIT state automatically. The bottom part is the system response templates in each end state.",
                "compound": true,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: State transition map of interaction in PHOTON. States with darker background are the end states that can receive user reply, and switch to INIT state automatically. The bottom part is the system response templates in each end state.",
            "categories": "nan",
            "figure_id": "2020.acl-demos.24.pdf-Figure2",
            "image_path": "2020.acl-demos.24.pdf-Figure2.png",
            "instance_id": "ee401870365d4c2075a4c03ab118c7c8",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Are the end states square boxes connected with a black arrow to a diamond state?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: State transition map of interaction in PHOTON. States with darker background are the end states that can receive user reply, and switch to INIT state automatically. The bottom part is the system response templates in each end state.",
                "compound": true,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: State transition map of interaction in PHOTON. States with darker background are the end states that can receive user reply, and switch to INIT state automatically. The bottom part is the system response templates in each end state.",
            "categories": "nan",
            "figure_id": "2020.acl-demos.24.pdf-Figure2",
            "image_path": "2020.acl-demos.24.pdf-Figure2.png",
            "instance_id": "279a4766c7c9bd05a14429684026ca06",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "State INIT is directly connected to INVALID_QUERY state?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "CONFIRM_SQL and NEED_REPHRASE"
                    },
                    {
                        "B": "NEED_REPHRASE and CONFIRM_RESULT"
                    },
                    {
                        "C": "CLARIFY and CONFIRM_SQL"
                    },
                    {
                        "D": "CONFIRM_CORRECTION and CONFIRM_SQL"
                    }
                ],
                "caption": "Figure 2: State transition map of interaction in PHOTON. States with darker background are the end states that can receive user reply, and switch to INIT state automatically. The bottom part is the system response templates in each end state.",
                "compound": true,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: State transition map of interaction in PHOTON. States with darker background are the end states that can receive user reply, and switch to INIT state automatically. The bottom part is the system response templates in each end state.",
            "categories": "nan",
            "figure_id": "2020.acl-demos.24.pdf-Figure2",
            "image_path": "2020.acl-demos.24.pdf-Figure2.png",
            "instance_id": "e345e1be539b8b3e9aac151ceb7934e9",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following states are in a white background box?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Confirm_SQL to Executable or not "
                    },
                    {
                        "B": "Executable or not  to CONFIRM_RESULT"
                    },
                    {
                        "C": "Has span or not to NEED_REPHRASE"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 2: State transition map of interaction in PHOTON. States with darker background are the end states that can receive user reply, and switch to INIT state automatically. The bottom part is the system response templates in each end state.",
                "compound": true,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: State transition map of interaction in PHOTON. States with darker background are the end states that can receive user reply, and switch to INIT state automatically. The bottom part is the system response templates in each end state.",
            "categories": "nan",
            "figure_id": "2020.acl-demos.24.pdf-Figure2",
            "image_path": "2020.acl-demos.24.pdf-Figure2.png",
            "instance_id": "f6237328477f3731f953c7adaf1fc336",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following states is directly connected to other state with a No label? ",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: State transition map of interaction in PHOTON. States with darker background are the end states that can receive user reply, and switch to INIT state automatically. The bottom part is the system response templates in each end state.",
                "compound": true,
                "figure_type": "architecture diagram",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: State transition map of interaction in PHOTON. States with darker background are the end states that can receive user reply, and switch to INIT state automatically. The bottom part is the system response templates in each end state.",
            "categories": "nan",
            "figure_id": "2020.acl-demos.24.pdf-Figure2",
            "image_path": "2020.acl-demos.24.pdf-Figure2.png",
            "instance_id": "314d9cc71a7c10427ffc4f5cc735e184",
            "qa_pair_type": "unanswerable",
            "question": "What is the logic implemented in the PHOTON system to determine if a user's input is translatable or not and how is it reflected in the plot?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The logic implemented in the PHOTON system for determining if a user's input is translatable follows these steps:\n\n1. **INIT**: The process begins by checking if the input is translatable.\n2. If the input is **translatable**, it leads to the **CONFIRM_SQL** stage.\n3. If it is **not translatable**, the system moves to **CLARIFY**.\n4. In the **CLARIFY** stage, the system checks if the input needs to be rephrased.\n   - If it does **not** need rephrasing, the next step is to check whether the input has a span.\n     - If it **has** a span, it goes to **CONFIRM_CORRECTION**.\n     - If it **does not** have a span, it proceeds to **INVALID_QUERY**.\n5. If rephrasing is needed, the system prompts the user to rephrase the question (goes to **NEED_REPHRASE**).\n6. Finally, the flow can lead to **CONFIRM_RESULT** if the input is executable, or **INVALID_QUERY** if it is not.\n\nThis structured approach ensures that the user input is processed in a systematic way to determine its translatability and appropriateness for SQL execution, reflected in the flowchart's various decision points and responses.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Profile plot of MAP",
                "compound": false,
                "figure_type": "box plot",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Profile plot of MAP",
            "categories": "nan",
            "figure_id": "W10-1203.pdf-Figure3",
            "image_path": "W10-1203.pdf-Figure3.png",
            "instance_id": "39a802f4bde34390008eb57f78ef7e44",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate median value of the gray boxplot for the 'and' query model?",
            "reference_answer": "0.15"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Profile plot of MAP",
                "compound": false,
                "figure_type": "box plot",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Profile plot of MAP",
            "categories": "nan",
            "figure_id": "W10-1203.pdf-Figure3",
            "image_path": "W10-1203.pdf-Figure3.png",
            "instance_id": "aa548dbf3a2029689ea1915427d60158",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What are the three query models shown in Figure 3?",
            "reference_answer": "and, or, mlt"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The three query models shown in the figure are:\n\n1. and\n2. or\n3. mlt",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Profile plot of MAP",
                "compound": false,
                "figure_type": "box plot",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Profile plot of MAP",
            "categories": "nan",
            "figure_id": "W10-1203.pdf-Figure3",
            "image_path": "W10-1203.pdf-Figure3.png",
            "instance_id": "9241237d034bb8041d1966caae3b0504",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Are the red circles in 'and' model higher than the red circles for the 'or' model?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Profile plot of MAP",
                "compound": false,
                "figure_type": "box plot",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Profile plot of MAP",
            "categories": "nan",
            "figure_id": "W10-1203.pdf-Figure3",
            "image_path": "W10-1203.pdf-Figure3.png",
            "instance_id": "feb10c48fd2cfa935bbf2fd1476219ea",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the median value of the 'stem' boxplot for the 'and' query model higher than the median value of the 'raw' boxplot for the same query model?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "yellow with black borders"
                    },
                    {
                        "B": "yellow with red borders"
                    },
                    {
                        "C": "gray with blue borders"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 3: Profile plot of MAP",
                "compound": false,
                "figure_type": "box plot",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Profile plot of MAP",
            "categories": "nan",
            "figure_id": "W10-1203.pdf-Figure3",
            "image_path": "W10-1203.pdf-Figure3.png",
            "instance_id": "78c7e47f331e203e655d36124ca825c1",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which stem type has the highest mean?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "from 0 to 9"
                    },
                    {
                        "B": "from 0 to 5"
                    },
                    {
                        "C": "from 0 to 7"
                    },
                    {
                        "D": "from 0 to 1.2"
                    }
                ],
                "caption": "Figure 3: Profile plot of MAP",
                "compound": false,
                "figure_type": "box plot",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Profile plot of MAP",
            "categories": "nan",
            "figure_id": "W10-1203.pdf-Figure3",
            "image_path": "W10-1203.pdf-Figure3.png",
            "instance_id": "810b22cc476c32b20dcc5366eb3a9c1b",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the range of the average precision?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Profile plot of MAP",
                "compound": false,
                "figure_type": "box plot",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Profile plot of MAP",
            "categories": "nan",
            "figure_id": "W10-1203.pdf-Figure3",
            "image_path": "W10-1203.pdf-Figure3.png",
            "instance_id": "6320242e7fe7b971836217acaa1b8d1d",
            "qa_pair_type": "unanswerable",
            "question": "What is the statistical significance of the difference in Mean Average Precision (MAP) between the 'raw' and 'stem' query models for the 'and' query type, considering a significance level of 0.05?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Confusion Matrix of the OLID gold test set, sub-task A. Depicted are instances and normalized values.",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Confusion Matrix of the OLID gold test set, sub-task A. Depicted are instances and normalized values.",
            "categories": "nan",
            "figure_id": "S19-2127.pdf-Figure2",
            "image_path": "S19-2127.pdf-Figure2.png",
            "instance_id": "be30de72f2e8d0b440c29344dd450633",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of the darkest blue square in the confusion matrix?",
            "reference_answer": "560"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The value of the darkest blue square in the confusion matrix is 560.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Confusion Matrix of the OLID gold test set, sub-task A. Depicted are instances and normalized values.",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Confusion Matrix of the OLID gold test set, sub-task A. Depicted are instances and normalized values.",
            "categories": "nan",
            "figure_id": "S19-2127.pdf-Figure2",
            "image_path": "S19-2127.pdf-Figure2.png",
            "instance_id": "5870b09543abf7a052ad1dd167fc4899",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the number of instances correctly predicted as OFF?",
            "reference_answer": "161"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The number of instances correctly predicted as OFF is 161.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Confusion Matrix of the OLID gold test set, sub-task A. Depicted are instances and normalized values.",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Confusion Matrix of the OLID gold test set, sub-task A. Depicted are instances and normalized values.",
            "categories": "nan",
            "figure_id": "S19-2127.pdf-Figure2",
            "image_path": "S19-2127.pdf-Figure2.png",
            "instance_id": "5982322a0aa50ddfcc2a857b6b705f8a",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the percentage value in the top right square of the confusion matrix greater than 50%?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Confusion Matrix of the OLID gold test set, sub-task A. Depicted are instances and normalized values.",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Confusion Matrix of the OLID gold test set, sub-task A. Depicted are instances and normalized values.",
            "categories": "nan",
            "figure_id": "S19-2127.pdf-Figure2",
            "image_path": "S19-2127.pdf-Figure2.png",
            "instance_id": "7ef02388b3f9b03f3872fad4306582aa",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the normalized value for the correctly predicted 'NOT' instances higher than the normalized value for the incorrectly predicted 'OFF' instances?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The normalized value for the correctly predicted 'NOT' instances is 90.32%, which is higher than the normalized value for the incorrectly predicted 'OFF' instances (32.92%).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Circles"
                    },
                    {
                        "B": "Rectangles"
                    },
                    {
                        "C": "Cylinders"
                    },
                    {
                        "D": "Squares"
                    }
                ],
                "caption": "Figure 2: Confusion Matrix of the OLID gold test set, sub-task A. Depicted are instances and normalized values.",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Confusion Matrix of the OLID gold test set, sub-task A. Depicted are instances and normalized values.",
            "categories": "nan",
            "figure_id": "S19-2127.pdf-Figure2",
            "image_path": "S19-2127.pdf-Figure2.png",
            "instance_id": "9a8c586d3b3fda142cf47eb0c9360858",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What is the shape of the figures presented in the confusion matrix?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "BD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "560, 60, 79, 161"
                    },
                    {
                        "B": "65%, 9.68%, 32.92%, 67.08%"
                    },
                    {
                        "C": " 0.20, 0.67, 0.32, 0.10"
                    },
                    {
                        "D": "All of the above"
                    }
                ],
                "caption": "Figure 2: Confusion Matrix of the OLID gold test set, sub-task A. Depicted are instances and normalized values.",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Confusion Matrix of the OLID gold test set, sub-task A. Depicted are instances and normalized values.",
            "categories": "nan",
            "figure_id": "S19-2127.pdf-Figure2",
            "image_path": "S19-2127.pdf-Figure2.png",
            "instance_id": "f8aa9f33915fe3c309c32936561cf8c4",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following values are displayed in the confusion matrix?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Confusion Matrix of the OLID gold test set, sub-task A. Depicted are instances and normalized values.",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Confusion Matrix of the OLID gold test set, sub-task A. Depicted are instances and normalized values.",
            "categories": "nan",
            "figure_id": "S19-2127.pdf-Figure2",
            "image_path": "S19-2127.pdf-Figure2.png",
            "instance_id": "7ba16b09aa1027811aada110d67d365b",
            "qa_pair_type": "unanswerable",
            "question": "What is the precision of the 'OFF' class in the OLID gold test set, sub-task A and what does it tell us about the models performance?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "To calculate precision for the 'OFF' class, use the formula:\n\n\\[ \\text{Precision} = \\frac{TP}{TP + FP} \\]\n\nWhere:\n- TP (True Positives) = 161 (correctly predicted 'OFF')\n- FP (False Positives) = 60 (incorrectly predicted 'OFF' when true label is 'NOT')\n\nCalculating precision:\n\n\\[ \\text{Precision} = \\frac{161}{161 + 60} = \\frac{161}{221} \\approx 0.729 \\, (\\text{or } 72.9\\%) \\]\n\n### Interpretation:\nA precision of approximately 72.9% means that when the model predicts 'OFF', it is correct about 72.9% of the time. This indicates a moderately good performance in predicting the 'OFF' class, suggesting that there is room for improvement in reducing false positives.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Number of emotion labels per example before and after filtering the labels chosen by only a single annotator.",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Number of emotion labels per example before and after filtering the labels chosen by only a single annotator.",
            "categories": "nan",
            "figure_id": "2020.acl-main.372.pdf-Figure5",
            "image_path": "2020.acl-main.372.pdf-Figure5.png",
            "instance_id": "61d3a04f7d6107e5ae9f6b67afbdd4bd",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the height of the tallest light blue bar in the histogram?",
            "reference_answer": "20k"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The height of the tallest light blue bar in the histogram is approximately 30k (30,000).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Number of emotion labels per example before and after filtering the labels chosen by only a single annotator.",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Number of emotion labels per example before and after filtering the labels chosen by only a single annotator.",
            "categories": "nan",
            "figure_id": "2020.acl-main.372.pdf-Figure5",
            "image_path": "2020.acl-main.372.pdf-Figure5.png",
            "instance_id": "c544def77e6c1583508e6ce7d0f7200d",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the total number of emotion labels with post-filtering?",
            "reference_answer": "45000"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Number of emotion labels per example before and after filtering the labels chosen by only a single annotator.",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Number of emotion labels per example before and after filtering the labels chosen by only a single annotator.",
            "categories": "nan",
            "figure_id": "2020.acl-main.372.pdf-Figure5",
            "image_path": "2020.acl-main.372.pdf-Figure5.png",
            "instance_id": "5254303373c8c0f6c5bd31609ce9414d",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is there a dark blue bar in with number of labels 4, 5, 6, and 7?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, there is a dark blue bar for the number of labels 4. There are no dark blue bars for the number of labels 5, 6, and 7.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Number of emotion labels per example before and after filtering the labels chosen by only a single annotator.",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Number of emotion labels per example before and after filtering the labels chosen by only a single annotator.",
            "categories": "nan",
            "figure_id": "2020.acl-main.372.pdf-Figure5",
            "image_path": "2020.acl-main.372.pdf-Figure5.png",
            "instance_id": "9b9fa9df313fbb6dba28016196a034c3",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Did the filtering process reduce the number of examples with more than one emotion label?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the filtering process reduced the number of examples with more than one emotion label. You can see that after the filtering (post-filter), the bars for categories with more than one label (2, 3, 4, 5, 6, 7) are significantly lower compared to the pre-filter bars.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The dark blue bar with 10k and light blue bar with 20k"
                    },
                    {
                        "B": "The dark blue bar with 40k and light blue bar with 20k"
                    },
                    {
                        "C": "The dark blue bar with 0k and light blue bar with 20k"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 5: Number of emotion labels per example before and after filtering the labels chosen by only a single annotator.",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Number of emotion labels per example before and after filtering the labels chosen by only a single annotator.",
            "categories": "nan",
            "figure_id": "2020.acl-main.372.pdf-Figure5",
            "image_path": "2020.acl-main.372.pdf-Figure5.png",
            "instance_id": "56dd4c9556907f7eda86d17b11847e3e",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Considering the bars select the correct option that describes its color and the number of examples for condition with number of labels 2?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "pre and post filter"
                    },
                    {
                        "B": "without filtering"
                    },
                    {
                        "C": "only pre filtering "
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 5: Number of emotion labels per example before and after filtering the labels chosen by only a single annotator.",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Number of emotion labels per example before and after filtering the labels chosen by only a single annotator.",
            "categories": "nan",
            "figure_id": "2020.acl-main.372.pdf-Figure5",
            "image_path": "2020.acl-main.372.pdf-Figure5.png",
            "instance_id": "7aa3806f4a83c91aa42a05913d7f0d7d",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What two conditions of filtering are presented in the plot?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Number of emotion labels per example before and after filtering the labels chosen by only a single annotator.",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Number of emotion labels per example before and after filtering the labels chosen by only a single annotator.",
            "categories": "nan",
            "figure_id": "2020.acl-main.372.pdf-Figure5",
            "image_path": "2020.acl-main.372.pdf-Figure5.png",
            "instance_id": "807b88fef075199eeb214d118b3d953d",
            "qa_pair_type": "unanswerable",
            "question": "What is the exact number of examples with four emotion labels before filtering, and how many annotators contributed to each of these examples?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: (Left): Negative class F1-score of LSC with #past domains in natural class distribution. (Right): Accuracy of LSC with #past domains in balanced class distribution.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: (Left): Negative class F1-score of LSC with #past domains in natural class distribution. (Right): Accuracy of LSC with #past domains in balanced class distribution.",
            "categories": "['cs.CL cs.IR cs.LG']",
            "figure_id": "1801.02808v1-Figure1-1",
            "image_path": "1801.02808v1-Figure1-1.png",
            "instance_id": "52f35f68a8253f24275c48f7bbe99448",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is approximately the value on the y-axis corresponding to the point marked with an 'x' at the rightmost end of the blue line on the left plot?",
            "reference_answer": "0.67"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The approximate value on the y-axis corresponding to the point marked with an 'x' at the rightmost end of the blue line on the left plot is about 0.68.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: (Left): Negative class F1-score of LSC with #past domains in natural class distribution. (Right): Accuracy of LSC with #past domains in balanced class distribution.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: (Left): Negative class F1-score of LSC with #past domains in natural class distribution. (Right): Accuracy of LSC with #past domains in balanced class distribution.",
            "categories": "['cs.CL cs.IR cs.LG']",
            "figure_id": "1801.02808v1-Figure1-1",
            "image_path": "1801.02808v1-Figure1-1.png",
            "instance_id": "6d63fef0f0e602b522ec09a2bc6e16b6",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is approximately the accuracy of LSC with 19 past domains in balanced class distribution?",
            "reference_answer": "0.83"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: (Left): Negative class F1-score of LSC with #past domains in natural class distribution. (Right): Accuracy of LSC with #past domains in balanced class distribution.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: (Left): Negative class F1-score of LSC with #past domains in natural class distribution. (Right): Accuracy of LSC with #past domains in balanced class distribution.",
            "categories": "['cs.CL cs.IR cs.LG']",
            "figure_id": "1801.02808v1-Figure1-1",
            "image_path": "1801.02808v1-Figure1-1.png",
            "instance_id": "ffe24af264d0113b0cee318dde386131",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the value of the leftmost data point on the right graph greater than 0.8?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: (Left): Negative class F1-score of LSC with #past domains in natural class distribution. (Right): Accuracy of LSC with #past domains in balanced class distribution.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: (Left): Negative class F1-score of LSC with #past domains in natural class distribution. (Right): Accuracy of LSC with #past domains in balanced class distribution.",
            "categories": "['cs.CL cs.IR cs.LG']",
            "figure_id": "1801.02808v1-Figure1-1",
            "image_path": "1801.02808v1-Figure1-1.png",
            "instance_id": "5e023060eeae8472a998f65aa82c2c30",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the accuracy of LSC increase with the number of past domains in balanced class distribution?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Left plot"
                    },
                    {
                        "B": "Right plot"
                    },
                    {
                        "C": "Both plots have the same maximum value"
                    },
                    {
                        "D": "Neither plot has a defined maximum value"
                    }
                ],
                "caption": "Figure 1: (Left): Negative class F1-score of LSC with #past domains in natural class distribution. (Right): Accuracy of LSC with #past domains in balanced class distribution.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: (Left): Negative class F1-score of LSC with #past domains in natural class distribution. (Right): Accuracy of LSC with #past domains in balanced class distribution.",
            "categories": "['cs.CL cs.IR cs.LG']",
            "figure_id": "1801.02808v1-Figure1-1",
            "image_path": "1801.02808v1-Figure1-1.png",
            "instance_id": "e0cafca8a061883cfa5b7e56d064731b",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the plots shows a higher maximum value on the y-axis?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Accuracy"
                    },
                    {
                        "B": "F1-score"
                    },
                    {
                        "C": "Precision"
                    },
                    {
                        "D": "Recall"
                    }
                ],
                "caption": "Figure 1: (Left): Negative class F1-score of LSC with #past domains in natural class distribution. (Right): Accuracy of LSC with #past domains in balanced class distribution.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: (Left): Negative class F1-score of LSC with #past domains in natural class distribution. (Right): Accuracy of LSC with #past domains in balanced class distribution.",
            "categories": "['cs.CL cs.IR cs.LG']",
            "figure_id": "1801.02808v1-Figure1-1",
            "image_path": "1801.02808v1-Figure1-1.png",
            "instance_id": "0063a9ac7b4522d2f21c8e2e6c5e4722",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following metrics are represented in the figure?",
            "reference_answer": "AB"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: (Left): Negative class F1-score of LSC with #past domains in natural class distribution. (Right): Accuracy of LSC with #past domains in balanced class distribution.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: (Left): Negative class F1-score of LSC with #past domains in natural class distribution. (Right): Accuracy of LSC with #past domains in balanced class distribution.",
            "categories": "['cs.CL cs.IR cs.LG']",
            "figure_id": "1801.02808v1-Figure1-1",
            "image_path": "1801.02808v1-Figure1-1.png",
            "instance_id": "bd146a7de50bca1d328bb09a564b7f0f",
            "qa_pair_type": "unanswerable",
            "question": "What is the difference in accuracy between LSC with 5 past domains in a balanced class distribution and LSC with 19 past domains in a balanced class distribution?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Performance change with respect to (a) sampling ratio of mentions from the training set on the Wiki dataset; and (b) regularization parameter \u03bb on the BBN dataset.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Performance change with respect to (a) sampling ratio of mentions from the training set on the Wiki dataset; and (b) regularization parameter \u03bb on the BBN dataset.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1602.05307v1-Figure4-1",
            "image_path": "1602.05307v1-Figure4-1.png",
            "instance_id": "bd8c9addcbd57817c2a8fa791ada3b6f",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the red line at the sampling ratio of 50% in the leftmost figure?",
            "reference_answer": "0.7"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Performance change with respect to (a) sampling ratio of mentions from the training set on the Wiki dataset; and (b) regularization parameter \u03bb on the BBN dataset.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Performance change with respect to (a) sampling ratio of mentions from the training set on the Wiki dataset; and (b) regularization parameter \u03bb on the BBN dataset.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1602.05307v1-Figure4-1",
            "image_path": "1602.05307v1-Figure4-1.png",
            "instance_id": "b46169cc368b5f481a3e9eab600577f2",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "At which aproximate lambda PLE has Micro-F1 score of 0.45?",
            "reference_answer": "1"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Performance change with respect to (a) sampling ratio of mentions from the training set on the Wiki dataset; and (b) regularization parameter \u03bb on the BBN dataset.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Performance change with respect to (a) sampling ratio of mentions from the training set on the Wiki dataset; and (b) regularization parameter \u03bb on the BBN dataset.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1602.05307v1-Figure4-1",
            "image_path": "1602.05307v1-Figure4-1.png",
            "instance_id": "1e0601bfdecaaaa0fea6594bfc0d4de6",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the performance of the blue line decrease when the sampling ratio is increased from 30% to 50% in the left graph?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Performance change with respect to (a) sampling ratio of mentions from the training set on the Wiki dataset; and (b) regularization parameter \u03bb on the BBN dataset.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Performance change with respect to (a) sampling ratio of mentions from the training set on the Wiki dataset; and (b) regularization parameter \u03bb on the BBN dataset.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1602.05307v1-Figure4-1",
            "image_path": "1602.05307v1-Figure4-1.png",
            "instance_id": "2e84e27c7f314c72c66d6bfe76abdbfa",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the performance of the PLE-NoCo improve with an increase in sampling ratio?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "PLE"
                    },
                    {
                        "B": "PLE-NoCo, PLE, PTE"
                    },
                    {
                        "C": "PLE, PTE, PLE-NoCo"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 4: Performance change with respect to (a) sampling ratio of mentions from the training set on the Wiki dataset; and (b) regularization parameter \u03bb on the BBN dataset.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Performance change with respect to (a) sampling ratio of mentions from the training set on the Wiki dataset; and (b) regularization parameter \u03bb on the BBN dataset.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1602.05307v1-Figure4-1",
            "image_path": "1602.05307v1-Figure4-1.png",
            "instance_id": "77e9789c23eafa0606ffef0c14a0d24b",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What is the line in the right figure representing?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "PTE and PLE"
                    },
                    {
                        "B": "PLE and PLE-NoCo"
                    },
                    {
                        "C": "PTE, PLE and PLE-NoCo"
                    },
                    {
                        "D": "PTE and PLE-NoCo"
                    }
                ],
                "caption": "Figure 4: Performance change with respect to (a) sampling ratio of mentions from the training set on the Wiki dataset; and (b) regularization parameter \u03bb on the BBN dataset.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Performance change with respect to (a) sampling ratio of mentions from the training set on the Wiki dataset; and (b) regularization parameter \u03bb on the BBN dataset.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1602.05307v1-Figure4-1",
            "image_path": "1602.05307v1-Figure4-1.png",
            "instance_id": "1d65cb55b34624e21a3adfd2ebe31d39",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which methods show a performance of aproximately 0.75? ",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Performance change with respect to (a) sampling ratio of mentions from the training set on the Wiki dataset; and (b) regularization parameter \u03bb on the BBN dataset.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Performance change with respect to (a) sampling ratio of mentions from the training set on the Wiki dataset; and (b) regularization parameter \u03bb on the BBN dataset.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1602.05307v1-Figure4-1",
            "image_path": "1602.05307v1-Figure4-1.png",
            "instance_id": "b12683c79be4dc8ef640da8fc76d9004",
            "qa_pair_type": "unanswerable",
            "question": "What are the values of the regularization parameter \u03bb that were used in the BBN dataset for the experiment?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Average cumulative loss on training data for sparse multiclass text classification. All results are averaged over 3 runs, with mean results in bold lines, 2 standard deviations in filled areas.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Average cumulative loss on training data for sparse multiclass text classification. All results are averaged over 3 runs, with mean results in bold lines, 2 standard deviations in filled areas.",
            "categories": "['stat.ML cs.CL cs.LG']",
            "figure_id": "1806.04458v3-Figure2-1",
            "image_path": "1806.04458v3-Figure2-1.png",
            "instance_id": "a2c6e7b58765067e187f1d986248b70b",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the average cumulative loss for the green solid line at 2,500 iterations?",
            "reference_answer": "0.45"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Average cumulative loss on training data for sparse multiclass text classification. All results are averaged over 3 runs, with mean results in bold lines, 2 standard deviations in filled areas.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Average cumulative loss on training data for sparse multiclass text classification. All results are averaged over 3 runs, with mean results in bold lines, 2 standard deviations in filled areas.",
            "categories": "['stat.ML cs.CL cs.LG']",
            "figure_id": "1806.04458v3-Figure2-1",
            "image_path": "1806.04458v3-Figure2-1.png",
            "instance_id": "7ef0e85fb9a535393eb2f5b38d3fdc52",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "How many runs were the results averaged over?",
            "reference_answer": "3"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Average cumulative loss on training data for sparse multiclass text classification. All results are averaged over 3 runs, with mean results in bold lines, 2 standard deviations in filled areas.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Average cumulative loss on training data for sparse multiclass text classification. All results are averaged over 3 runs, with mean results in bold lines, 2 standard deviations in filled areas.",
            "categories": "['stat.ML cs.CL cs.LG']",
            "figure_id": "1806.04458v3-Figure2-1",
            "image_path": "1806.04458v3-Figure2-1.png",
            "instance_id": "65d947295c4c654898bd3294c50bed4f",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the orange line representing 'FUNCTION COMP. (ALL)' have a higher average cumulative loss value than the green line representing 'TWO-POINT (ALL)' at the beginning of the x-axis?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Average cumulative loss on training data for sparse multiclass text classification. All results are averaged over 3 runs, with mean results in bold lines, 2 standard deviations in filled areas.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Average cumulative loss on training data for sparse multiclass text classification. All results are averaged over 3 runs, with mean results in bold lines, 2 standard deviations in filled areas.",
            "categories": "['stat.ML cs.CL cs.LG']",
            "figure_id": "1806.04458v3-Figure2-1",
            "image_path": "1806.04458v3-Figure2-1.png",
            "instance_id": "9b645569237719ecf70088ca8286c85a",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the average cumulative loss for 'FUNCTION COMP. (ALL)' lower than that for 'TWO-POINT (ALL)' throughout the iterations?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the average cumulative loss for 'FUNCTION COMP. (ALL)' is lower than that for 'TWO-POINT (ALL)' throughout the iterations.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Orange and Green"
                    },
                    {
                        "B": "Orange and Brown"
                    },
                    {
                        "C": "Purple and Pink"
                    },
                    {
                        "D": "Blue and Green"
                    }
                ],
                "caption": "Figure 2: Average cumulative loss on training data for sparse multiclass text classification. All results are averaged over 3 runs, with mean results in bold lines, 2 standard deviations in filled areas.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Average cumulative loss on training data for sparse multiclass text classification. All results are averaged over 3 runs, with mean results in bold lines, 2 standard deviations in filled areas.",
            "categories": "['stat.ML cs.CL cs.LG']",
            "figure_id": "1806.04458v3-Figure2-1",
            "image_path": "1806.04458v3-Figure2-1.png",
            "instance_id": "4408273216fc2fbd9751118d6a65275f",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which bolded lines on the graph start over 0.5 of Average Cumulative Loss Energy?",
            "reference_answer": "A,C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "FUNCTION COMP. (SPARSE)"
                    },
                    {
                        "B": "TWO-POINT (SPARSE)"
                    },
                    {
                        "C": "BASELINE COMP. (ALL)"
                    },
                    {
                        "D": "SFO"
                    }
                ],
                "caption": "Figure 2: Average cumulative loss on training data for sparse multiclass text classification. All results are averaged over 3 runs, with mean results in bold lines, 2 standard deviations in filled areas.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Average cumulative loss on training data for sparse multiclass text classification. All results are averaged over 3 runs, with mean results in bold lines, 2 standard deviations in filled areas.",
            "categories": "['stat.ML cs.CL cs.LG']",
            "figure_id": "1806.04458v3-Figure2-1",
            "image_path": "1806.04458v3-Figure2-1.png",
            "instance_id": "d621d9514d8dce40b10f9d19922d9914",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following methods are used in the experiment?",
            "reference_answer": "ABCD"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ABCD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Average cumulative loss on training data for sparse multiclass text classification. All results are averaged over 3 runs, with mean results in bold lines, 2 standard deviations in filled areas.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Average cumulative loss on training data for sparse multiclass text classification. All results are averaged over 3 runs, with mean results in bold lines, 2 standard deviations in filled areas.",
            "categories": "['stat.ML cs.CL cs.LG']",
            "figure_id": "1806.04458v3-Figure2-1",
            "image_path": "1806.04458v3-Figure2-1.png",
            "instance_id": "9e34b3889886d80247a8b64770be0176",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific dataset used for training the models represented in Figure 2?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 16: Training Error for English Text \u2013 BUNOW Model",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 16: Training Error for English Text \u2013 BUNOW Model",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1903.07588v1-Figure16-1",
            "image_path": "1903.07588v1-Figure16-1.png",
            "instance_id": "2d4418ddb8b8f67a4f906d542cd167eb",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the orange line at 60 epochs?",
            "reference_answer": "0.2"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 16: Training Error for English Text \u2013 BUNOW Model",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 16: Training Error for English Text \u2013 BUNOW Model",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1903.07588v1-Figure16-1",
            "image_path": "1903.07588v1-Figure16-1.png",
            "instance_id": "66c0590fb461404feb5290d85b8ee601",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What are the two types of errors shown in the figure?",
            "reference_answer": "Validation and training"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 16: Training Error for English Text \u2013 BUNOW Model",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 16: Training Error for English Text \u2013 BUNOW Model",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1903.07588v1-Figure16-1",
            "image_path": "1903.07588v1-Figure16-1.png",
            "instance_id": "7ef41f3e4cdc28277d8c829ae62740ec",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the blue line, representing validation loss, plateau at around 0.25?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the blue line representing validation loss appears to plateau around 0.25 toward the end of the epochs.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 16: Training Error for English Text \u2013 BUNOW Model",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 16: Training Error for English Text \u2013 BUNOW Model",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1903.07588v1-Figure16-1",
            "image_path": "1903.07588v1-Figure16-1.png",
            "instance_id": "e5d3500d8417eede21ab1851bddc52ee",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the training error consistently lower than the validation error?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The blue line"
                    },
                    {
                        "B": "The orange line"
                    },
                    {
                        "C": "Both lines"
                    },
                    {
                        "D": "Neither line"
                    }
                ],
                "caption": "Figure 16: Training Error for English Text \u2013 BUNOW Model",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 16: Training Error for English Text \u2013 BUNOW Model",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1903.07588v1-Figure16-1",
            "image_path": "1903.07588v1-Figure16-1.png",
            "instance_id": "11e86db9402827625007e9c6311f3da3",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line represents the validation error?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The model is overfitting"
                    },
                    {
                        "B": "The model is underfitting"
                    },
                    {
                        "C": "The model is performing optimally"
                    },
                    {
                        "D": "The model is not applicable to the data"
                    }
                ],
                "caption": "Figure 16: Training Error for English Text \u2013 BUNOW Model",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 16: Training Error for English Text \u2013 BUNOW Model",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1903.07588v1-Figure16-1",
            "image_path": "1903.07588v1-Figure16-1.png",
            "instance_id": "7f314686a2ed70295a2b4e6164c5f740",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What does the BUNOW model training error indicate about the model's performance?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 16: Training Error for English Text \u2013 BUNOW Model",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 16: Training Error for English Text \u2013 BUNOW Model",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1903.07588v1-Figure16-1",
            "image_path": "1903.07588v1-Figure16-1.png",
            "instance_id": "a9de0c811e18cface79d1b244c60c6a4",
            "qa_pair_type": "unanswerable",
            "question": "What is the size of the training set and validation set used for training the BUNOW model?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Comparison of different refinement policies for the piecewise bound on a 10x10 Ising model grid.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Comparison of different refinement policies for the piecewise bound on a 10x10 Ising model grid.",
            "categories": "['cs.AI cs.CL cs.LG']",
            "figure_id": "1207.0742v1-Figure5-1",
            "image_path": "1207.0742v1-Figure5-1.png",
            "instance_id": "127b661886e9207c429382e2a5fdf2d5",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the color of the line representing the 'highest acceptance rate' policy in the right plot?",
            "reference_answer": "Cyan"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The color of the line representing the 'highest acceptance rate' policy in the right plot is cyan.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Comparison of different refinement policies for the piecewise bound on a 10x10 Ising model grid.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Comparison of different refinement policies for the piecewise bound on a 10x10 Ising model grid.",
            "categories": "['cs.AI cs.CL cs.LG']",
            "figure_id": "1207.0742v1-Figure5-1",
            "image_path": "1207.0742v1-Figure5-1.png",
            "instance_id": "8746bb9d8a075abefb584db3a56254e5",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "In which unit is the time of the second graph measured?",
            "reference_answer": "seconds"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The time of the second graph is measured in seconds.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Comparison of different refinement policies for the piecewise bound on a 10x10 Ising model grid.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Comparison of different refinement policies for the piecewise bound on a 10x10 Ising model grid.",
            "categories": "['cs.AI cs.CL cs.LG']",
            "figure_id": "1207.0742v1-Figure5-1",
            "image_path": "1207.0742v1-Figure5-1.png",
            "instance_id": "e2ddcbd08c884918fe0831918d1b1870",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the green in the left graph always increasing as the number of refinements increases?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Comparison of different refinement policies for the piecewise bound on a 10x10 Ising model grid.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Comparison of different refinement policies for the piecewise bound on a 10x10 Ising model grid.",
            "categories": "['cs.AI cs.CL cs.LG']",
            "figure_id": "1207.0742v1-Figure5-1",
            "image_path": "1207.0742v1-Figure5-1.png",
            "instance_id": "c0fbf4a69005e7ff47f164adeb266786",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the highest acceptance rate policy associated with the highest expected computation time?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the highest acceptance rate policy is associated with the highest expected computation time, as indicated by the graph on the right where the curve representing the highest acceptance rate has the longest expected computation time compared to the others.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "cyan"
                    },
                    {
                        "B": "blue"
                    },
                    {
                        "C": "green"
                    },
                    {
                        "D": "red"
                    }
                ],
                "caption": "Figure 5: Comparison of different refinement policies for the piecewise bound on a 10x10 Ising model grid.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Comparison of different refinement policies for the piecewise bound on a 10x10 Ising model grid.",
            "categories": "['cs.AI cs.CL cs.LG']",
            "figure_id": "1207.0742v1-Figure5-1",
            "image_path": "1207.0742v1-Figure5-1.png",
            "instance_id": "58a5f3903b252e5e757dd656b481c71f",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line represents the 'highest bound improvement on rejected sample'?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "(i)"
                    },
                    {
                        "B": "(ii)"
                    },
                    {
                        "C": "(iii)"
                    },
                    {
                        "D": "(iv)"
                    }
                ],
                "caption": "Figure 5: Comparison of different refinement policies for the piecewise bound on a 10x10 Ising model grid.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Comparison of different refinement policies for the piecewise bound on a 10x10 Ising model grid.",
            "categories": "['cs.AI cs.CL cs.LG']",
            "figure_id": "1207.0742v1-Figure5-1",
            "image_path": "1207.0742v1-Figure5-1.png",
            "instance_id": "256dfa50ee894d8151d8e46ad15f7025",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which refinement policy has the lowest acceptance probability?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Comparison of different refinement policies for the piecewise bound on a 10x10 Ising model grid.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Comparison of different refinement policies for the piecewise bound on a 10x10 Ising model grid.",
            "categories": "['cs.AI cs.CL cs.LG']",
            "figure_id": "1207.0742v1-Figure5-1",
            "image_path": "1207.0742v1-Figure5-1.png",
            "instance_id": "4ce60813a21a7adc37f802e50fe8ee74",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific algorithm used to generate the piecewise bound for the 10x10 Ising model grid in Figure 5?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Cumulative mass for analogy experiment of 8-mer with 3-nt snippet. 1000 samples were generated with the strong-concatenation analogy setup. We compared it with another 1000 samples using the scrambledsnippet sampling procedure.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Cumulative mass for analogy experiment of 8-mer with 3-nt snippet. 1000 samples were generated with the strong-concatenation analogy setup. We compared it with another 1000 samples using the scrambledsnippet sampling procedure.",
            "categories": "['q-bio.QM cs.CL cs.LG stat.ML']",
            "figure_id": "1701.06279v1-Figure3-1",
            "image_path": "1701.06279v1-Figure3-1.png",
            "instance_id": "a1512771fe35d90298875a78575ba0d9",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the red line at n-Nearest Neighbors = 100?",
            "reference_answer": "1000"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The approximate value of the red line at n-Nearest Neighbors = 100 is around 1000.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Cumulative mass for analogy experiment of 8-mer with 3-nt snippet. 1000 samples were generated with the strong-concatenation analogy setup. We compared it with another 1000 samples using the scrambledsnippet sampling procedure.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Cumulative mass for analogy experiment of 8-mer with 3-nt snippet. 1000 samples were generated with the strong-concatenation analogy setup. We compared it with another 1000 samples using the scrambledsnippet sampling procedure.",
            "categories": "['q-bio.QM cs.CL cs.LG stat.ML']",
            "figure_id": "1701.06279v1-Figure3-1",
            "image_path": "1701.06279v1-Figure3-1.png",
            "instance_id": "25e5ca5dc3d7082f5dcce0dec750f8a6",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the x-axis representing?",
            "reference_answer": "n-Nearest Neighbors"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The x-axis represents the number of nearest neighbors (n-Nearest Neighbors).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Cumulative mass for analogy experiment of 8-mer with 3-nt snippet. 1000 samples were generated with the strong-concatenation analogy setup. We compared it with another 1000 samples using the scrambledsnippet sampling procedure.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Cumulative mass for analogy experiment of 8-mer with 3-nt snippet. 1000 samples were generated with the strong-concatenation analogy setup. We compared it with another 1000 samples using the scrambledsnippet sampling procedure.",
            "categories": "['q-bio.QM cs.CL cs.LG stat.ML']",
            "figure_id": "1701.06279v1-Figure3-1",
            "image_path": "1701.06279v1-Figure3-1.png",
            "instance_id": "9b4cba966ae867d6e600d2fabfaaea3e",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the red line reach a higher value than the blue line at the end of the x-axis?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the red line reaches a higher value than the blue line at the end of the x-axis.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Cumulative mass for analogy experiment of 8-mer with 3-nt snippet. 1000 samples were generated with the strong-concatenation analogy setup. We compared it with another 1000 samples using the scrambledsnippet sampling procedure.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Cumulative mass for analogy experiment of 8-mer with 3-nt snippet. 1000 samples were generated with the strong-concatenation analogy setup. We compared it with another 1000 samples using the scrambledsnippet sampling procedure.",
            "categories": "['q-bio.QM cs.CL cs.LG stat.ML']",
            "figure_id": "1701.06279v1-Figure3-1",
            "image_path": "1701.06279v1-Figure3-1.png",
            "instance_id": "a81373372937e54f43586fb91ba87e2b",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the count for scrambled-snippet task surpass the number of 500 at anywhere?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "analogy"
                    },
                    {
                        "B": "scrambled-snippet"
                    },
                    {
                        "C": "Both lines"
                    },
                    {
                        "D": "Neither line"
                    }
                ],
                "caption": "Figure 3: Cumulative mass for analogy experiment of 8-mer with 3-nt snippet. 1000 samples were generated with the strong-concatenation analogy setup. We compared it with another 1000 samples using the scrambledsnippet sampling procedure.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Cumulative mass for analogy experiment of 8-mer with 3-nt snippet. 1000 samples were generated with the strong-concatenation analogy setup. We compared it with another 1000 samples using the scrambledsnippet sampling procedure.",
            "categories": "['q-bio.QM cs.CL cs.LG stat.ML']",
            "figure_id": "1701.06279v1-Figure3-1",
            "image_path": "1701.06279v1-Figure3-1.png",
            "instance_id": "061fc8355f7f72bcf048ac6d4a4ad5d9",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line in the figure reaches 1000 samples when n-Nearest Neighbors is around 100?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "analogy"
                    },
                    {
                        "B": "scrambled-snippet"
                    },
                    {
                        "C": "Both"
                    },
                    {
                        "D": "Neither"
                    }
                ],
                "caption": "Figure 3: Cumulative mass for analogy experiment of 8-mer with 3-nt snippet. 1000 samples were generated with the strong-concatenation analogy setup. We compared it with another 1000 samples using the scrambledsnippet sampling procedure.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Cumulative mass for analogy experiment of 8-mer with 3-nt snippet. 1000 samples were generated with the strong-concatenation analogy setup. We compared it with another 1000 samples using the scrambledsnippet sampling procedure.",
            "categories": "['q-bio.QM cs.CL cs.LG stat.ML']",
            "figure_id": "1701.06279v1-Figure3-1",
            "image_path": "1701.06279v1-Figure3-1.png",
            "instance_id": "05acee1acea9295a9d0aef1540bb743a",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which task had more than 750 samples reach cumulative mass by the end of the experiment?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Cumulative mass for analogy experiment of 8-mer with 3-nt snippet. 1000 samples were generated with the strong-concatenation analogy setup. We compared it with another 1000 samples using the scrambledsnippet sampling procedure.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Cumulative mass for analogy experiment of 8-mer with 3-nt snippet. 1000 samples were generated with the strong-concatenation analogy setup. We compared it with another 1000 samples using the scrambledsnippet sampling procedure.",
            "categories": "['q-bio.QM cs.CL cs.LG stat.ML']",
            "figure_id": "1701.06279v1-Figure3-1",
            "image_path": "1701.06279v1-Figure3-1.png",
            "instance_id": "a52a2b1bda4841025ec83128263794f4",
            "qa_pair_type": "unanswerable",
            "question": "What is the count for n-Nearest Neighbors = 200?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Average OC of one-hop neighbor sets of correct alignment during the first 200 training epochs on DBP15K.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Average OC of one-hop neighbor sets of correct alignment during the first 200 training epochs on DBP15K.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "1911.08936v1-Figure5-1",
            "image_path": "1911.08936v1-Figure5-1.png",
            "instance_id": "152c143d841e7aa0cb2e0aae02d1fd61",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the black line at epoch 150 for DBP_{JA-EN}?",
            "reference_answer": "0.72"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Average OC of one-hop neighbor sets of correct alignment during the first 200 training epochs on DBP15K.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Average OC of one-hop neighbor sets of correct alignment during the first 200 training epochs on DBP15K.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "1911.08936v1-Figure5-1",
            "image_path": "1911.08936v1-Figure5-1.png",
            "instance_id": "c49bd61eccfe7c1bddfc04c8f99353ee",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "In the second graph which languages are considered for DBP?",
            "reference_answer": "Japanese and English"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Average OC of one-hop neighbor sets of correct alignment during the first 200 training epochs on DBP15K.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Average OC of one-hop neighbor sets of correct alignment during the first 200 training epochs on DBP15K.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "1911.08936v1-Figure5-1",
            "image_path": "1911.08936v1-Figure5-1.png",
            "instance_id": "85c6379ef079b51aa3461cac201f923b",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the black line representing AliNet always have a higher value than the grey line representing GCN for the first 200 training epochs?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Average OC of one-hop neighbor sets of correct alignment during the first 200 training epochs on DBP15K.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Average OC of one-hop neighbor sets of correct alignment during the first 200 training epochs on DBP15K.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "1911.08936v1-Figure5-1",
            "image_path": "1911.08936v1-Figure5-1.png",
            "instance_id": "835b4216eb8790797deaee52ea085cb3",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the average OC of the AliNet model higher than the average OC of the GCN model across the three datasets?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The black line"
                    },
                    {
                        "B": "The grey line"
                    },
                    {
                        "C": "Both lines"
                    },
                    {
                        "D": "Neither line"
                    }
                ],
                "caption": "Figure 5: Average OC of one-hop neighbor sets of correct alignment during the first 200 training epochs on DBP15K.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Average OC of one-hop neighbor sets of correct alignment during the first 200 training epochs on DBP15K.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "1911.08936v1-Figure5-1",
            "image_path": "1911.08936v1-Figure5-1.png",
            "instance_id": "81c066d29ece8d02c685938751ebd7f8",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the lines is labeled as 'AliNet'?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "DBP15K"
                    },
                    {
                        "B": "DBP ZH-EN"
                    },
                    {
                        "C": "DBP JA-EN"
                    },
                    {
                        "D": "DBP FR-EN"
                    }
                ],
                "caption": "Figure 5: Average OC of one-hop neighbor sets of correct alignment during the first 200 training epochs on DBP15K.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Average OC of one-hop neighbor sets of correct alignment during the first 200 training epochs on DBP15K.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "1911.08936v1-Figure5-1",
            "image_path": "1911.08936v1-Figure5-1.png",
            "instance_id": "d30f04d1ee289118fd2f724e946f9f80",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which languages are considered for the DBP?",
            "reference_answer": "B,C,D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B C D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Average OC of one-hop neighbor sets of correct alignment during the first 200 training epochs on DBP15K.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Average OC of one-hop neighbor sets of correct alignment during the first 200 training epochs on DBP15K.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "1911.08936v1-Figure5-1",
            "image_path": "1911.08936v1-Figure5-1.png",
            "instance_id": "4aab0eb3ad0842fc652725f1261cc974",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific meaning of 'OC' in the context of the caption 'Figure 5: Average OC of one-hop neighbor sets of correct alignment during the first 200 training epochs on DBP15K.'?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Average labeled F1 scores for semantic parsing w.r.t. sentence lengths. LAS and UAS are represented by solid and dashed lines, and scores from the baseline and \\BERT models are shown in blue and red, respectively.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Average labeled F1 scores for semantic parsing w.r.t. sentence lengths. LAS and UAS are represented by solid and dashed lines, and scores from the baseline and \\BERT models are shown in blue and red, respectively.",
            "categories": "['cs.CL']",
            "figure_id": "1908.04943v4-Figure5-1",
            "image_path": "1908.04943v4-Figure5-1.png",
            "instance_id": "773fdf1eabf0b3f242893e42bb69d232",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of the red dashed line in the third subplot at sentence length 10?",
            "reference_answer": "88"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Average labeled F1 scores for semantic parsing w.r.t. sentence lengths. LAS and UAS are represented by solid and dashed lines, and scores from the baseline and \\BERT models are shown in blue and red, respectively.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Average labeled F1 scores for semantic parsing w.r.t. sentence lengths. LAS and UAS are represented by solid and dashed lines, and scores from the baseline and \\BERT models are shown in blue and red, respectively.",
            "categories": "['cs.CL']",
            "figure_id": "1908.04943v4-Figure5-1",
            "image_path": "1908.04943v4-Figure5-1.png",
            "instance_id": "ef60218bc976d8acd68fd6b9e2e8a405",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "Which ID is represented in third graph?",
            "reference_answer": "PSD"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The ID represented in the third graph is PSD.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Average labeled F1 scores for semantic parsing w.r.t. sentence lengths. LAS and UAS are represented by solid and dashed lines, and scores from the baseline and \\BERT models are shown in blue and red, respectively.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Average labeled F1 scores for semantic parsing w.r.t. sentence lengths. LAS and UAS are represented by solid and dashed lines, and scores from the baseline and \\BERT models are shown in blue and red, respectively.",
            "categories": "['cs.CL']",
            "figure_id": "1908.04943v4-Figure5-1",
            "image_path": "1908.04943v4-Figure5-1.png",
            "instance_id": "d20a0aab472bb758e1115e18f5d42bc0",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the solid red line in the first plot higher than the dashed red line at the value 10 on the x-axis?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Average labeled F1 scores for semantic parsing w.r.t. sentence lengths. LAS and UAS are represented by solid and dashed lines, and scores from the baseline and \\BERT models are shown in blue and red, respectively.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Average labeled F1 scores for semantic parsing w.r.t. sentence lengths. LAS and UAS are represented by solid and dashed lines, and scores from the baseline and \\BERT models are shown in blue and red, respectively.",
            "categories": "['cs.CL']",
            "figure_id": "1908.04943v4-Figure5-1",
            "image_path": "1908.04943v4-Figure5-1.png",
            "instance_id": "e39e333f8e99f56d12edb62c6e824e76",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Are the F1 scores for the baseline model consistently higher than those of the BERT model?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Plot (a), Plot (c), Plot (d)"
                    },
                    {
                        "B": "Plot (b), Plot (c), Plot (e)"
                    },
                    {
                        "C": "Plot (a), Plot (b), Plot (e)"
                    },
                    {
                        "D": "Plot (a), Plot (b), Plot (d)"
                    }
                ],
                "caption": "Figure 5: Average labeled F1 scores for semantic parsing w.r.t. sentence lengths. LAS and UAS are represented by solid and dashed lines, and scores from the baseline and \\BERT models are shown in blue and red, respectively.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Average labeled F1 scores for semantic parsing w.r.t. sentence lengths. LAS and UAS are represented by solid and dashed lines, and scores from the baseline and \\BERT models are shown in blue and red, respectively.",
            "categories": "['cs.CL']",
            "figure_id": "1908.04943v4-Figure5-1",
            "image_path": "1908.04943v4-Figure5-1.png",
            "instance_id": "ff0857ea0ef46d950ec179f8fed3ece1",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following plots show a decrease in both solid blue and dashed blue lines from left to right?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "91"
                    },
                    {
                        "B": "93"
                    },
                    {
                        "C": "99"
                    },
                    {
                        "D": "96"
                    }
                ],
                "caption": "Figure 5: Average labeled F1 scores for semantic parsing w.r.t. sentence lengths. LAS and UAS are represented by solid and dashed lines, and scores from the baseline and \\BERT models are shown in blue and red, respectively.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Average labeled F1 scores for semantic parsing w.r.t. sentence lengths. LAS and UAS are represented by solid and dashed lines, and scores from the baseline and \\BERT models are shown in blue and red, respectively.",
            "categories": "['cs.CL']",
            "figure_id": "1908.04943v4-Figure5-1",
            "image_path": "1908.04943v4-Figure5-1.png",
            "instance_id": "1ecb89f221972a30ade2367162baedad",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the approximate minimal F1 score for the LAS baseline at the first image?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A:B:D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Average labeled F1 scores for semantic parsing w.r.t. sentence lengths. LAS and UAS are represented by solid and dashed lines, and scores from the baseline and \\BERT models are shown in blue and red, respectively.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Average labeled F1 scores for semantic parsing w.r.t. sentence lengths. LAS and UAS are represented by solid and dashed lines, and scores from the baseline and \\BERT models are shown in blue and red, respectively.",
            "categories": "['cs.CL']",
            "figure_id": "1908.04943v4-Figure5-1",
            "image_path": "1908.04943v4-Figure5-1.png",
            "instance_id": "1ff94968b52768e40e9a15361b657db4",
            "qa_pair_type": "unanswerable",
            "question": "What is the F1 score for the BERT model when the sentence length is 30 words and the parsing task is OOD: PAS?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 4. Performance of the proposed method in terms of macro and micro measures for different datsets.",
                "compound": true,
                "figure_type": "Graph",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 4. Performance of the proposed method in terms of macro and micro measures for different datsets.",
            "categories": "['cs.IR cs.CL']",
            "figure_id": "1610.04814v1-Figure4-1",
            "image_path": "1610.04814v1-Figure4-1.png",
            "instance_id": "1cdbcf54e04d258780bd055fbcaeeff6",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of the green line in the top plot at the 70% training mark?",
            "reference_answer": "0.68"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 4. Performance of the proposed method in terms of macro and micro measures for different datsets.",
                "compound": true,
                "figure_type": "Graph",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 4. Performance of the proposed method in terms of macro and micro measures for different datsets.",
            "categories": "['cs.IR cs.CL']",
            "figure_id": "1610.04814v1-Figure4-1",
            "image_path": "1610.04814v1-Figure4-1.png",
            "instance_id": "e88f72fcf82f1ee16c03a2fd68870551",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What are the different datasets used to evaluate the method's performance?",
            "reference_answer": "20Newsgroups, Reuters21578, RCV1-v2"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The different datasets used to evaluate the method's performance are:\n\n1. 20Newsgroups\n2. Reuters21578\n3. RCV1-v2",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 4. Performance of the proposed method in terms of macro and micro measures for different datsets.",
                "compound": true,
                "figure_type": "Graph",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 4. Performance of the proposed method in terms of macro and micro measures for different datsets.",
            "categories": "['cs.IR cs.CL']",
            "figure_id": "1610.04814v1-Figure4-1",
            "image_path": "1610.04814v1-Figure4-1.png",
            "instance_id": "9d6e5bc7a109f1dbb347021d2b374987",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the blue line in the top graph consistently higher than the red line?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 4. Performance of the proposed method in terms of macro and micro measures for different datsets.",
                "compound": true,
                "figure_type": "Graph",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 4. Performance of the proposed method in terms of macro and micro measures for different datsets.",
            "categories": "['cs.IR cs.CL']",
            "figure_id": "1610.04814v1-Figure4-1",
            "image_path": "1610.04814v1-Figure4-1.png",
            "instance_id": "e753fe0121aab189e050bf790364b43e",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the proposed method perform better on RCV1-v2 dataset than the other two datasets in terms of Macro-P measure at 80% of training?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Purple"
                    },
                    {
                        "B": "Green"
                    },
                    {
                        "C": "Red"
                    },
                    {
                        "D": "Blue"
                    }
                ],
                "caption": "Fig. 4. Performance of the proposed method in terms of macro and micro measures for different datsets.",
                "compound": true,
                "figure_type": "Graph",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 4. Performance of the proposed method in terms of macro and micro measures for different datsets.",
            "categories": "['cs.IR cs.CL']",
            "figure_id": "1610.04814v1-Figure4-1",
            "image_path": "1610.04814v1-Figure4-1.png",
            "instance_id": "28465ac8767fd03e4e93e1d08d9eb9dd",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What is the color of the line representing 'Micro-F' in the graph labeled 'RCV1-v2'?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "20Newsgroup, Reuters21578, RCV1-v2"
                    },
                    {
                        "B": "Reuters21578, RCV1-v2"
                    },
                    {
                        "C": "20Newsgroup, RCV1-v2"
                    },
                    {
                        "D": "20Newsgroup, Reuters21578"
                    }
                ],
                "caption": "Fig. 4. Performance of the proposed method in terms of macro and micro measures for different datsets.",
                "compound": true,
                "figure_type": "Graph",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 4. Performance of the proposed method in terms of macro and micro measures for different datsets.",
            "categories": "['cs.IR cs.CL']",
            "figure_id": "1610.04814v1-Figure4-1",
            "image_path": "1610.04814v1-Figure4-1.png",
            "instance_id": "ddab4c895322fb1eb948847d1093c5c3",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which datasets are included in the figure?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 4. Performance of the proposed method in terms of macro and micro measures for different datsets.",
                "compound": true,
                "figure_type": "Graph",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 4. Performance of the proposed method in terms of macro and micro measures for different datsets.",
            "categories": "['cs.IR cs.CL']",
            "figure_id": "1610.04814v1-Figure4-1",
            "image_path": "1610.04814v1-Figure4-1.png",
            "instance_id": "846675c6eb77cf587bea00683a5ab38b",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific algorithm used in the proposed method shown in Fig. 4?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: No matter the amount of labeled samples is big or small, performance degradation and performance improvement can both be observed by manipulating the biasvariance trade-off.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: No matter the amount of labeled samples is big or small, performance degradation and performance improvement can both be observed by manipulating the biasvariance trade-off.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1308.0658v1-Figure3-1",
            "image_path": "1308.0658v1-Figure3-1.png",
            "instance_id": "f3f706700a31e28a2fed87845fc945b0",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate classification accuracy for the green line in the right graph at 3000 unlabeled data?",
            "reference_answer": "62%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: No matter the amount of labeled samples is big or small, performance degradation and performance improvement can both be observed by manipulating the biasvariance trade-off.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: No matter the amount of labeled samples is big or small, performance degradation and performance improvement can both be observed by manipulating the biasvariance trade-off.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1308.0658v1-Figure3-1",
            "image_path": "1308.0658v1-Figure3-1.png",
            "instance_id": "cd03ae0e283b23c287760ca19285fe95",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the Y-axis representing?",
            "reference_answer": "Classification accuracy"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The Y-axis represents \"Classification accuracy (%)\".",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: No matter the amount of labeled samples is big or small, performance degradation and performance improvement can both be observed by manipulating the biasvariance trade-off.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: No matter the amount of labeled samples is big or small, performance degradation and performance improvement can both be observed by manipulating the biasvariance trade-off.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1308.0658v1-Figure3-1",
            "image_path": "1308.0658v1-Figure3-1.png",
            "instance_id": "aab31cca0fbd6eb5433f1b4525e90b70",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "In Figure (a), does the blue line represent the classification accuracy when the vocabulary size is 4052?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. In Figure (a), the blue line represents the classification accuracy generated from figure 2(a) with a vocabulary size of 4052.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: No matter the amount of labeled samples is big or small, performance degradation and performance improvement can both be observed by manipulating the biasvariance trade-off.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: No matter the amount of labeled samples is big or small, performance degradation and performance improvement can both be observed by manipulating the biasvariance trade-off.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1308.0658v1-Figure3-1",
            "image_path": "1308.0658v1-Figure3-1.png",
            "instance_id": "30c2d68543134368f620c679f6687b5c",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does changing the number of unlabeled data affect the classification accuracy?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, changing the number of unlabeled data affects the classification accuracy, as evidenced by the fluctuations in accuracy in both graphs (a) and (b) with different amounts of unlabeled data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The line with squares is higher than the line with circles"
                    },
                    {
                        "B": "The line with circles is higher than the line with squares"
                    },
                    {
                        "C": "Both lines have the same classification accuracy"
                    },
                    {
                        "D": "Neither of the above"
                    }
                ],
                "caption": "Figure 3: No matter the amount of labeled samples is big or small, performance degradation and performance improvement can both be observed by manipulating the biasvariance trade-off.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: No matter the amount of labeled samples is big or small, performance degradation and performance improvement can both be observed by manipulating the biasvariance trade-off.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1308.0658v1-Figure3-1",
            "image_path": "1308.0658v1-Figure3-1.png",
            "instance_id": "bbbab5d2f1af46a108e888389306f5a6",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the lines in Figure (a) have a higher classification accuracy when there are 2000 unlabeled data points?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "60"
                    },
                    {
                        "B": "56.8"
                    },
                    {
                        "C": "61"
                    },
                    {
                        "D": "63"
                    }
                ],
                "caption": "Figure 3: No matter the amount of labeled samples is big or small, performance degradation and performance improvement can both be observed by manipulating the biasvariance trade-off.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: No matter the amount of labeled samples is big or small, performance degradation and performance improvement can both be observed by manipulating the biasvariance trade-off.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1308.0658v1-Figure3-1",
            "image_path": "1308.0658v1-Figure3-1.png",
            "instance_id": "5421f7985d6b10dd5aa700cba558068b",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the lowest accuracy achieved by any of the experiments?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: No matter the amount of labeled samples is big or small, performance degradation and performance improvement can both be observed by manipulating the biasvariance trade-off.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: No matter the amount of labeled samples is big or small, performance degradation and performance improvement can both be observed by manipulating the biasvariance trade-off.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1308.0658v1-Figure3-1",
            "image_path": "1308.0658v1-Figure3-1.png",
            "instance_id": "1dd6c6fe5a26401b44268355b695eea0",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific machine learning algorithm used in the experiment shown in Figure 3?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Effect of training on increasing number of in-domain (a) and out-of-domain (b) parallel sentences",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Effect of training on increasing number of in-domain (a) and out-of-domain (b) parallel sentences",
            "categories": "['cs.CL']",
            "figure_id": "1906.00376v1-Figure5-1",
            "image_path": "1906.00376v1-Figure5-1.png",
            "instance_id": "6b7cb6b8fb5e7bc11840701313b8fcc4",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate BLEU score of the green method at 480K in-domain size?",
            "reference_answer": "37"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Effect of training on increasing number of in-domain (a) and out-of-domain (b) parallel sentences",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Effect of training on increasing number of in-domain (a) and out-of-domain (b) parallel sentences",
            "categories": "['cs.CL']",
            "figure_id": "1906.00376v1-Figure5-1",
            "image_path": "1906.00376v1-Figure5-1.png",
            "instance_id": "cb9fab8b1afa528a9918d35f2c1c2eca",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "Which training method had the highest BLEU score for the 'Subtitles-Medical' dataset with an out-of-domain size of 14M?",
            "reference_answer": "BT+DALI-U"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "BT+DALI-U",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Effect of training on increasing number of in-domain (a) and out-of-domain (b) parallel sentences",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Effect of training on increasing number of in-domain (a) and out-of-domain (b) parallel sentences",
            "categories": "['cs.CL']",
            "figure_id": "1906.00376v1-Figure5-1",
            "image_path": "1906.00376v1-Figure5-1.png",
            "instance_id": "39576feb696b1f188f6a26cb4974c39c",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the blue line in the right graph show a consistent increase in value?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Effect of training on increasing number of in-domain (a) and out-of-domain (b) parallel sentences",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Effect of training on increasing number of in-domain (a) and out-of-domain (b) parallel sentences",
            "categories": "['cs.CL']",
            "figure_id": "1906.00376v1-Figure5-1",
            "image_path": "1906.00376v1-Figure5-1.png",
            "instance_id": "219655f3365950baeafcb6139da9ddc4",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the BLEU score for the 'semi+DALI-U' training method increase with increasing in-domain size?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The BLEU score for the 'semi+DALI-U' training method increases with increasing in-domain size in the IT-Medical graph.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Red"
                    },
                    {
                        "B": "Green"
                    },
                    {
                        "C": "Blue"
                    },
                    {
                        "D": "Teal"
                    }
                ],
                "caption": "Figure 5: Effect of training on increasing number of in-domain (a) and out-of-domain (b) parallel sentences",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Effect of training on increasing number of in-domain (a) and out-of-domain (b) parallel sentences",
            "categories": "['cs.CL']",
            "figure_id": "1906.00376v1-Figure5-1",
            "image_path": "1906.00376v1-Figure5-1.png",
            "instance_id": "2db029e96e8792a6b999052c34b93b6a",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line in the right graph shows the highest BLEU score for the DALI-U method with a training size of 14M?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "semi"
                    },
                    {
                        "B": "semi+DALI-U"
                    },
                    {
                        "C": "DALI-U"
                    },
                    {
                        "D": "BT+DALI-U"
                    }
                ],
                "caption": "Figure 5: Effect of training on increasing number of in-domain (a) and out-of-domain (b) parallel sentences",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Effect of training on increasing number of in-domain (a) and out-of-domain (b) parallel sentences",
            "categories": "['cs.CL']",
            "figure_id": "1906.00376v1-Figure5-1",
            "image_path": "1906.00376v1-Figure5-1.png",
            "instance_id": "609dabfe802b025e71012005d0489310",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which training method(s) have an increasing BLEU score with increased in-domain data size?",
            "reference_answer": "AB"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Effect of training on increasing number of in-domain (a) and out-of-domain (b) parallel sentences",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Effect of training on increasing number of in-domain (a) and out-of-domain (b) parallel sentences",
            "categories": "['cs.CL']",
            "figure_id": "1906.00376v1-Figure5-1",
            "image_path": "1906.00376v1-Figure5-1.png",
            "instance_id": "f38df1bd2008886ac9e445918bfc0752",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific task that these different training methods were applied to?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2. EM Log-Likelihood vs. training iterations for random initialization and SSID initialization.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2. EM Log-Likelihood vs. training iterations for random initialization and SSID initialization.",
            "categories": "['stat.ML cs.CL cs.LG']",
            "figure_id": "1502.04081v2-Figure2-1",
            "image_path": "1502.04081v2-Figure2-1.png",
            "instance_id": "d2370cdad9358b601c426877e74d6bc0",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the Log-Likelihood for the SSID initialization at approximately 90 iterations?",
            "reference_answer": "-4.6852"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2. EM Log-Likelihood vs. training iterations for random initialization and SSID initialization.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2. EM Log-Likelihood vs. training iterations for random initialization and SSID initialization.",
            "categories": "['stat.ML cs.CL cs.LG']",
            "figure_id": "1502.04081v2-Figure2-1",
            "image_path": "1502.04081v2-Figure2-1.png",
            "instance_id": "fef9bdb1fb874e19865e927397e2561b",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What are the two types of initialization used?",
            "reference_answer": "RANDOM and SSID"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The two types of initialization used are RANDOM and SSID.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2. EM Log-Likelihood vs. training iterations for random initialization and SSID initialization.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2. EM Log-Likelihood vs. training iterations for random initialization and SSID initialization.",
            "categories": "['stat.ML cs.CL cs.LG']",
            "figure_id": "1502.04081v2-Figure2-1",
            "image_path": "1502.04081v2-Figure2-1.png",
            "instance_id": "8a31b2e1f3f2cd994f701f623e236789",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the green line representing SSID initialization consistently have a higher value than the blue line representing RANDOM initialization?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the green line representing SSID initialization consistently has a higher value than the blue line representing RANDOM initialization throughout the iterations.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2. EM Log-Likelihood vs. training iterations for random initialization and SSID initialization.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2. EM Log-Likelihood vs. training iterations for random initialization and SSID initialization.",
            "categories": "['stat.ML cs.CL cs.LG']",
            "figure_id": "1502.04081v2-Figure2-1",
            "image_path": "1502.04081v2-Figure2-1.png",
            "instance_id": "f159da3fd912dd63c62a7dfacd552653",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does SSID initialization achieve a higher log-likelihood than random initialization after 100 training iterations?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, SSID initialization achieves a higher log-likelihood than random initialization after 100 training iterations, as indicated by the graph where the SSID curve is above the RANDOM curve at the 100 iteration mark.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The green line"
                    },
                    {
                        "B": "The blue line"
                    },
                    {
                        "C": "Both"
                    },
                    {
                        "D": "Neither"
                    }
                ],
                "caption": "Figure 2. EM Log-Likelihood vs. training iterations for random initialization and SSID initialization.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2. EM Log-Likelihood vs. training iterations for random initialization and SSID initialization.",
            "categories": "['stat.ML cs.CL cs.LG']",
            "figure_id": "1502.04081v2-Figure2-1",
            "image_path": "1502.04081v2-Figure2-1.png",
            "instance_id": "cfd83a497a6235bbd44dcac3f7688f3f",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line represents the 'RANDOM' initialization?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "RANDOM"
                    },
                    {
                        "B": "SSID"
                    },
                    {
                        "C": "Both are equal"
                    },
                    {
                        "D": "Neither"
                    }
                ],
                "caption": "Figure 2. EM Log-Likelihood vs. training iterations for random initialization and SSID initialization.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2. EM Log-Likelihood vs. training iterations for random initialization and SSID initialization.",
            "categories": "['stat.ML cs.CL cs.LG']",
            "figure_id": "1502.04081v2-Figure2-1",
            "image_path": "1502.04081v2-Figure2-1.png",
            "instance_id": "550d76859d2616292168606c0272891e",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which initialization method shows a higher log-likelihood value after 100 training iterations?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2. EM Log-Likelihood vs. training iterations for random initialization and SSID initialization.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2. EM Log-Likelihood vs. training iterations for random initialization and SSID initialization.",
            "categories": "['stat.ML cs.CL cs.LG']",
            "figure_id": "1502.04081v2-Figure2-1",
            "image_path": "1502.04081v2-Figure2-1.png",
            "instance_id": "c2751850db020631e7702e9b989ad64e",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific task or problem being solved by the model with random initialization compared to the model with SSID initialization?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Balancing constituent and dependency of joint span HPSG parsing on English dev set.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Balancing constituent and dependency of joint span HPSG parsing on English dev set.",
            "categories": "['cs.CL']",
            "figure_id": "1907.02684v4-Figure5-1",
            "image_path": "1907.02684v4-Figure5-1.png",
            "instance_id": "a4c723088505b700967656cc865eb9a9",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the red line at the x-axis value of 0.5?",
            "reference_answer": "93.8"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The approximate value of the red line (F1 of Constituent Parsing) at the x-axis value of 0.5 is around 94.2.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Balancing constituent and dependency of joint span HPSG parsing on English dev set.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Balancing constituent and dependency of joint span HPSG parsing on English dev set.",
            "categories": "['cs.CL']",
            "figure_id": "1907.02684v4-Figure5-1",
            "image_path": "1907.02684v4-Figure5-1.png",
            "instance_id": "87cd6add35e4927ca65f00e314c5326e",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the name of the parsing technique performing lower?",
            "reference_answer": "Dependency"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The parsing technique performing lower is Dependency Parsing.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Balancing constituent and dependency of joint span HPSG parsing on English dev set.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Balancing constituent and dependency of joint span HPSG parsing on English dev set.",
            "categories": "['cs.CL']",
            "figure_id": "1907.02684v4-Figure5-1",
            "image_path": "1907.02684v4-Figure5-1.png",
            "instance_id": "c86a67f85519d61c205e84f5ce142f1b",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the blue dashed line representing 'Dependency' reach a peak value at the x-axis value of 0.5?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, the blue dashed line representing 'Dependency' does not reach a peak value at the x-axis value of 0.5.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Balancing constituent and dependency of joint span HPSG parsing on English dev set.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Balancing constituent and dependency of joint span HPSG parsing on English dev set.",
            "categories": "['cs.CL']",
            "figure_id": "1907.02684v4-Figure5-1",
            "image_path": "1907.02684v4-Figure5-1.png",
            "instance_id": "bb46ddf7a3142b73b1e044708d44d229",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the value of constituent parsing F1 measure reach 95.7?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, the value of constituent parsing F1 measure does not reach 95.7.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The red line"
                    },
                    {
                        "B": "The blue line"
                    },
                    {
                        "C": "The green line"
                    },
                    {
                        "D": "The black line"
                    }
                ],
                "caption": "Figure 5: Balancing constituent and dependency of joint span HPSG parsing on English dev set.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Balancing constituent and dependency of joint span HPSG parsing on English dev set.",
            "categories": "['cs.CL']",
            "figure_id": "1907.02684v4-Figure5-1",
            "image_path": "1907.02684v4-Figure5-1.png",
            "instance_id": "051fb0df99bf0b9d1e78f62bff6db495",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line represents the Dependency parsing data?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "95.9"
                    },
                    {
                        "B": "96.0"
                    },
                    {
                        "C": "93.8"
                    },
                    {
                        "D": "93.7"
                    }
                ],
                "caption": "Figure 5: Balancing constituent and dependency of joint span HPSG parsing on English dev set.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Balancing constituent and dependency of joint span HPSG parsing on English dev set.",
            "categories": "['cs.CL']",
            "figure_id": "1907.02684v4-Figure5-1",
            "image_path": "1907.02684v4-Figure5-1.png",
            "instance_id": "8885b3e93fd0a381734ec8fa81685bed",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the approximate maximum value of F1 of constituent parsing?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Balancing constituent and dependency of joint span HPSG parsing on English dev set.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Balancing constituent and dependency of joint span HPSG parsing on English dev set.",
            "categories": "['cs.CL']",
            "figure_id": "1907.02684v4-Figure5-1",
            "image_path": "1907.02684v4-Figure5-1.png",
            "instance_id": "3b8f7a4b6217736b5ffc36ac34bdd18d",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific dataset used for the dev set?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 2: Theoretical analysis of surprise values in top-k sampling under Zipfian statistics. We note that surprise values increase sharply for small values of k, whereas surprise values hardly change for large values of k.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2: Theoretical analysis of surprise values in top-k sampling under Zipfian statistics. We note that surprise values increase sharply for small values of k, whereas surprise values hardly change for large values of k.",
            "categories": "['cs.CL cs.IT math.IT']",
            "figure_id": "2007.14966v1-Figure2-1",
            "image_path": "2007.14966v1-Figure2-1.png",
            "instance_id": "998ff861d8e5f6d706f44bdb6cb2baa0",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the y-axis at the point where the blue line in the left plot crosses the x-axis?",
            "reference_answer": "1"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 2: Theoretical analysis of surprise values in top-k sampling under Zipfian statistics. We note that surprise values increase sharply for small values of k, whereas surprise values hardly change for large values of k.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2: Theoretical analysis of surprise values in top-k sampling under Zipfian statistics. We note that surprise values increase sharply for small values of k, whereas surprise values hardly change for large values of k.",
            "categories": "['cs.CL cs.IT math.IT']",
            "figure_id": "2007.14966v1-Figure2-1",
            "image_path": "2007.14966v1-Figure2-1.png",
            "instance_id": "5eab9b52f6d971def6886d56bfefc5fa",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "For what values of k do surprise values hardly change?",
            "reference_answer": "Large values of k"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 2: Theoretical analysis of surprise values in top-k sampling under Zipfian statistics. We note that surprise values increase sharply for small values of k, whereas surprise values hardly change for large values of k.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2: Theoretical analysis of surprise values in top-k sampling under Zipfian statistics. We note that surprise values increase sharply for small values of k, whereas surprise values hardly change for large values of k.",
            "categories": "['cs.CL cs.IT math.IT']",
            "figure_id": "2007.14966v1-Figure2-1",
            "image_path": "2007.14966v1-Figure2-1.png",
            "instance_id": "3f46a95b3e120354e5ce9611956d1a82",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the right graph represents more than one line?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 2: Theoretical analysis of surprise values in top-k sampling under Zipfian statistics. We note that surprise values increase sharply for small values of k, whereas surprise values hardly change for large values of k.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2: Theoretical analysis of surprise values in top-k sampling under Zipfian statistics. We note that surprise values increase sharply for small values of k, whereas surprise values hardly change for large values of k.",
            "categories": "['cs.CL cs.IT math.IT']",
            "figure_id": "2007.14966v1-Figure2-1",
            "image_path": "2007.14966v1-Figure2-1.png",
            "instance_id": "04efcb53ce8c4be4a9a1cb3ab4777926",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Do surprise values change more significantly for smaller values of k compared to larger values of k?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Linear"
                    },
                    {
                        "B": "Exponential"
                    },
                    {
                        "C": "Curved"
                    },
                    {
                        "D": "Zigzag"
                    }
                ],
                "caption": "Fig. 2: Theoretical analysis of surprise values in top-k sampling under Zipfian statistics. We note that surprise values increase sharply for small values of k, whereas surprise values hardly change for large values of k.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2: Theoretical analysis of surprise values in top-k sampling under Zipfian statistics. We note that surprise values increase sharply for small values of k, whereas surprise values hardly change for large values of k.",
            "categories": "['cs.CL cs.IT math.IT']",
            "figure_id": "2007.14966v1-Figure2-1",
            "image_path": "2007.14966v1-Figure2-1.png",
            "instance_id": "899727d47b3171f4b8285b1c3c5d6291",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What is the shape of the line in the left plot?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "True"
                    },
                    {
                        "B": "False"
                    },
                    {
                        "C": "200"
                    },
                    {
                        "D": "900"
                    }
                ],
                "caption": "Fig. 2: Theoretical analysis of surprise values in top-k sampling under Zipfian statistics. We note that surprise values increase sharply for small values of k, whereas surprise values hardly change for large values of k.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2: Theoretical analysis of surprise values in top-k sampling under Zipfian statistics. We note that surprise values increase sharply for small values of k, whereas surprise values hardly change for large values of k.",
            "categories": "['cs.CL cs.IT math.IT']",
            "figure_id": "2007.14966v1-Figure2-1",
            "image_path": "2007.14966v1-Figure2-1.png",
            "instance_id": "9ff1a00d89bda92b54e120b3e081715c",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "How many values of K are considered?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 2: Theoretical analysis of surprise values in top-k sampling under Zipfian statistics. We note that surprise values increase sharply for small values of k, whereas surprise values hardly change for large values of k.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2: Theoretical analysis of surprise values in top-k sampling under Zipfian statistics. We note that surprise values increase sharply for small values of k, whereas surprise values hardly change for large values of k.",
            "categories": "['cs.CL cs.IT math.IT']",
            "figure_id": "2007.14966v1-Figure2-1",
            "image_path": "2007.14966v1-Figure2-1.png",
            "instance_id": "25b5cbddb471b88ca864319eab5f5a5d",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific value of the surprise value for k = 50?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: The performance of matching models on Transformer with different number of layers.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: The performance of matching models on Transformer with different number of layers.",
            "categories": "['cs.CL']",
            "figure_id": "2001.07234v1-Figure2-1",
            "image_path": "2001.07234v1-Figure2-1.png",
            "instance_id": "ce0fe4c8fe803b27a3df0ca36ff953b3",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate accuracy of the red line at layer 12?",
            "reference_answer": "83"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: The performance of matching models on Transformer with different number of layers.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: The performance of matching models on Transformer with different number of layers.",
            "categories": "['cs.CL']",
            "figure_id": "2001.07234v1-Figure2-1",
            "image_path": "2001.07234v1-Figure2-1.png",
            "instance_id": "8c830466fca280a305c1d795e123eca8",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the model with the highest accuracy at 20 layers?",
            "reference_answer": "Multi-level head match"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The model with the highest accuracy at 20 layers is the multi-level head match.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: The performance of matching models on Transformer with different number of layers.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: The performance of matching models on Transformer with different number of layers.",
            "categories": "['cs.CL']",
            "figure_id": "2001.07234v1-Figure2-1",
            "image_path": "2001.07234v1-Figure2-1.png",
            "instance_id": "85aa345e93d36ebdfb9188fc36d288ae",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the blue line consistently higher than the red line?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The blue line (multi-level head match) is consistently higher than the red line (classic match) throughout the graph.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: The performance of matching models on Transformer with different number of layers.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: The performance of matching models on Transformer with different number of layers.",
            "categories": "['cs.CL']",
            "figure_id": "2001.07234v1-Figure2-1",
            "image_path": "2001.07234v1-Figure2-1.png",
            "instance_id": "915eef70b4feceeda0db83d9d576356e",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the accuracy of the single-level head match model consistently surpass the accuracy of the classic match model?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "red"
                    },
                    {
                        "B": "green"
                    },
                    {
                        "C": "blue"
                    },
                    {
                        "D": "all three show the same accuracy"
                    }
                ],
                "caption": "Figure 2: The performance of matching models on Transformer with different number of layers.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: The performance of matching models on Transformer with different number of layers.",
            "categories": "['cs.CL']",
            "figure_id": "2001.07234v1-Figure2-1",
            "image_path": "2001.07234v1-Figure2-1.png",
            "instance_id": "34fb4b22684c7cb8f3baa9bfa7a45ba7",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line shows the highest accuracy at the highest layer number?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "classic match"
                    },
                    {
                        "B": "single-level head match"
                    },
                    {
                        "C": "multi-level head match"
                    },
                    {
                        "D": "All of the above"
                    }
                ],
                "caption": "Figure 2: The performance of matching models on Transformer with different number of layers.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: The performance of matching models on Transformer with different number of layers.",
            "categories": "['cs.CL']",
            "figure_id": "2001.07234v1-Figure2-1",
            "image_path": "2001.07234v1-Figure2-1.png",
            "instance_id": "af44d01c683dea61c5efa2bcf4483efd",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which matching models have an accuracy of above 86 at Layer 18?",
            "reference_answer": "B,C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "BC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: The performance of matching models on Transformer with different number of layers.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: The performance of matching models on Transformer with different number of layers.",
            "categories": "['cs.CL']",
            "figure_id": "2001.07234v1-Figure2-1",
            "image_path": "2001.07234v1-Figure2-1.png",
            "instance_id": "2ebb57d62012ea9f43439e5c33c11be0",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific type of Transformer used in this experiment?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Comparison of the NER performance trained with the FineTune scheme, across six datasets. Solid lines compare the different active learning strategies. Dashed lines show the ablation experiments. The x-axis denotes the total number of tokens annotated and the y-axis denotes the F1 score.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison of the NER performance trained with the FineTune scheme, across six datasets. Solid lines compare the different active learning strategies. Dashed lines show the ablation experiments. The x-axis denotes the total number of tokens annotated and the y-axis denotes the F1 score.",
            "categories": "['cs.CL']",
            "figure_id": "1908.08983v1-Figure2-1",
            "image_path": "1908.08983v1-Figure2-1.png",
            "instance_id": "2a8627e1b5ec1041dea7279ee3e7e2cb",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the F1 score of the solid green line at the intersection with the x-axis label of 200 in the Spanish CoNLL subplot?",
            "reference_answer": "35"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Comparison of the NER performance trained with the FineTune scheme, across six datasets. Solid lines compare the different active learning strategies. Dashed lines show the ablation experiments. The x-axis denotes the total number of tokens annotated and the y-axis denotes the F1 score.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison of the NER performance trained with the FineTune scheme, across six datasets. Solid lines compare the different active learning strategies. Dashed lines show the ablation experiments. The x-axis denotes the total number of tokens annotated and the y-axis denotes the F1 score.",
            "categories": "['cs.CL']",
            "figure_id": "1908.08983v1-Figure2-1",
            "image_path": "1908.08983v1-Figure2-1.png",
            "instance_id": "be5492a89d978c80e0d4bcb1ffa6ff3b",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the maximum number of tokens annotated in the Hindi LDC dataset?",
            "reference_answer": "4000"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Comparison of the NER performance trained with the FineTune scheme, across six datasets. Solid lines compare the different active learning strategies. Dashed lines show the ablation experiments. The x-axis denotes the total number of tokens annotated and the y-axis denotes the F1 score.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison of the NER performance trained with the FineTune scheme, across six datasets. Solid lines compare the different active learning strategies. Dashed lines show the ablation experiments. The x-axis denotes the total number of tokens annotated and the y-axis denotes the F1 score.",
            "categories": "['cs.CL']",
            "figure_id": "1908.08983v1-Figure2-1",
            "image_path": "1908.08983v1-Figure2-1.png",
            "instance_id": "bc0697cc8133fcb6ce5fdebf81c301f2",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the performance of 'ETAL + PARTIAL-CRF + CT' (blue line) in the 'Hindi LDC' dataset better than the 'Supervised All' (pink line) when the total number of tokens annotated is 1000?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the performance of 'ETAL + PARTIAL-CRF + CT' (blue line) in the 'Hindi LDC' dataset is better than the 'Supervised All' (pink line) when the total number of tokens annotated is 1000.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Comparison of the NER performance trained with the FineTune scheme, across six datasets. Solid lines compare the different active learning strategies. Dashed lines show the ablation experiments. The x-axis denotes the total number of tokens annotated and the y-axis denotes the F1 score.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison of the NER performance trained with the FineTune scheme, across six datasets. Solid lines compare the different active learning strategies. Dashed lines show the ablation experiments. The x-axis denotes the total number of tokens annotated and the y-axis denotes the F1 score.",
            "categories": "['cs.CL']",
            "figure_id": "1908.08983v1-Figure2-1",
            "image_path": "1908.08983v1-Figure2-1.png",
            "instance_id": "1a859d6dcd7e63337dd1b528fe1f6871",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the F1 score generally increase as the number of annotated tokens increases?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "50"
                    },
                    {
                        "B": "60"
                    },
                    {
                        "C": "70"
                    },
                    {
                        "D": "80"
                    }
                ],
                "caption": "Figure 2: Comparison of the NER performance trained with the FineTune scheme, across six datasets. Solid lines compare the different active learning strategies. Dashed lines show the ablation experiments. The x-axis denotes the total number of tokens annotated and the y-axis denotes the F1 score.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison of the NER performance trained with the FineTune scheme, across six datasets. Solid lines compare the different active learning strategies. Dashed lines show the ablation experiments. The x-axis denotes the total number of tokens annotated and the y-axis denotes the F1 score.",
            "categories": "['cs.CL']",
            "figure_id": "1908.08983v1-Figure2-1",
            "image_path": "1908.08983v1-Figure2-1.png",
            "instance_id": "a783b57b15e7d8d7168b56bcda23eead",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What is the highest F1 score of the purple line in the bottom right subplot?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B\u0643\u062aostP: ",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "RAND + PARTIAL-CRF + CT"
                    },
                    {
                        "B": "ETAL + PARTIAL-CRF + CT"
                    },
                    {
                        "C": "CFEAL + PARTIAL-CRF + CT"
                    },
                    {
                        "D": "SAL + FULL-CRF + CT"
                    }
                ],
                "caption": "Figure 2: Comparison of the NER performance trained with the FineTune scheme, across six datasets. Solid lines compare the different active learning strategies. Dashed lines show the ablation experiments. The x-axis denotes the total number of tokens annotated and the y-axis denotes the F1 score.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison of the NER performance trained with the FineTune scheme, across six datasets. Solid lines compare the different active learning strategies. Dashed lines show the ablation experiments. The x-axis denotes the total number of tokens annotated and the y-axis denotes the F1 score.",
            "categories": "['cs.CL']",
            "figure_id": "1908.08983v1-Figure2-1",
            "image_path": "1908.08983v1-Figure2-1.png",
            "instance_id": "19726ae50d1403a3f031717260b6411f",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which strategie performs the best in all the datasets?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Comparison of the NER performance trained with the FineTune scheme, across six datasets. Solid lines compare the different active learning strategies. Dashed lines show the ablation experiments. The x-axis denotes the total number of tokens annotated and the y-axis denotes the F1 score.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison of the NER performance trained with the FineTune scheme, across six datasets. Solid lines compare the different active learning strategies. Dashed lines show the ablation experiments. The x-axis denotes the total number of tokens annotated and the y-axis denotes the F1 score.",
            "categories": "['cs.CL']",
            "figure_id": "1908.08983v1-Figure2-1",
            "image_path": "1908.08983v1-Figure2-1.png",
            "instance_id": "9e816664daa630ca43a5cf670783c109",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific NER model used for training in the 'FineTune' scheme?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7. Defense with adversarial training in different settings. (a) and (b) On RT and IMDB datasets, data augmentation with adversarial data generated from scratch under different \u03c6. (c) On RT dataset, accuracy of models trained with equal size of augmentation adversarial data, which is generated in pair-wise way and unrestricted generation way respectively.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7. Defense with adversarial training in different settings. (a) and (b) On RT and IMDB datasets, data augmentation with adversarial data generated from scratch under different \u03c6. (c) On RT dataset, accuracy of models trained with equal size of augmentation adversarial data, which is generated in pair-wise way and unrestricted generation way respectively.",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "2003.10388v1-Figure7-1",
            "image_path": "2003.10388v1-Figure7-1.png",
            "instance_id": "b0c0127868449aa10d704c19b8aa07af",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the accuracy of the red line on the RT dataset for \u03c6 = 7?",
            "reference_answer": "94.9"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7. Defense with adversarial training in different settings. (a) and (b) On RT and IMDB datasets, data augmentation with adversarial data generated from scratch under different \u03c6. (c) On RT dataset, accuracy of models trained with equal size of augmentation adversarial data, which is generated in pair-wise way and unrestricted generation way respectively.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7. Defense with adversarial training in different settings. (a) and (b) On RT and IMDB datasets, data augmentation with adversarial data generated from scratch under different \u03c6. (c) On RT dataset, accuracy of models trained with equal size of augmentation adversarial data, which is generated in pair-wise way and unrestricted generation way respectively.",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "2003.10388v1-Figure7-1",
            "image_path": "2003.10388v1-Figure7-1.png",
            "instance_id": "7d729924defabe49b85e1eaef3b94a33",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "Which test data accuracy performs the best in the first two images?",
            "reference_answer": "Adversarial Test Data Accuracy"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The test data accuracy that performs the best in the first two images (RT and IMDB) is the \"Original Test Data Acc.\" shown with blue lines.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7. Defense with adversarial training in different settings. (a) and (b) On RT and IMDB datasets, data augmentation with adversarial data generated from scratch under different \u03c6. (c) On RT dataset, accuracy of models trained with equal size of augmentation adversarial data, which is generated in pair-wise way and unrestricted generation way respectively.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7. Defense with adversarial training in different settings. (a) and (b) On RT and IMDB datasets, data augmentation with adversarial data generated from scratch under different \u03c6. (c) On RT dataset, accuracy of models trained with equal size of augmentation adversarial data, which is generated in pair-wise way and unrestricted generation way respectively.",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "2003.10388v1-Figure7-1",
            "image_path": "2003.10388v1-Figure7-1.png",
            "instance_id": "be20008c44394945cec5fe537d96cbfc",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "In the figure labelled (a) RT, is the red line for the 'Adversarial Test Data Acc.' higher than the blue line for the 'Original Test Data Acc.' at the point '\u03c6' = 3?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7. Defense with adversarial training in different settings. (a) and (b) On RT and IMDB datasets, data augmentation with adversarial data generated from scratch under different \u03c6. (c) On RT dataset, accuracy of models trained with equal size of augmentation adversarial data, which is generated in pair-wise way and unrestricted generation way respectively.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7. Defense with adversarial training in different settings. (a) and (b) On RT and IMDB datasets, data augmentation with adversarial data generated from scratch under different \u03c6. (c) On RT dataset, accuracy of models trained with equal size of augmentation adversarial data, which is generated in pair-wise way and unrestricted generation way respectively.",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "2003.10388v1-Figure7-1",
            "image_path": "2003.10388v1-Figure7-1.png",
            "instance_id": "5ef8f3ec8d2c1b1c5fe03ed86a7508bd",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the adversarial test data accuracy on the IMDB dataset consistently higher than the original test data accuracy?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Green"
                    },
                    {
                        "B": "Blue"
                    },
                    {
                        "C": "Red"
                    },
                    {
                        "D": "Yellow"
                    }
                ],
                "caption": "Figure 7. Defense with adversarial training in different settings. (a) and (b) On RT and IMDB datasets, data augmentation with adversarial data generated from scratch under different \u03c6. (c) On RT dataset, accuracy of models trained with equal size of augmentation adversarial data, which is generated in pair-wise way and unrestricted generation way respectively.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7. Defense with adversarial training in different settings. (a) and (b) On RT and IMDB datasets, data augmentation with adversarial data generated from scratch under different \u03c6. (c) On RT dataset, accuracy of models trained with equal size of augmentation adversarial data, which is generated in pair-wise way and unrestricted generation way respectively.",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "2003.10388v1-Figure7-1",
            "image_path": "2003.10388v1-Figure7-1.png",
            "instance_id": "dfbcd8b7c0adec3a31ef4676047dacbb",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "In the third plot (labeled \"(c) Data augmentation compare\"), what color is the line representing 'Adversarial Test Data Acc. (Pair-wise)'?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Wikipedia"
                    },
                    {
                        "B": "IMDB"
                    },
                    {
                        "C": "RT and IMDB"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 7. Defense with adversarial training in different settings. (a) and (b) On RT and IMDB datasets, data augmentation with adversarial data generated from scratch under different \u03c6. (c) On RT dataset, accuracy of models trained with equal size of augmentation adversarial data, which is generated in pair-wise way and unrestricted generation way respectively.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7. Defense with adversarial training in different settings. (a) and (b) On RT and IMDB datasets, data augmentation with adversarial data generated from scratch under different \u03c6. (c) On RT dataset, accuracy of models trained with equal size of augmentation adversarial data, which is generated in pair-wise way and unrestricted generation way respectively.",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "2003.10388v1-Figure7-1",
            "image_path": "2003.10388v1-Figure7-1.png",
            "instance_id": "711bff7dbfdaa1d565c13c1c85e3145a",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which datasets were used to compare the effect of data augmentation with adversarial training on the accuracy of models?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7. Defense with adversarial training in different settings. (a) and (b) On RT and IMDB datasets, data augmentation with adversarial data generated from scratch under different \u03c6. (c) On RT dataset, accuracy of models trained with equal size of augmentation adversarial data, which is generated in pair-wise way and unrestricted generation way respectively.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7. Defense with adversarial training in different settings. (a) and (b) On RT and IMDB datasets, data augmentation with adversarial data generated from scratch under different \u03c6. (c) On RT dataset, accuracy of models trained with equal size of augmentation adversarial data, which is generated in pair-wise way and unrestricted generation way respectively.",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "2003.10388v1-Figure7-1",
            "image_path": "2003.10388v1-Figure7-1.png",
            "instance_id": "d7329ea2da1dbd7b6a0fd17001dfcdb0",
            "qa_pair_type": "unanswerable",
            "question": "What is the average accuracy of the adversarial training on the IMDB dataset for different values of \u03c6?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Correlation Analysis with Hostility-Anger",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Correlation Analysis with Hostility-Anger",
            "categories": "['cs.SI cs.CL']",
            "figure_id": "1410.8749v1-Figure4-1",
            "image_path": "1410.8749v1-Figure4-1.png",
            "instance_id": "66c41dffc1944e811825da206b9ad620",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of the red horizontal line in the graph labeled (d) Weekday Effect?",
            "reference_answer": "0"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Correlation Analysis with Hostility-Anger",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Correlation Analysis with Hostility-Anger",
            "categories": "['cs.SI cs.CL']",
            "figure_id": "1410.8749v1-Figure4-1",
            "image_path": "1410.8749v1-Figure4-1.png",
            "instance_id": "ddeba97846b654c0edcbfe5683890460",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the p-value for the correlation analysis with Snow Depth?",
            "reference_answer": "0.422"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The p-value for the correlation analysis with Snow Depth is 0.422.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Correlation Analysis with Hostility-Anger",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Correlation Analysis with Hostility-Anger",
            "categories": "['cs.SI cs.CL']",
            "figure_id": "1410.8749v1-Figure4-1",
            "image_path": "1410.8749v1-Figure4-1.png",
            "instance_id": "c5486f6f6032c76a80aea45293ca1055",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the red line in the third graph (snow depth) intersect with the black line?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Correlation Analysis with Hostility-Anger",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Correlation Analysis with Hostility-Anger",
            "categories": "['cs.SI cs.CL']",
            "figure_id": "1410.8749v1-Figure4-1",
            "image_path": "1410.8749v1-Figure4-1.png",
            "instance_id": "5f576e46c2435a9ea1c5de1facb1c8fb",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the P-value for snow depth greater than 0.05?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The P-value for snow depth is 0.422, which is greater than 0.05.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "(a) Average Temperature"
                    },
                    {
                        "B": "(b) Precipitation"
                    },
                    {
                        "C": "(c) Snow Depth"
                    },
                    {
                        "D": "(d) Weekday Effect"
                    }
                ],
                "caption": "Figure 4: Correlation Analysis with Hostility-Anger",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Correlation Analysis with Hostility-Anger",
            "categories": "['cs.SI cs.CL']",
            "figure_id": "1410.8749v1-Figure4-1",
            "image_path": "1410.8749v1-Figure4-1.png",
            "instance_id": "367a6b2dd5e60ba764c6fe109f8c8364",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following subplots exhibit a statistically significant relationship (P-Value < 0.05) between the independent variable and dependent variable?",
            "reference_answer": "A,B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ABCD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Average Temperature"
                    },
                    {
                        "B": "Precipitation"
                    },
                    {
                        "C": "Snow Depth"
                    },
                    {
                        "D": "Weekday Effect"
                    }
                ],
                "caption": "Figure 4: Correlation Analysis with Hostility-Anger",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Correlation Analysis with Hostility-Anger",
            "categories": "['cs.SI cs.CL']",
            "figure_id": "1410.8749v1-Figure4-1",
            "image_path": "1410.8749v1-Figure4-1.png",
            "instance_id": "1a65ef346fda160147fc6f0c1d8c7144",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following factors are considered to be possibly correlated with Hostility-Anger?",
            "reference_answer": "A,B,C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ABD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Correlation Analysis with Hostility-Anger",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Correlation Analysis with Hostility-Anger",
            "categories": "['cs.SI cs.CL']",
            "figure_id": "1410.8749v1-Figure4-1",
            "image_path": "1410.8749v1-Figure4-1.png",
            "instance_id": "bf5b7389b530be6f17561ad2a47d28ac",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific method used to calculate the correlation between Hostility-Anger and the variables shown in Figure 4?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3. Mean relative cross-entropy loss difference (%) between each baseline output layer (B) and our output layer (DRILL) computed over different word frequency intervals on PennTreebank.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3. Mean relative cross-entropy loss difference (%) between each baseline output layer (B) and our output layer (DRILL) computed over different word frequency intervals on PennTreebank.",
            "categories": "['cs.CL']",
            "figure_id": "1905.05513v2-Figure3-1",
            "image_path": "1905.05513v2-Figure3-1.png",
            "instance_id": "9babbbfe774f8f653198097de38cfc77",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the blue line at the interval [2.5K-5K]?",
            "reference_answer": "-1"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3. Mean relative cross-entropy loss difference (%) between each baseline output layer (B) and our output layer (DRILL) computed over different word frequency intervals on PennTreebank.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3. Mean relative cross-entropy loss difference (%) between each baseline output layer (B) and our output layer (DRILL) computed over different word frequency intervals on PennTreebank.",
            "categories": "['cs.CL']",
            "figure_id": "1905.05513v2-Figure3-1",
            "image_path": "1905.05513v2-Figure3-1.png",
            "instance_id": "9a9c78b5e9129271f8d14b42c25ba919",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the lowest value of the mean relative cross-entropy loss difference (%) on PennTreebank for the bilinear map.",
            "reference_answer": "-2"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3. Mean relative cross-entropy loss difference (%) between each baseline output layer (B) and our output layer (DRILL) computed over different word frequency intervals on PennTreebank.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3. Mean relative cross-entropy loss difference (%) between each baseline output layer (B) and our output layer (DRILL) computed over different word frequency intervals on PennTreebank.",
            "categories": "['cs.CL']",
            "figure_id": "1905.05513v2-Figure3-1",
            "image_path": "1905.05513v2-Figure3-1.png",
            "instance_id": "dd7398352b7b1d59b6a08f1b1f787de5",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the value of the blue star at the interval [1-50] greater than 10?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3. Mean relative cross-entropy loss difference (%) between each baseline output layer (B) and our output layer (DRILL) computed over different word frequency intervals on PennTreebank.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3. Mean relative cross-entropy loss difference (%) between each baseline output layer (B) and our output layer (DRILL) computed over different word frequency intervals on PennTreebank.",
            "categories": "['cs.CL']",
            "figure_id": "1905.05513v2-Figure3-1",
            "image_path": "1905.05513v2-Figure3-1.png",
            "instance_id": "35dd73ef4bb3812d1ef8c13966a95a1a",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the mean relative cross-entropy loss difference consistently lower for dual nonlinear map than for bilinear map?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "[1 - 50]"
                    },
                    {
                        "B": "[50 - 100]"
                    },
                    {
                        "C": "[250 - 500]"
                    },
                    {
                        "D": "[5K - 100K]"
                    }
                ],
                "caption": "Figure 3. Mean relative cross-entropy loss difference (%) between each baseline output layer (B) and our output layer (DRILL) computed over different word frequency intervals on PennTreebank.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3. Mean relative cross-entropy loss difference (%) between each baseline output layer (B) and our output layer (DRILL) computed over different word frequency intervals on PennTreebank.",
            "categories": "['cs.CL']",
            "figure_id": "1905.05513v2-Figure3-1",
            "image_path": "1905.05513v2-Figure3-1.png",
            "instance_id": "8188bb03a88c84c20c82bba7a9b0caac",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following word frequency intervals has the highest value for the blue line in the figure?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Bilinear map"
                    },
                    {
                        "B": "Dual nonlinear map"
                    },
                    {
                        "C": "Both"
                    },
                    {
                        "D": "None"
                    }
                ],
                "caption": "Figure 3. Mean relative cross-entropy loss difference (%) between each baseline output layer (B) and our output layer (DRILL) computed over different word frequency intervals on PennTreebank.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3. Mean relative cross-entropy loss difference (%) between each baseline output layer (B) and our output layer (DRILL) computed over different word frequency intervals on PennTreebank.",
            "categories": "['cs.CL']",
            "figure_id": "1905.05513v2-Figure3-1",
            "image_path": "1905.05513v2-Figure3-1.png",
            "instance_id": "74f91e19b31d55d06c85df7848290389",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which output layer type shows the lowest cross-entropy loss difference (%) for words with frequency between 1K and 2.5K?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3. Mean relative cross-entropy loss difference (%) between each baseline output layer (B) and our output layer (DRILL) computed over different word frequency intervals on PennTreebank.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3. Mean relative cross-entropy loss difference (%) between each baseline output layer (B) and our output layer (DRILL) computed over different word frequency intervals on PennTreebank.",
            "categories": "['cs.CL']",
            "figure_id": "1905.05513v2-Figure3-1",
            "image_path": "1905.05513v2-Figure3-1.png",
            "instance_id": "4e214af32c01391e31743458f4f7ff68",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific implementation of the 'Bilinear map' technique in the 'Weight tying [PW17]' method that leads to the observed trend in cross-entropy loss difference? ",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 9: Learning Curve",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: Learning Curve",
            "categories": "['cs.CL']",
            "figure_id": "1705.04038v1-Figure9-1",
            "image_path": "1705.04038v1-Figure9-1.png",
            "instance_id": "d707891eee68b833a02a2fe40a7794be",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the figure used in the line?",
            "reference_answer": "circle"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The figure used in the line is the F1 score.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 9: Learning Curve",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: Learning Curve",
            "categories": "['cs.CL']",
            "figure_id": "1705.04038v1-Figure9-1",
            "image_path": "1705.04038v1-Figure9-1.png",
            "instance_id": "058dcf61b09c2a37a9ea53b2edf384d9",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the approximate F1 score when 4800 sentences are used in training data?",
            "reference_answer": "73"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 9: Learning Curve",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: Learning Curve",
            "categories": "['cs.CL']",
            "figure_id": "1705.04038v1-Figure9-1",
            "image_path": "1705.04038v1-Figure9-1.png",
            "instance_id": "0408f5e6e6941e04c2c7a59507271a50",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the value of the black circle at 4800 sentences on the horizontal axis higher than the value of the black circle at 1600 sentences?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 9: Learning Curve",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: Learning Curve",
            "categories": "['cs.CL']",
            "figure_id": "1705.04038v1-Figure9-1",
            "image_path": "1705.04038v1-Figure9-1.png",
            "instance_id": "862b701e5ae173585ced2823cfcc0fc1",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the learning curve for F1 score show a decreasing trend as the number of sentences in training data increases?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, the learning curve for F1 score does not show a decreasing trend as the number of sentences in training data increases.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "3"
                    },
                    {
                        "B": "2"
                    },
                    {
                        "C": "1"
                    },
                    {
                        "D": "None"
                    }
                ],
                "caption": "Figure 9: Learning Curve",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: Learning Curve",
            "categories": "['cs.CL']",
            "figure_id": "1705.04038v1-Figure9-1",
            "image_path": "1705.04038v1-Figure9-1.png",
            "instance_id": "7ae0d94e8dc8d2c634b896bca399bf57",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "How many circles share the same F1 score?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "growing"
                    },
                    {
                        "B": "decreasing"
                    },
                    {
                        "C": "being constant"
                    },
                    {
                        "D": "growing and being constant"
                    }
                ],
                "caption": "Figure 9: Learning Curve",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: Learning Curve",
            "categories": "['cs.CL']",
            "figure_id": "1705.04038v1-Figure9-1",
            "image_path": "1705.04038v1-Figure9-1.png",
            "instance_id": "3cf30696ed0ae183b5f286dfe7202087",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the general tendency of the graph?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 9: Learning Curve",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: Learning Curve",
            "categories": "['cs.CL']",
            "figure_id": "1705.04038v1-Figure9-1",
            "image_path": "1705.04038v1-Figure9-1.png",
            "instance_id": "eee7946593354126afa7db29cf71e4b7",
            "qa_pair_type": "unanswerable",
            "question": "What is the exact value of F1 score when the number of training sentences is 3500?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: The transformer accuracy v.s. number of epoch for the domain class",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: The transformer accuracy v.s. number of epoch for the domain class",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2008.10984v1-Figure2-1",
            "image_path": "2008.10984v1-Figure2-1.png",
            "instance_id": "3a747ffe00b617fca8af779f4c9f0ee1",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "How many circles are there with an accuracy of 96% or more?",
            "reference_answer": "4"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: The transformer accuracy v.s. number of epoch for the domain class",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: The transformer accuracy v.s. number of epoch for the domain class",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2008.10984v1-Figure2-1",
            "image_path": "2008.10984v1-Figure2-1.png",
            "instance_id": "d261aef7880923f0ce09ef33aca6c402",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the accuracy of the transformer at 150 epochs?",
            "reference_answer": "98%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: The transformer accuracy v.s. number of epoch for the domain class",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: The transformer accuracy v.s. number of epoch for the domain class",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2008.10984v1-Figure2-1",
            "image_path": "2008.10984v1-Figure2-1.png",
            "instance_id": "a48fdd38b2f2b1f6596dabc942eeaa4d",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "After epoch 70 does the black line have a constant shape?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, after epoch 70, the black line appears to be relatively constant, indicating that the accuracy does not significantly change with additional epochs.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: The transformer accuracy v.s. number of epoch for the domain class",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: The transformer accuracy v.s. number of epoch for the domain class",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2008.10984v1-Figure2-1",
            "image_path": "2008.10984v1-Figure2-1.png",
            "instance_id": "7c4f099b3ade365c7fb2901e1a5da171",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the transformer accuracy increase with the number of epochs?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the transformer accuracy increases with the number of epochs, reaching a plateau after a certain point.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "90"
                    },
                    {
                        "B": "There is no black line there."
                    },
                    {
                        "C": "98"
                    },
                    {
                        "D": "94"
                    }
                ],
                "caption": "Figure 2: The transformer accuracy v.s. number of epoch for the domain class",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: The transformer accuracy v.s. number of epoch for the domain class",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2008.10984v1-Figure2-1",
            "image_path": "2008.10984v1-Figure2-1.png",
            "instance_id": "7282b3f6df897ac1b8aa70a1d416394a",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What is the accuracy for the black line at the bottom right corner?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "97"
                    },
                    {
                        "B": "95"
                    },
                    {
                        "C": "92"
                    },
                    {
                        "D": "99"
                    }
                ],
                "caption": "Figure 2: The transformer accuracy v.s. number of epoch for the domain class",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: The transformer accuracy v.s. number of epoch for the domain class",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2008.10984v1-Figure2-1",
            "image_path": "2008.10984v1-Figure2-1.png",
            "instance_id": "f316564cc697906c39976767726a9d9c",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the highest accuracy achieved by the transformer model?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: The transformer accuracy v.s. number of epoch for the domain class",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: The transformer accuracy v.s. number of epoch for the domain class",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2008.10984v1-Figure2-1",
            "image_path": "2008.10984v1-Figure2-1.png",
            "instance_id": "4993fcc4aec723a1d5258baefe6ad1a4",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific transformer architecture used in this experiment?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Distribution of mus \u2018mouse\u2019/\u2018muscle\u2019/\u2018mussel\u2019 by genre vs its senses over time. Lines track mus proportions in each genre and century, while bars show the mus occurrence proportions with each sense and century.",
                "compound": false,
                "figure_type": "Line Chart,Bar Chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Distribution of mus \u2018mouse\u2019/\u2018muscle\u2019/\u2018mussel\u2019 by genre vs its senses over time. Lines track mus proportions in each genre and century, while bars show the mus occurrence proportions with each sense and century.",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1903.05587v2-Figure1-1",
            "image_path": "1903.05587v2-Figure1-1.png",
            "instance_id": "c73a4f9ba2182415f7120c0591a45f87",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of the orange bar representing the 'mus: mouse' sense for the century -2?",
            "reference_answer": "100"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Distribution of mus \u2018mouse\u2019/\u2018muscle\u2019/\u2018mussel\u2019 by genre vs its senses over time. Lines track mus proportions in each genre and century, while bars show the mus occurrence proportions with each sense and century.",
                "compound": false,
                "figure_type": "Line Chart,Bar Chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Distribution of mus \u2018mouse\u2019/\u2018muscle\u2019/\u2018mussel\u2019 by genre vs its senses over time. Lines track mus proportions in each genre and century, while bars show the mus occurrence proportions with each sense and century.",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1903.05587v2-Figure1-1",
            "image_path": "1903.05587v2-Figure1-1.png",
            "instance_id": "3bec6c2b307bd34c622b88c7e491bf5d",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is approximately the highest proportion of 'mus' occurrences associated with the sense 'muscle' throughout the centuries?",
            "reference_answer": "50%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Distribution of mus \u2018mouse\u2019/\u2018muscle\u2019/\u2018mussel\u2019 by genre vs its senses over time. Lines track mus proportions in each genre and century, while bars show the mus occurrence proportions with each sense and century.",
                "compound": false,
                "figure_type": "Line Chart,Bar Chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Distribution of mus \u2018mouse\u2019/\u2018muscle\u2019/\u2018mussel\u2019 by genre vs its senses over time. Lines track mus proportions in each genre and century, while bars show the mus occurrence proportions with each sense and century.",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1903.05587v2-Figure1-1",
            "image_path": "1903.05587v2-Figure1-1.png",
            "instance_id": "a7c95e81c2ff1baafabd69040963465f",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the orange bar consistently higher than the purple bar?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Distribution of mus \u2018mouse\u2019/\u2018muscle\u2019/\u2018mussel\u2019 by genre vs its senses over time. Lines track mus proportions in each genre and century, while bars show the mus occurrence proportions with each sense and century.",
                "compound": false,
                "figure_type": "Line Chart,Bar Chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Distribution of mus \u2018mouse\u2019/\u2018muscle\u2019/\u2018mussel\u2019 by genre vs its senses over time. Lines track mus proportions in each genre and century, while bars show the mus occurrence proportions with each sense and century.",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1903.05587v2-Figure1-1",
            "image_path": "1903.05587v2-Figure1-1.png",
            "instance_id": "04cb3ed0ed5cae595c5b43c3a3917a8e",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the proportion of 'mus' as 'muscle' higher in the 4th century than the proportion of 'mus' as 'mouse' in the 3rd century?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Blue"
                    },
                    {
                        "B": "Green"
                    },
                    {
                        "C": "Orange"
                    },
                    {
                        "D": "Red"
                    }
                ],
                "caption": "Figure 1: Distribution of mus \u2018mouse\u2019/\u2018muscle\u2019/\u2018mussel\u2019 by genre vs its senses over time. Lines track mus proportions in each genre and century, while bars show the mus occurrence proportions with each sense and century.",
                "compound": false,
                "figure_type": "Line Chart,Bar Chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Distribution of mus \u2018mouse\u2019/\u2018muscle\u2019/\u2018mussel\u2019 by genre vs its senses over time. Lines track mus proportions in each genre and century, while bars show the mus occurrence proportions with each sense and century.",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1903.05587v2-Figure1-1",
            "image_path": "1903.05587v2-Figure1-1.png",
            "instance_id": "e3852fad82adb116ca1fe91eb8e50621",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which color line represents the proportion of the word 'mus' used in the genre 'technical' across centuries?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Tragedy"
                    },
                    {
                        "B": "Technical"
                    },
                    {
                        "C": "Poetry"
                    },
                    {
                        "D": "Essays"
                    }
                ],
                "caption": "Figure 1: Distribution of mus \u2018mouse\u2019/\u2018muscle\u2019/\u2018mussel\u2019 by genre vs its senses over time. Lines track mus proportions in each genre and century, while bars show the mus occurrence proportions with each sense and century.",
                "compound": false,
                "figure_type": "Line Chart,Bar Chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Distribution of mus \u2018mouse\u2019/\u2018muscle\u2019/\u2018mussel\u2019 by genre vs its senses over time. Lines track mus proportions in each genre and century, while bars show the mus occurrence proportions with each sense and century.",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1903.05587v2-Figure1-1",
            "image_path": "1903.05587v2-Figure1-1.png",
            "instance_id": "3db03eef3e6550eb47c845250b934823",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which genre(s) had the highest proportion of the word 'mus' used for 'muscle'?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Distribution of mus \u2018mouse\u2019/\u2018muscle\u2019/\u2018mussel\u2019 by genre vs its senses over time. Lines track mus proportions in each genre and century, while bars show the mus occurrence proportions with each sense and century.",
                "compound": false,
                "figure_type": "Line Chart,Bar Chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Distribution of mus \u2018mouse\u2019/\u2018muscle\u2019/\u2018mussel\u2019 by genre vs its senses over time. Lines track mus proportions in each genre and century, while bars show the mus occurrence proportions with each sense and century.",
            "categories": "['cs.CL cs.LG stat.ML']",
            "figure_id": "1903.05587v2-Figure1-1",
            "image_path": "1903.05587v2-Figure1-1.png",
            "instance_id": "07550bcd57b890e65a806480fbdcef15",
            "qa_pair_type": "unanswerable",
            "question": "What is the most frequent sense of the word \"mus\" in the 18th century?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: An example of a generated natural language explanation from a chart from our model.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: An example of a generated natural language explanation from a chart from our model.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2010.09142v1-Figure1-1",
            "image_path": "2010.09142v1-Figure1-1.png",
            "instance_id": "0341131f3e7f2ee576e3ad16c540da0a",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate revenue for the green line in the 2017/18 season?",
            "reference_answer": "145 million euros"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: An example of a generated natural language explanation from a chart from our model.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: An example of a generated natural language explanation from a chart from our model.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2010.09142v1-Figure1-1",
            "image_path": "2010.09142v1-Figure1-1.png",
            "instance_id": "ece446e1d201a405a11a0bb819e74fe5",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "Approximatevely how much revenue did Liverpool FC earn from commercial and broadcasting in 2018/2019?",
            "reference_answer": "550 million euros"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: An example of a generated natural language explanation from a chart from our model.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: An example of a generated natural language explanation from a chart from our model.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2010.09142v1-Figure1-1",
            "image_path": "2010.09142v1-Figure1-1.png",
            "instance_id": "6e06f8859d3bbf247bf293f3c75488a2",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the blue line representing the 'Matchday' revenue higher than the green line representing 'Commercial' revenue for the season 2018/19?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: An example of a generated natural language explanation from a chart from our model.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: An example of a generated natural language explanation from a chart from our model.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2010.09142v1-Figure1-1",
            "image_path": "2010.09142v1-Figure1-1.png",
            "instance_id": "6f6904d2957e0c079523be9e2ea89c4a",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the broadcasting revenue stream the largest source of revenue for Liverpool FC?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Green Line"
                    },
                    {
                        "B": "Blue Line"
                    },
                    {
                        "C": "Light Blue Line"
                    },
                    {
                        "D": "Yellow Line"
                    }
                ],
                "caption": "Figure 1: An example of a generated natural language explanation from a chart from our model.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: An example of a generated natural language explanation from a chart from our model.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2010.09142v1-Figure1-1",
            "image_path": "2010.09142v1-Figure1-1.png",
            "instance_id": "be18378005de8b95cf19ed97b82ca7ea",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line represents revenue from \"Matchday\"?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Matchday"
                    },
                    {
                        "B": "Commercial"
                    },
                    {
                        "C": "Broadcasting"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 1: An example of a generated natural language explanation from a chart from our model.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: An example of a generated natural language explanation from a chart from our model.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2010.09142v1-Figure1-1",
            "image_path": "2010.09142v1-Figure1-1.png",
            "instance_id": "f4769cebefc5376d29de930f46c4965b",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following revenue streams is the medium for Liverpool FC in 2018/2019?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: An example of a generated natural language explanation from a chart from our model.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: An example of a generated natural language explanation from a chart from our model.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2010.09142v1-Figure1-1",
            "image_path": "2010.09142v1-Figure1-1.png",
            "instance_id": "509f2293eb54881113cb862e6a8b85f1",
            "qa_pair_type": "unanswerable",
            "question": "What were the total revenues for Liverpool FC in 2014/2015 from matchday, commercial, and broadcasting streams?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Accuracy on the complex negation dataset. The xaxis values correspond to levels of negation: For example, l3 contains terms like \u2018not not not p\u2019.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Accuracy on the complex negation dataset. The xaxis values correspond to levels of negation: For example, l3 contains terms like \u2018not not not p\u2019.",
            "categories": "['cs.CL']",
            "figure_id": "1710.02076v1-Figure4-1",
            "image_path": "1710.02076v1-Figure4-1.png",
            "instance_id": "27cab224740c522738bfb4e2a65ac742",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the green line at l3?",
            "reference_answer": "48"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Accuracy on the complex negation dataset. The xaxis values correspond to levels of negation: For example, l3 contains terms like \u2018not not not p\u2019.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Accuracy on the complex negation dataset. The xaxis values correspond to levels of negation: For example, l3 contains terms like \u2018not not not p\u2019.",
            "categories": "['cs.CL']",
            "figure_id": "1710.02076v1-Figure4-1",
            "image_path": "1710.02076v1-Figure4-1.png",
            "instance_id": "b8bf7810cdb803efef58461d3d66a31a",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the highest level of negation shown on the x-axis?",
            "reference_answer": "l6"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Accuracy on the complex negation dataset. The xaxis values correspond to levels of negation: For example, l3 contains terms like \u2018not not not p\u2019.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Accuracy on the complex negation dataset. The xaxis values correspond to levels of negation: For example, l3 contains terms like \u2018not not not p\u2019.",
            "categories": "['cs.CL']",
            "figure_id": "1710.02076v1-Figure4-1",
            "image_path": "1710.02076v1-Figure4-1.png",
            "instance_id": "da4a859611f0ea9ef28f9b1c0de93e42",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the green line higher than the red line at the x-axis value of 13?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Accuracy on the complex negation dataset. The xaxis values correspond to levels of negation: For example, l3 contains terms like \u2018not not not p\u2019.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Accuracy on the complex negation dataset. The xaxis values correspond to levels of negation: For example, l3 contains terms like \u2018not not not p\u2019.",
            "categories": "['cs.CL']",
            "figure_id": "1710.02076v1-Figure4-1",
            "image_path": "1710.02076v1-Figure4-1.png",
            "instance_id": "a503a6a6ed1c04f0235f1bed921469b0",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the accuracy decrease as the level of negation increases?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the accuracy decreases as the level of negation increases in the plotted lines.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "green"
                    },
                    {
                        "B": "purple"
                    },
                    {
                        "C": "red"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 4: Accuracy on the complex negation dataset. The xaxis values correspond to levels of negation: For example, l3 contains terms like \u2018not not not p\u2019.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Accuracy on the complex negation dataset. The xaxis values correspond to levels of negation: For example, l3 contains terms like \u2018not not not p\u2019.",
            "categories": "['cs.CL']",
            "figure_id": "1710.02076v1-Figure4-1",
            "image_path": "1710.02076v1-Figure4-1.png",
            "instance_id": "d4f2d445d62310d0a0ad7ef367ce4ed2",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line shows the highest accuracy for 'l3' level of negation?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "GloVe"
                    },
                    {
                        "B": "GloVeRetro"
                    },
                    {
                        "C": "Random"
                    },
                    {
                        "D": "All of the above"
                    }
                ],
                "caption": "Figure 4: Accuracy on the complex negation dataset. The xaxis values correspond to levels of negation: For example, l3 contains terms like \u2018not not not p\u2019.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Accuracy on the complex negation dataset. The xaxis values correspond to levels of negation: For example, l3 contains terms like \u2018not not not p\u2019.",
            "categories": "['cs.CL']",
            "figure_id": "1710.02076v1-Figure4-1",
            "image_path": "1710.02076v1-Figure4-1.png",
            "instance_id": "adb43eb163f923ee992fef6f03a30fcd",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which method(s) show a decrease in accuracy as the levels of negation increase?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Accuracy on the complex negation dataset. The xaxis values correspond to levels of negation: For example, l3 contains terms like \u2018not not not p\u2019.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Accuracy on the complex negation dataset. The xaxis values correspond to levels of negation: For example, l3 contains terms like \u2018not not not p\u2019.",
            "categories": "['cs.CL']",
            "figure_id": "1710.02076v1-Figure4-1",
            "image_path": "1710.02076v1-Figure4-1.png",
            "instance_id": "64bea76937e02fb920c8d969e4e443cf",
            "qa_pair_type": "unanswerable",
            "question": "What is the accuracy of GloVe on the complex negation dataset for level l2?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3. Classifier accuracy depending on the number of used vector components (k)",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3. Classifier accuracy depending on the number of used vector components (k)",
            "categories": "['cs.CL']",
            "figure_id": "1608.03803v1-Figure3-1",
            "image_path": "1608.03803v1-Figure3-1.png",
            "instance_id": "fe2ca932d77150fcd35e66cab91effc3",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate maximum value of the blue line on the y-axis in the top right part of the image?",
            "reference_answer": "1.0"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The approximate maximum value of the blue line on the y-axis in the top right part of the image is 1.0.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3. Classifier accuracy depending on the number of used vector components (k)",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3. Classifier accuracy depending on the number of used vector components (k)",
            "categories": "['cs.CL']",
            "figure_id": "1608.03803v1-Figure3-1",
            "image_path": "1608.03803v1-Figure3-1.png",
            "instance_id": "01e961c43af0030846bcdb75db2433b3",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the maximum classifier accuracy?",
            "reference_answer": "1.0"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3. Classifier accuracy depending on the number of used vector components (k)",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3. Classifier accuracy depending on the number of used vector components (k)",
            "categories": "['cs.CL']",
            "figure_id": "1608.03803v1-Figure3-1",
            "image_path": "1608.03803v1-Figure3-1.png",
            "instance_id": "65fe240325bcef0cb1e74e3884250bca",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the classifier accuracy reach a plateau after approximately 150 features are used?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the classifier accuracy appears to reach a plateau after approximately 150 features are used.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3. Classifier accuracy depending on the number of used vector components (k)",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3. Classifier accuracy depending on the number of used vector components (k)",
            "categories": "['cs.CL']",
            "figure_id": "1608.03803v1-Figure3-1",
            "image_path": "1608.03803v1-Figure3-1.png",
            "instance_id": "783d29fdea397ba1bd27ae5c0bd05946",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the classifier accuracy increase monotonically with the number of best features used?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the classifier accuracy increases monotonically with the number of best features used. The graph shows a non-decreasing trend in accuracy as the number of features increases.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "2"
                    },
                    {
                        "B": "5"
                    },
                    {
                        "C": "19"
                    },
                    {
                        "D": "90"
                    }
                ],
                "caption": "Figure 3. Classifier accuracy depending on the number of used vector components (k)",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3. Classifier accuracy depending on the number of used vector components (k)",
            "categories": "['cs.CL']",
            "figure_id": "1608.03803v1-Figure3-1",
            "image_path": "1608.03803v1-Figure3-1.png",
            "instance_id": "341b8d053f4ad303a6cbcf8a66f2fea1",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "How many stars can be found at the beginning of the graph, in the very bottom left part of the image?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "0.97"
                    },
                    {
                        "B": "0.55"
                    },
                    {
                        "C": "1.00"
                    },
                    {
                        "D": "0.75"
                    }
                ],
                "caption": "Figure 3. Classifier accuracy depending on the number of used vector components (k)",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3. Classifier accuracy depending on the number of used vector components (k)",
            "categories": "['cs.CL']",
            "figure_id": "1608.03803v1-Figure3-1",
            "image_path": "1608.03803v1-Figure3-1.png",
            "instance_id": "3355defe2ba0b518c0852a18dec0958c",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the approximate classifier accuracy when the number of best features used is around 200?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3. Classifier accuracy depending on the number of used vector components (k)",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3. Classifier accuracy depending on the number of used vector components (k)",
            "categories": "['cs.CL']",
            "figure_id": "1608.03803v1-Figure3-1",
            "image_path": "1608.03803v1-Figure3-1.png",
            "instance_id": "627596f307b118a25a384507ce81c8ee",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific type of classifier used in this experiment?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Convergence analysis of global iterations of BiPageRank-HITS. 10 randomly chosen samples are plotted.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Convergence analysis of global iterations of BiPageRank-HITS. 10 randomly chosen samples are plotted.",
            "categories": "['cs.CL cs.AI cs.IR']",
            "figure_id": "1604.04358v1-Figure5-1",
            "image_path": "1604.04358v1-Figure5-1.png",
            "instance_id": "b504381a58da261166dd9a00bb36817c",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value on the y-axis at iteration 3 for the black line?",
            "reference_answer": "0.1"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Convergence analysis of global iterations of BiPageRank-HITS. 10 randomly chosen samples are plotted.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Convergence analysis of global iterations of BiPageRank-HITS. 10 randomly chosen samples are plotted.",
            "categories": "['cs.CL cs.AI cs.IR']",
            "figure_id": "1604.04358v1-Figure5-1",
            "image_path": "1604.04358v1-Figure5-1.png",
            "instance_id": "2ceebf964ff75d6b4c6a1496951193e4",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "How many interation were used?",
            "reference_answer": "5"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "There were 5 iterations used, as indicated on the x-axis of the graph.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Convergence analysis of global iterations of BiPageRank-HITS. 10 randomly chosen samples are plotted.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Convergence analysis of global iterations of BiPageRank-HITS. 10 randomly chosen samples are plotted.",
            "categories": "['cs.CL cs.AI cs.IR']",
            "figure_id": "1604.04358v1-Figure5-1",
            "image_path": "1604.04358v1-Figure5-1.png",
            "instance_id": "e16fd77fa9ee796aaec618bca55a9546",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the blue dot plotted at iteration 5 positioned lower than other dots plotted at iteration 5?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Convergence analysis of global iterations of BiPageRank-HITS. 10 randomly chosen samples are plotted.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Convergence analysis of global iterations of BiPageRank-HITS. 10 randomly chosen samples are plotted.",
            "categories": "['cs.CL cs.AI cs.IR']",
            "figure_id": "1604.04358v1-Figure5-1",
            "image_path": "1604.04358v1-Figure5-1.png",
            "instance_id": "70576c7a0be4f488205300185fa8fa34",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Are the global iterations of BiPageRank-HITS  more than 5?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Green, Yellow, and Red"
                    },
                    {
                        "B": "Blue and Black"
                    },
                    {
                        "C": "Purple and Magenta"
                    },
                    {
                        "D": "All of the above"
                    }
                ],
                "caption": "Figure 5: Convergence analysis of global iterations of BiPageRank-HITS. 10 randomly chosen samples are plotted.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Convergence analysis of global iterations of BiPageRank-HITS. 10 randomly chosen samples are plotted.",
            "categories": "['cs.CL cs.AI cs.IR']",
            "figure_id": "1604.04358v1-Figure5-1",
            "image_path": "1604.04358v1-Figure5-1.png",
            "instance_id": "74cfe61b40122b2f7d3bd3cb77a40d8f",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which colors of the lines have their highest values at iteration 1?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A: Green, Yellow, and Red",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "0.5"
                    },
                    {
                        "B": "0.3"
                    },
                    {
                        "C": "0.1"
                    },
                    {
                        "D": "0.2"
                    }
                ],
                "caption": "Figure 5: Convergence analysis of global iterations of BiPageRank-HITS. 10 randomly chosen samples are plotted.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Convergence analysis of global iterations of BiPageRank-HITS. 10 randomly chosen samples are plotted.",
            "categories": "['cs.CL cs.AI cs.IR']",
            "figure_id": "1604.04358v1-Figure5-1",
            "image_path": "1604.04358v1-Figure5-1.png",
            "instance_id": "a8a0a44e63ad2dc589f4e0302b3b7441",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which is the maximum y-value achieved?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Convergence analysis of global iterations of BiPageRank-HITS. 10 randomly chosen samples are plotted.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Convergence analysis of global iterations of BiPageRank-HITS. 10 randomly chosen samples are plotted.",
            "categories": "['cs.CL cs.AI cs.IR']",
            "figure_id": "1604.04358v1-Figure5-1",
            "image_path": "1604.04358v1-Figure5-1.png",
            "instance_id": "8d116a3505108b8870de6facb40f8d17",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific dataset used to generate this convergence analysis?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: OpenTag active learning results on held-out test set. OpenTag with tag flip (TF) outperforms least confidence (LC) [6] strategy, aswell asOpenTagwithout active learning. X-axis shows the number of epochs; Y-axis shows corresponding precision and recall values.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: OpenTag active learning results on held-out test set. OpenTag with tag flip (TF) outperforms least confidence (LC) [6] strategy, aswell asOpenTagwithout active learning. X-axis shows the number of epochs; Y-axis shows corresponding precision and recall values.",
            "categories": "['cs.CL cs.AI cs.IR stat.ML']",
            "figure_id": "1806.01264v2-Figure5-1",
            "image_path": "1806.01264v2-Figure5-1.png",
            "instance_id": "309c714e818dce04ea95b1ee32dd1f6b",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the maximum value of the red diamond line in the right graph?",
            "reference_answer": "74.3%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: OpenTag active learning results on held-out test set. OpenTag with tag flip (TF) outperforms least confidence (LC) [6] strategy, aswell asOpenTagwithout active learning. X-axis shows the number of epochs; Y-axis shows corresponding precision and recall values.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: OpenTag active learning results on held-out test set. OpenTag with tag flip (TF) outperforms least confidence (LC) [6] strategy, aswell asOpenTagwithout active learning. X-axis shows the number of epochs; Y-axis shows corresponding precision and recall values.",
            "categories": "['cs.CL cs.AI cs.IR stat.ML']",
            "figure_id": "1806.01264v2-Figure5-1",
            "image_path": "1806.01264v2-Figure5-1.png",
            "instance_id": "c0a2f1c3527f4dd640944f22b77dc2e4",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the highest recorded precision for OpenTag with tag flip?",
            "reference_answer": "91.5%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: OpenTag active learning results on held-out test set. OpenTag with tag flip (TF) outperforms least confidence (LC) [6] strategy, aswell asOpenTagwithout active learning. X-axis shows the number of epochs; Y-axis shows corresponding precision and recall values.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: OpenTag active learning results on held-out test set. OpenTag with tag flip (TF) outperforms least confidence (LC) [6] strategy, aswell asOpenTagwithout active learning. X-axis shows the number of epochs; Y-axis shows corresponding precision and recall values.",
            "categories": "['cs.CL cs.AI cs.IR stat.ML']",
            "figure_id": "1806.01264v2-Figure5-1",
            "image_path": "1806.01264v2-Figure5-1.png",
            "instance_id": "1581f1837e7db03f3f90316b6fdd0381",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the blue line representing LC Recall reach a value higher than 0.9 at any point on the graph?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the blue line representing LC Recall does reach a value higher than 0.9 at a point on the graph.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: OpenTag active learning results on held-out test set. OpenTag with tag flip (TF) outperforms least confidence (LC) [6] strategy, aswell asOpenTagwithout active learning. X-axis shows the number of epochs; Y-axis shows corresponding precision and recall values.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: OpenTag active learning results on held-out test set. OpenTag with tag flip (TF) outperforms least confidence (LC) [6] strategy, aswell asOpenTagwithout active learning. X-axis shows the number of epochs; Y-axis shows corresponding precision and recall values.",
            "categories": "['cs.CL cs.AI cs.IR stat.ML']",
            "figure_id": "1806.01264v2-Figure5-1",
            "image_path": "1806.01264v2-Figure5-1.png",
            "instance_id": "e8457ae7d43a386ea3f1316142bded24",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does OpenTag with tag flip (TF) consistently outperform the least confidence (LC) strategy?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Based on the provided graph, it appears that OpenTag with tag flip (TF) generally has higher precision compared to the least confidence (LC) strategy across both datasets (detergent data and multi extraction). However, for recall, while TF performs well, it doesn't consistently outperform LC in every instance.\n\nTherefore, the answer is: **It is not possible to answer this question based only on the provided data.**",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "red with triangles"
                    },
                    {
                        "B": "red with diamonds"
                    },
                    {
                        "C": "blue with crosses"
                    },
                    {
                        "D": "All of them"
                    }
                ],
                "caption": "Figure 5: OpenTag active learning results on held-out test set. OpenTag with tag flip (TF) outperforms least confidence (LC) [6] strategy, aswell asOpenTagwithout active learning. X-axis shows the number of epochs; Y-axis shows corresponding precision and recall values.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: OpenTag active learning results on held-out test set. OpenTag with tag flip (TF) outperforms least confidence (LC) [6] strategy, aswell asOpenTagwithout active learning. X-axis shows the number of epochs; Y-axis shows corresponding precision and recall values.",
            "categories": "['cs.CL cs.AI cs.IR stat.ML']",
            "figure_id": "1806.01264v2-Figure5-1",
            "image_path": "1806.01264v2-Figure5-1.png",
            "instance_id": "ccb01397a034444b6eb51154434b6571",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line has a maximum value of less than 0.90 in the leftmost graph?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "TF Precision"
                    },
                    {
                        "B": "TF Recall"
                    },
                    {
                        "C": "None"
                    },
                    {
                        "D": "OpenTag"
                    }
                ],
                "caption": "Figure 5: OpenTag active learning results on held-out test set. OpenTag with tag flip (TF) outperforms least confidence (LC) [6] strategy, aswell asOpenTagwithout active learning. X-axis shows the number of epochs; Y-axis shows corresponding precision and recall values.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: OpenTag active learning results on held-out test set. OpenTag with tag flip (TF) outperforms least confidence (LC) [6] strategy, aswell asOpenTagwithout active learning. X-axis shows the number of epochs; Y-axis shows corresponding precision and recall values.",
            "categories": "['cs.CL cs.AI cs.IR stat.ML']",
            "figure_id": "1806.01264v2-Figure5-1",
            "image_path": "1806.01264v2-Figure5-1.png",
            "instance_id": "3672aaa3b82accb1bb42d4b95570b82e",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which strategies outperform LC Precission for around 3% points, on the multi extraction figure?",
            "reference_answer": "A,B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: OpenTag active learning results on held-out test set. OpenTag with tag flip (TF) outperforms least confidence (LC) [6] strategy, aswell asOpenTagwithout active learning. X-axis shows the number of epochs; Y-axis shows corresponding precision and recall values.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: OpenTag active learning results on held-out test set. OpenTag with tag flip (TF) outperforms least confidence (LC) [6] strategy, aswell asOpenTagwithout active learning. X-axis shows the number of epochs; Y-axis shows corresponding precision and recall values.",
            "categories": "['cs.CL cs.AI cs.IR stat.ML']",
            "figure_id": "1806.01264v2-Figure5-1",
            "image_path": "1806.01264v2-Figure5-1.png",
            "instance_id": "42c3803341eb28c20b5f70bc98cc793b",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific algorithm used in the OpenTag active learning framework for tag flipping (TF)?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Online Cifar test results. Left: average task accuracy over each test stream. Center: perseveration error rate and lower is better. Right: catastrophic interference measured at two subsequent tasks.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Online Cifar test results. Left: average task accuracy over each test stream. Center: perseveration error rate and lower is better. Right: catastrophic interference measured at two subsequent tasks.",
            "categories": "['cs.NE cs.AI cs.CL cs.LG stat.ML']",
            "figure_id": "2009.01803v1-Figure4-1",
            "image_path": "2009.01803v1-Figure4-1.png",
            "instance_id": "08909f8824f3b1922439f89038a4eea9",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate average task accuracy of the green line at the task length of '40-55'?",
            "reference_answer": "76%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Online Cifar test results. Left: average task accuracy over each test stream. Center: perseveration error rate and lower is better. Right: catastrophic interference measured at two subsequent tasks.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Online Cifar test results. Left: average task accuracy over each test stream. Center: perseveration error rate and lower is better. Right: catastrophic interference measured at two subsequent tasks.",
            "categories": "['cs.NE cs.AI cs.CL cs.LG stat.ML']",
            "figure_id": "2009.01803v1-Figure4-1",
            "image_path": "2009.01803v1-Figure4-1.png",
            "instance_id": "c5625876a5ad8d651e4d1be9c5506d54",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "Which metric is represented on the third image of Figure 4?",
            "reference_answer": "Interference rate"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The metric represented in the third image of Figure 4 is \"Interference Rate.\"",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Online Cifar test results. Left: average task accuracy over each test stream. Center: perseveration error rate and lower is better. Right: catastrophic interference measured at two subsequent tasks.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Online Cifar test results. Left: average task accuracy over each test stream. Center: perseveration error rate and lower is better. Right: catastrophic interference measured at two subsequent tasks.",
            "categories": "['cs.NE cs.AI cs.CL cs.LG stat.ML']",
            "figure_id": "2009.01803v1-Figure4-1",
            "image_path": "2009.01803v1-Figure4-1.png",
            "instance_id": "dcbd0ad5bbcafc1651584c549b304d83",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the blue line in the center graph represent perseveration error rate of the Online Fine-tuning of CIFAR?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Online Cifar test results. Left: average task accuracy over each test stream. Center: perseveration error rate and lower is better. Right: catastrophic interference measured at two subsequent tasks.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Online Cifar test results. Left: average task accuracy over each test stream. Center: perseveration error rate and lower is better. Right: catastrophic interference measured at two subsequent tasks.",
            "categories": "['cs.NE cs.AI cs.CL cs.LG stat.ML']",
            "figure_id": "2009.01803v1-Figure4-1",
            "image_path": "2009.01803v1-Figure4-1.png",
            "instance_id": "345657d3de73b789f524903182437aaf",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the average task accuracy for 'Fine-tuning with Pretraining' consistently higher than that of 'Sparse-Meta-Net'?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "orange line"
                    },
                    {
                        "B": "red line"
                    },
                    {
                        "C": "blue line"
                    },
                    {
                        "D": "green line"
                    }
                ],
                "caption": "Figure 4: Online Cifar test results. Left: average task accuracy over each test stream. Center: perseveration error rate and lower is better. Right: catastrophic interference measured at two subsequent tasks.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Online Cifar test results. Left: average task accuracy over each test stream. Center: perseveration error rate and lower is better. Right: catastrophic interference measured at two subsequent tasks.",
            "categories": "['cs.NE cs.AI cs.CL cs.LG stat.ML']",
            "figure_id": "2009.01803v1-Figure4-1",
            "image_path": "2009.01803v1-Figure4-1.png",
            "instance_id": "441a9baa92d28e6db2771f55426ab1e4",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line represents the method that had the lowest 'average performance' at task length 20-35?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Sparse-Meta-Net"
                    },
                    {
                        "B": "Entire Fine-tuning"
                    },
                    {
                        "C": "Online fine tuning with Pretraining"
                    },
                    {
                        "D": "None"
                    }
                ],
                "caption": "Figure 4: Online Cifar test results. Left: average task accuracy over each test stream. Center: perseveration error rate and lower is better. Right: catastrophic interference measured at two subsequent tasks.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Online Cifar test results. Left: average task accuracy over each test stream. Center: perseveration error rate and lower is better. Right: catastrophic interference measured at two subsequent tasks.",
            "categories": "['cs.NE cs.AI cs.CL cs.LG stat.ML']",
            "figure_id": "2009.01803v1-Figure4-1",
            "image_path": "2009.01803v1-Figure4-1.png",
            "instance_id": "d12f11c89b2b9e7ceb9f9e2d67723b25",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following methods show a decreasing trend for the average task accuracy over the test stream?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A B C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Online Cifar test results. Left: average task accuracy over each test stream. Center: perseveration error rate and lower is better. Right: catastrophic interference measured at two subsequent tasks.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Online Cifar test results. Left: average task accuracy over each test stream. Center: perseveration error rate and lower is better. Right: catastrophic interference measured at two subsequent tasks.",
            "categories": "['cs.NE cs.AI cs.CL cs.LG stat.ML']",
            "figure_id": "2009.01803v1-Figure4-1",
            "image_path": "2009.01803v1-Figure4-1.png",
            "instance_id": "30c7e19f5aa91e9bc76023a836c3309c",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific hardware configuration used for these experiments, including CPU, GPU, and memory?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Validation performance in early training on synthetic speech",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Validation performance in early training on synthetic speech",
            "categories": "nan",
            "figure_id": "2020.acl-main.1.pdf-Figure2",
            "image_path": "2020.acl-main.1.pdf-Figure2.png",
            "instance_id": "92878d7543cc2c2b347296e2bbe1c62d",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of the green solid line at x=2?",
            "reference_answer": "0.80"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Validation performance in early training on synthetic speech",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Validation performance in early training on synthetic speech",
            "categories": "nan",
            "figure_id": "2020.acl-main.1.pdf-Figure2",
            "image_path": "2020.acl-main.1.pdf-Figure2.png",
            "instance_id": "000446189a165c623aaa83c32b2fe18d",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What type of performance does Figure 2 show?",
            "reference_answer": "Validation performance"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Validation performance in early training on synthetic speech",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Validation performance in early training on synthetic speech",
            "categories": "nan",
            "figure_id": "2020.acl-main.1.pdf-Figure2",
            "image_path": "2020.acl-main.1.pdf-Figure2.png",
            "instance_id": "36e4d4c9304d1ee407e231a79db83fb3",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the green line representing Recall@10 reach a value of 1.0?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the green line representing Recall@10 reaches a value of 1.0 in the graph.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Validation performance in early training on synthetic speech",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Validation performance in early training on synthetic speech",
            "categories": "nan",
            "figure_id": "2020.acl-main.1.pdf-Figure2",
            "image_path": "2020.acl-main.1.pdf-Figure2.png",
            "instance_id": "a97c3a7d534afd6e95fcf2e3231d53f1",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the performance of ADS consistently better than CDS during early training?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Black Solid Line"
                    },
                    {
                        "B": "Red Solid Line"
                    },
                    {
                        "C": "Green Solid Line"
                    },
                    {
                        "D": "None of the Above"
                    }
                ],
                "caption": "Figure 2: Validation performance in early training on synthetic speech",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Validation performance in early training on synthetic speech",
            "categories": "nan",
            "figure_id": "2020.acl-main.1.pdf-Figure2",
            "image_path": "2020.acl-main.1.pdf-Figure2.png",
            "instance_id": "f83b579e4ed130673f6b397ffb72e4ae",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line, if any, represents the performance metric of Recall@5 on the provided figure?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Recall@1 ADS"
                    },
                    {
                        "B": "Recall@1 CDS"
                    },
                    {
                        "C": "Recall@5 ADS"
                    },
                    {
                        "D": "Recall@10 ADS"
                    }
                ],
                "caption": "Figure 2: Validation performance in early training on synthetic speech",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Validation performance in early training on synthetic speech",
            "categories": "nan",
            "figure_id": "2020.acl-main.1.pdf-Figure2",
            "image_path": "2020.acl-main.1.pdf-Figure2.png",
            "instance_id": "18dc2faecd61e3519025c1e55febecaa",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which metric are represented in the graph?",
            "reference_answer": "A,B,C,D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Validation performance in early training on synthetic speech",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Validation performance in early training on synthetic speech",
            "categories": "nan",
            "figure_id": "2020.acl-main.1.pdf-Figure2",
            "image_path": "2020.acl-main.1.pdf-Figure2.png",
            "instance_id": "435658bd8e87d063154c5174cdd3a001",
            "qa_pair_type": "unanswerable",
            "question": "What was the average difference in Recall@5 score between epochs 2 and 8?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Effective counts for varying values of\u03c4 . For the datasets considered in this paper,\u03c4 usually falls in the range between500 and1000.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Effective counts for varying values of\u03c4 . For the datasets considered in this paper,\u03c4 usually falls in the range between500 and1000.",
            "categories": "['cs.LG cs.CL stat.ML']",
            "figure_id": "1611.06933v1-Figure1-1",
            "image_path": "1611.06933v1-Figure1-1.png",
            "instance_id": "bf138ec7f2a52e03d65532cb015b9db2",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of \u03c4 for the line with blue circles?",
            "reference_answer": "100"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The value of \u03c4 for the line with blue circles is 100.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Effective counts for varying values of\u03c4 . For the datasets considered in this paper,\u03c4 usually falls in the range between500 and1000.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Effective counts for varying values of\u03c4 . For the datasets considered in this paper,\u03c4 usually falls in the range between500 and1000.",
            "categories": "['cs.LG cs.CL stat.ML']",
            "figure_id": "1611.06933v1-Figure1-1",
            "image_path": "1611.06933v1-Figure1-1.png",
            "instance_id": "876cacdd7d01fd9e13f3b00887bbc96b",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the value of gamma in this study?",
            "reference_answer": "0.5"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The value of gamma in this study is 0.5.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Effective counts for varying values of\u03c4 . For the datasets considered in this paper,\u03c4 usually falls in the range between500 and1000.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Effective counts for varying values of\u03c4 . For the datasets considered in this paper,\u03c4 usually falls in the range between500 and1000.",
            "categories": "['cs.LG cs.CL stat.ML']",
            "figure_id": "1611.06933v1-Figure1-1",
            "image_path": "1611.06933v1-Figure1-1.png",
            "instance_id": "9f5e05de39a4aa6c004c3f973ccf7734",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the blue line, representing \u03c4 = 100, have a lower value than the green line, representing \u03c4 = 1000, at the point where the x-axis value is 2?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Effective counts for varying values of\u03c4 . For the datasets considered in this paper,\u03c4 usually falls in the range between500 and1000.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Effective counts for varying values of\u03c4 . For the datasets considered in this paper,\u03c4 usually falls in the range between500 and1000.",
            "categories": "['cs.LG cs.CL stat.ML']",
            "figure_id": "1611.06933v1-Figure1-1",
            "image_path": "1611.06933v1-Figure1-1.png",
            "instance_id": "b8dbcc70fa83863bd1bfd81dbc7ecfe1",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the behaviour consistently constant when T=100 is?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Blue and Green"
                    },
                    {
                        "B": "Green, Red, and Turquoise"
                    },
                    {
                        "C": "Red and Turquoise"
                    },
                    {
                        "D": "Blue, Red, and Turquoise"
                    }
                ],
                "caption": "Figure 1: Effective counts for varying values of\u03c4 . For the datasets considered in this paper,\u03c4 usually falls in the range between500 and1000.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Effective counts for varying values of\u03c4 . For the datasets considered in this paper,\u03c4 usually falls in the range between500 and1000.",
            "categories": "['cs.LG cs.CL stat.ML']",
            "figure_id": "1611.06933v1-Figure1-1",
            "image_path": "1611.06933v1-Figure1-1.png",
            "instance_id": "f9c7de62ebd85c3d97d4a3ac36c03e58",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the lines on the graph have a \u03c4 value of 100 or greater?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "1000"
                    },
                    {
                        "B": "100000"
                    },
                    {
                        "C": "10"
                    },
                    {
                        "D": "100"
                    }
                ],
                "caption": "Figure 1: Effective counts for varying values of\u03c4 . For the datasets considered in this paper,\u03c4 usually falls in the range between500 and1000.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Effective counts for varying values of\u03c4 . For the datasets considered in this paper,\u03c4 usually falls in the range between500 and1000.",
            "categories": "['cs.LG cs.CL stat.ML']",
            "figure_id": "1611.06933v1-Figure1-1",
            "image_path": "1611.06933v1-Figure1-1.png",
            "instance_id": "be790724e6e9de04efb06163d5d6726d",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which T value leads to the best effective count?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Effective counts for varying values of\u03c4 . For the datasets considered in this paper,\u03c4 usually falls in the range between500 and1000.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Effective counts for varying values of\u03c4 . For the datasets considered in this paper,\u03c4 usually falls in the range between500 and1000.",
            "categories": "['cs.LG cs.CL stat.ML']",
            "figure_id": "1611.06933v1-Figure1-1",
            "image_path": "1611.06933v1-Figure1-1.png",
            "instance_id": "b56ff5115d0ed0567cb824aad6c5497a",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific experimental setup used to obtain the data for these effective counts?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8: Test-data perplexities and error rates for PCFG models trained with the GS algorithm with random and HMM initialisations (Billboard data, N\u2126 = 20 + 1). The results for HMMs trained with the GS algorithm are shown as references. See the caption to Fig. 2 for an explanation of symbols.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: Test-data perplexities and error rates for PCFG models trained with the GS algorithm with random and HMM initialisations (Billboard data, N\u2126 = 20 + 1). The results for HMMs trained with the GS algorithm are shown as references. See the caption to Fig. 2 for an explanation of symbols.",
            "categories": "['cs.AI cs.CL cs.SD']",
            "figure_id": "1708.02255v3-Figure8-1",
            "image_path": "1708.02255v3-Figure8-1.png",
            "instance_id": "6f7a30fc4f109e5f3d1376643b5464c6",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the test-data perplexity for the line with triangles when the model size is 10 and N_x = 1531?",
            "reference_answer": "6.5"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8: Test-data perplexities and error rates for PCFG models trained with the GS algorithm with random and HMM initialisations (Billboard data, N\u2126 = 20 + 1). The results for HMMs trained with the GS algorithm are shown as references. See the caption to Fig. 2 for an explanation of symbols.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: Test-data perplexities and error rates for PCFG models trained with the GS algorithm with random and HMM initialisations (Billboard data, N\u2126 = 20 + 1). The results for HMMs trained with the GS algorithm are shown as references. See the caption to Fig. 2 for an explanation of symbols.",
            "categories": "['cs.AI cs.CL cs.SD']",
            "figure_id": "1708.02255v3-Figure8-1",
            "image_path": "1708.02255v3-Figure8-1.png",
            "instance_id": "f04e1bc85d6697ff570cc17fc1bdc34e",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What are the three values of NX used in the experiments?",
            "reference_answer": "30, 300, 1531"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The three values of \\( N_X \\) used in the experiments are 30, 300, and 1531.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8: Test-data perplexities and error rates for PCFG models trained with the GS algorithm with random and HMM initialisations (Billboard data, N\u2126 = 20 + 1). The results for HMMs trained with the GS algorithm are shown as references. See the caption to Fig. 2 for an explanation of symbols.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: Test-data perplexities and error rates for PCFG models trained with the GS algorithm with random and HMM initialisations (Billboard data, N\u2126 = 20 + 1). The results for HMMs trained with the GS algorithm are shown as references. See the caption to Fig. 2 for an explanation of symbols.",
            "categories": "['cs.AI cs.CL cs.SD']",
            "figure_id": "1708.02255v3-Figure8-1",
            "image_path": "1708.02255v3-Figure8-1.png",
            "instance_id": "d1b2656437e33bd5d7334c7b1ba4e0d4",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the error rate of the blue line with squares) higher than the error rate of the HMM model (black line with dots) for the model size N_r/N_\u2206 equal to 10 in both subplots?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8: Test-data perplexities and error rates for PCFG models trained with the GS algorithm with random and HMM initialisations (Billboard data, N\u2126 = 20 + 1). The results for HMMs trained with the GS algorithm are shown as references. See the caption to Fig. 2 for an explanation of symbols.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: Test-data perplexities and error rates for PCFG models trained with the GS algorithm with random and HMM initialisations (Billboard data, N\u2126 = 20 + 1). The results for HMMs trained with the GS algorithm are shown as references. See the caption to Fig. 2 for an explanation of symbols.",
            "categories": "['cs.AI cs.CL cs.SD']",
            "figure_id": "1708.02255v3-Figure8-1",
            "image_path": "1708.02255v3-Figure8-1.png",
            "instance_id": "5f32a6a9796e9239df752241b6262d48",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the test-data perplexity for PCFG models trained with HMM initializations consistently lower than the test-data perplexity for PCFG models trained with GS algorithms?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Black solid line"
                    },
                    {
                        "B": "Blue solid line"
                    },
                    {
                        "C": "Gray solid line"
                    },
                    {
                        "D": "Dashed line with triangles"
                    }
                ],
                "caption": "Figure 8: Test-data perplexities and error rates for PCFG models trained with the GS algorithm with random and HMM initialisations (Billboard data, N\u2126 = 20 + 1). The results for HMMs trained with the GS algorithm are shown as references. See the caption to Fig. 2 for an explanation of symbols.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: Test-data perplexities and error rates for PCFG models trained with the GS algorithm with random and HMM initialisations (Billboard data, N\u2126 = 20 + 1). The results for HMMs trained with the GS algorithm are shown as references. See the caption to Fig. 2 for an explanation of symbols.",
            "categories": "['cs.AI cs.CL cs.SD']",
            "figure_id": "1708.02255v3-Figure8-1",
            "image_path": "1708.02255v3-Figure8-1.png",
            "instance_id": "66d8a5b7ea4b44a5d55eb51769b67daf",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the lines represent PCFG models trained with the GS algorithm with random initialization?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Nx = 30"
                    },
                    {
                        "B": "Nx = 300"
                    },
                    {
                        "C": "Nx = 1531"
                    },
                    {
                        "D": "Nx = 20 + 1"
                    }
                ],
                "caption": "Figure 8: Test-data perplexities and error rates for PCFG models trained with the GS algorithm with random and HMM initialisations (Billboard data, N\u2126 = 20 + 1). The results for HMMs trained with the GS algorithm are shown as references. See the caption to Fig. 2 for an explanation of symbols.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: Test-data perplexities and error rates for PCFG models trained with the GS algorithm with random and HMM initialisations (Billboard data, N\u2126 = 20 + 1). The results for HMMs trained with the GS algorithm are shown as references. See the caption to Fig. 2 for an explanation of symbols.",
            "categories": "['cs.AI cs.CL cs.SD']",
            "figure_id": "1708.02255v3-Figure8-1",
            "image_path": "1708.02255v3-Figure8-1.png",
            "instance_id": "ec38e5bae5c8f0c66ac1f06b6b1bf328",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following model sizes are associated with the test-data perplexity shown in the figure?",
            "reference_answer": "ABC"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ABCD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8: Test-data perplexities and error rates for PCFG models trained with the GS algorithm with random and HMM initialisations (Billboard data, N\u2126 = 20 + 1). The results for HMMs trained with the GS algorithm are shown as references. See the caption to Fig. 2 for an explanation of symbols.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: Test-data perplexities and error rates for PCFG models trained with the GS algorithm with random and HMM initialisations (Billboard data, N\u2126 = 20 + 1). The results for HMMs trained with the GS algorithm are shown as references. See the caption to Fig. 2 for an explanation of symbols.",
            "categories": "['cs.AI cs.CL cs.SD']",
            "figure_id": "1708.02255v3-Figure8-1",
            "image_path": "1708.02255v3-Figure8-1.png",
            "instance_id": "d465178a6fbd24a6c8acad08eb76064b",
            "qa_pair_type": "unanswerable",
            "question": "What is the exact value of the test-data perplexity for the PCFG model trained with the GS algorithm with random initialization when the model size is 5 and N_x = 300?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Syllabification and Alignment",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Syllabification and Alignment",
            "categories": "nan",
            "figure_id": "Y11-1002.pdf-Figure1",
            "image_path": "Y11-1002.pdf-Figure1.png",
            "instance_id": "76d9db6e224b73b3e87f2e997e2d5acc",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "Which latin letters are there just below the first sigma?",
            "reference_answer": "O, N"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The Latin letters just below the first sigma are O and N.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Syllabification and Alignment",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Syllabification and Alignment",
            "categories": "nan",
            "figure_id": "Y11-1002.pdf-Figure1",
            "image_path": "Y11-1002.pdf-Figure1.png",
            "instance_id": "8cb99ea266c93ef09a656ce1be369f38",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the name depicted in the figure?",
            "reference_answer": "JACOBSTEIN"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The name depicted in the figure is \"Jacob Stein.\"",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Syllabification and Alignment",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Syllabification and Alignment",
            "categories": "nan",
            "figure_id": "Y11-1002.pdf-Figure1",
            "image_path": "Y11-1002.pdf-Figure1.png",
            "instance_id": "2f58f24942ab1648dfd43598115d4c59",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Are there more vertical lines than upside-down triangles in the 'Syllabification' section?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Syllabification and Alignment",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Syllabification and Alignment",
            "categories": "nan",
            "figure_id": "Y11-1002.pdf-Figure1",
            "image_path": "Y11-1002.pdf-Figure1.png",
            "instance_id": "a50dbbff60b4ac9448d664615c6eaa11",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the word \"STEIN\" represented by a single syllable?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the word \"STEIN\" is represented by a single syllable in the provided diagram.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "2"
                    },
                    {
                        "B": "4"
                    },
                    {
                        "C": "5"
                    },
                    {
                        "D": "3"
                    }
                ],
                "caption": "Figure 1: Syllabification and Alignment",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Syllabification and Alignment",
            "categories": "nan",
            "figure_id": "Y11-1002.pdf-Figure1",
            "image_path": "Y11-1002.pdf-Figure1.png",
            "instance_id": "15393f7fcd9f9dc72f14f4799e84d6f3",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "How many lines are there in the alignment section?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "JA"
                    },
                    {
                        "B": "CO"
                    },
                    {
                        "C": "ST"
                    },
                    {
                        "D": "EI"
                    }
                ],
                "caption": "Figure 1: Syllabification and Alignment",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Syllabification and Alignment",
            "categories": "nan",
            "figure_id": "Y11-1002.pdf-Figure1",
            "image_path": "Y11-1002.pdf-Figure1.png",
            "instance_id": "aa019662e8238b622e2846d9fd28a255",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following syllables have a sub-syllabification marked by a 'V'?",
            "reference_answer": "A,B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ABCD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Syllabification and Alignment",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Syllabification and Alignment",
            "categories": "nan",
            "figure_id": "Y11-1002.pdf-Figure1",
            "image_path": "Y11-1002.pdf-Figure1.png",
            "instance_id": "439276f60f94814187b4426679d2da18",
            "qa_pair_type": "unanswerable",
            "question": "What is the name of the language represented by the alignment shown in Figure 1?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Example of a regular NP construction -",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Example of a regular NP construction -",
            "categories": "nan",
            "figure_id": "2020.lrec-1.652.pdf-Figure6",
            "image_path": "2020.lrec-1.652.pdf-Figure6.png",
            "instance_id": "6dd167f2bdb2cd578a62d0903b239e17",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the label of the node directly below the green node labelled 'NP'?",
            "reference_answer": "NC"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The label of the node directly below the green node labelled 'NP' is 'DET'.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Example of a regular NP construction -",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Example of a regular NP construction -",
            "categories": "nan",
            "figure_id": "2020.lrec-1.652.pdf-Figure6",
            "image_path": "2020.lrec-1.652.pdf-Figure6.png",
            "instance_id": "7fd679e808b368deaa56aa33bc6a470e",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What are the words in the terminal nodes?",
            "reference_answer": "un, numero, de, code"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The words in the terminal nodes are:\n\n- un\n- n\u00famero\n- de\n- code",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Example of a regular NP construction -",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Example of a regular NP construction -",
            "categories": "nan",
            "figure_id": "2020.lrec-1.652.pdf-Figure6",
            "image_path": "2020.lrec-1.652.pdf-Figure6.png",
            "instance_id": "71310d7a3bcae70ad77b9a71eec6b662",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the blue node labeled 'de' directly connected to the green node labeled 'PP'?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the blue node labeled 'de' is directly connected to the green node labeled 'PP'.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Example of a regular NP construction -",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Example of a regular NP construction -",
            "categories": "nan",
            "figure_id": "2020.lrec-1.652.pdf-Figure6",
            "image_path": "2020.lrec-1.652.pdf-Figure6.png",
            "instance_id": "c6782f6f9d563aae7993ca3c1f959ba6",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the figure depict a construction of NP?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The figure depicts a construction of a noun phrase (NP).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "DET"
                    },
                    {
                        "B": "NC"
                    },
                    {
                        "C": "P"
                    },
                    {
                        "D": "PP"
                    }
                ],
                "caption": "Figure 6: Example of a regular NP construction -",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Example of a regular NP construction -",
            "categories": "nan",
            "figure_id": "2020.lrec-1.652.pdf-Figure6",
            "image_path": "2020.lrec-1.652.pdf-Figure6.png",
            "instance_id": "53c9ed7fbd942284b15f4a4d46b9f05f",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following nodes is NOT connected to a node labeled 'NP'?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "DET"
                    },
                    {
                        "B": "P"
                    },
                    {
                        "C": "NC"
                    },
                    {
                        "D": "NNP"
                    }
                ],
                "caption": "Figure 6: Example of a regular NP construction -",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Example of a regular NP construction -",
            "categories": "nan",
            "figure_id": "2020.lrec-1.652.pdf-Figure6",
            "image_path": "2020.lrec-1.652.pdf-Figure6.png",
            "instance_id": "92b9fdb78357cb0650d2a508cd7741ae",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following is NOT a node in the construction?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Example of a regular NP construction -",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Example of a regular NP construction -",
            "categories": "nan",
            "figure_id": "2020.lrec-1.652.pdf-Figure6",
            "image_path": "2020.lrec-1.652.pdf-Figure6.png",
            "instance_id": "b2ff4794c765e5522396415a842710cb",
            "qa_pair_type": "unanswerable",
            "question": "What is the full sentence represented by the NP construction in Figure 6?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 11: Split scope components for scope rigidity in (5)",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 11: Split scope components for scope rigidity in (5)",
            "categories": "nan",
            "figure_id": "W12-4627.pdf-Figure11",
            "image_path": "W12-4627.pdf-Figure11.png",
            "instance_id": "3b119c7dfa8ed62214875a8688c22e02",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "How many numbered rectangular boxes are present in the leftmost tree structure in Figure 11?",
            "reference_answer": "2"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "There are 2 numbered rectangular boxes present in the leftmost tree structure in Figure 11.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 11: Split scope components for scope rigidity in (5)",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 11: Split scope components for scope rigidity in (5)",
            "categories": "nan",
            "figure_id": "W12-4627.pdf-Figure11",
            "image_path": "W12-4627.pdf-Figure11.png",
            "instance_id": "be02a930149d467816c0d5799ac14f59",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What are the two components of TP?",
            "reference_answer": "DP and T'"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The two components of TP are T' and VP.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 11: Split scope components for scope rigidity in (5)",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 11: Split scope components for scope rigidity in (5)",
            "categories": "nan",
            "figure_id": "W12-4627.pdf-Figure11",
            "image_path": "W12-4627.pdf-Figure11.png",
            "instance_id": "08c858447d23af1e04536aba1e356e32",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Are there more square boxes labeled with the number 1 than square boxes labeled with the number 2 in the figure?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, there are more square boxes labeled with the number 1 than those labeled with the number 2 in the figure.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 11: Split scope components for scope rigidity in (5)",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 11: Split scope components for scope rigidity in (5)",
            "categories": "nan",
            "figure_id": "W12-4627.pdf-Figure11",
            "image_path": "W12-4627.pdf-Figure11.png",
            "instance_id": "96c16733d6fd679df1d93cf172d52ffd",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is lambda calculus used in th figure?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. Lambda calculus is used in the figure, as evidenced by the presence of lambda symbols (\u03bb) in the notation.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "0"
                    },
                    {
                        "B": "1"
                    },
                    {
                        "C": "2"
                    },
                    {
                        "D": "3"
                    }
                ],
                "caption": "Figure 11: Split scope components for scope rigidity in (5)",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 11: Split scope components for scope rigidity in (5)",
            "categories": "nan",
            "figure_id": "W12-4627.pdf-Figure11",
            "image_path": "W12-4627.pdf-Figure11.png",
            "instance_id": "c3c37d3bf829d85962b4c3a1097d413a",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "How many boxes with the numer 1 inside are there in the figure?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "aisiteiru no"
                    },
                    {
                        "B": "love"
                    },
                    {
                        "C": "house"
                    },
                    {
                        "D": "lemon"
                    }
                ],
                "caption": "Figure 11: Split scope components for scope rigidity in (5)",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 11: Split scope components for scope rigidity in (5)",
            "categories": "nan",
            "figure_id": "W12-4627.pdf-Figure11",
            "image_path": "W12-4627.pdf-Figure11.png",
            "instance_id": "b840df47132275c3dce5d517d8f58ad2",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which words are components of V?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 11: Split scope components for scope rigidity in (5)",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 11: Split scope components for scope rigidity in (5)",
            "categories": "nan",
            "figure_id": "W12-4627.pdf-Figure11",
            "image_path": "W12-4627.pdf-Figure11.png",
            "instance_id": "d829f99f37b3cc09889d38d84826d3ea",
            "qa_pair_type": "unanswerable",
            "question": "What is the meaning of 'aisiteiru no' in the sentence represented by the syntactic tree in Figure 11?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Hyperparameter search results with one point for each configuration. The line separates where our approach is better (left) or worse (right).",
                "compound": false,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Hyperparameter search results with one point for each configuration. The line separates where our approach is better (left) or worse (right).",
            "categories": "['cs.CL']",
            "figure_id": "2009.14109v2-Figure1-1",
            "image_path": "2009.14109v2-Figure1-1.png",
            "instance_id": "01a2b6c26b876cbec3a94cd03abbb77c",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate PPL for the red line when the PPL for baseline is 70?",
            "reference_answer": "70"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Hyperparameter search results with one point for each configuration. The line separates where our approach is better (left) or worse (right).",
                "compound": false,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Hyperparameter search results with one point for each configuration. The line separates where our approach is better (left) or worse (right).",
            "categories": "['cs.CL']",
            "figure_id": "2009.14109v2-Figure1-1",
            "image_path": "2009.14109v2-Figure1-1.png",
            "instance_id": "0e2f04bbccf712bc9aa6335d8044e75c",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is being depicted by line red?",
            "reference_answer": "x=y"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The red line represents the line of equality, where the value of PPL for the baseline is equal to the value of PPL for the proposed approach (i.e., \\( x = y \\)). If a point lies above this line, it indicates that the baseline performs better, while points below indicate that the proposed approach performs better.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Hyperparameter search results with one point for each configuration. The line separates where our approach is better (left) or worse (right).",
                "compound": false,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Hyperparameter search results with one point for each configuration. The line separates where our approach is better (left) or worse (right).",
            "categories": "['cs.CL']",
            "figure_id": "2009.14109v2-Figure1-1",
            "image_path": "2009.14109v2-Figure1-1.png",
            "instance_id": "d69ceb86417d4d107915e9f9d93fd5d1",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Are most of the blue points located above the red line?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Hyperparameter search results with one point for each configuration. The line separates where our approach is better (left) or worse (right).",
                "compound": false,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Hyperparameter search results with one point for each configuration. The line separates where our approach is better (left) or worse (right).",
            "categories": "['cs.CL']",
            "figure_id": "2009.14109v2-Figure1-1",
            "image_path": "2009.14109v2-Figure1-1.png",
            "instance_id": "cf866a6c3677ee8e23683355421a18b2",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is our approach always better than the baseline?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "When the value of 'PPL for our approach' is above the red line"
                    },
                    {
                        "B": "When the value of 'PPL for our approach' is below the red line"
                    },
                    {
                        "C": "When the value of 'PPL for our approach' is left of the red line"
                    },
                    {
                        "D": "When the value of 'PPL for our approach' is right of the red line"
                    }
                ],
                "caption": "Figure 1: Hyperparameter search results with one point for each configuration. The line separates where our approach is better (left) or worse (right).",
                "compound": false,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Hyperparameter search results with one point for each configuration. The line separates where our approach is better (left) or worse (right).",
            "categories": "['cs.CL']",
            "figure_id": "2009.14109v2-Figure1-1",
            "image_path": "2009.14109v2-Figure1-1.png",
            "instance_id": "c0feaf7a04f1e797e22d61d8098eef2c",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Based on the red line, where is our approach worse than the baseline?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "PPL for the baseline vs PPL for the proposed approach"
                    },
                    {
                        "B": "x vs y"
                    },
                    {
                        "C": "A better approach vs a bad approach"
                    },
                    {
                        "D": "Parameters and hyperparameters"
                    }
                ],
                "caption": "Figure 1: Hyperparameter search results with one point for each configuration. The line separates where our approach is better (left) or worse (right).",
                "compound": false,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Hyperparameter search results with one point for each configuration. The line separates where our approach is better (left) or worse (right).",
            "categories": "['cs.CL']",
            "figure_id": "2009.14109v2-Figure1-1",
            "image_path": "2009.14109v2-Figure1-1.png",
            "instance_id": "cd3fdd13abc0f6c4d9f05551c200cb4e",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is exactly being compared in the graph?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Hyperparameter search results with one point for each configuration. The line separates where our approach is better (left) or worse (right).",
                "compound": false,
                "figure_type": "scatter plot",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Hyperparameter search results with one point for each configuration. The line separates where our approach is better (left) or worse (right).",
            "categories": "['cs.CL']",
            "figure_id": "2009.14109v2-Figure1-1",
            "image_path": "2009.14109v2-Figure1-1.png",
            "instance_id": "268c847c95e87335c92c258082604bbd",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific range of hyperparameters used for the baseline and our approach?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Distribution of testing set based on PCIO.",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Distribution of testing set based on PCIO.",
            "categories": "nan",
            "figure_id": "2020.acl-main.100.pdf-Figure3",
            "image_path": "2020.acl-main.100.pdf-Figure3.png",
            "instance_id": "d6803b4983616c40608a7fa8e8057aef",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the percentage of the testing set represented by the light green section with a grid pattern?",
            "reference_answer": "61.6%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The percentage of the testing set represented by the light green section with a grid pattern is 3.0%.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Distribution of testing set based on PCIO.",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Distribution of testing set based on PCIO.",
            "categories": "nan",
            "figure_id": "2020.acl-main.100.pdf-Figure3",
            "image_path": "2020.acl-main.100.pdf-Figure3.png",
            "instance_id": "b0c18ed8c8ae3650deecda55f5d49f09",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the largest portion of the testing set based on PCIO?",
            "reference_answer": "Symptoms"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "61.6%",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Distribution of testing set based on PCIO.",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Distribution of testing set based on PCIO.",
            "categories": "nan",
            "figure_id": "2020.acl-main.100.pdf-Figure3",
            "image_path": "2020.acl-main.100.pdf-Figure3.png",
            "instance_id": "07daeff44eead8f8b12baa214e9731c2",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the section representing 'Evaluation' larger than the section representing 'Etiology'?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The section representing 'Evaluation' (11.3%) is larger than the section representing 'Etiology' (3.0%).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Distribution of testing set based on PCIO.",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Distribution of testing set based on PCIO.",
            "categories": "nan",
            "figure_id": "2020.acl-main.100.pdf-Figure3",
            "image_path": "2020.acl-main.100.pdf-Figure3.png",
            "instance_id": "0e3c301b2402303384bf8aa09b9016f9",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the percentage of the testing set related to 'Treatment' greater than 10%?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Symptoms"
                    },
                    {
                        "B": "Diagnosis"
                    },
                    {
                        "C": "Etiology"
                    },
                    {
                        "D": "Treatment and Prognosis"
                    }
                ],
                "caption": "Figure 3: Distribution of testing set based on PCIO.",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Distribution of testing set based on PCIO.",
            "categories": "nan",
            "figure_id": "2020.acl-main.100.pdf-Figure3",
            "image_path": "2020.acl-main.100.pdf-Figure3.png",
            "instance_id": "0cf963094b0fb5f1ad7f78dbaeea414e",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following components make up more than 20% of the pie chart?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A B C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Symptoms"
                    },
                    {
                        "B": "Diagnosis"
                    },
                    {
                        "C": "Treatment"
                    },
                    {
                        "D": "Prognosis"
                    }
                ],
                "caption": "Figure 3: Distribution of testing set based on PCIO.",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Distribution of testing set based on PCIO.",
            "categories": "nan",
            "figure_id": "2020.acl-main.100.pdf-Figure3",
            "image_path": "2020.acl-main.100.pdf-Figure3.png",
            "instance_id": "15edaebd7819c81364821c70a2277729",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which PCIO category constitutes the smalles proportion of the testing set?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Distribution of testing set based on PCIO.",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Distribution of testing set based on PCIO.",
            "categories": "nan",
            "figure_id": "2020.acl-main.100.pdf-Figure3",
            "image_path": "2020.acl-main.100.pdf-Figure3.png",
            "instance_id": "bac16ae3304e6e9b615bdee1fb7be523",
            "qa_pair_type": "unanswerable",
            "question": "What are the exact values for the number of questions in each PCIO category for the testing set?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Data distribution in manually created dataset",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Data distribution in manually created dataset",
            "categories": "nan",
            "figure_id": "2020.lrec-1.398.pdf-Figure1",
            "image_path": "2020.lrec-1.398.pdf-Figure1.png",
            "instance_id": "8a317300917e4fec8636975d77bbb956",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the percentage of the blue slice in the pie chart?",
            "reference_answer": "81.7%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The percentage of the blue slice in the pie chart is 81.7%.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Data distribution in manually created dataset",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Data distribution in manually created dataset",
            "categories": "nan",
            "figure_id": "2020.lrec-1.398.pdf-Figure1",
            "image_path": "2020.lrec-1.398.pdf-Figure1.png",
            "instance_id": "ce08d7311a5a744c02372a890ed08629",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the percentage of the dataset classified as 'weak equivalence'?",
            "reference_answer": "4.7%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The percentage of the dataset classified as 'weak equivalence' is 4.7%.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Data distribution in manually created dataset",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Data distribution in manually created dataset",
            "categories": "nan",
            "figure_id": "2020.lrec-1.398.pdf-Figure1",
            "image_path": "2020.lrec-1.398.pdf-Figure1.png",
            "instance_id": "4a0fcfa125291d59abba5851dfdc2efc",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the blue slice of the pie chart larger than the red slice?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the blue slice of the pie chart (81.7%) is larger than the red slice (13.6%).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Data distribution in manually created dataset",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Data distribution in manually created dataset",
            "categories": "nan",
            "figure_id": "2020.lrec-1.398.pdf-Figure1",
            "image_path": "2020.lrec-1.398.pdf-Figure1.png",
            "instance_id": "b515f4bc3bb6bc19074bf6432b1e2c85",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the percentage of the dataset with strong equivalence greater than the percentage of the dataset with regular and weak equivalence combined?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The percentage of the dataset with strong equivalence (81.7%) is greater than the combined percentage of regular (13.6%) and weak equivalence (4.7%), which totals to 18.3%.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Red"
                    },
                    {
                        "B": "Orange"
                    },
                    {
                        "C": "Blue"
                    },
                    {
                        "D": "Gray"
                    }
                ],
                "caption": "Figure 1: Data distribution in manually created dataset",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Data distribution in manually created dataset",
            "categories": "nan",
            "figure_id": "2020.lrec-1.398.pdf-Figure1",
            "image_path": "2020.lrec-1.398.pdf-Figure1.png",
            "instance_id": "28f3b7097316941e9e37a44fcf6b376f",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following colors is the largest section of the pie chart?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "weak equivalence"
                    },
                    {
                        "B": "strong equivalence"
                    },
                    {
                        "C": "regular equivalence"
                    },
                    {
                        "D": "all of the above"
                    }
                ],
                "caption": "Figure 1: Data distribution in manually created dataset",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Data distribution in manually created dataset",
            "categories": "nan",
            "figure_id": "2020.lrec-1.398.pdf-Figure1",
            "image_path": "2020.lrec-1.398.pdf-Figure1.png",
            "instance_id": "80afc0452cb99d485137c1eeeafc8cfc",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following are present in the manually created dataset?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ABD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Data distribution in manually created dataset",
                "compound": false,
                "figure_type": "pie chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Data distribution in manually created dataset",
            "categories": "nan",
            "figure_id": "2020.lrec-1.398.pdf-Figure1",
            "image_path": "2020.lrec-1.398.pdf-Figure1.png",
            "instance_id": "f57e98296bfc95bc6d6ff34f8a32a43f",
            "qa_pair_type": "unanswerable",
            "question": "What is the exact process used to create the dataset shown in Figure 1?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Confusion matrix training data",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Confusion matrix training data",
            "categories": "nan",
            "figure_id": "S19-2213.pdf-Figure1",
            "image_path": "S19-2213.pdf-Figure1.png",
            "instance_id": "7510d2ea32f28ccc23157816cbdabdad",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value in the top-left cell of the confusion matrix?",
            "reference_answer": "5852"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The value in the top-left cell of the confusion matrix is 5852.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Confusion matrix training data",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Confusion matrix training data",
            "categories": "nan",
            "figure_id": "S19-2213.pdf-Figure1",
            "image_path": "S19-2213.pdf-Figure1.png",
            "instance_id": "bbe78db7ee4b0f681edbf588843cdc1c",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "How many data points were correctly classified as 'Non Sug'?",
            "reference_answer": "5852"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The number of data points correctly classified as 'Non Sug' is 5852.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Confusion matrix training data",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Confusion matrix training data",
            "categories": "nan",
            "figure_id": "S19-2213.pdf-Figure1",
            "image_path": "S19-2213.pdf-Figure1.png",
            "instance_id": "1393c240577fecc028ed0a66598f8976",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the value of the top left square in the confusion matrix greater than 5000?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The value of the top left square in the confusion matrix is 5852, which is greater than 5000.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Confusion matrix training data",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Confusion matrix training data",
            "categories": "nan",
            "figure_id": "S19-2213.pdf-Figure1",
            "image_path": "S19-2213.pdf-Figure1.png",
            "instance_id": "89967517b4f387cd5264bfc9d3a126e4",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the number of correctly predicted 'Non Sug' instances greater than the number of correctly predicted 'Sug' instances?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the number of correctly predicted 'Non Sug' instances (5852) is greater than the number of correctly predicted 'Sug' instances (1858).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The top left square"
                    },
                    {
                        "B": "The top right square"
                    },
                    {
                        "C": "The bottom left square"
                    },
                    {
                        "D": "The bottom right square"
                    }
                ],
                "caption": "Figure 1: Confusion matrix training data",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Confusion matrix training data",
            "categories": "nan",
            "figure_id": "S19-2213.pdf-Figure1",
            "image_path": "S19-2213.pdf-Figure1.png",
            "instance_id": "0ab9069c72eee8542dc1a943477485bd",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the squares in the matrix has a value greater than 5000?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "5852"
                    },
                    {
                        "B": "1000"
                    },
                    {
                        "C": "227"
                    },
                    {
                        "D": "1858"
                    }
                ],
                "caption": "Figure 1: Confusion matrix training data",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Confusion matrix training data",
            "categories": "nan",
            "figure_id": "S19-2213.pdf-Figure1",
            "image_path": "S19-2213.pdf-Figure1.png",
            "instance_id": "3545f2d7ecc83ae91afa68e4fe36644c",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following values are present in the confusion matrix?",
            "reference_answer": "['A', 'C', 'D']"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A C D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Confusion matrix training data",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Confusion matrix training data",
            "categories": "nan",
            "figure_id": "S19-2213.pdf-Figure1",
            "image_path": "S19-2213.pdf-Figure1.png",
            "instance_id": "f2fc57d103bf9fbbda800a6248942bf1",
            "qa_pair_type": "unanswerable",
            "question": "What is the accuracy of the model based on the training data?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "To calculate the accuracy of the model based on the training data, use the formula:\n\n\\[\n\\text{Accuracy} = \\frac{\\text{True Positives} + \\text{True Negatives}}{\\text{Total Samples}}\n\\]\n\nFrom the confusion matrix provided:\n\n- True Positives (TP) for \"Sug\": 1858\n- True Negatives (TN) for \"Non Sug\": 5852\n- False Positives (FP): 563\n- False Negatives (FN): 227\n\nTotal samples = TP + TN + FP + FN = 1858 + 5852 + 563 + 227 = 8280\n\nNow, substituting into the accuracy formula:\n\n\\[\n\\text{Accuracy} = \\frac{1858 + 5852}{8280} = \\frac{7710}{8280} \\approx 0.93\n\\]\n\nSo, the accuracy of the model based on the training data is approximately 0.93, or 93%.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: Significance test results for pairs of systems competing in the news domain translation task (cs-en, de-en, fi-en), where a green cell denotes a significantly higher DA adequacy or fluency score for the system in a given row over the system in a given column, Combined results show overall conclusions when adequacy is primarily used to rank systems with fluency used to break ties between systems tied with respect to adequacy.",
                "compound": true,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Significance test results for pairs of systems competing in the news domain translation task (cs-en, de-en, fi-en), where a green cell denotes a significantly higher DA adequacy or fluency score for the system in a given row over the system in a given column, Combined results show overall conclusions when adequacy is primarily used to rank systems with fluency used to break ties between systems tied with respect to adequacy.",
            "categories": "nan",
            "figure_id": "W16-2301.pdf-Figure7",
            "image_path": "W16-2301.pdf-Figure7.png",
            "instance_id": "ad7f77885e802babf2e2ac00fe4618c4",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "In which corner are the green squares mostly located?",
            "reference_answer": "Top right corner"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The green squares are mostly located in the top left corner of the matrices.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: Significance test results for pairs of systems competing in the news domain translation task (cs-en, de-en, fi-en), where a green cell denotes a significantly higher DA adequacy or fluency score for the system in a given row over the system in a given column, Combined results show overall conclusions when adequacy is primarily used to rank systems with fluency used to break ties between systems tied with respect to adequacy.",
                "compound": true,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Significance test results for pairs of systems competing in the news domain translation task (cs-en, de-en, fi-en), where a green cell denotes a significantly higher DA adequacy or fluency score for the system in a given row over the system in a given column, Combined results show overall conclusions when adequacy is primarily used to rank systems with fluency used to break ties between systems tied with respect to adequacy.",
            "categories": "nan",
            "figure_id": "W16-2301.pdf-Figure7",
            "image_path": "W16-2301.pdf-Figure7.png",
            "instance_id": "43366b45caa7c34f90a9bc963e0eb37c",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What metrics are used ?",
            "reference_answer": "Adecuacy, fluency and combination"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The metrics used in the provided data are:\n\n1. Adequacy\n2. Fluency\n3. Combined",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: Significance test results for pairs of systems competing in the news domain translation task (cs-en, de-en, fi-en), where a green cell denotes a significantly higher DA adequacy or fluency score for the system in a given row over the system in a given column, Combined results show overall conclusions when adequacy is primarily used to rank systems with fluency used to break ties between systems tied with respect to adequacy.",
                "compound": true,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Significance test results for pairs of systems competing in the news domain translation task (cs-en, de-en, fi-en), where a green cell denotes a significantly higher DA adequacy or fluency score for the system in a given row over the system in a given column, Combined results show overall conclusions when adequacy is primarily used to rank systems with fluency used to break ties between systems tied with respect to adequacy.",
            "categories": "nan",
            "figure_id": "W16-2301.pdf-Figure7",
            "image_path": "W16-2301.pdf-Figure7.png",
            "instance_id": "2f129a382d15ad3443274ede1ccc95f7",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Do all subplots have the same number of squares?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: Significance test results for pairs of systems competing in the news domain translation task (cs-en, de-en, fi-en), where a green cell denotes a significantly higher DA adequacy or fluency score for the system in a given row over the system in a given column, Combined results show overall conclusions when adequacy is primarily used to rank systems with fluency used to break ties between systems tied with respect to adequacy.",
                "compound": true,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Significance test results for pairs of systems competing in the news domain translation task (cs-en, de-en, fi-en), where a green cell denotes a significantly higher DA adequacy or fluency score for the system in a given row over the system in a given column, Combined results show overall conclusions when adequacy is primarily used to rank systems with fluency used to break ties between systems tied with respect to adequacy.",
            "categories": "nan",
            "figure_id": "W16-2301.pdf-Figure7",
            "image_path": "W16-2301.pdf-Figure7.png",
            "instance_id": "6365c2b2df10875a7ec0c233d34dc794",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the 'Combined' results section always show the same conclusion as the 'Adequacy' results section?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Top-right corner"
                    },
                    {
                        "B": "The subplot in the middle of the figure"
                    },
                    {
                        "C": "Bottom-left corner"
                    },
                    {
                        "D": "Bottom-right"
                    }
                ],
                "caption": "Figure 7: Significance test results for pairs of systems competing in the news domain translation task (cs-en, de-en, fi-en), where a green cell denotes a significantly higher DA adequacy or fluency score for the system in a given row over the system in a given column, Combined results show overall conclusions when adequacy is primarily used to rank systems with fluency used to break ties between systems tied with respect to adequacy.",
                "compound": true,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Significance test results for pairs of systems competing in the news domain translation task (cs-en, de-en, fi-en), where a green cell denotes a significantly higher DA adequacy or fluency score for the system in a given row over the system in a given column, Combined results show overall conclusions when adequacy is primarily used to rank systems with fluency used to break ties between systems tied with respect to adequacy.",
            "categories": "nan",
            "figure_id": "W16-2301.pdf-Figure7",
            "image_path": "W16-2301.pdf-Figure7.png",
            "instance_id": "5bbc82084bfd2584b2a92e7aee8a0c47",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following subplots has the lowest number of squares?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "BC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "cs-en, de-en, fi-en"
                    },
                    {
                        "B": "cs-en, es-en, fi-en"
                    },
                    {
                        "C": "cs-fr, de-fr, fi-fr"
                    },
                    {
                        "D": "cs-en, de-en, fi-de"
                    }
                ],
                "caption": "Figure 7: Significance test results for pairs of systems competing in the news domain translation task (cs-en, de-en, fi-en), where a green cell denotes a significantly higher DA adequacy or fluency score for the system in a given row over the system in a given column, Combined results show overall conclusions when adequacy is primarily used to rank systems with fluency used to break ties between systems tied with respect to adequacy.",
                "compound": true,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Significance test results for pairs of systems competing in the news domain translation task (cs-en, de-en, fi-en), where a green cell denotes a significantly higher DA adequacy or fluency score for the system in a given row over the system in a given column, Combined results show overall conclusions when adequacy is primarily used to rank systems with fluency used to break ties between systems tied with respect to adequacy.",
            "categories": "nan",
            "figure_id": "W16-2301.pdf-Figure7",
            "image_path": "W16-2301.pdf-Figure7.png",
            "instance_id": "550dec05188166b0a1d2a5a49a5e6b42",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which language pairs were compared for significance of adequacy or fluency?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: Significance test results for pairs of systems competing in the news domain translation task (cs-en, de-en, fi-en), where a green cell denotes a significantly higher DA adequacy or fluency score for the system in a given row over the system in a given column, Combined results show overall conclusions when adequacy is primarily used to rank systems with fluency used to break ties between systems tied with respect to adequacy.",
                "compound": true,
                "figure_type": "confusion matrix",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Significance test results for pairs of systems competing in the news domain translation task (cs-en, de-en, fi-en), where a green cell denotes a significantly higher DA adequacy or fluency score for the system in a given row over the system in a given column, Combined results show overall conclusions when adequacy is primarily used to rank systems with fluency used to break ties between systems tied with respect to adequacy.",
            "categories": "nan",
            "figure_id": "W16-2301.pdf-Figure7",
            "image_path": "W16-2301.pdf-Figure7.png",
            "instance_id": "df9daad0eddf31a4536b0c9d1578def8",
            "qa_pair_type": "unanswerable",
            "question": "What is the numeric range of values for adequacy for the de-en pair?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Sub-task A, HAD-Tubingen LSTM + Hashtag parsing.",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Sub-task A, HAD-Tubingen LSTM + Hashtag parsing.",
            "categories": "nan",
            "figure_id": "S19-2111.pdf-Figure4",
            "image_path": "S19-2111.pdf-Figure4.png",
            "instance_id": "62e83825387bdca6e823834619914e35",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value represented by the darkest shade of blue in the confusion matrix shown in Figure 4?",
            "reference_answer": "65"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Sub-task A, HAD-Tubingen LSTM + Hashtag parsing.",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Sub-task A, HAD-Tubingen LSTM + Hashtag parsing.",
            "categories": "nan",
            "figure_id": "S19-2111.pdf-Figure4",
            "image_path": "S19-2111.pdf-Figure4.png",
            "instance_id": "426956402935c0c80f17e2828537263d",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the value of the cell \"Not\" classified correctly?",
            "reference_answer": "555"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The value of the cell \"Not\" classified correctly is 65.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Sub-task A, HAD-Tubingen LSTM + Hashtag parsing.",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Sub-task A, HAD-Tubingen LSTM + Hashtag parsing.",
            "categories": "nan",
            "figure_id": "S19-2111.pdf-Figure4",
            "image_path": "S19-2111.pdf-Figure4.png",
            "instance_id": "5404a562f0c1e5c9c28e4923fd81670d",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the color of the bottom-right cell (OFF, OFF) in the confusion matrix different than the one of the top-right cell (NOT, OFF)?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the color of the bottom-right cell (OFF, OFF) is different from the one of the top-right cell (NOT, OFF).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Sub-task A, HAD-Tubingen LSTM + Hashtag parsing.",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Sub-task A, HAD-Tubingen LSTM + Hashtag parsing.",
            "categories": "nan",
            "figure_id": "S19-2111.pdf-Figure4",
            "image_path": "S19-2111.pdf-Figure4.png",
            "instance_id": "ca99fda55b6bddc29c661d0091e26fa0",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Are the values of correct classified values higher than the incorrect classified values?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the values of correctly classified instances (555 for NOT and 131 for OFF) are higher than the incorrectly classified instances (65 for NOT and 109 for OFF).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The cell representing true 'NOT' and predicted 'NOT' has the highest intensity."
                    },
                    {
                        "B": "The cell representing true 'OFF' and predicted 'OFF' is green."
                    },
                    {
                        "C": "The cell representing true 'OFF' and predicted 'NOT' is located in the top right corner."
                    },
                    {
                        "D": "All cells have equal intensity."
                    }
                ],
                "caption": "Figure 4: Sub-task A, HAD-Tubingen LSTM + Hashtag parsing.",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Sub-task A, HAD-Tubingen LSTM + Hashtag parsing.",
            "categories": "nan",
            "figure_id": "S19-2111.pdf-Figure4",
            "image_path": "S19-2111.pdf-Figure4.png",
            "instance_id": "5ea58a3697f4b3a25dcef3d0e85d0e76",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Considering the color intensity of the cells in the confusion matrix shown in Figure 4, which of the following statements are true?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The model predicted 'NOT' correctly more often than it predicted 'OFF' correctly."
                    },
                    {
                        "B": "The model had more false positives for 'OFF' than false negatives for 'NOT'."
                    },
                    {
                        "C": "The model correctly predicted 'NOT' 555 times."
                    },
                    {
                        "D": "The model's prediction of 'OFF' was more accurate than its prediction of 'NOT'."
                    }
                ],
                "caption": "Figure 4: Sub-task A, HAD-Tubingen LSTM + Hashtag parsing.",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Sub-task A, HAD-Tubingen LSTM + Hashtag parsing.",
            "categories": "nan",
            "figure_id": "S19-2111.pdf-Figure4",
            "image_path": "S19-2111.pdf-Figure4.png",
            "instance_id": "51b33b52aa7b911d59c26e9a245ef576",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Based on Figure 4's caption and the provided confusion matrix, which of the following statements are true regarding the performance of HAD-Tubingen LSTM + Hashtag parsing on Sub-task A?",
            "reference_answer": "A,B,C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Sub-task A, HAD-Tubingen LSTM + Hashtag parsing.",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Sub-task A, HAD-Tubingen LSTM + Hashtag parsing.",
            "categories": "nan",
            "figure_id": "S19-2111.pdf-Figure4",
            "image_path": "S19-2111.pdf-Figure4.png",
            "instance_id": "e93475ecc8b043c9de1670ed36082286",
            "qa_pair_type": "unanswerable",
            "question": "What is the F1-score for the 'OFF' class in Sub-task A using the HAD-Tubingen LSTM model with Hashtag parsing, as depicted in Figure 4?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: Transducer relating gesture and speech (R:G!W )",
                "compound": false,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Transducer relating gesture and speech (R:G!W )",
            "categories": "nan",
            "figure_id": "C00-1054.pdf-Figure7",
            "image_path": "C00-1054.pdf-Figure7.png",
            "instance_id": "bb58c55956cdf5012b01f3be70ea4b40",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What are the two labels of the curved arrows pointing from circle 1 to circle 2?",
            "reference_answer": "eps:this and eps:that"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The two labels of the curved arrows pointing from circle 1 to circle 2 are \"eps:that\" and \"eps:this\".",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: Transducer relating gesture and speech (R:G!W )",
                "compound": false,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Transducer relating gesture and speech (R:G!W )",
            "categories": "nan",
            "figure_id": "C00-1054.pdf-Figure7",
            "image_path": "C00-1054.pdf-Figure7.png",
            "instance_id": "63200cd43a009cb7c3a9ab770fabe1f5",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "How many states are there?",
            "reference_answer": "five"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "There are 5 states in the diagram.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: Transducer relating gesture and speech (R:G!W )",
                "compound": false,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Transducer relating gesture and speech (R:G!W )",
            "categories": "nan",
            "figure_id": "C00-1054.pdf-Figure7",
            "image_path": "C00-1054.pdf-Figure7.png",
            "instance_id": "f8df1f180489043c58c39108ec776e61",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is there a curved arrow pointing from circle 0 to circle 2?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: Transducer relating gesture and speech (R:G!W )",
                "compound": false,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Transducer relating gesture and speech (R:G!W )",
            "categories": "nan",
            "figure_id": "C00-1054.pdf-Figure7",
            "image_path": "C00-1054.pdf-Figure7.png",
            "instance_id": "51ed8a2e13fb397a0991bad608eb1103",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is there a transition from state 3 to state 2?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, there is no transition from state 3 to state 2 in the diagram.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "3"
                    },
                    {
                        "B": "4"
                    },
                    {
                        "C": "1"
                    },
                    {
                        "D": "2"
                    }
                ],
                "caption": "Figure 7: Transducer relating gesture and speech (R:G!W )",
                "compound": false,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Transducer relating gesture and speech (R:G!W )",
            "categories": "nan",
            "figure_id": "C00-1054.pdf-Figure7",
            "image_path": "C00-1054.pdf-Figure7.png",
            "instance_id": "11acfa9b7e9abfcc3724f513035aaec1",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What is the label of the circle that is positioned the furthest right and has a double line around it?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "from 1 to 2"
                    },
                    {
                        "B": "from 2 to 4"
                    },
                    {
                        "C": "from 4 to 1"
                    },
                    {
                        "D": "from 3 to 1"
                    }
                ],
                "caption": "Figure 7: Transducer relating gesture and speech (R:G!W )",
                "compound": false,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Transducer relating gesture and speech (R:G!W )",
            "categories": "nan",
            "figure_id": "C00-1054.pdf-Figure7",
            "image_path": "C00-1054.pdf-Figure7.png",
            "instance_id": "0135dd31f7050889056b6a2b5a2bd69d",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which are possible direct transitions?",
            "reference_answer": "A,C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: Transducer relating gesture and speech (R:G!W )",
                "compound": false,
                "figure_type": "graph",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Transducer relating gesture and speech (R:G!W )",
            "categories": "nan",
            "figure_id": "C00-1054.pdf-Figure7",
            "image_path": "C00-1054.pdf-Figure7.png",
            "instance_id": "0d8578f615395259b5645d9df0a19d5c",
            "qa_pair_type": "unanswerable",
            "question": "What is the acceptance rate of this transducer?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Graphical model of the utterance model.",
                "compound": true,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Graphical model of the utterance model.",
            "categories": "nan",
            "figure_id": "D16-1232.pdf-Figure4",
            "image_path": "D16-1232.pdf-Figure4.png",
            "instance_id": "82dc8ab20458105e534bbb53f0948d29",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "Are there more arrows pointing to the right or left?",
            "reference_answer": "Right"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Graphical model of the utterance model.",
                "compound": true,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Graphical model of the utterance model.",
            "categories": "nan",
            "figure_id": "D16-1232.pdf-Figure4",
            "image_path": "D16-1232.pdf-Figure4.png",
            "instance_id": "727f05c2371c653436faa415cd60f817",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the input of U?",
            "reference_answer": "S and F"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Graphical model of the utterance model.",
                "compound": true,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Graphical model of the utterance model.",
            "categories": "nan",
            "figure_id": "D16-1232.pdf-Figure4",
            "image_path": "D16-1232.pdf-Figure4.png",
            "instance_id": "4b75e5fcac60804ac2888c5f211e0f1d",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the arrow pointing to the circle labeled 'S' coming from a circle labeled 'G'?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the arrow pointing to the circle labeled 'S' is coming from a circle labeled 'G'.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Graphical model of the utterance model.",
                "compound": true,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Graphical model of the utterance model.",
            "categories": "nan",
            "figure_id": "D16-1232.pdf-Figure4",
            "image_path": "D16-1232.pdf-Figure4.png",
            "instance_id": "cb68bd1081046440580fe91140ed606c",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the model include a component labeled 'M_S'?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The model includes a component labeled 'M_S'.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "H^1, H^3"
                    },
                    {
                        "B": "H^1, S"
                    },
                    {
                        "C": "H^3, u"
                    },
                    {
                        "D": "H^3, S"
                    }
                ],
                "caption": "Figure 4: Graphical model of the utterance model.",
                "compound": true,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Graphical model of the utterance model.",
            "categories": "nan",
            "figure_id": "D16-1232.pdf-Figure4",
            "image_path": "D16-1232.pdf-Figure4.png",
            "instance_id": "e4c645451bf07518eeedfb156050fac2",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which nodes are directly connected to node 'F'?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "CD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "G"
                    },
                    {
                        "B": "H"
                    },
                    {
                        "C": "S"
                    },
                    {
                        "D": "F"
                    }
                ],
                "caption": "Figure 4: Graphical model of the utterance model.",
                "compound": true,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Graphical model of the utterance model.",
            "categories": "nan",
            "figure_id": "D16-1232.pdf-Figure4",
            "image_path": "D16-1232.pdf-Figure4.png",
            "instance_id": "d05d25d6332ffb616f8ef0be562a6fcb",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of these are components of the model?",
            "reference_answer": "ABCD"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ABCD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Graphical model of the utterance model.",
                "compound": true,
                "figure_type": "graph",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Graphical model of the utterance model.",
            "categories": "nan",
            "figure_id": "D16-1232.pdf-Figure4",
            "image_path": "D16-1232.pdf-Figure4.png",
            "instance_id": "2c5222d6be208ae7fed9032f7222074b",
            "qa_pair_type": "unanswerable",
            "question": "What are the specific values of the parameters used for each of the model components, such as G^0, G^1, H^0, H^1, G^3, H^3, S, F, M_S, and M_F, in the utterance model presented in Figure 4?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: The human-annotation for Ex1 provided in TE3, where many TLINKs are missing due to the annotation difficulty. Solid lines: original human annotations. Dotted lines: TLINKs inferred from solid lines. Dashed lines: missing relations.",
                "compound": false,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: The human-annotation for Ex1 provided in TE3, where many TLINKs are missing due to the annotation difficulty. Solid lines: original human annotations. Dotted lines: TLINKs inferred from solid lines. Dashed lines: missing relations.",
            "categories": "nan",
            "figure_id": "D17-1108.pdf-Figure2",
            "image_path": "D17-1108.pdf-Figure2.png",
            "instance_id": "20153145bcb12a0b9e717f84ad547670",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What kind of line connects the 'ripping' and 'ordered' nodes?",
            "reference_answer": "Dotted"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The line connecting the 'ripping' and 'ordered' nodes is a dashed line, which indicates \"no relation.\"",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: The human-annotation for Ex1 provided in TE3, where many TLINKs are missing due to the annotation difficulty. Solid lines: original human annotations. Dotted lines: TLINKs inferred from solid lines. Dashed lines: missing relations.",
                "compound": false,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: The human-annotation for Ex1 provided in TE3, where many TLINKs are missing due to the annotation difficulty. Solid lines: original human annotations. Dotted lines: TLINKs inferred from solid lines. Dashed lines: missing relations.",
            "categories": "nan",
            "figure_id": "D17-1108.pdf-Figure2",
            "image_path": "D17-1108.pdf-Figure2.png",
            "instance_id": "df797179374bc54a7d8ac51849de5cb2",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "Which relation is missing between 'ripping' and 'ordered'?",
            "reference_answer": "BEFORE"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: The human-annotation for Ex1 provided in TE3, where many TLINKs are missing due to the annotation difficulty. Solid lines: original human annotations. Dotted lines: TLINKs inferred from solid lines. Dashed lines: missing relations.",
                "compound": false,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: The human-annotation for Ex1 provided in TE3, where many TLINKs are missing due to the annotation difficulty. Solid lines: original human annotations. Dotted lines: TLINKs inferred from solid lines. Dashed lines: missing relations.",
            "categories": "nan",
            "figure_id": "D17-1108.pdf-Figure2",
            "image_path": "D17-1108.pdf-Figure2.png",
            "instance_id": "3c00a7e15e80a635938a4812f2442652",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is there a solid line connecting 'ripping' and 'monitor'?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, there is no solid line connecting 'ripping' and 'monitor'.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: The human-annotation for Ex1 provided in TE3, where many TLINKs are missing due to the annotation difficulty. Solid lines: original human annotations. Dotted lines: TLINKs inferred from solid lines. Dashed lines: missing relations.",
                "compound": false,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: The human-annotation for Ex1 provided in TE3, where many TLINKs are missing due to the annotation difficulty. Solid lines: original human annotations. Dotted lines: TLINKs inferred from solid lines. Dashed lines: missing relations.",
            "categories": "nan",
            "figure_id": "D17-1108.pdf-Figure2",
            "image_path": "D17-1108.pdf-Figure2.png",
            "instance_id": "ffdd433e5f3ee8826d10acdd022b4d42",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Are there any relations between 'ripping' and 'monitor' that were not originally annotated?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "ripping to hurt"
                    },
                    {
                        "B": "ripping to ordered"
                    },
                    {
                        "C": "monitor to ordered"
                    },
                    {
                        "D": "cascaded to monitor"
                    }
                ],
                "caption": "Figure 2: The human-annotation for Ex1 provided in TE3, where many TLINKs are missing due to the annotation difficulty. Solid lines: original human annotations. Dotted lines: TLINKs inferred from solid lines. Dashed lines: missing relations.",
                "compound": false,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: The human-annotation for Ex1 provided in TE3, where many TLINKs are missing due to the annotation difficulty. Solid lines: original human annotations. Dotted lines: TLINKs inferred from solid lines. Dashed lines: missing relations.",
            "categories": "nan",
            "figure_id": "D17-1108.pdf-Figure2",
            "image_path": "D17-1108.pdf-Figure2.png",
            "instance_id": "c9a44231bf4d1035399409529c0fd719",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following connections have a dashed line indicating a missing relation between the nodes?",
            "reference_answer": "C,D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "BC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "ripping, hurt"
                    },
                    {
                        "B": "monitor, ordered"
                    },
                    {
                        "C": "ripping, monitor"
                    },
                    {
                        "D": "hurt, cascaded"
                    }
                ],
                "caption": "Figure 2: The human-annotation for Ex1 provided in TE3, where many TLINKs are missing due to the annotation difficulty. Solid lines: original human annotations. Dotted lines: TLINKs inferred from solid lines. Dashed lines: missing relations.",
                "compound": false,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: The human-annotation for Ex1 provided in TE3, where many TLINKs are missing due to the annotation difficulty. Solid lines: original human annotations. Dotted lines: TLINKs inferred from solid lines. Dashed lines: missing relations.",
            "categories": "nan",
            "figure_id": "D17-1108.pdf-Figure2",
            "image_path": "D17-1108.pdf-Figure2.png",
            "instance_id": "0393275c2daa32b1666c9331f763afdc",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following pairs has a 'BEFORE' human annotated relationship between them?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: The human-annotation for Ex1 provided in TE3, where many TLINKs are missing due to the annotation difficulty. Solid lines: original human annotations. Dotted lines: TLINKs inferred from solid lines. Dashed lines: missing relations.",
                "compound": false,
                "figure_type": "graph",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: The human-annotation for Ex1 provided in TE3, where many TLINKs are missing due to the annotation difficulty. Solid lines: original human annotations. Dotted lines: TLINKs inferred from solid lines. Dashed lines: missing relations.",
            "categories": "nan",
            "figure_id": "D17-1108.pdf-Figure2",
            "image_path": "D17-1108.pdf-Figure2.png",
            "instance_id": "4533485af7ddbfe708516d6533eb1faa",
            "qa_pair_type": "unanswerable",
            "question": "What are the specific events that caused the TLINKs to be missing in Ex1?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: The distribution of the support scores on JAMUL.",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The distribution of the support scores on JAMUL.",
            "categories": "nan",
            "figure_id": "2020.acl-main.123.pdf-Figure4",
            "image_path": "2020.acl-main.123.pdf-Figure4.png",
            "instance_id": "d3aba2fed439f452916b3cbe9b911111",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate number of examples in the blue bar for the 80-100 ROUGE-1 score bin?",
            "reference_answer": "700"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: The distribution of the support scores on JAMUL.",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The distribution of the support scores on JAMUL.",
            "categories": "nan",
            "figure_id": "2020.acl-main.123.pdf-Figure4",
            "image_path": "2020.acl-main.123.pdf-Figure4.png",
            "instance_id": "5d8e8f2699d1b666bef8d49118d00b25",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the highest ROUGE-1 (recall) score bin shown in Figure 4?",
            "reference_answer": "100"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The highest ROUGE-1 (recall) score bin shown in Figure 4 is the \"80-100\" bin.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: The distribution of the support scores on JAMUL.",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The distribution of the support scores on JAMUL.",
            "categories": "nan",
            "figure_id": "2020.acl-main.123.pdf-Figure4",
            "image_path": "2020.acl-main.123.pdf-Figure4.png",
            "instance_id": "27bef2205eb31fbe8afcf3f82004dc5d",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the height of the blue bar in the 80-100 bin taller than the height of the orange bar in the same bin?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the height of the blue bar in the 80-100 bin is taller than the height of the orange bar in the same bin.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: The distribution of the support scores on JAMUL.",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The distribution of the support scores on JAMUL.",
            "categories": "nan",
            "figure_id": "2020.acl-main.123.pdf-Figure4",
            "image_path": "2020.acl-main.123.pdf-Figure4.png",
            "instance_id": "61ad138ac6befd9b2a6a8ad43181fc53",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the figure show the distribution of support scores on JAMUL for both 'full data' and 'filtered+pseudo' categories?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The tallest bar representing 'full data' is blue and has a height greater than 700."
                    },
                    {
                        "B": "The shortest bar representing 'full data' is blue and is between 0 and 50 in height."
                    },
                    {
                        "C": "At least one bar representing 'full data' is orange."
                    },
                    {
                        "D": "There are several blue bars with heights ranging from approximately 200 to 700."
                    }
                ],
                "caption": "Figure 4: The distribution of the support scores on JAMUL.",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The distribution of the support scores on JAMUL.",
            "categories": "nan",
            "figure_id": "2020.acl-main.123.pdf-Figure4",
            "image_path": "2020.acl-main.123.pdf-Figure4.png",
            "instance_id": "89ecd3147fc1b0747b93eebb89daf55e",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Considering Figure 4, which of the following statements about the height and color of the bars representing the 'full data' are correct?  Select all that apply.",
            "reference_answer": "A,B,D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "BD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "0-20, 20-40, 40-60"
                    },
                    {
                        "B": "60-80, 80-100, 100"
                    },
                    {
                        "C": "60-80, 100"
                    },
                    {
                        "D": "80-100"
                    }
                ],
                "caption": "Figure 4: The distribution of the support scores on JAMUL.",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The distribution of the support scores on JAMUL.",
            "categories": "nan",
            "figure_id": "2020.acl-main.123.pdf-Figure4",
            "image_path": "2020.acl-main.123.pdf-Figure4.png",
            "instance_id": "00f7e518753d493e786133ae26bbdccc",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Based on Figure 4, which ROUGE-1 (recall) score bin ranges contain more than 200 examples in the 'full data' category?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: The distribution of the support scores on JAMUL.",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: The distribution of the support scores on JAMUL.",
            "categories": "nan",
            "figure_id": "2020.acl-main.123.pdf-Figure4",
            "image_path": "2020.acl-main.123.pdf-Figure4.png",
            "instance_id": "51894201bb305bafc001ab5cb5e043ed",
            "qa_pair_type": "unanswerable",
            "question": "What is the exact number of examples with ROUGE-1 (recall) scores between 20 and 40 in the 'filtered+pseudo' dataset, and what is the standard deviation of these scores?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: F1 scores across all held-out language families, comparing pretraining with no pretraining.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: F1 scores across all held-out language families, comparing pretraining with no pretraining.",
            "categories": "['cs.CL']",
            "figure_id": "1903.10950v3-Figure6-1",
            "image_path": "1903.10950v3-Figure6-1.png",
            "instance_id": "3b687519f009271dca51c2b568154b00",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the F1 score of the green circle at 20% in-family training?",
            "reference_answer": "approximately 1"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: F1 scores across all held-out language families, comparing pretraining with no pretraining.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: F1 scores across all held-out language families, comparing pretraining with no pretraining.",
            "categories": "['cs.CL']",
            "figure_id": "1903.10950v3-Figure6-1",
            "image_path": "1903.10950v3-Figure6-1.png",
            "instance_id": "b41ddf80b5f9af1cfd5a6393942908c8",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "At what value of in-family training do the F1 scores for pretraining and no pretraining become equal?",
            "reference_answer": "at approximately 0 %"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: F1 scores across all held-out language families, comparing pretraining with no pretraining.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: F1 scores across all held-out language families, comparing pretraining with no pretraining.",
            "categories": "['cs.CL']",
            "figure_id": "1903.10950v3-Figure6-1",
            "image_path": "1903.10950v3-Figure6-1.png",
            "instance_id": "d1d2282e9c74f468ff90e3cc4fbbae92",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the green circle corresponding to 20% in-family training higher than the purple circle corresponding to 20% in-family training?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the green circle corresponding to 20% in-family training is higher than the purple circle corresponding to 20% in-family training.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: F1 scores across all held-out language families, comparing pretraining with no pretraining.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: F1 scores across all held-out language families, comparing pretraining with no pretraining.",
            "categories": "['cs.CL']",
            "figure_id": "1903.10950v3-Figure6-1",
            "image_path": "1903.10950v3-Figure6-1.png",
            "instance_id": "46c347527391f3ba1ff9861fb5dfe5d9",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does pretraining consistently result in higher F1 scores across all held-out language families compared to no pretraining?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, pretraining consistently results in higher F1 scores across all in-family training percentages compared to no pretraining, as shown by the consistently higher green line for pretraining in the graph.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The green data point with x-axis value 1"
                    },
                    {
                        "B": "The green data point with x-axis value 20"
                    },
                    {
                        "C": "The green data point with x-axis value 10"
                    },
                    {
                        "D": "The green data point with x-axis value 5"
                    }
                ],
                "caption": "Figure 6: F1 scores across all held-out language families, comparing pretraining with no pretraining.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: F1 scores across all held-out language families, comparing pretraining with no pretraining.",
            "categories": "['cs.CL']",
            "figure_id": "1903.10950v3-Figure6-1",
            "image_path": "1903.10950v3-Figure6-1.png",
            "instance_id": "3b79dae6ce42ac7b90c825b730470c80",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which data point on the graph represents the highest F1 score when pretraining is used?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "no pretraining"
                    },
                    {
                        "B": "pretraining"
                    },
                    {
                        "C": "Neither"
                    },
                    {
                        "D": "Both"
                    }
                ],
                "caption": "Figure 6: F1 scores across all held-out language families, comparing pretraining with no pretraining.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: F1 scores across all held-out language families, comparing pretraining with no pretraining.",
            "categories": "['cs.CL']",
            "figure_id": "1903.10950v3-Figure6-1",
            "image_path": "1903.10950v3-Figure6-1.png",
            "instance_id": "f1284cc3d8c3647ffe946393fd2d5af3",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which case achieves higher than 0.8 F1 score at 10% in-family training?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: F1 scores across all held-out language families, comparing pretraining with no pretraining.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: F1 scores across all held-out language families, comparing pretraining with no pretraining.",
            "categories": "['cs.CL']",
            "figure_id": "1903.10950v3-Figure6-1",
            "image_path": "1903.10950v3-Figure6-1.png",
            "instance_id": "b07bd80f13acd6f5977626a471c0620b",
            "qa_pair_type": "unanswerable",
            "question": "What are the specific language families used in this experiment?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 2. Dependency between the number of CNNs in ensemble and its total accuracy for the binary [left] and multi-classification [right] problems",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2. Dependency between the number of CNNs in ensemble and its total accuracy for the binary [left] and multi-classification [right] problems",
            "categories": "['cs.IR cs.CL']",
            "figure_id": "1706.05549v1-Figure2-1",
            "image_path": "1706.05549v1-Figure2-1.png",
            "instance_id": "ac1245480643b3bba6164d0905ed3974",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate position along the y axis of the blue line at x = 5 in the right figure?",
            "reference_answer": "approximately 60"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 2. Dependency between the number of CNNs in ensemble and its total accuracy for the binary [left] and multi-classification [right] problems",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2. Dependency between the number of CNNs in ensemble and its total accuracy for the binary [left] and multi-classification [right] problems",
            "categories": "['cs.IR cs.CL']",
            "figure_id": "1706.05549v1-Figure2-1",
            "image_path": "1706.05549v1-Figure2-1.png",
            "instance_id": "79683152767e9413f9c4fab6fdfc56c1",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the approximate overall accuracy for the binary classification problem using 45 CNNs?",
            "reference_answer": "87%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 2. Dependency between the number of CNNs in ensemble and its total accuracy for the binary [left] and multi-classification [right] problems",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2. Dependency between the number of CNNs in ensemble and its total accuracy for the binary [left] and multi-classification [right] problems",
            "categories": "['cs.IR cs.CL']",
            "figure_id": "1706.05549v1-Figure2-1",
            "image_path": "1706.05549v1-Figure2-1.png",
            "instance_id": "464d3f6a797e5ffa26adb183aeea5720",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the accuracy of the left graph increase with the number of CNNs before reaching a plateau?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the accuracy of the left graph increases with the number of CNNs before reaching a plateau.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 2. Dependency between the number of CNNs in ensemble and its total accuracy for the binary [left] and multi-classification [right] problems",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2. Dependency between the number of CNNs in ensemble and its total accuracy for the binary [left] and multi-classification [right] problems",
            "categories": "['cs.IR cs.CL']",
            "figure_id": "1706.05549v1-Figure2-1",
            "image_path": "1706.05549v1-Figure2-1.png",
            "instance_id": "f37edfdfe7661d481ae296ee40eb5efd",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the overall accuracy for the binary problem higher than the multi-classification problem at the maximum number of CNNs?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The right one"
                    },
                    {
                        "B": "The left one"
                    },
                    {
                        "C": "Both"
                    },
                    {
                        "D": "None"
                    }
                ],
                "caption": "Fig. 2. Dependency between the number of CNNs in ensemble and its total accuracy for the binary [left] and multi-classification [right] problems",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2. Dependency between the number of CNNs in ensemble and its total accuracy for the binary [left] and multi-classification [right] problems",
            "categories": "['cs.IR cs.CL']",
            "figure_id": "1706.05549v1-Figure2-1",
            "image_path": "1706.05549v1-Figure2-1.png",
            "instance_id": "ab8dcb83cb9bf145c8a511aefb1805f6",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "In which graph does the overall accuracy reach above 80?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Yes"
                    },
                    {
                        "B": "No"
                    },
                    {
                        "C": "It increases until a certain point then decreases"
                    },
                    {
                        "D": "The accuracy stays roughly the same"
                    }
                ],
                "caption": "Fig. 2. Dependency between the number of CNNs in ensemble and its total accuracy for the binary [left] and multi-classification [right] problems",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2. Dependency between the number of CNNs in ensemble and its total accuracy for the binary [left] and multi-classification [right] problems",
            "categories": "['cs.IR cs.CL']",
            "figure_id": "1706.05549v1-Figure2-1",
            "image_path": "1706.05549v1-Figure2-1.png",
            "instance_id": "de0466e1cf6ba17dcbad11f0da7b58bd",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Does the overall accuracy of the ensemble increase with the number of CNNs for the binary classification problem?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 2. Dependency between the number of CNNs in ensemble and its total accuracy for the binary [left] and multi-classification [right] problems",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2. Dependency between the number of CNNs in ensemble and its total accuracy for the binary [left] and multi-classification [right] problems",
            "categories": "['cs.IR cs.CL']",
            "figure_id": "1706.05549v1-Figure2-1",
            "image_path": "1706.05549v1-Figure2-1.png",
            "instance_id": "f1de4afc354ffdea2cf0108f85b7e065",
            "qa_pair_type": "unanswerable",
            "question": "What is the experiment trying to classify?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Transformer models with bi/uni-directional encoders trained on wait-1 and wait-7 decoding paths.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Transformer models with bi/uni-directional encoders trained on wait-1 and wait-7 decoding paths.",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2005.08595v2-Figure3-1",
            "image_path": "2005.08595v2-Figure3-1.png",
            "instance_id": "b85917281c067991d22f3ea7d58e2228",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of the blue circle at the average lagging of 6 in the figure on the left?",
            "reference_answer": "between 30 and 31"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Transformer models with bi/uni-directional encoders trained on wait-1 and wait-7 decoding paths.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Transformer models with bi/uni-directional encoders trained on wait-1 and wait-7 decoding paths.",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2005.08595v2-Figure3-1",
            "image_path": "2005.08595v2-Figure3-1.png",
            "instance_id": "6e1b65cfd6befe4bc9326e10c776f8e6",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the range of BLEU scores for which data was collected for the En to Vi task?",
            "reference_answer": "from 18 to 29"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Transformer models with bi/uni-directional encoders trained on wait-1 and wait-7 decoding paths.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Transformer models with bi/uni-directional encoders trained on wait-1 and wait-7 decoding paths.",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2005.08595v2-Figure3-1",
            "image_path": "2005.08595v2-Figure3-1.png",
            "instance_id": "a5f5dfb8f1938ae4015c262f2423f347",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Do the blue lines representing the 'k_train = 7' encoder have a higher value than the red lines representing the 'k_train = 1' encoder at the average lagging of 5 for both the bidirectional and unidirectional versions (each compared separately) in both figures?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the blue lines representing the 'k_train = 7' encoder have a higher value than the red lines representing the 'k_train = 1' encoder at the average lagging of 5 for both the bidirectional and unidirectional versions in both figures.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Transformer models with bi/uni-directional encoders trained on wait-1 and wait-7 decoding paths.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Transformer models with bi/uni-directional encoders trained on wait-1 and wait-7 decoding paths.",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2005.08595v2-Figure3-1",
            "image_path": "2005.08595v2-Figure3-1.png",
            "instance_id": "b6530b2dfbe1502a5078a16f284c9b27",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Are BLUE scores measured for exactly the same average lagging values between different values of k and between unidirectional and bidirectional versions?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Red circles"
                    },
                    {
                        "B": "Red x's"
                    },
                    {
                        "C": "Blue circles"
                    },
                    {
                        "D": "Blue x's"
                    }
                ],
                "caption": "Figure 3: Transformer models with bi/uni-directional encoders trained on wait-1 and wait-7 decoding paths.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Transformer models with bi/uni-directional encoders trained on wait-1 and wait-7 decoding paths.",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2005.08595v2-Figure3-1",
            "image_path": "2005.08595v2-Figure3-1.png",
            "instance_id": "4ae06f39f154a990877c03f9453b1098",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line on the left graph represents the results of the transformer model with a unidirectional encoder trained on the wait-7 decoding path?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "unidirectional wait - 1"
                    },
                    {
                        "B": "unidirectional wait - 7"
                    },
                    {
                        "C": "bidirectional wait - 1"
                    },
                    {
                        "D": "bidirectional wait - 7"
                    }
                ],
                "caption": "Figure 3: Transformer models with bi/uni-directional encoders trained on wait-1 and wait-7 decoding paths.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Transformer models with bi/uni-directional encoders trained on wait-1 and wait-7 decoding paths.",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2005.08595v2-Figure3-1",
            "image_path": "2005.08595v2-Figure3-1.png",
            "instance_id": "3e475dffcef66aa540d3b5b95336967a",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which case achieves higher than 28 BLUE for En to Vi for any average lagging?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Transformer models with bi/uni-directional encoders trained on wait-1 and wait-7 decoding paths.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Transformer models with bi/uni-directional encoders trained on wait-1 and wait-7 decoding paths.",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2005.08595v2-Figure3-1",
            "image_path": "2005.08595v2-Figure3-1.png",
            "instance_id": "a3e9264e0b1f9f26b4a28e03b7b00a9f",
            "qa_pair_type": "unanswerable",
            "question": "What was the dataset used for this experiment?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The datasets used for the experiments are IWSLT'14 for the De\u2192En translation task and IWSLT'15 for the En\u2192Vi translation task.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Probability densities of supervised classification accuracy in low-resource (200 labeled instances; left) and high-resource (10K labeled instances; right) settings for IMDB and AG datasets using randomly initialized trainable embeddings. Each search consists of 300 trials over 5 seeds and varying hyperparameters. We experiment with four different classifiers: Logistic Regression, LSTM-based classifier, Deep Averaging Network, and a CNNbased Classifier. We choose to use the Deep Averaging Network for all classifier baselines, due to its reliability, expressiveness, and low-maintenance.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Probability densities of supervised classification accuracy in low-resource (200 labeled instances; left) and high-resource (10K labeled instances; right) settings for IMDB and AG datasets using randomly initialized trainable embeddings. Each search consists of 300 trials over 5 seeds and varying hyperparameters. We experiment with four different classifiers: Logistic Regression, LSTM-based classifier, Deep Averaging Network, and a CNNbased Classifier. We choose to use the Deep Averaging Network for all classifier baselines, due to its reliability, expressiveness, and low-maintenance.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1906.02242v1-Figure6-1",
            "image_path": "1906.02242v1-Figure6-1.png",
            "instance_id": "fa87155093dc4ac95c91480bde84e789",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate maximum value of the probability density for the green line in the plot labeled \"AG News: 10K labeled instances\"?",
            "reference_answer": "1.2"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Probability densities of supervised classification accuracy in low-resource (200 labeled instances; left) and high-resource (10K labeled instances; right) settings for IMDB and AG datasets using randomly initialized trainable embeddings. Each search consists of 300 trials over 5 seeds and varying hyperparameters. We experiment with four different classifiers: Logistic Regression, LSTM-based classifier, Deep Averaging Network, and a CNNbased Classifier. We choose to use the Deep Averaging Network for all classifier baselines, due to its reliability, expressiveness, and low-maintenance.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Probability densities of supervised classification accuracy in low-resource (200 labeled instances; left) and high-resource (10K labeled instances; right) settings for IMDB and AG datasets using randomly initialized trainable embeddings. Each search consists of 300 trials over 5 seeds and varying hyperparameters. We experiment with four different classifiers: Logistic Regression, LSTM-based classifier, Deep Averaging Network, and a CNNbased Classifier. We choose to use the Deep Averaging Network for all classifier baselines, due to its reliability, expressiveness, and low-maintenance.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1906.02242v1-Figure6-1",
            "image_path": "1906.02242v1-Figure6-1.png",
            "instance_id": "b4d7e972a77509078173d935b282fa0e",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "Which classifier has the highest probability density for the IMDB dataset with 10K labeled instances?",
            "reference_answer": "Deep Averaging Network"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Probability densities of supervised classification accuracy in low-resource (200 labeled instances; left) and high-resource (10K labeled instances; right) settings for IMDB and AG datasets using randomly initialized trainable embeddings. Each search consists of 300 trials over 5 seeds and varying hyperparameters. We experiment with four different classifiers: Logistic Regression, LSTM-based classifier, Deep Averaging Network, and a CNNbased Classifier. We choose to use the Deep Averaging Network for all classifier baselines, due to its reliability, expressiveness, and low-maintenance.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Probability densities of supervised classification accuracy in low-resource (200 labeled instances; left) and high-resource (10K labeled instances; right) settings for IMDB and AG datasets using randomly initialized trainable embeddings. Each search consists of 300 trials over 5 seeds and varying hyperparameters. We experiment with four different classifiers: Logistic Regression, LSTM-based classifier, Deep Averaging Network, and a CNNbased Classifier. We choose to use the Deep Averaging Network for all classifier baselines, due to its reliability, expressiveness, and low-maintenance.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1906.02242v1-Figure6-1",
            "image_path": "1906.02242v1-Figure6-1.png",
            "instance_id": "0427bfbec5a8cc789bd1e4f43fd2f832",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the peak of the green curve in the 'IMDB: 200 labeled instances' subplot higher than that of the red curve in the 'AG News: 200 labeled instances' subplot?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Probability densities of supervised classification accuracy in low-resource (200 labeled instances; left) and high-resource (10K labeled instances; right) settings for IMDB and AG datasets using randomly initialized trainable embeddings. Each search consists of 300 trials over 5 seeds and varying hyperparameters. We experiment with four different classifiers: Logistic Regression, LSTM-based classifier, Deep Averaging Network, and a CNNbased Classifier. We choose to use the Deep Averaging Network for all classifier baselines, due to its reliability, expressiveness, and low-maintenance.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Probability densities of supervised classification accuracy in low-resource (200 labeled instances; left) and high-resource (10K labeled instances; right) settings for IMDB and AG datasets using randomly initialized trainable embeddings. Each search consists of 300 trials over 5 seeds and varying hyperparameters. We experiment with four different classifiers: Logistic Regression, LSTM-based classifier, Deep Averaging Network, and a CNNbased Classifier. We choose to use the Deep Averaging Network for all classifier baselines, due to its reliability, expressiveness, and low-maintenance.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1906.02242v1-Figure6-1",
            "image_path": "1906.02242v1-Figure6-1.png",
            "instance_id": "c79735bd7eb6fec909acc817b0c59870",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the probability density of the Deep Averaging Network classifier consistently higher than the Logistic Regression classifier in the IMDB dataset with 200 labeled instances?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "green line"
                    },
                    {
                        "B": "blue line"
                    },
                    {
                        "C": "red line"
                    },
                    {
                        "D": "orange line"
                    }
                ],
                "caption": "Figure 6: Probability densities of supervised classification accuracy in low-resource (200 labeled instances; left) and high-resource (10K labeled instances; right) settings for IMDB and AG datasets using randomly initialized trainable embeddings. Each search consists of 300 trials over 5 seeds and varying hyperparameters. We experiment with four different classifiers: Logistic Regression, LSTM-based classifier, Deep Averaging Network, and a CNNbased Classifier. We choose to use the Deep Averaging Network for all classifier baselines, due to its reliability, expressiveness, and low-maintenance.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Probability densities of supervised classification accuracy in low-resource (200 labeled instances; left) and high-resource (10K labeled instances; right) settings for IMDB and AG datasets using randomly initialized trainable embeddings. Each search consists of 300 trials over 5 seeds and varying hyperparameters. We experiment with four different classifiers: Logistic Regression, LSTM-based classifier, Deep Averaging Network, and a CNNbased Classifier. We choose to use the Deep Averaging Network for all classifier baselines, due to its reliability, expressiveness, and low-maintenance.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1906.02242v1-Figure6-1",
            "image_path": "1906.02242v1-Figure6-1.png",
            "instance_id": "b0b313a216f3a3df892a1fa94547e391",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which color probability distributions have higher mean validation accuracy in the 'AG News: 10K labeled instances' setting than in the 'AG News: 200 labeled instances' setting?",
            "reference_answer": "A,B,C,D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Logistic Regression"
                    },
                    {
                        "B": "Support Vector Machine"
                    },
                    {
                        "C": "CNN-based Classifier"
                    },
                    {
                        "D": "LSTM-based Classifier"
                    }
                ],
                "caption": "Figure 6: Probability densities of supervised classification accuracy in low-resource (200 labeled instances; left) and high-resource (10K labeled instances; right) settings for IMDB and AG datasets using randomly initialized trainable embeddings. Each search consists of 300 trials over 5 seeds and varying hyperparameters. We experiment with four different classifiers: Logistic Regression, LSTM-based classifier, Deep Averaging Network, and a CNNbased Classifier. We choose to use the Deep Averaging Network for all classifier baselines, due to its reliability, expressiveness, and low-maintenance.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Probability densities of supervised classification accuracy in low-resource (200 labeled instances; left) and high-resource (10K labeled instances; right) settings for IMDB and AG datasets using randomly initialized trainable embeddings. Each search consists of 300 trials over 5 seeds and varying hyperparameters. We experiment with four different classifiers: Logistic Regression, LSTM-based classifier, Deep Averaging Network, and a CNNbased Classifier. We choose to use the Deep Averaging Network for all classifier baselines, due to its reliability, expressiveness, and low-maintenance.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1906.02242v1-Figure6-1",
            "image_path": "1906.02242v1-Figure6-1.png",
            "instance_id": "2b2c3845a57a908538cfbc8f8b23506f",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following classifiers is NOT used in the experiment?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Probability densities of supervised classification accuracy in low-resource (200 labeled instances; left) and high-resource (10K labeled instances; right) settings for IMDB and AG datasets using randomly initialized trainable embeddings. Each search consists of 300 trials over 5 seeds and varying hyperparameters. We experiment with four different classifiers: Logistic Regression, LSTM-based classifier, Deep Averaging Network, and a CNNbased Classifier. We choose to use the Deep Averaging Network for all classifier baselines, due to its reliability, expressiveness, and low-maintenance.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Probability densities of supervised classification accuracy in low-resource (200 labeled instances; left) and high-resource (10K labeled instances; right) settings for IMDB and AG datasets using randomly initialized trainable embeddings. Each search consists of 300 trials over 5 seeds and varying hyperparameters. We experiment with four different classifiers: Logistic Regression, LSTM-based classifier, Deep Averaging Network, and a CNNbased Classifier. We choose to use the Deep Averaging Network for all classifier baselines, due to its reliability, expressiveness, and low-maintenance.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1906.02242v1-Figure6-1",
            "image_path": "1906.02242v1-Figure6-1.png",
            "instance_id": "59c2649d51a9cf9ef50e6a589bf310f1",
            "qa_pair_type": "unanswerable",
            "question": "What hyperparameters were varied in this experiment?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 11 . The figure depicts how the distribution of retrievals is generated from the activation-based model with different variances. The bottom figure depicts the parameters of the activation-based model, the full lines in green and red are the mean finishing times tc=Target and tc=Competitor, and the broken lines are finishing times one standard deviation away from the mean. The middle figure shows the distributions of finishing times for target and candidate; since every chunk is associated a potential finishing time, t, both distributions have the same number of elements. The top-most figure shows the distribution of retrieval times (adding the shift parameter \u03c8 would transform it to reading times); since only the winning chunks are retrieved, the distribution of retrieval times for targets has more elements than the distribution of the competitors. Notice that even though the finishing times for the competitors are slower on average than those of the targets (middle plot), the situation is reversed for the retrieval times (top-most plot).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 11 . The figure depicts how the distribution of retrievals is generated from the activation-based model with different variances. The bottom figure depicts the parameters of the activation-based model, the full lines in green and red are the mean finishing times tc=Target and tc=Competitor, and the broken lines are finishing times one standard deviation away from the mean. The middle figure shows the distributions of finishing times for target and candidate; since every chunk is associated a potential finishing time, t, both distributions have the same number of elements. The top-most figure shows the distribution of retrieval times (adding the shift parameter \u03c8 would transform it to reading times); since only the winning chunks are retrieved, the distribution of retrieval times for targets has more elements than the distribution of the competitors. Notice that even though the finishing times for the competitors are slower on average than those of the targets (middle plot), the situation is reversed for the retrieval times (top-most plot).",
            "categories": "['cs.CL stat.AP stat.ML']",
            "figure_id": "1612.04174v2-Figure11-1",
            "image_path": "1612.04174v2-Figure11-1.png",
            "instance_id": "250e7a040c0432ef03dcc0d8c54d019c",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the finishing time of the vertical solid red line that intersects the peak of the red curve in the middle figure?",
            "reference_answer": "between 1000 and 5000"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 11 . The figure depicts how the distribution of retrievals is generated from the activation-based model with different variances. The bottom figure depicts the parameters of the activation-based model, the full lines in green and red are the mean finishing times tc=Target and tc=Competitor, and the broken lines are finishing times one standard deviation away from the mean. The middle figure shows the distributions of finishing times for target and candidate; since every chunk is associated a potential finishing time, t, both distributions have the same number of elements. The top-most figure shows the distribution of retrieval times (adding the shift parameter \u03c8 would transform it to reading times); since only the winning chunks are retrieved, the distribution of retrieval times for targets has more elements than the distribution of the competitors. Notice that even though the finishing times for the competitors are slower on average than those of the targets (middle plot), the situation is reversed for the retrieval times (top-most plot).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 11 . The figure depicts how the distribution of retrievals is generated from the activation-based model with different variances. The bottom figure depicts the parameters of the activation-based model, the full lines in green and red are the mean finishing times tc=Target and tc=Competitor, and the broken lines are finishing times one standard deviation away from the mean. The middle figure shows the distributions of finishing times for target and candidate; since every chunk is associated a potential finishing time, t, both distributions have the same number of elements. The top-most figure shows the distribution of retrieval times (adding the shift parameter \u03c8 would transform it to reading times); since only the winning chunks are retrieved, the distribution of retrieval times for targets has more elements than the distribution of the competitors. Notice that even though the finishing times for the competitors are slower on average than those of the targets (middle plot), the situation is reversed for the retrieval times (top-most plot).",
            "categories": "['cs.CL stat.AP stat.ML']",
            "figure_id": "1612.04174v2-Figure11-1",
            "image_path": "1612.04174v2-Figure11-1.png",
            "instance_id": "e90e4c6cf4d69542f046f8a7e54cfa85",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the maximum density of retrieval times for targets?",
            "reference_answer": "Approximately 0.8"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 11 . The figure depicts how the distribution of retrievals is generated from the activation-based model with different variances. The bottom figure depicts the parameters of the activation-based model, the full lines in green and red are the mean finishing times tc=Target and tc=Competitor, and the broken lines are finishing times one standard deviation away from the mean. The middle figure shows the distributions of finishing times for target and candidate; since every chunk is associated a potential finishing time, t, both distributions have the same number of elements. The top-most figure shows the distribution of retrieval times (adding the shift parameter \u03c8 would transform it to reading times); since only the winning chunks are retrieved, the distribution of retrieval times for targets has more elements than the distribution of the competitors. Notice that even though the finishing times for the competitors are slower on average than those of the targets (middle plot), the situation is reversed for the retrieval times (top-most plot).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 11 . The figure depicts how the distribution of retrievals is generated from the activation-based model with different variances. The bottom figure depicts the parameters of the activation-based model, the full lines in green and red are the mean finishing times tc=Target and tc=Competitor, and the broken lines are finishing times one standard deviation away from the mean. The middle figure shows the distributions of finishing times for target and candidate; since every chunk is associated a potential finishing time, t, both distributions have the same number of elements. The top-most figure shows the distribution of retrieval times (adding the shift parameter \u03c8 would transform it to reading times); since only the winning chunks are retrieved, the distribution of retrieval times for targets has more elements than the distribution of the competitors. Notice that even though the finishing times for the competitors are slower on average than those of the targets (middle plot), the situation is reversed for the retrieval times (top-most plot).",
            "categories": "['cs.CL stat.AP stat.ML']",
            "figure_id": "1612.04174v2-Figure11-1",
            "image_path": "1612.04174v2-Figure11-1.png",
            "instance_id": "17148e17e8fefa6d37170f75457d2bf3",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Are the green lines in the bottom plot representing the mean finishing times for 'Target' and 'Competitor'?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 11 . The figure depicts how the distribution of retrievals is generated from the activation-based model with different variances. The bottom figure depicts the parameters of the activation-based model, the full lines in green and red are the mean finishing times tc=Target and tc=Competitor, and the broken lines are finishing times one standard deviation away from the mean. The middle figure shows the distributions of finishing times for target and candidate; since every chunk is associated a potential finishing time, t, both distributions have the same number of elements. The top-most figure shows the distribution of retrieval times (adding the shift parameter \u03c8 would transform it to reading times); since only the winning chunks are retrieved, the distribution of retrieval times for targets has more elements than the distribution of the competitors. Notice that even though the finishing times for the competitors are slower on average than those of the targets (middle plot), the situation is reversed for the retrieval times (top-most plot).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 11 . The figure depicts how the distribution of retrievals is generated from the activation-based model with different variances. The bottom figure depicts the parameters of the activation-based model, the full lines in green and red are the mean finishing times tc=Target and tc=Competitor, and the broken lines are finishing times one standard deviation away from the mean. The middle figure shows the distributions of finishing times for target and candidate; since every chunk is associated a potential finishing time, t, both distributions have the same number of elements. The top-most figure shows the distribution of retrieval times (adding the shift parameter \u03c8 would transform it to reading times); since only the winning chunks are retrieved, the distribution of retrieval times for targets has more elements than the distribution of the competitors. Notice that even though the finishing times for the competitors are slower on average than those of the targets (middle plot), the situation is reversed for the retrieval times (top-most plot).",
            "categories": "['cs.CL stat.AP stat.ML']",
            "figure_id": "1612.04174v2-Figure11-1",
            "image_path": "1612.04174v2-Figure11-1.png",
            "instance_id": "9a7f192530802aa024e2d3a67a3912db",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the x axis use a linear scale for retrieval and finishing times?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, the x-axis uses a logarithmic scale for both retrieval and finishing times.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Top figure"
                    },
                    {
                        "B": "Middle figure"
                    },
                    {
                        "C": "Both"
                    },
                    {
                        "D": "Neither"
                    }
                ],
                "caption": "Figure 11 . The figure depicts how the distribution of retrievals is generated from the activation-based model with different variances. The bottom figure depicts the parameters of the activation-based model, the full lines in green and red are the mean finishing times tc=Target and tc=Competitor, and the broken lines are finishing times one standard deviation away from the mean. The middle figure shows the distributions of finishing times for target and candidate; since every chunk is associated a potential finishing time, t, both distributions have the same number of elements. The top-most figure shows the distribution of retrieval times (adding the shift parameter \u03c8 would transform it to reading times); since only the winning chunks are retrieved, the distribution of retrieval times for targets has more elements than the distribution of the competitors. Notice that even though the finishing times for the competitors are slower on average than those of the targets (middle plot), the situation is reversed for the retrieval times (top-most plot).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 11 . The figure depicts how the distribution of retrievals is generated from the activation-based model with different variances. The bottom figure depicts the parameters of the activation-based model, the full lines in green and red are the mean finishing times tc=Target and tc=Competitor, and the broken lines are finishing times one standard deviation away from the mean. The middle figure shows the distributions of finishing times for target and candidate; since every chunk is associated a potential finishing time, t, both distributions have the same number of elements. The top-most figure shows the distribution of retrieval times (adding the shift parameter \u03c8 would transform it to reading times); since only the winning chunks are retrieved, the distribution of retrieval times for targets has more elements than the distribution of the competitors. Notice that even though the finishing times for the competitors are slower on average than those of the targets (middle plot), the situation is reversed for the retrieval times (top-most plot).",
            "categories": "['cs.CL stat.AP stat.ML']",
            "figure_id": "1612.04174v2-Figure11-1",
            "image_path": "1612.04174v2-Figure11-1.png",
            "instance_id": "c81c69958b4153054d40955c1f15a1fc",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "In which figure do we see intersection of green and red curves at a distribution value greater than 0.4?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Between 100 and 200"
                    },
                    {
                        "B": "Between 200 and 300"
                    },
                    {
                        "C": "Between 300 and 400"
                    },
                    {
                        "D": "Between 400 and 500"
                    }
                ],
                "caption": "Figure 11 . The figure depicts how the distribution of retrievals is generated from the activation-based model with different variances. The bottom figure depicts the parameters of the activation-based model, the full lines in green and red are the mean finishing times tc=Target and tc=Competitor, and the broken lines are finishing times one standard deviation away from the mean. The middle figure shows the distributions of finishing times for target and candidate; since every chunk is associated a potential finishing time, t, both distributions have the same number of elements. The top-most figure shows the distribution of retrieval times (adding the shift parameter \u03c8 would transform it to reading times); since only the winning chunks are retrieved, the distribution of retrieval times for targets has more elements than the distribution of the competitors. Notice that even though the finishing times for the competitors are slower on average than those of the targets (middle plot), the situation is reversed for the retrieval times (top-most plot).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 11 . The figure depicts how the distribution of retrievals is generated from the activation-based model with different variances. The bottom figure depicts the parameters of the activation-based model, the full lines in green and red are the mean finishing times tc=Target and tc=Competitor, and the broken lines are finishing times one standard deviation away from the mean. The middle figure shows the distributions of finishing times for target and candidate; since every chunk is associated a potential finishing time, t, both distributions have the same number of elements. The top-most figure shows the distribution of retrieval times (adding the shift parameter \u03c8 would transform it to reading times); since only the winning chunks are retrieved, the distribution of retrieval times for targets has more elements than the distribution of the competitors. Notice that even though the finishing times for the competitors are slower on average than those of the targets (middle plot), the situation is reversed for the retrieval times (top-most plot).",
            "categories": "['cs.CL stat.AP stat.ML']",
            "figure_id": "1612.04174v2-Figure11-1",
            "image_path": "1612.04174v2-Figure11-1.png",
            "instance_id": "66ad5ebd1934b409bac075d90191ba1e",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "At what approximate retrieval time does the target distribution become maximum?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 11 . The figure depicts how the distribution of retrievals is generated from the activation-based model with different variances. The bottom figure depicts the parameters of the activation-based model, the full lines in green and red are the mean finishing times tc=Target and tc=Competitor, and the broken lines are finishing times one standard deviation away from the mean. The middle figure shows the distributions of finishing times for target and candidate; since every chunk is associated a potential finishing time, t, both distributions have the same number of elements. The top-most figure shows the distribution of retrieval times (adding the shift parameter \u03c8 would transform it to reading times); since only the winning chunks are retrieved, the distribution of retrieval times for targets has more elements than the distribution of the competitors. Notice that even though the finishing times for the competitors are slower on average than those of the targets (middle plot), the situation is reversed for the retrieval times (top-most plot).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 11 . The figure depicts how the distribution of retrievals is generated from the activation-based model with different variances. The bottom figure depicts the parameters of the activation-based model, the full lines in green and red are the mean finishing times tc=Target and tc=Competitor, and the broken lines are finishing times one standard deviation away from the mean. The middle figure shows the distributions of finishing times for target and candidate; since every chunk is associated a potential finishing time, t, both distributions have the same number of elements. The top-most figure shows the distribution of retrieval times (adding the shift parameter \u03c8 would transform it to reading times); since only the winning chunks are retrieved, the distribution of retrieval times for targets has more elements than the distribution of the competitors. Notice that even though the finishing times for the competitors are slower on average than those of the targets (middle plot), the situation is reversed for the retrieval times (top-most plot).",
            "categories": "['cs.CL stat.AP stat.ML']",
            "figure_id": "1612.04174v2-Figure11-1",
            "image_path": "1612.04174v2-Figure11-1.png",
            "instance_id": "084e1832db6b58ba5a6ce9b0850c0825",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific value of the shift parameter \u03c8?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Distribution of z(%) on six datasets. Because the number of candidate summaries for each document is different (short text may have relatively few candidates), we use z / number of candidate summaries as the X-axis. The Y-axis represents the proportion of the best-summaries with this rank in the test set.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Distribution of z(%) on six datasets. Because the number of candidate summaries for each document is different (short text may have relatively few candidates), we use z / number of candidate summaries as the X-axis. The Y-axis represents the proportion of the best-summaries with this rank in the test set.",
            "categories": "['cs.CL']",
            "figure_id": "2004.08795v1-Figure2-1",
            "image_path": "2004.08795v1-Figure2-1.png",
            "instance_id": "24413ad9ec72432a46b765a29095d60f",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the maximum of the enveloping curve of the green area in the bottom left subfigure?",
            "reference_answer": "40%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Distribution of z(%) on six datasets. Because the number of candidate summaries for each document is different (short text may have relatively few candidates), we use z / number of candidate summaries as the X-axis. The Y-axis represents the proportion of the best-summaries with this rank in the test set.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Distribution of z(%) on six datasets. Because the number of candidate summaries for each document is different (short text may have relatively few candidates), we use z / number of candidate summaries as the X-axis. The Y-axis represents the proportion of the best-summaries with this rank in the test set.",
            "categories": "['cs.CL']",
            "figure_id": "2004.08795v1-Figure2-1",
            "image_path": "2004.08795v1-Figure2-1.png",
            "instance_id": "7dbee68b42868de4acfe0aab27b04fef",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "For which dataset does proportion consistently decrease with ranking of Best-Summary?",
            "reference_answer": "XSum"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Distribution of z(%) on six datasets. Because the number of candidate summaries for each document is different (short text may have relatively few candidates), we use z / number of candidate summaries as the X-axis. The Y-axis represents the proportion of the best-summaries with this rank in the test set.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Distribution of z(%) on six datasets. Because the number of candidate summaries for each document is different (short text may have relatively few candidates), we use z / number of candidate summaries as the X-axis. The Y-axis represents the proportion of the best-summaries with this rank in the test set.",
            "categories": "['cs.CL']",
            "figure_id": "2004.08795v1-Figure2-1",
            "image_path": "2004.08795v1-Figure2-1.png",
            "instance_id": "d5c22be8309d73d840dd60b7196c88ca",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the green area exceed a height of 20% in the top left subfigure?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Distribution of z(%) on six datasets. Because the number of candidate summaries for each document is different (short text may have relatively few candidates), we use z / number of candidate summaries as the X-axis. The Y-axis represents the proportion of the best-summaries with this rank in the test set.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Distribution of z(%) on six datasets. Because the number of candidate summaries for each document is different (short text may have relatively few candidates), we use z / number of candidate summaries as the X-axis. The Y-axis represents the proportion of the best-summaries with this rank in the test set.",
            "categories": "['cs.CL']",
            "figure_id": "2004.08795v1-Figure2-1",
            "image_path": "2004.08795v1-Figure2-1.png",
            "instance_id": "2469c225a16c3b464b54eecf85a326ae",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is Multi-News among the datasets represented in the figure?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. Multi-News is among the datasets represented in the figure.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Top left"
                    },
                    {
                        "B": "Top right"
                    },
                    {
                        "C": "Middle left"
                    },
                    {
                        "D": "Middle right"
                    }
                ],
                "caption": "Figure 2: Distribution of z(%) on six datasets. Because the number of candidate summaries for each document is different (short text may have relatively few candidates), we use z / number of candidate summaries as the X-axis. The Y-axis represents the proportion of the best-summaries with this rank in the test set.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Distribution of z(%) on six datasets. Because the number of candidate summaries for each document is different (short text may have relatively few candidates), we use z / number of candidate summaries as the X-axis. The Y-axis represents the proportion of the best-summaries with this rank in the test set.",
            "categories": "['cs.CL']",
            "figure_id": "2004.08795v1-Figure2-1",
            "image_path": "2004.08795v1-Figure2-1.png",
            "instance_id": "80c1297bb5f72898167c33e537d03d77",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which subfigure has a range of 0% to 15% marked on the y axis?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Reddit"
                    },
                    {
                        "B": "XSum"
                    },
                    {
                        "C": "CNN/DM"
                    },
                    {
                        "D": "PubMed"
                    }
                ],
                "caption": "Figure 2: Distribution of z(%) on six datasets. Because the number of candidate summaries for each document is different (short text may have relatively few candidates), we use z / number of candidate summaries as the X-axis. The Y-axis represents the proportion of the best-summaries with this rank in the test set.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Distribution of z(%) on six datasets. Because the number of candidate summaries for each document is different (short text may have relatively few candidates), we use z / number of candidate summaries as the X-axis. The Y-axis represents the proportion of the best-summaries with this rank in the test set.",
            "categories": "['cs.CL']",
            "figure_id": "2004.08795v1-Figure2-1",
            "image_path": "2004.08795v1-Figure2-1.png",
            "instance_id": "d40dc220ca5f8fd8b02c02cc63347b54",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following datasets show the highest proportion of best-summaries with a rank of z(%) between 0% and 5%? ",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ACD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Distribution of z(%) on six datasets. Because the number of candidate summaries for each document is different (short text may have relatively few candidates), we use z / number of candidate summaries as the X-axis. The Y-axis represents the proportion of the best-summaries with this rank in the test set.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Distribution of z(%) on six datasets. Because the number of candidate summaries for each document is different (short text may have relatively few candidates), we use z / number of candidate summaries as the X-axis. The Y-axis represents the proportion of the best-summaries with this rank in the test set.",
            "categories": "['cs.CL']",
            "figure_id": "2004.08795v1-Figure2-1",
            "image_path": "2004.08795v1-Figure2-1.png",
            "instance_id": "960b5878e38dadd78e733e430f9fb242",
            "qa_pair_type": "unanswerable",
            "question": "What is the average number of candidate summaries for each document in the XSum dataset?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5. A comparison of multi-label classification performance with different model initializations.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5. A comparison of multi-label classification performance with different model initializations.",
            "categories": "['cs.CV cs.CL']",
            "figure_id": "1705.02315v5-Figure5-1",
            "image_path": "1705.02315v5-Figure5-1.png",
            "instance_id": "96c1e84433d4dd52ffacef0bd26a6dab",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "Which model initialization has the highest sensitivity value for the red dashed line at 1 - Specificity of 0.2?",
            "reference_answer": "ResNet"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5. A comparison of multi-label classification performance with different model initializations.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5. A comparison of multi-label classification performance with different model initializations.",
            "categories": "['cs.CV cs.CL']",
            "figure_id": "1705.02315v5-Figure5-1",
            "image_path": "1705.02315v5-Figure5-1.png",
            "instance_id": "384f58d8a76eb7b6ebb2eecbf868792a",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the performance metric being compared in Figure 5?",
            "reference_answer": "Sensitivity"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The performance metric being compared in Figure 5 is Sensitivity, plotted against 1-Specificity for different conditions (like Atelectasis, Cardiomegaly, etc.) across various models (ResNet, GoogLeNet, VGGNet, AlexNet).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5. A comparison of multi-label classification performance with different model initializations.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5. A comparison of multi-label classification performance with different model initializations.",
            "categories": "['cs.CV cs.CL']",
            "figure_id": "1705.02315v5-Figure5-1",
            "image_path": "1705.02315v5-Figure5-1.png",
            "instance_id": "c22ccc097bf3b247cb5f4911f091b8ba",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the performance of the red dashed line, representing 'Pneumonia', consistently higher than that of the green dashed line representing 'Pneumothorax' in the second graph?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5. A comparison of multi-label classification performance with different model initializations.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5. A comparison of multi-label classification performance with different model initializations.",
            "categories": "['cs.CV cs.CL']",
            "figure_id": "1705.02315v5-Figure5-1",
            "image_path": "1705.02315v5-Figure5-1.png",
            "instance_id": "44c75edfe2502524509f85ae662af5c3",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does sensitivity increase with specificity for different model initializations?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Top left"
                    },
                    {
                        "B": "Top right"
                    },
                    {
                        "C": "Bottom left"
                    },
                    {
                        "D": "Bottom right"
                    }
                ],
                "caption": "Figure 5. A comparison of multi-label classification performance with different model initializations.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5. A comparison of multi-label classification performance with different model initializations.",
            "categories": "['cs.CV cs.CL']",
            "figure_id": "1705.02315v5-Figure5-1",
            "image_path": "1705.02315v5-Figure5-1.png",
            "instance_id": "9ea007d686d4c8eea47243f0090e4839",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "In which of the four plots does the solid black line reach sensitivity of 0.8 earlier, i.e. at a lower specificity?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "ResNet, VGG, AlexNet"
                    },
                    {
                        "B": "GoogleVec, ResNet"
                    },
                    {
                        "C": "ResNet, VGGhe, GoogleVec, AlexNet"
                    },
                    {
                        "D": "VGGhe, GoogleVec, AlexNet"
                    }
                ],
                "caption": "Figure 5. A comparison of multi-label classification performance with different model initializations.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5. A comparison of multi-label classification performance with different model initializations.",
            "categories": "['cs.CV cs.CL']",
            "figure_id": "1705.02315v5-Figure5-1",
            "image_path": "1705.02315v5-Figure5-1.png",
            "instance_id": "1c47ba0841d67050724db7b8d96fd8e2",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which model initialization methods were compared?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5. A comparison of multi-label classification performance with different model initializations.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5. A comparison of multi-label classification performance with different model initializations.",
            "categories": "['cs.CV cs.CL']",
            "figure_id": "1705.02315v5-Figure5-1",
            "image_path": "1705.02315v5-Figure5-1.png",
            "instance_id": "5b21229a0e99fb48712f6b27fa46e84d",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific data used for training the models, and are the models trained separately for each image?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: The average performance scores (y-axis) of subsets of models (x-axis) selected by domain similarity or training size (scores are averaged over the included models). The oracle always selects the best models.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: The average performance scores (y-axis) of subsets of models (x-axis) selected by domain similarity or training size (scores are averaged over the included models). The oracle always selects the best models.",
            "categories": "['cs.CL cs.IR']",
            "figure_id": "2010.00980v1-Figure3-1",
            "image_path": "2010.00980v1-Figure3-1.png",
            "instance_id": "75cf626aff18dcb3ec5fc139cb8343e4",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the maximum value of the red line in the first plot from the left?",
            "reference_answer": "Approximately 0.57"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: The average performance scores (y-axis) of subsets of models (x-axis) selected by domain similarity or training size (scores are averaged over the included models). The oracle always selects the best models.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: The average performance scores (y-axis) of subsets of models (x-axis) selected by domain similarity or training size (scores are averaged over the included models). The oracle always selects the best models.",
            "categories": "['cs.CL cs.IR']",
            "figure_id": "2010.00980v1-Figure3-1",
            "image_path": "2010.00980v1-Figure3-1.png",
            "instance_id": "04ff19e01811c54acd8e9007dc9b9a4f",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "Which selection method, domain similarity or training size, has the highest average performance score when all models are included for the 'SE Apple' subset?",
            "reference_answer": "Both seem more or less equal."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: The average performance scores (y-axis) of subsets of models (x-axis) selected by domain similarity or training size (scores are averaged over the included models). The oracle always selects the best models.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: The average performance scores (y-axis) of subsets of models (x-axis) selected by domain similarity or training size (scores are averaged over the included models). The oracle always selects the best models.",
            "categories": "['cs.CL cs.IR']",
            "figure_id": "2010.00980v1-Figure3-1",
            "image_path": "2010.00980v1-Figure3-1.png",
            "instance_id": "44bb5e36350c48eb7a2efb5a1d9489e7",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "In the plot labeled 'SE Travel', does the red line representing 'Domain Similarity' always trend upwards?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, the red line representing 'Domain Similarity' does not always trend upwards in the plot labeled 'SE Travel'.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: The average performance scores (y-axis) of subsets of models (x-axis) selected by domain similarity or training size (scores are averaged over the included models). The oracle always selects the best models.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: The average performance scores (y-axis) of subsets of models (x-axis) selected by domain similarity or training size (scores are averaged over the included models). The oracle always selects the best models.",
            "categories": "['cs.CL cs.IR']",
            "figure_id": "2010.00980v1-Figure3-1",
            "image_path": "2010.00980v1-Figure3-1.png",
            "instance_id": "65027e13942a9cb011f692efdb9e1c7c",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the 'Domain Similarity' selection method always achieve the highest average performance score?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Top center"
                    },
                    {
                        "B": "Middle row right"
                    },
                    {
                        "C": "Top right"
                    },
                    {
                        "D": "Bottom center"
                    }
                ],
                "caption": "Figure 3: The average performance scores (y-axis) of subsets of models (x-axis) selected by domain similarity or training size (scores are averaged over the included models). The oracle always selects the best models.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: The average performance scores (y-axis) of subsets of models (x-axis) selected by domain similarity or training size (scores are averaged over the included models). The oracle always selects the best models.",
            "categories": "['cs.CL cs.IR']",
            "figure_id": "2010.00980v1-Figure3-1",
            "image_path": "2010.00980v1-Figure3-1.png",
            "instance_id": "2c646ae826829d8a92bfd8e5407d758a",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which plot has the highest average performance score for models selected by training size (black line)?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A B C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "InsuranceQA"
                    },
                    {
                        "B": "SE Travel"
                    },
                    {
                        "C": "SE Cooking"
                    },
                    {
                        "D": "WikiPassageQA"
                    }
                ],
                "caption": "Figure 3: The average performance scores (y-axis) of subsets of models (x-axis) selected by domain similarity or training size (scores are averaged over the included models). The oracle always selects the best models.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: The average performance scores (y-axis) of subsets of models (x-axis) selected by domain similarity or training size (scores are averaged over the included models). The oracle always selects the best models.",
            "categories": "['cs.CL cs.IR']",
            "figure_id": "2010.00980v1-Figure3-1",
            "image_path": "2010.00980v1-Figure3-1.png",
            "instance_id": "ff22199f98c838c4805b4e0994f76780",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "For which one does one performance score remain consistently higher than the other for all different values of included models?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: The average performance scores (y-axis) of subsets of models (x-axis) selected by domain similarity or training size (scores are averaged over the included models). The oracle always selects the best models.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: The average performance scores (y-axis) of subsets of models (x-axis) selected by domain similarity or training size (scores are averaged over the included models). The oracle always selects the best models.",
            "categories": "['cs.CL cs.IR']",
            "figure_id": "2010.00980v1-Figure3-1",
            "image_path": "2010.00980v1-Figure3-1.png",
            "instance_id": "a30edb842464c8f5c556e3b9642322e0",
            "qa_pair_type": "unanswerable",
            "question": "What is the performance score of the best performing model for the SemEval17 dataset?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Learning curves. Left: NIST ZH-to-EN; Right EN-to-DE.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Learning curves. Left: NIST ZH-to-EN; Right EN-to-DE.",
            "categories": "['cs.CL']",
            "figure_id": "1805.00178v3-Figure1-1",
            "image_path": "1805.00178v3-Figure1-1.png",
            "instance_id": "e2d0a72524be5577604ab8fd82e4eece",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the maximum value of the orange line in the right plot?",
            "reference_answer": "Between 17 and 18"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Learning curves. Left: NIST ZH-to-EN; Right EN-to-DE.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Learning curves. Left: NIST ZH-to-EN; Right EN-to-DE.",
            "categories": "['cs.CL']",
            "figure_id": "1805.00178v3-Figure1-1",
            "image_path": "1805.00178v3-Figure1-1.png",
            "instance_id": "0c6a053ffabfce91e7116ceb9d1d0f5b",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "How many models were plotted?",
            "reference_answer": "6"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Learning curves. Left: NIST ZH-to-EN; Right EN-to-DE.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Learning curves. Left: NIST ZH-to-EN; Right EN-to-DE.",
            "categories": "['cs.CL']",
            "figure_id": "1805.00178v3-Figure1-1",
            "image_path": "1805.00178v3-Figure1-1.png",
            "instance_id": "36993d155f8804050052127efbbe3bb5",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the green line in the left graph reach the highest value at the end of the x-axis?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The green line in the left graph reaches the highest value at the end of the x-axis.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Learning curves. Left: NIST ZH-to-EN; Right EN-to-DE.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Learning curves. Left: NIST ZH-to-EN; Right EN-to-DE.",
            "categories": "['cs.CL']",
            "figure_id": "1805.00178v3-Figure1-1",
            "image_path": "1805.00178v3-Figure1-1.png",
            "instance_id": "44ff691d98787d957a99e2b12a4ce889",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the 'Ko\u00e7mi' model achieve a higher BLEU score than the 'Vanilla' model in both scenarios?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The black line"
                    },
                    {
                        "B": "The gray line"
                    },
                    {
                        "C": "The green line"
                    },
                    {
                        "D": "The blue line"
                    }
                ],
                "caption": "Figure 1: Learning curves. Left: NIST ZH-to-EN; Right EN-to-DE.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Learning curves. Left: NIST ZH-to-EN; Right EN-to-DE.",
            "categories": "['cs.CL']",
            "figure_id": "1805.00178v3-Figure1-1",
            "image_path": "1805.00178v3-Figure1-1.png",
            "instance_id": "c9a72d4b47170e15f2ff9c606f0fb0fe",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which lines on the left graph have a maximum value greater than 35?",
            "reference_answer": "B,C,D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "CDC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Chinese to English"
                    },
                    {
                        "B": "English to German"
                    },
                    {
                        "C": "Both"
                    },
                    {
                        "D": "Neither"
                    }
                ],
                "caption": "Figure 1: Learning curves. Left: NIST ZH-to-EN; Right EN-to-DE.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Learning curves. Left: NIST ZH-to-EN; Right EN-to-DE.",
            "categories": "['cs.CL']",
            "figure_id": "1805.00178v3-Figure1-1",
            "image_path": "1805.00178v3-Figure1-1.png",
            "instance_id": "c13e3902ec62051f3482cd5ca86bd120",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following language pairs always has a BLEU score higher than 5 for all values of training batches (K)?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Learning curves. Left: NIST ZH-to-EN; Right EN-to-DE.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Learning curves. Left: NIST ZH-to-EN; Right EN-to-DE.",
            "categories": "['cs.CL']",
            "figure_id": "1805.00178v3-Figure1-1",
            "image_path": "1805.00178v3-Figure1-1.png",
            "instance_id": "2c26a5c9de1a18f14ed695d18996ec79",
            "qa_pair_type": "unanswerable",
            "question": "What dataset was used in the experiment?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Accuracy (%) of overall-best model with attention only from first layer (bottom1), first two layers (bottom2), . . . , last two layers (top2), top layer only (top1). Means and standard deviations across 5 seeds. Dashed lines show full multi-layer attention results.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Accuracy (%) of overall-best model with attention only from first layer (bottom1), first two layers (bottom2), . . . , last two layers (top2), top layer only (top1). Means and standard deviations across 5 seeds. Dashed lines show full multi-layer attention results.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "1905.08527v1-Figure4-1",
            "image_path": "1905.08527v1-Figure4-1.png",
            "instance_id": "1cc06c63415a6196bf1810ca5da921df",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the accuracy value of the solid green line at the 'top2' position?",
            "reference_answer": "Between 50 and 60"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Accuracy (%) of overall-best model with attention only from first layer (bottom1), first two layers (bottom2), . . . , last two layers (top2), top layer only (top1). Means and standard deviations across 5 seeds. Dashed lines show full multi-layer attention results.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Accuracy (%) of overall-best model with attention only from first layer (bottom1), first two layers (bottom2), . . . , last two layers (top2), top layer only (top1). Means and standard deviations across 5 seeds. Dashed lines show full multi-layer attention results.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "1905.08527v1-Figure4-1",
            "image_path": "1905.08527v1-Figure4-1.png",
            "instance_id": "01249522f3972b9652bbb43eb36df123",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the model accuracy of the \"around-right\" approach when considering only the last two layers?",
            "reference_answer": "Between 40 and 50"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Accuracy (%) of overall-best model with attention only from first layer (bottom1), first two layers (bottom2), . . . , last two layers (top2), top layer only (top1). Means and standard deviations across 5 seeds. Dashed lines show full multi-layer attention results.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Accuracy (%) of overall-best model with attention only from first layer (bottom1), first two layers (bottom2), . . . , last two layers (top2), top layer only (top1). Means and standard deviations across 5 seeds. Dashed lines show full multi-layer attention results.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "1905.08527v1-Figure4-1",
            "image_path": "1905.08527v1-Figure4-1.png",
            "instance_id": "1f1ded4d1beed9e3f1397d1f5e9e032b",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the solid green line consistently higher than the solid blue line?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Accuracy (%) of overall-best model with attention only from first layer (bottom1), first two layers (bottom2), . . . , last two layers (top2), top layer only (top1). Means and standard deviations across 5 seeds. Dashed lines show full multi-layer attention results.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Accuracy (%) of overall-best model with attention only from first layer (bottom1), first two layers (bottom2), . . . , last two layers (top2), top layer only (top1). Means and standard deviations across 5 seeds. Dashed lines show full multi-layer attention results.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "1905.08527v1-Figure4-1",
            "image_path": "1905.08527v1-Figure4-1.png",
            "instance_id": "2caa20df5d866835301d8fc58f8ba1b4",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the accuracy of the 'around-right' model decrease consistently from 'bottom1' to 'top1'?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Solid red line"
                    },
                    {
                        "B": "Solid green line"
                    },
                    {
                        "C": "Solid blue line"
                    },
                    {
                        "D": "All are equal"
                    }
                ],
                "caption": "Figure 4: Accuracy (%) of overall-best model with attention only from first layer (bottom1), first two layers (bottom2), . . . , last two layers (top2), top layer only (top1). Means and standard deviations across 5 seeds. Dashed lines show full multi-layer attention results.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Accuracy (%) of overall-best model with attention only from first layer (bottom1), first two layers (bottom2), . . . , last two layers (top2), top layer only (top1). Means and standard deviations across 5 seeds. Dashed lines show full multi-layer attention results.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "1905.08527v1-Figure4-1",
            "image_path": "1905.08527v1-Figure4-1.png",
            "instance_id": "2ee479e427d068eb22d982c03fa8167a",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following line types has the highest value at 'bottom2'?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "random"
                    },
                    {
                        "B": "jump"
                    },
                    {
                        "C": "around-right"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 4: Accuracy (%) of overall-best model with attention only from first layer (bottom1), first two layers (bottom2), . . . , last two layers (top2), top layer only (top1). Means and standard deviations across 5 seeds. Dashed lines show full multi-layer attention results.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Accuracy (%) of overall-best model with attention only from first layer (bottom1), first two layers (bottom2), . . . , last two layers (top2), top layer only (top1). Means and standard deviations across 5 seeds. Dashed lines show full multi-layer attention results.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "1905.08527v1-Figure4-1",
            "image_path": "1905.08527v1-Figure4-1.png",
            "instance_id": "51124511909216b48882c368080e80f8",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following models have an accuracy greater than 60% when attention comes from the top three layers?",
            "reference_answer": "A,C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "BC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Accuracy (%) of overall-best model with attention only from first layer (bottom1), first two layers (bottom2), . . . , last two layers (top2), top layer only (top1). Means and standard deviations across 5 seeds. Dashed lines show full multi-layer attention results.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Accuracy (%) of overall-best model with attention only from first layer (bottom1), first two layers (bottom2), . . . , last two layers (top2), top layer only (top1). Means and standard deviations across 5 seeds. Dashed lines show full multi-layer attention results.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "1905.08527v1-Figure4-1",
            "image_path": "1905.08527v1-Figure4-1.png",
            "instance_id": "e5277eecaebfb1e51831d9a882954e92",
            "qa_pair_type": "unanswerable",
            "question": "What specific task or dataset was used to evaluate the model's accuracy in this figure?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Effect of increased batch size for training and of tuning on data selected for the test set. The red line shows the learning curve for the original training settings (mini-batches of ca. 1,200 sentence pairs). The other lines are the learning curves for models that were initialised with the model parameters of another model at some point in its training process (specifically: at the point where the new learning curve branches off), and then trained with increased batch sizes on the same data (blue and magenta lines), or on data specifically selected to contain rare n-grams that also occur in the test / validation set.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Effect of increased batch size for training and of tuning on data selected for the test set. The red line shows the learning curve for the original training settings (mini-batches of ca. 1,200 sentence pairs). The other lines are the learning curves for models that were initialised with the model parameters of another model at some point in its training process (specifically: at the point where the new learning curve branches off), and then trained with increased batch sizes on the same data (blue and magenta lines), or on data specifically selected to contain rare n-grams that also occur in the test / validation set.",
            "categories": "['cs.CL']",
            "figure_id": "1907.05854v1-Figure4-1",
            "image_path": "1907.05854v1-Figure4-1.png",
            "instance_id": "8b31afb2f259b7222f6bdc6c87e3596c",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate batch size of the model represented by the blue line?",
            "reference_answer": "13K sentence pairs/batch"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The approximate batch size of the model represented by the blue line is 22K sentence pairs per batch.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Effect of increased batch size for training and of tuning on data selected for the test set. The red line shows the learning curve for the original training settings (mini-batches of ca. 1,200 sentence pairs). The other lines are the learning curves for models that were initialised with the model parameters of another model at some point in its training process (specifically: at the point where the new learning curve branches off), and then trained with increased batch sizes on the same data (blue and magenta lines), or on data specifically selected to contain rare n-grams that also occur in the test / validation set.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Effect of increased batch size for training and of tuning on data selected for the test set. The red line shows the learning curve for the original training settings (mini-batches of ca. 1,200 sentence pairs). The other lines are the learning curves for models that were initialised with the model parameters of another model at some point in its training process (specifically: at the point where the new learning curve branches off), and then trained with increased batch sizes on the same data (blue and magenta lines), or on data specifically selected to contain rare n-grams that also occur in the test / validation set.",
            "categories": "['cs.CL']",
            "figure_id": "1907.05854v1-Figure4-1",
            "image_path": "1907.05854v1-Figure4-1.png",
            "instance_id": "d6b878c8a16d24eee96664f8504873c2",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the maximum BLEU achieved by any one of the training processes at any amount of data seen?",
            "reference_answer": "Approximately 49"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The maximum BLEU score achieved by any one of the training processes is approximately 48.5.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Effect of increased batch size for training and of tuning on data selected for the test set. The red line shows the learning curve for the original training settings (mini-batches of ca. 1,200 sentence pairs). The other lines are the learning curves for models that were initialised with the model parameters of another model at some point in its training process (specifically: at the point where the new learning curve branches off), and then trained with increased batch sizes on the same data (blue and magenta lines), or on data specifically selected to contain rare n-grams that also occur in the test / validation set.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Effect of increased batch size for training and of tuning on data selected for the test set. The red line shows the learning curve for the original training settings (mini-batches of ca. 1,200 sentence pairs). The other lines are the learning curves for models that were initialised with the model parameters of another model at some point in its training process (specifically: at the point where the new learning curve branches off), and then trained with increased batch sizes on the same data (blue and magenta lines), or on data specifically selected to contain rare n-grams that also occur in the test / validation set.",
            "categories": "['cs.CL']",
            "figure_id": "1907.05854v1-Figure4-1",
            "image_path": "1907.05854v1-Figure4-1.png",
            "instance_id": "e15a053d9aa3bbde32c2092de6db0a7b",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the red line reach a higher validation BLEU score than any other line in the figure?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, the red line does not reach a higher validation BLEU score than any other line in the figure.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Effect of increased batch size for training and of tuning on data selected for the test set. The red line shows the learning curve for the original training settings (mini-batches of ca. 1,200 sentence pairs). The other lines are the learning curves for models that were initialised with the model parameters of another model at some point in its training process (specifically: at the point where the new learning curve branches off), and then trained with increased batch sizes on the same data (blue and magenta lines), or on data specifically selected to contain rare n-grams that also occur in the test / validation set.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Effect of increased batch size for training and of tuning on data selected for the test set. The red line shows the learning curve for the original training settings (mini-batches of ca. 1,200 sentence pairs). The other lines are the learning curves for models that were initialised with the model parameters of another model at some point in its training process (specifically: at the point where the new learning curve branches off), and then trained with increased batch sizes on the same data (blue and magenta lines), or on data specifically selected to contain rare n-grams that also occur in the test / validation set.",
            "categories": "['cs.CL']",
            "figure_id": "1907.05854v1-Figure4-1",
            "image_path": "1907.05854v1-Figure4-1.png",
            "instance_id": "6be4c1b594d4b48139fa6b70fe2107f0",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the BLEU score consistently increase with amount of data seen on any one of the training processes starting from its point of initialization?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Blue line"
                    },
                    {
                        "B": "Red line"
                    },
                    {
                        "C": "Magenta line"
                    },
                    {
                        "D": "Light blue line"
                    }
                ],
                "caption": "Figure 4: Effect of increased batch size for training and of tuning on data selected for the test set. The red line shows the learning curve for the original training settings (mini-batches of ca. 1,200 sentence pairs). The other lines are the learning curves for models that were initialised with the model parameters of another model at some point in its training process (specifically: at the point where the new learning curve branches off), and then trained with increased batch sizes on the same data (blue and magenta lines), or on data specifically selected to contain rare n-grams that also occur in the test / validation set.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Effect of increased batch size for training and of tuning on data selected for the test set. The red line shows the learning curve for the original training settings (mini-batches of ca. 1,200 sentence pairs). The other lines are the learning curves for models that were initialised with the model parameters of another model at some point in its training process (specifically: at the point where the new learning curve branches off), and then trained with increased batch sizes on the same data (blue and magenta lines), or on data specifically selected to contain rare n-grams that also occur in the test / validation set.",
            "categories": "['cs.CL']",
            "figure_id": "1907.05854v1-Figure4-1",
            "image_path": "1907.05854v1-Figure4-1.png",
            "instance_id": "7f715d93ea72ea3954dab7e00c523125",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line represents the learning curve for the model that was trained with the increased batch size of approximately 9K sentence pairs per batch?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "ca. 1.2K sentence pairs/batch"
                    },
                    {
                        "B": "ca. 9K sentence pairs/batch"
                    },
                    {
                        "C": "ca. 13K sentence pairs/batch"
                    },
                    {
                        "D": "ca. 22K sentence pairs/batch"
                    }
                ],
                "caption": "Figure 4: Effect of increased batch size for training and of tuning on data selected for the test set. The red line shows the learning curve for the original training settings (mini-batches of ca. 1,200 sentence pairs). The other lines are the learning curves for models that were initialised with the model parameters of another model at some point in its training process (specifically: at the point where the new learning curve branches off), and then trained with increased batch sizes on the same data (blue and magenta lines), or on data specifically selected to contain rare n-grams that also occur in the test / validation set.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Effect of increased batch size for training and of tuning on data selected for the test set. The red line shows the learning curve for the original training settings (mini-batches of ca. 1,200 sentence pairs). The other lines are the learning curves for models that were initialised with the model parameters of another model at some point in its training process (specifically: at the point where the new learning curve branches off), and then trained with increased batch sizes on the same data (blue and magenta lines), or on data specifically selected to contain rare n-grams that also occur in the test / validation set.",
            "categories": "['cs.CL']",
            "figure_id": "1907.05854v1-Figure4-1",
            "image_path": "1907.05854v1-Figure4-1.png",
            "instance_id": "6273717e8644f7428c09dff2a69d6246",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "The training process of which batch size was carried out furthest along the amount of seen data?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Effect of increased batch size for training and of tuning on data selected for the test set. The red line shows the learning curve for the original training settings (mini-batches of ca. 1,200 sentence pairs). The other lines are the learning curves for models that were initialised with the model parameters of another model at some point in its training process (specifically: at the point where the new learning curve branches off), and then trained with increased batch sizes on the same data (blue and magenta lines), or on data specifically selected to contain rare n-grams that also occur in the test / validation set.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Effect of increased batch size for training and of tuning on data selected for the test set. The red line shows the learning curve for the original training settings (mini-batches of ca. 1,200 sentence pairs). The other lines are the learning curves for models that were initialised with the model parameters of another model at some point in its training process (specifically: at the point where the new learning curve branches off), and then trained with increased batch sizes on the same data (blue and magenta lines), or on data specifically selected to contain rare n-grams that also occur in the test / validation set.",
            "categories": "['cs.CL']",
            "figure_id": "1907.05854v1-Figure4-1",
            "image_path": "1907.05854v1-Figure4-1.png",
            "instance_id": "1f8d601f8824edbbd41811d5f8c3a161",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific training process used to initialize the model parameters for the blue and magenta learning curves?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4. Entropy and reward (from BERT-grams and n-grams) of the generative model over the course of training. The vertical dotted line indicates the end of ML pre-training.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4. Entropy and reward (from BERT-grams and n-grams) of the generative model over the course of training. The vertical dotted line indicates the end of ML pre-training.",
            "categories": "['cs.LG cs.CL stat.ML']",
            "figure_id": "2003.02738v1-Figure4-1",
            "image_path": "2003.02738v1-Figure4-1.png",
            "instance_id": "726773b31f52a0a8a797b6ced2aacb74",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the reward at the end of ML pre-training for the dashed red line?",
            "reference_answer": "Between 0.5 and 0.6"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4. Entropy and reward (from BERT-grams and n-grams) of the generative model over the course of training. The vertical dotted line indicates the end of ML pre-training.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4. Entropy and reward (from BERT-grams and n-grams) of the generative model over the course of training. The vertical dotted line indicates the end of ML pre-training.",
            "categories": "['cs.LG cs.CL stat.ML']",
            "figure_id": "2003.02738v1-Figure4-1",
            "image_path": "2003.02738v1-Figure4-1.png",
            "instance_id": "33b52e430c7c3a82c133bb92bd0384b2",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the approximate reward of R BERT-gram after 1.4 training steps?",
            "reference_answer": "Approximately 0.4"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4. Entropy and reward (from BERT-grams and n-grams) of the generative model over the course of training. The vertical dotted line indicates the end of ML pre-training.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4. Entropy and reward (from BERT-grams and n-grams) of the generative model over the course of training. The vertical dotted line indicates the end of ML pre-training.",
            "categories": "['cs.LG cs.CL stat.ML']",
            "figure_id": "2003.02738v1-Figure4-1",
            "image_path": "2003.02738v1-Figure4-1.png",
            "instance_id": "331a6c17acfe9caab2e519deaf9f1b2f",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the blue line represent the value of the reward?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the blue line represents the value of the reward.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4. Entropy and reward (from BERT-grams and n-grams) of the generative model over the course of training. The vertical dotted line indicates the end of ML pre-training.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4. Entropy and reward (from BERT-grams and n-grams) of the generative model over the course of training. The vertical dotted line indicates the end of ML pre-training.",
            "categories": "['cs.LG cs.CL stat.ML']",
            "figure_id": "2003.02738v1-Figure4-1",
            "image_path": "2003.02738v1-Figure4-1.png",
            "instance_id": "b6dbd738ff8433de28b57f7a59718451",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Has the entropy of the generative model increased by the end of ML pre-training compared to the beginning of the range on the training steps axis?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The blue line"
                    },
                    {
                        "B": "The red line"
                    },
                    {
                        "C": "The dashed red line"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 4. Entropy and reward (from BERT-grams and n-grams) of the generative model over the course of training. The vertical dotted line indicates the end of ML pre-training.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4. Entropy and reward (from BERT-grams and n-grams) of the generative model over the course of training. The vertical dotted line indicates the end of ML pre-training.",
            "categories": "['cs.LG cs.CL stat.ML']",
            "figure_id": "2003.02738v1-Figure4-1",
            "image_path": "2003.02738v1-Figure4-1.png",
            "instance_id": "a702489bacd3fba342f0e89602fcef0c",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line represents the reward from BERT-grams?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Reward"
                    },
                    {
                        "B": "Entropy"
                    },
                    {
                        "C": "Accuracy"
                    },
                    {
                        "D": "Precision"
                    }
                ],
                "caption": "Figure 4. Entropy and reward (from BERT-grams and n-grams) of the generative model over the course of training. The vertical dotted line indicates the end of ML pre-training.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4. Entropy and reward (from BERT-grams and n-grams) of the generative model over the course of training. The vertical dotted line indicates the end of ML pre-training.",
            "categories": "['cs.LG cs.CL stat.ML']",
            "figure_id": "2003.02738v1-Figure4-1",
            "image_path": "2003.02738v1-Figure4-1.png",
            "instance_id": "4b836252efc3bf1451b8316841e52a2e",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following metrics are evaluated in the training process of the generative model?",
            "reference_answer": "AB"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4. Entropy and reward (from BERT-grams and n-grams) of the generative model over the course of training. The vertical dotted line indicates the end of ML pre-training.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4. Entropy and reward (from BERT-grams and n-grams) of the generative model over the course of training. The vertical dotted line indicates the end of ML pre-training.",
            "categories": "['cs.LG cs.CL stat.ML']",
            "figure_id": "2003.02738v1-Figure4-1",
            "image_path": "2003.02738v1-Figure4-1.png",
            "instance_id": "9b6afb67d0f169a3b7beee7e2a05315d",
            "qa_pair_type": "unanswerable",
            "question": "How many datapoints were collected to draw this graph?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Performance of different methods of UT using varying amounts of training data on ATIS (a), SNIPS (d), Domain-A (b), Domain-B (e). Performance on Domain A and B using UT+ST is presented in (c) and (f). The y-scale of (b) and (e) is kept same as (c) and (f) respectively for comparison. Best viewed in color.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Performance of different methods of UT using varying amounts of training data on ATIS (a), SNIPS (d), Domain-A (b), Domain-B (e). Performance on Domain A and B using UT+ST is presented in (c) and (f). The y-scale of (b) and (e) is kept same as (c) and (f) respectively for comparison. Best viewed in color.",
            "categories": "['cs.CL cs.AI cs.LG stat.ML']",
            "figure_id": "1811.05370v1-Figure3-1",
            "image_path": "1811.05370v1-Figure3-1.png",
            "instance_id": "b09281b6dfc517fc9ae690920d803a6f",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the black line at 1000 training samples in the bottom center graph?",
            "reference_answer": "Between 40 and 50"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Performance of different methods of UT using varying amounts of training data on ATIS (a), SNIPS (d), Domain-A (b), Domain-B (e). Performance on Domain A and B using UT+ST is presented in (c) and (f). The y-scale of (b) and (e) is kept same as (c) and (f) respectively for comparison. Best viewed in color.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Performance of different methods of UT using varying amounts of training data on ATIS (a), SNIPS (d), Domain-A (b), Domain-B (e). Performance on Domain A and B using UT+ST is presented in (c) and (f). The y-scale of (b) and (e) is kept same as (c) and (f) respectively for comparison. Best viewed in color.",
            "categories": "['cs.CL cs.AI cs.LG stat.ML']",
            "figure_id": "1811.05370v1-Figure3-1",
            "image_path": "1811.05370v1-Figure3-1.png",
            "instance_id": "02c4ad8273362d921150bbe7471f4ccb",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "Which method shows the lowest SER when using 1000 training samples on SNIPS?",
            "reference_answer": "ELMo"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Performance of different methods of UT using varying amounts of training data on ATIS (a), SNIPS (d), Domain-A (b), Domain-B (e). Performance on Domain A and B using UT+ST is presented in (c) and (f). The y-scale of (b) and (e) is kept same as (c) and (f) respectively for comparison. Best viewed in color.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Performance of different methods of UT using varying amounts of training data on ATIS (a), SNIPS (d), Domain-A (b), Domain-B (e). Performance on Domain A and B using UT+ST is presented in (c) and (f). The y-scale of (b) and (e) is kept same as (c) and (f) respectively for comparison. Best viewed in color.",
            "categories": "['cs.CL cs.AI cs.LG stat.ML']",
            "figure_id": "1811.05370v1-Figure3-1",
            "image_path": "1811.05370v1-Figure3-1.png",
            "instance_id": "5ba8ea0bb5b72d99a0e590d1a8023ace",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "In the top center graph, is the performance of the red line higher than the performance of the green line at the training sample size of 2000?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Performance of different methods of UT using varying amounts of training data on ATIS (a), SNIPS (d), Domain-A (b), Domain-B (e). Performance on Domain A and B using UT+ST is presented in (c) and (f). The y-scale of (b) and (e) is kept same as (c) and (f) respectively for comparison. Best viewed in color.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Performance of different methods of UT using varying amounts of training data on ATIS (a), SNIPS (d), Domain-A (b), Domain-B (e). Performance on Domain A and B using UT+ST is presented in (c) and (f). The y-scale of (b) and (e) is kept same as (c) and (f) respectively for comparison. Best viewed in color.",
            "categories": "['cs.CL cs.AI cs.LG stat.ML']",
            "figure_id": "1811.05370v1-Figure3-1",
            "image_path": "1811.05370v1-Figure3-1.png",
            "instance_id": "dbce24573797d42f07ca0cde8a95de85",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the performance of all methods improve when using more training data?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the performance of all methods generally improves when using more training data, as indicated by the decrease in the SER (Sample Error Rate) across the graphs for all cases.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Red dotted line"
                    },
                    {
                        "B": "Green dashed line"
                    },
                    {
                        "C": "Blue dashed line"
                    },
                    {
                        "D": "Black solid line"
                    }
                ],
                "caption": "Figure 3: Performance of different methods of UT using varying amounts of training data on ATIS (a), SNIPS (d), Domain-A (b), Domain-B (e). Performance on Domain A and B using UT+ST is presented in (c) and (f). The y-scale of (b) and (e) is kept same as (c) and (f) respectively for comparison. Best viewed in color.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Performance of different methods of UT using varying amounts of training data on ATIS (a), SNIPS (d), Domain-A (b), Domain-B (e). Performance on Domain A and B using UT+ST is presented in (c) and (f). The y-scale of (b) and (e) is kept same as (c) and (f) respectively for comparison. Best viewed in color.",
            "categories": "['cs.CL cs.AI cs.LG stat.ML']",
            "figure_id": "1811.05370v1-Figure3-1",
            "image_path": "1811.05370v1-Figure3-1.png",
            "instance_id": "23f789d3e7e84f24db5b36439a9e8a87",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line represents the performance of ELMo with ST?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "No-UT, FastText, ELMo, ELMoL"
                    },
                    {
                        "B": "No-UT, FastText, ELMo, ELMoM"
                    },
                    {
                        "C": "No-UT, FastText, ELMo, ELMoS"
                    },
                    {
                        "D": "No-UT, FastText, ELMo, ELMoG"
                    }
                ],
                "caption": "Figure 3: Performance of different methods of UT using varying amounts of training data on ATIS (a), SNIPS (d), Domain-A (b), Domain-B (e). Performance on Domain A and B using UT+ST is presented in (c) and (f). The y-scale of (b) and (e) is kept same as (c) and (f) respectively for comparison. Best viewed in color.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Performance of different methods of UT using varying amounts of training data on ATIS (a), SNIPS (d), Domain-A (b), Domain-B (e). Performance on Domain A and B using UT+ST is presented in (c) and (f). The y-scale of (b) and (e) is kept same as (c) and (f) respectively for comparison. Best viewed in color.",
            "categories": "['cs.CL cs.AI cs.LG stat.ML']",
            "figure_id": "1811.05370v1-Figure3-1",
            "image_path": "1811.05370v1-Figure3-1.png",
            "instance_id": "47aaf8743210628ab064ce264fd2fd7a",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which methods are being compared in Figure 3?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Performance of different methods of UT using varying amounts of training data on ATIS (a), SNIPS (d), Domain-A (b), Domain-B (e). Performance on Domain A and B using UT+ST is presented in (c) and (f). The y-scale of (b) and (e) is kept same as (c) and (f) respectively for comparison. Best viewed in color.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Performance of different methods of UT using varying amounts of training data on ATIS (a), SNIPS (d), Domain-A (b), Domain-B (e). Performance on Domain A and B using UT+ST is presented in (c) and (f). The y-scale of (b) and (e) is kept same as (c) and (f) respectively for comparison. Best viewed in color.",
            "categories": "['cs.CL cs.AI cs.LG stat.ML']",
            "figure_id": "1811.05370v1-Figure3-1",
            "image_path": "1811.05370v1-Figure3-1.png",
            "instance_id": "12459fbdf46146883ce4603944f02e56",
            "qa_pair_type": "unanswerable",
            "question": "What task was performance evaluated on?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The performance was evaluated on tasks related to ATIS and SNIPS datasets.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 6: ConvSE Analysis. Left : comparison of moment generation methods. Right : comparison of ConvSE filters with different kernel sizes (k)",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 6: ConvSE Analysis. Left : comparison of moment generation methods. Right : comparison of ConvSE filters with different kernel sizes (k)",
            "categories": "['cs.CV cs.CL cs.IR']",
            "figure_id": "2001.09099v2-Figure6-1",
            "image_path": "2001.09099v2-Figure6-1.png",
            "instance_id": "64ed7e57c61cecc223e5977e644f4473",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of the green line at a temporal IoU of 0.6 in the leftmost figure?",
            "reference_answer": "Between 2 and 3"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 6: ConvSE Analysis. Left : comparison of moment generation methods. Right : comparison of ConvSE filters with different kernel sizes (k)",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 6: ConvSE Analysis. Left : comparison of moment generation methods. Right : comparison of ConvSE filters with different kernel sizes (k)",
            "categories": "['cs.CV cs.CL cs.IR']",
            "figure_id": "2001.09099v2-Figure6-1",
            "image_path": "2001.09099v2-Figure6-1.png",
            "instance_id": "0f36a11cec066bfd26bfbc701548feda",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "Which task type shows the highest recall@1 for the 'k=1' ConvSE filter across all values of Temporal IoU?",
            "reference_answer": "SVMR"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 6: ConvSE Analysis. Left : comparison of moment generation methods. Right : comparison of ConvSE filters with different kernel sizes (k)",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 6: ConvSE Analysis. Left : comparison of moment generation methods. Right : comparison of ConvSE filters with different kernel sizes (k)",
            "categories": "['cs.CV cs.CL cs.IR']",
            "figure_id": "2001.09099v2-Figure6-1",
            "image_path": "2001.09099v2-Figure6-1.png",
            "instance_id": "ff7861b671881b3fc3b1e4be4a34f569",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the green line in the leftmost plot representing ConvSE consistently above the red line representing SlidingWindow?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, the green line representing ConvSE is not consistently above the red line representing SlidingWindow in the leftmost plot. As the temporal IoU increases, the ConvSE line falls below the SlidingWindow line.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 6: ConvSE Analysis. Left : comparison of moment generation methods. Right : comparison of ConvSE filters with different kernel sizes (k)",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 6: ConvSE Analysis. Left : comparison of moment generation methods. Right : comparison of ConvSE filters with different kernel sizes (k)",
            "categories": "['cs.CV cs.CL cs.IR']",
            "figure_id": "2001.09099v2-Figure6-1",
            "image_path": "2001.09099v2-Figure6-1.png",
            "instance_id": "1c41ee45e985cb973b227626af1a7f14",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the ConvSE method outperform the TAG method in terms of recall at temporal IoU of 0.2?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The brown line"
                    },
                    {
                        "B": "The red line"
                    },
                    {
                        "C": "The green line"
                    },
                    {
                        "D": "The purple line"
                    }
                ],
                "caption": "Fig. 6: ConvSE Analysis. Left : comparison of moment generation methods. Right : comparison of ConvSE filters with different kernel sizes (k)",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 6: ConvSE Analysis. Left : comparison of moment generation methods. Right : comparison of ConvSE filters with different kernel sizes (k)",
            "categories": "['cs.CV cs.CL cs.IR']",
            "figure_id": "2001.09099v2-Figure6-1",
            "image_path": "2001.09099v2-Figure6-1.png",
            "instance_id": "447534240a884036a76124775eb3080b",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following line colors have the lowest value at a temporal IoU of 0.2 in the third subplot from the left?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "BC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "VCMR"
                    },
                    {
                        "B": "SVMR"
                    },
                    {
                        "C": "Both"
                    },
                    {
                        "D": "Neither"
                    }
                ],
                "caption": "Fig. 6: ConvSE Analysis. Left : comparison of moment generation methods. Right : comparison of ConvSE filters with different kernel sizes (k)",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 6: ConvSE Analysis. Left : comparison of moment generation methods. Right : comparison of ConvSE filters with different kernel sizes (k)",
            "categories": "['cs.CV cs.CL cs.IR']",
            "figure_id": "2001.09099v2-Figure6-1",
            "image_path": "2001.09099v2-Figure6-1.png",
            "instance_id": "857c74594602f757548fc1ba0b3c1d58",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "For which task does recall@1 consistently decrease with Temporal IoU across all  moment generation methods and filters with different kernel sizes?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 6: ConvSE Analysis. Left : comparison of moment generation methods. Right : comparison of ConvSE filters with different kernel sizes (k)",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 6: ConvSE Analysis. Left : comparison of moment generation methods. Right : comparison of ConvSE filters with different kernel sizes (k)",
            "categories": "['cs.CV cs.CL cs.IR']",
            "figure_id": "2001.09099v2-Figure6-1",
            "image_path": "2001.09099v2-Figure6-1.png",
            "instance_id": "57d3cefe5899ba03685b32feb5b472f4",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific dataset used in this figure to show the performance of the ConvSE method? ",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 11: Accuracy (y-axis) percentage on SST2 dataset with varying window size.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 11: Accuracy (y-axis) percentage on SST2 dataset with varying window size.",
            "categories": "['cs.CL']",
            "figure_id": "1909.00080v2-Figure11-1",
            "image_path": "1909.00080v2-Figure11-1.png",
            "instance_id": "1fb063e8dc6afa7eccf1e5e09d0da7a9",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the accuracy percentage of the blue line at window size 29?",
            "reference_answer": "Approximately 77"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 11: Accuracy (y-axis) percentage on SST2 dataset with varying window size.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 11: Accuracy (y-axis) percentage on SST2 dataset with varying window size.",
            "categories": "['cs.CL']",
            "figure_id": "1909.00080v2-Figure11-1",
            "image_path": "1909.00080v2-Figure11-1.png",
            "instance_id": "399af776e8796e5236d049ef22c8a15c",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the accuracy percentage on the SST2 dataset for the 'Correct Ordering' method when the window size is 29?",
            "reference_answer": "Approximately 78.5"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 11: Accuracy (y-axis) percentage on SST2 dataset with varying window size.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 11: Accuracy (y-axis) percentage on SST2 dataset with varying window size.",
            "categories": "['cs.CL']",
            "figure_id": "1909.00080v2-Figure11-1",
            "image_path": "1909.00080v2-Figure11-1.png",
            "instance_id": "f3fab0e82819e817e763eda01e0e32f3",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the green line represent the highest accuracy at the window size of 1?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The green line, representing Correct Ordering, shows the highest accuracy at the window size of 1.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 11: Accuracy (y-axis) percentage on SST2 dataset with varying window size.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 11: Accuracy (y-axis) percentage on SST2 dataset with varying window size.",
            "categories": "['cs.CL']",
            "figure_id": "1909.00080v2-Figure11-1",
            "image_path": "1909.00080v2-Figure11-1.png",
            "instance_id": "4c62f1966fb955c8669ef6836f36a778",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the accuracy of 'Correct Ordering' exceed the accuracy of 'Alternate Shuffle' for all window sizes?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Blue"
                    },
                    {
                        "B": "Orange"
                    },
                    {
                        "C": "Green"
                    },
                    {
                        "D": "All lines have the same peak value"
                    }
                ],
                "caption": "Figure 11: Accuracy (y-axis) percentage on SST2 dataset with varying window size.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 11: Accuracy (y-axis) percentage on SST2 dataset with varying window size.",
            "categories": "['cs.CL']",
            "figure_id": "1909.00080v2-Figure11-1",
            "image_path": "1909.00080v2-Figure11-1.png",
            "instance_id": "7d15064f543dfe2d7ee08c9b89e8149c",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line has the highest peak value?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Random Ordering"
                    },
                    {
                        "B": "Alternate Shuffle"
                    },
                    {
                        "C": "Correct Ordering"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 11: Accuracy (y-axis) percentage on SST2 dataset with varying window size.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 11: Accuracy (y-axis) percentage on SST2 dataset with varying window size.",
            "categories": "['cs.CL']",
            "figure_id": "1909.00080v2-Figure11-1",
            "image_path": "1909.00080v2-Figure11-1.png",
            "instance_id": "6a374129dfd166ad70b6f48cbe457a0f",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which ordering method has a consistently decreasing accuracy on the SST2 dataset with window size?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 11: Accuracy (y-axis) percentage on SST2 dataset with varying window size.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 11: Accuracy (y-axis) percentage on SST2 dataset with varying window size.",
            "categories": "['cs.CL']",
            "figure_id": "1909.00080v2-Figure11-1",
            "image_path": "1909.00080v2-Figure11-1.png",
            "instance_id": "ae7ef9458c30ca49917a3426b65091f9",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific data processing technique used for the SST2 dataset?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: F1 score on CoNLL-2005 after performing incremental corrections from He et al. (2017). Solid/dotted lines indicate ELMo/GLoVe embeddings, respectively.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: F1 score on CoNLL-2005 after performing incremental corrections from He et al. (2017). Solid/dotted lines indicate ELMo/GLoVe embeddings, respectively.",
            "categories": "['cs.CL']",
            "figure_id": "1811.04773v1-Figure2-1",
            "image_path": "1811.04773v1-Figure2-1.png",
            "instance_id": "dc5b64b9e87426797b6bfce160188bbf",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the F1 score of the solid green line at the 'Move Core Arg' point?",
            "reference_answer": "Approximately 90"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The F1 score of the solid green line at the 'Move Core Arg' point is approximately 90.5.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: F1 score on CoNLL-2005 after performing incremental corrections from He et al. (2017). Solid/dotted lines indicate ELMo/GLoVe embeddings, respectively.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: F1 score on CoNLL-2005 after performing incremental corrections from He et al. (2017). Solid/dotted lines indicate ELMo/GLoVe embeddings, respectively.",
            "categories": "['cs.CL']",
            "figure_id": "1811.04773v1-Figure2-1",
            "image_path": "1811.04773v1-Figure2-1.png",
            "instance_id": "b1cb1659c56fbe4cf77a80ebd601371e",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the F1 score for the +Gold method after the 'Merge Spans' correction?",
            "reference_answer": "Approximately 94.5"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: F1 score on CoNLL-2005 after performing incremental corrections from He et al. (2017). Solid/dotted lines indicate ELMo/GLoVe embeddings, respectively.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: F1 score on CoNLL-2005 after performing incremental corrections from He et al. (2017). Solid/dotted lines indicate ELMo/GLoVe embeddings, respectively.",
            "categories": "['cs.CL']",
            "figure_id": "1811.04773v1-Figure2-1",
            "image_path": "1811.04773v1-Figure2-1.png",
            "instance_id": "c34b01a73dd713001dfb42501c900847",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the blue line reach a higher F1 score than the green line at the 'Add Arg.' boundary?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: F1 score on CoNLL-2005 after performing incremental corrections from He et al. (2017). Solid/dotted lines indicate ELMo/GLoVe embeddings, respectively.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: F1 score on CoNLL-2005 after performing incremental corrections from He et al. (2017). Solid/dotted lines indicate ELMo/GLoVe embeddings, respectively.",
            "categories": "['cs.CL']",
            "figure_id": "1811.04773v1-Figure2-1",
            "image_path": "1811.04773v1-Figure2-1.png",
            "instance_id": "3b8b4bc24342a0d4147005379b752605",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the F1 score for LISA consistently increase after each incremental correction?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Blue"
                    },
                    {
                        "B": "Green"
                    },
                    {
                        "C": "Orange"
                    },
                    {
                        "D": "All three lines have the same F1 score"
                    }
                ],
                "caption": "Figure 2: F1 score on CoNLL-2005 after performing incremental corrections from He et al. (2017). Solid/dotted lines indicate ELMo/GLoVe embeddings, respectively.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: F1 score on CoNLL-2005 after performing incremental corrections from He et al. (2017). Solid/dotted lines indicate ELMo/GLoVe embeddings, respectively.",
            "categories": "['cs.CL']",
            "figure_id": "1811.04773v1-Figure2-1",
            "image_path": "1811.04773v1-Figure2-1.png",
            "instance_id": "9d4fb8cf6a7eda26e2416a9594a13800",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line has the highest F1 score when the boundary is 'Add Arg.'?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "ELMo is consistently better across all methods and correction steps."
                    },
                    {
                        "B": "GLoVe is consistently better across all methods and correction steps."
                    },
                    {
                        "C": "One is better than the other depending on method."
                    },
                    {
                        "D": "One is better than the other depending on correction step."
                    }
                ],
                "caption": "Figure 2: F1 score on CoNLL-2005 after performing incremental corrections from He et al. (2017). Solid/dotted lines indicate ELMo/GLoVe embeddings, respectively.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: F1 score on CoNLL-2005 after performing incremental corrections from He et al. (2017). Solid/dotted lines indicate ELMo/GLoVe embeddings, respectively.",
            "categories": "['cs.CL']",
            "figure_id": "1811.04773v1-Figure2-1",
            "image_path": "1811.04773v1-Figure2-1.png",
            "instance_id": "9bad2e7fdca7ba54588203d9fec9d8d5",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What can be said about the performance of ELMo embeddings compared to GLoVe embeddings?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: F1 score on CoNLL-2005 after performing incremental corrections from He et al. (2017). Solid/dotted lines indicate ELMo/GLoVe embeddings, respectively.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: F1 score on CoNLL-2005 after performing incremental corrections from He et al. (2017). Solid/dotted lines indicate ELMo/GLoVe embeddings, respectively.",
            "categories": "['cs.CL']",
            "figure_id": "1811.04773v1-Figure2-1",
            "image_path": "1811.04773v1-Figure2-1.png",
            "instance_id": "f9c554d597e204f1f87d62837ce88310",
            "qa_pair_type": "unanswerable",
            "question": "What was the total runtime of the experiemnt?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 9: Trends in accuracy and spearman\u2019s rho based on the number of valid answers for a question. In case of 1 valid answer, spearman\u2019s rho is always taken as 0. The number in parenthesis denotes number of such examples seen in the test dataset.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: Trends in accuracy and spearman\u2019s rho based on the number of valid answers for a question. In case of 1 valid answer, spearman\u2019s rho is always taken as 0. The number in parenthesis denotes number of such examples seen in the test dataset.",
            "categories": "['cs.IR cs.CL cs.LG stat.ML']",
            "figure_id": "1907.01643v1-Figure9-1",
            "image_path": "1907.01643v1-Figure9-1.png",
            "instance_id": "d2d3b1711fa8077f8aba024e14a01efc",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of the orange line when the number of relevant candidates is 6?",
            "reference_answer": "Approximately 0.6"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The value of the orange line (Spearman's Rho) when the number of relevant candidates is 6 is approximately 0.4.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 9: Trends in accuracy and spearman\u2019s rho based on the number of valid answers for a question. In case of 1 valid answer, spearman\u2019s rho is always taken as 0. The number in parenthesis denotes number of such examples seen in the test dataset.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: Trends in accuracy and spearman\u2019s rho based on the number of valid answers for a question. In case of 1 valid answer, spearman\u2019s rho is always taken as 0. The number in parenthesis denotes number of such examples seen in the test dataset.",
            "categories": "['cs.IR cs.CL cs.LG stat.ML']",
            "figure_id": "1907.01643v1-Figure9-1",
            "image_path": "1907.01643v1-Figure9-1.png",
            "instance_id": "dea712d401233fe74411c8c756748436",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the number of examples seen in the test dataset when the number of valid answers is 4?",
            "reference_answer": "25"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 9: Trends in accuracy and spearman\u2019s rho based on the number of valid answers for a question. In case of 1 valid answer, spearman\u2019s rho is always taken as 0. The number in parenthesis denotes number of such examples seen in the test dataset.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: Trends in accuracy and spearman\u2019s rho based on the number of valid answers for a question. In case of 1 valid answer, spearman\u2019s rho is always taken as 0. The number in parenthesis denotes number of such examples seen in the test dataset.",
            "categories": "['cs.IR cs.CL cs.LG stat.ML']",
            "figure_id": "1907.01643v1-Figure9-1",
            "image_path": "1907.01643v1-Figure9-1.png",
            "instance_id": "c567527d950b026559fea09a670849cc",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the blue line reach its maximum value at 2 (30) on the x-axis?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 9: Trends in accuracy and spearman\u2019s rho based on the number of valid answers for a question. In case of 1 valid answer, spearman\u2019s rho is always taken as 0. The number in parenthesis denotes number of such examples seen in the test dataset.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: Trends in accuracy and spearman\u2019s rho based on the number of valid answers for a question. In case of 1 valid answer, spearman\u2019s rho is always taken as 0. The number in parenthesis denotes number of such examples seen in the test dataset.",
            "categories": "['cs.IR cs.CL cs.LG stat.ML']",
            "figure_id": "1907.01643v1-Figure9-1",
            "image_path": "1907.01643v1-Figure9-1.png",
            "instance_id": "15f48f1ab37d20368f5b6a3ac7511d94",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the highest accuracy observed when there are 3 valid answers?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "1(13)"
                    },
                    {
                        "B": "3(36)"
                    },
                    {
                        "C": "6(7)"
                    },
                    {
                        "D": "8(6)"
                    }
                ],
                "caption": "Figure 9: Trends in accuracy and spearman\u2019s rho based on the number of valid answers for a question. In case of 1 valid answer, spearman\u2019s rho is always taken as 0. The number in parenthesis denotes number of such examples seen in the test dataset.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: Trends in accuracy and spearman\u2019s rho based on the number of valid answers for a question. In case of 1 valid answer, spearman\u2019s rho is always taken as 0. The number in parenthesis denotes number of such examples seen in the test dataset.",
            "categories": "['cs.IR cs.CL cs.LG stat.ML']",
            "figure_id": "1907.01643v1-Figure9-1",
            "image_path": "1907.01643v1-Figure9-1.png",
            "instance_id": "aa95780b8c0bfdb65aa3240200b1d066",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following categories have the highest value for the blue line?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "13"
                    },
                    {
                        "B": "36"
                    },
                    {
                        "C": "25"
                    },
                    {
                        "D": "18"
                    }
                ],
                "caption": "Figure 9: Trends in accuracy and spearman\u2019s rho based on the number of valid answers for a question. In case of 1 valid answer, spearman\u2019s rho is always taken as 0. The number in parenthesis denotes number of such examples seen in the test dataset.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: Trends in accuracy and spearman\u2019s rho based on the number of valid answers for a question. In case of 1 valid answer, spearman\u2019s rho is always taken as 0. The number in parenthesis denotes number of such examples seen in the test dataset.",
            "categories": "['cs.IR cs.CL cs.LG stat.ML']",
            "figure_id": "1907.01643v1-Figure9-1",
            "image_path": "1907.01643v1-Figure9-1.png",
            "instance_id": "f7c13bc72917fb4f4c2f7bb2d6413899",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the number of test dataset examples seen for a question with 4 relevant candidates?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 9: Trends in accuracy and spearman\u2019s rho based on the number of valid answers for a question. In case of 1 valid answer, spearman\u2019s rho is always taken as 0. The number in parenthesis denotes number of such examples seen in the test dataset.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: Trends in accuracy and spearman\u2019s rho based on the number of valid answers for a question. In case of 1 valid answer, spearman\u2019s rho is always taken as 0. The number in parenthesis denotes number of such examples seen in the test dataset.",
            "categories": "['cs.IR cs.CL cs.LG stat.ML']",
            "figure_id": "1907.01643v1-Figure9-1",
            "image_path": "1907.01643v1-Figure9-1.png",
            "instance_id": "bfb63c7690ca4e82ea2e5b42eddadc48",
            "qa_pair_type": "unanswerable",
            "question": "What are the actual question types corresponding to each point in the graph, and how were these question types selected for the test dataset?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: By using adjacent DAs as context, DomSum is compared with two DA-level summarization metrics: OneTopic and MultiTopic. For DomSum, the words of context DA from dominant topic of the center DA (\u201cOne\u201d) is selected; For OneTopic and MultiTopic, three top ranked DAs are selected.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: By using adjacent DAs as context, DomSum is compared with two DA-level summarization metrics: OneTopic and MultiTopic. For DomSum, the words of context DA from dominant topic of the center DA (\u201cOne\u201d) is selected; For OneTopic and MultiTopic, three top ranked DAs are selected.",
            "categories": "['cs.CL']",
            "figure_id": "1606.07829v1-Figure5-1",
            "image_path": "1606.07829v1-Figure5-1.png",
            "instance_id": "8f752726a1b21dff0d89b299365a1cdc",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of the red line at 10 on the x-axis?",
            "reference_answer": "Between 12 and 12.5"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The value of the red line at 10 on the x-axis is approximately 12.5%.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: By using adjacent DAs as context, DomSum is compared with two DA-level summarization metrics: OneTopic and MultiTopic. For DomSum, the words of context DA from dominant topic of the center DA (\u201cOne\u201d) is selected; For OneTopic and MultiTopic, three top ranked DAs are selected.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: By using adjacent DAs as context, DomSum is compared with two DA-level summarization metrics: OneTopic and MultiTopic. For DomSum, the words of context DA from dominant topic of the center DA (\u201cOne\u201d) is selected; For OneTopic and MultiTopic, three top ranked DAs are selected.",
            "categories": "['cs.CL']",
            "figure_id": "1606.07829v1-Figure5-1",
            "image_path": "1606.07829v1-Figure5-1.png",
            "instance_id": "b074eec8ced61d2ad360f36e8034d6f3",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the maximum number of topics tested in the experiment?",
            "reference_answer": "10"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The maximum number of topics tested in the experiment is 10.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: By using adjacent DAs as context, DomSum is compared with two DA-level summarization metrics: OneTopic and MultiTopic. For DomSum, the words of context DA from dominant topic of the center DA (\u201cOne\u201d) is selected; For OneTopic and MultiTopic, three top ranked DAs are selected.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: By using adjacent DAs as context, DomSum is compared with two DA-level summarization metrics: OneTopic and MultiTopic. For DomSum, the words of context DA from dominant topic of the center DA (\u201cOne\u201d) is selected; For OneTopic and MultiTopic, three top ranked DAs are selected.",
            "categories": "['cs.CL']",
            "figure_id": "1606.07829v1-Figure5-1",
            "image_path": "1606.07829v1-Figure5-1.png",
            "instance_id": "2b3f2c74f77aaf92db0e512b82e660b0",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the green line increase from #Topic 2 to #Topic 10?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the green line (STM+DomSum(One)) does increase from #Topic 2 to #Topic 10.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: By using adjacent DAs as context, DomSum is compared with two DA-level summarization metrics: OneTopic and MultiTopic. For DomSum, the words of context DA from dominant topic of the center DA (\u201cOne\u201d) is selected; For OneTopic and MultiTopic, three top ranked DAs are selected.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: By using adjacent DAs as context, DomSum is compared with two DA-level summarization metrics: OneTopic and MultiTopic. For DomSum, the words of context DA from dominant topic of the center DA (\u201cOne\u201d) is selected; For OneTopic and MultiTopic, three top ranked DAs are selected.",
            "categories": "['cs.CL']",
            "figure_id": "1606.07829v1-Figure5-1",
            "image_path": "1606.07829v1-Figure5-1.png",
            "instance_id": "aef348069567ab99a8e6aed6419f6026",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the ROUGE-SU4 F score of LocalLDA+DomSum (One) consistently increase with the number of topics?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the ROUGE-SU4 F score of LocalLDA+DomSum (One) consistently increases with the number of topics.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Red line"
                    },
                    {
                        "B": "Yellow line"
                    },
                    {
                        "C": "Green line"
                    },
                    {
                        "D": "Blue line"
                    }
                ],
                "caption": "Figure 5: By using adjacent DAs as context, DomSum is compared with two DA-level summarization metrics: OneTopic and MultiTopic. For DomSum, the words of context DA from dominant topic of the center DA (\u201cOne\u201d) is selected; For OneTopic and MultiTopic, three top ranked DAs are selected.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: By using adjacent DAs as context, DomSum is compared with two DA-level summarization metrics: OneTopic and MultiTopic. For DomSum, the words of context DA from dominant topic of the center DA (\u201cOne\u201d) is selected; For OneTopic and MultiTopic, three top ranked DAs are selected.",
            "categories": "['cs.CL']",
            "figure_id": "1606.07829v1-Figure5-1",
            "image_path": "1606.07829v1-Figure5-1.png",
            "instance_id": "5643c4a827af5c31a7cbbb45e3737ccd",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following lines has the highest value at #Topic 9?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "DomSum"
                    },
                    {
                        "B": "OneTopic"
                    },
                    {
                        "C": "MultiTopic"
                    },
                    {
                        "D": "LocalLDA"
                    }
                ],
                "caption": "Figure 5: By using adjacent DAs as context, DomSum is compared with two DA-level summarization metrics: OneTopic and MultiTopic. For DomSum, the words of context DA from dominant topic of the center DA (\u201cOne\u201d) is selected; For OneTopic and MultiTopic, three top ranked DAs are selected.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: By using adjacent DAs as context, DomSum is compared with two DA-level summarization metrics: OneTopic and MultiTopic. For DomSum, the words of context DA from dominant topic of the center DA (\u201cOne\u201d) is selected; For OneTopic and MultiTopic, three top ranked DAs are selected.",
            "categories": "['cs.CL']",
            "figure_id": "1606.07829v1-Figure5-1",
            "image_path": "1606.07829v1-Figure5-1.png",
            "instance_id": "23ce75c7de7bf2083e4c5daaa1b97731",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which summarization methods are used in the experiment?",
            "reference_answer": "A,B,C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ABCD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: By using adjacent DAs as context, DomSum is compared with two DA-level summarization metrics: OneTopic and MultiTopic. For DomSum, the words of context DA from dominant topic of the center DA (\u201cOne\u201d) is selected; For OneTopic and MultiTopic, three top ranked DAs are selected.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: By using adjacent DAs as context, DomSum is compared with two DA-level summarization metrics: OneTopic and MultiTopic. For DomSum, the words of context DA from dominant topic of the center DA (\u201cOne\u201d) is selected; For OneTopic and MultiTopic, three top ranked DAs are selected.",
            "categories": "['cs.CL']",
            "figure_id": "1606.07829v1-Figure5-1",
            "image_path": "1606.07829v1-Figure5-1.png",
            "instance_id": "f59245089e959e12cdf6d3684ea9d498",
            "qa_pair_type": "unanswerable",
            "question": "What dataset was used to compare these methods?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 5: The influence of different amount of hypotheses.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 5: The influence of different amount of hypotheses.",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2001.05284v1-Figure5-1",
            "image_path": "2001.05284v1-Figure5-1.png",
            "instance_id": "e1e4f6c1a0e020442c5e51bbe42981f0",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the maximum value of the orange line?",
            "reference_answer": "Between 30 and 35"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 5: The influence of different amount of hypotheses.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 5: The influence of different amount of hypotheses.",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2001.05284v1-Figure5-1",
            "image_path": "2001.05284v1-Figure5-1.png",
            "instance_id": "b948a66a8d53d408232ce9664bbfa1f8",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the variable measured on the y-axis?",
            "reference_answer": "RErr (%)"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The variable measured on the y-axis is RErr (%).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 5: The influence of different amount of hypotheses.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 5: The influence of different amount of hypotheses.",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2001.05284v1-Figure5-1",
            "image_path": "2001.05284v1-Figure5-1.png",
            "instance_id": "e540a997a64d4c1579034954c22254c9",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the value of the red line at 3 hypotheses greater than 30?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 5: The influence of different amount of hypotheses.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 5: The influence of different amount of hypotheses.",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2001.05284v1-Figure5-1",
            "image_path": "2001.05284v1-Figure5-1.png",
            "instance_id": "3821be0db40f63a962b503265133f337",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the performance of 'Oracle' remain constant as the number of hypotheses increases?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, the performance of 'Oracle' does not remain constant as the number of hypotheses increases. The percentage of RErr for 'Oracle' decreases as the number of hypotheses increases.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Red"
                    },
                    {
                        "B": "Blue"
                    },
                    {
                        "C": "Yellow"
                    },
                    {
                        "D": "Orange"
                    }
                ],
                "caption": "Fig. 5: The influence of different amount of hypotheses.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 5: The influence of different amount of hypotheses.",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2001.05284v1-Figure5-1",
            "image_path": "2001.05284v1-Figure5-1.png",
            "instance_id": "6d35e24b75f1ad2ed8d9ebc676aeb9bd",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line(s) show an increase in values as the number of hypotheses increases?",
            "reference_answer": "A,B,C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "PoolingAvg"
                    },
                    {
                        "B": "SortByScore"
                    },
                    {
                        "C": "PoolingMax"
                    },
                    {
                        "D": "Baseline"
                    }
                ],
                "caption": "Fig. 5: The influence of different amount of hypotheses.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 5: The influence of different amount of hypotheses.",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2001.05284v1-Figure5-1",
            "image_path": "2001.05284v1-Figure5-1.png",
            "instance_id": "c95302fe0af6eacf66e810f2d903c135",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which has the lowest RErr (%) at 5 hypotheses?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 5: The influence of different amount of hypotheses.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 5: The influence of different amount of hypotheses.",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "2001.05284v1-Figure5-1",
            "image_path": "2001.05284v1-Figure5-1.png",
            "instance_id": "2e4e42f88efb6734c50da73a9b11a937",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific task or dataset used in this experiment to measure the influence of hypotheses on the RErr (Relative Error)?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: Proportional Frequency of the thirty most frequent characters in the Historical Corpus texts, the (alphabetic) Wikipedia Corpus texts, and Voynichese (Full Maximal and Minimal transcriptions). Simplified Maximal is identical to Full Maximal with regards to frequent characters. The first ranked character for each language is a space, and its frequency indicates average word length.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Proportional Frequency of the thirty most frequent characters in the Historical Corpus texts, the (alphabetic) Wikipedia Corpus texts, and Voynichese (Full Maximal and Minimal transcriptions). Simplified Maximal is identical to Full Maximal with regards to frequent characters. The first ranked character for each language is a space, and its frequency indicates average word length.",
            "categories": "['cs.CL']",
            "figure_id": "2010.14697v1-Figure7-1",
            "image_path": "2010.14697v1-Figure7-1.png",
            "instance_id": "34673f9cbd7e54eb8849457f125fb79e",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the frequency of the red line at letter rank 10?",
            "reference_answer": "Approximately 5%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: Proportional Frequency of the thirty most frequent characters in the Historical Corpus texts, the (alphabetic) Wikipedia Corpus texts, and Voynichese (Full Maximal and Minimal transcriptions). Simplified Maximal is identical to Full Maximal with regards to frequent characters. The first ranked character for each language is a space, and its frequency indicates average word length.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Proportional Frequency of the thirty most frequent characters in the Historical Corpus texts, the (alphabetic) Wikipedia Corpus texts, and Voynichese (Full Maximal and Minimal transcriptions). Simplified Maximal is identical to Full Maximal with regards to frequent characters. The first ranked character for each language is a space, and its frequency indicates average word length.",
            "categories": "['cs.CL']",
            "figure_id": "2010.14697v1-Figure7-1",
            "image_path": "2010.14697v1-Figure7-1.png",
            "instance_id": "f54c5074972041b27958190984b8c141",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "How many most frequent characters are represented in the graph?",
            "reference_answer": "30"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: Proportional Frequency of the thirty most frequent characters in the Historical Corpus texts, the (alphabetic) Wikipedia Corpus texts, and Voynichese (Full Maximal and Minimal transcriptions). Simplified Maximal is identical to Full Maximal with regards to frequent characters. The first ranked character for each language is a space, and its frequency indicates average word length.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Proportional Frequency of the thirty most frequent characters in the Historical Corpus texts, the (alphabetic) Wikipedia Corpus texts, and Voynichese (Full Maximal and Minimal transcriptions). Simplified Maximal is identical to Full Maximal with regards to frequent characters. The first ranked character for each language is a space, and its frequency indicates average word length.",
            "categories": "['cs.CL']",
            "figure_id": "2010.14697v1-Figure7-1",
            "image_path": "2010.14697v1-Figure7-1.png",
            "instance_id": "e3ff6c629b11c4a55687f09e9d9db130",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the red line higher than the blue line for the Letter Rank of 10?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: Proportional Frequency of the thirty most frequent characters in the Historical Corpus texts, the (alphabetic) Wikipedia Corpus texts, and Voynichese (Full Maximal and Minimal transcriptions). Simplified Maximal is identical to Full Maximal with regards to frequent characters. The first ranked character for each language is a space, and its frequency indicates average word length.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Proportional Frequency of the thirty most frequent characters in the Historical Corpus texts, the (alphabetic) Wikipedia Corpus texts, and Voynichese (Full Maximal and Minimal transcriptions). Simplified Maximal is identical to Full Maximal with regards to frequent characters. The first ranked character for each language is a space, and its frequency indicates average word length.",
            "categories": "['cs.CL']",
            "figure_id": "2010.14697v1-Figure7-1",
            "image_path": "2010.14697v1-Figure7-1.png",
            "instance_id": "e28325f5d0eb20ac5612fdee13d1797e",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the frequency of the most common character in Voynichese (Maximal) exceed 10%?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the frequency of the most common character in Voynichese (Maximal) exceeds 10%.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Red"
                    },
                    {
                        "B": "Blue"
                    },
                    {
                        "C": "Gray"
                    },
                    {
                        "D": "Black"
                    }
                ],
                "caption": "Figure 7: Proportional Frequency of the thirty most frequent characters in the Historical Corpus texts, the (alphabetic) Wikipedia Corpus texts, and Voynichese (Full Maximal and Minimal transcriptions). Simplified Maximal is identical to Full Maximal with regards to frequent characters. The first ranked character for each language is a space, and its frequency indicates average word length.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Proportional Frequency of the thirty most frequent characters in the Historical Corpus texts, the (alphabetic) Wikipedia Corpus texts, and Voynichese (Full Maximal and Minimal transcriptions). Simplified Maximal is identical to Full Maximal with regards to frequent characters. The first ranked character for each language is a space, and its frequency indicates average word length.",
            "categories": "['cs.CL']",
            "figure_id": "2010.14697v1-Figure7-1",
            "image_path": "2010.14697v1-Figure7-1.png",
            "instance_id": "fac6dd5b81520dcd137a13265ef6ff51",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line on the graph has the lowest value for the 20th ranked letter?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Historical"
                    },
                    {
                        "B": "Voynich (Max)"
                    },
                    {
                        "C": "Voynich (Min)"
                    },
                    {
                        "D": "Wikipedia"
                    }
                ],
                "caption": "Figure 7: Proportional Frequency of the thirty most frequent characters in the Historical Corpus texts, the (alphabetic) Wikipedia Corpus texts, and Voynichese (Full Maximal and Minimal transcriptions). Simplified Maximal is identical to Full Maximal with regards to frequent characters. The first ranked character for each language is a space, and its frequency indicates average word length.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Proportional Frequency of the thirty most frequent characters in the Historical Corpus texts, the (alphabetic) Wikipedia Corpus texts, and Voynichese (Full Maximal and Minimal transcriptions). Simplified Maximal is identical to Full Maximal with regards to frequent characters. The first ranked character for each language is a space, and its frequency indicates average word length.",
            "categories": "['cs.CL']",
            "figure_id": "2010.14697v1-Figure7-1",
            "image_path": "2010.14697v1-Figure7-1.png",
            "instance_id": "6a79ebe8f32da40a2075728f28e61590",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of these text types has the lowest frequency for its first ranked character?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: Proportional Frequency of the thirty most frequent characters in the Historical Corpus texts, the (alphabetic) Wikipedia Corpus texts, and Voynichese (Full Maximal and Minimal transcriptions). Simplified Maximal is identical to Full Maximal with regards to frequent characters. The first ranked character for each language is a space, and its frequency indicates average word length.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: Proportional Frequency of the thirty most frequent characters in the Historical Corpus texts, the (alphabetic) Wikipedia Corpus texts, and Voynichese (Full Maximal and Minimal transcriptions). Simplified Maximal is identical to Full Maximal with regards to frequent characters. The first ranked character for each language is a space, and its frequency indicates average word length.",
            "categories": "['cs.CL']",
            "figure_id": "2010.14697v1-Figure7-1",
            "image_path": "2010.14697v1-Figure7-1.png",
            "instance_id": "2ee077fb3519a20fe655659d73b2109b",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific character corresponding to each rank in the Voynichese corpus?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Upper: F1 scores with different khard; Lower: time (min) per epoch in learning with different khard.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Upper: F1 scores with different khard; Lower: time (min) per epoch in learning with different khard.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1805.04688v1-Figure2-1",
            "image_path": "1805.04688v1-Figure2-1.png",
            "instance_id": "0321e547047e28e7ffb9f32ddb842cb5",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the line in the lower figure for khard = 80?",
            "reference_answer": "12"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Upper: F1 scores with different khard; Lower: time (min) per epoch in learning with different khard.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Upper: F1 scores with different khard; Lower: time (min) per epoch in learning with different khard.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1805.04688v1-Figure2-1",
            "image_path": "1805.04688v1-Figure2-1.png",
            "instance_id": "4f76e8125c4fa91bd33be9876f47cfdc",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the maximum time per epoch shown on the y axis of the corresponding graph?",
            "reference_answer": "20 min"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Upper: F1 scores with different khard; Lower: time (min) per epoch in learning with different khard.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Upper: F1 scores with different khard; Lower: time (min) per epoch in learning with different khard.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1805.04688v1-Figure2-1",
            "image_path": "1805.04688v1-Figure2-1.png",
            "instance_id": "0b19bc237dc1ce440406755700a6f803",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the green line representing F1 score increasing in value at Khard = 60?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the green line representing the F1 score is at its highest value at Khard = 60, which indicates that it is not increasing in value at that point and has plateaued around that range.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Upper: F1 scores with different khard; Lower: time (min) per epoch in learning with different khard.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Upper: F1 scores with different khard; Lower: time (min) per epoch in learning with different khard.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1805.04688v1-Figure2-1",
            "image_path": "1805.04688v1-Figure2-1.png",
            "instance_id": "b3e1a136bfd4d2b12011ad60832dfb87",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the time per epoch increase consistently as Khards increase?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the time per epoch increases consistently as \\( k_{hard} \\) increases.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "82.0"
                    },
                    {
                        "B": "84.0"
                    },
                    {
                        "C": "76.0"
                    },
                    {
                        "D": "80.0"
                    }
                ],
                "caption": "Figure 2: Upper: F1 scores with different khard; Lower: time (min) per epoch in learning with different khard.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Upper: F1 scores with different khard; Lower: time (min) per epoch in learning with different khard.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1805.04688v1-Figure2-1",
            "image_path": "1805.04688v1-Figure2-1.png",
            "instance_id": "edd3c31cc31093a2e2e45cdfa47e57b8",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What is the approximate maximum value of the green line?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "30 to 40"
                    },
                    {
                        "B": "60 to 70"
                    },
                    {
                        "C": "70 to 80"
                    },
                    {
                        "D": "80 to +inf"
                    }
                ],
                "caption": "Figure 2: Upper: F1 scores with different khard; Lower: time (min) per epoch in learning with different khard.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Upper: F1 scores with different khard; Lower: time (min) per epoch in learning with different khard.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1805.04688v1-Figure2-1",
            "image_path": "1805.04688v1-Figure2-1.png",
            "instance_id": "462b58bb2ddaf3f23e7de180b7d80903",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "In which khard intervals does timer per epoch remain approximately constant?",
            "reference_answer": "B,C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ABCD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Upper: F1 scores with different khard; Lower: time (min) per epoch in learning with different khard.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Upper: F1 scores with different khard; Lower: time (min) per epoch in learning with different khard.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1805.04688v1-Figure2-1",
            "image_path": "1805.04688v1-Figure2-1.png",
            "instance_id": "9a3005346a8ea1e817b92e9a2eadae88",
            "qa_pair_type": "unanswerable",
            "question": "What is the exact value of time per epoch for a khard of 35?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 16: Results for the hierarchical same\u2013different task for a model in which both the input representations and the basic equality network are pretrained. The \u2018no pretrain\u2019 model is the best one from Figure 6a (25-dimensional embeddings, 100-dimensional hidden representations). The input-pretrained models use this same configuration.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 16: Results for the hierarchical same\u2013different task for a model in which both the input representations and the basic equality network are pretrained. The \u2018no pretrain\u2019 model is the best one from Figure 6a (25-dimensional embeddings, 100-dimensional hidden representations). The input-pretrained models use this same configuration.",
            "categories": "['cs.LG cs.AI cs.CL']",
            "figure_id": "2006.07968v2-Figure16-1",
            "image_path": "2006.07968v2-Figure16-1.png",
            "instance_id": "b21347f2b7a199861d3765118912f807",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the color of the line representing the 'no pretrain' model?",
            "reference_answer": "Green"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The color of the line representing the 'no pretrain' model is green.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 16: Results for the hierarchical same\u2013different task for a model in which both the input representations and the basic equality network are pretrained. The \u2018no pretrain\u2019 model is the best one from Figure 6a (25-dimensional embeddings, 100-dimensional hidden representations). The input-pretrained models use this same configuration.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 16: Results for the hierarchical same\u2013different task for a model in which both the input representations and the basic equality network are pretrained. The \u2018no pretrain\u2019 model is the best one from Figure 6a (25-dimensional embeddings, 100-dimensional hidden representations). The input-pretrained models use this same configuration.",
            "categories": "['cs.LG cs.AI cs.CL']",
            "figure_id": "2006.07968v2-Figure16-1",
            "image_path": "2006.07968v2-Figure16-1.png",
            "instance_id": "eaa655f4c56635edd1e140052f806bc7",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the step size of the x ticks?",
            "reference_answer": "250"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 16: Results for the hierarchical same\u2013different task for a model in which both the input representations and the basic equality network are pretrained. The \u2018no pretrain\u2019 model is the best one from Figure 6a (25-dimensional embeddings, 100-dimensional hidden representations). The input-pretrained models use this same configuration.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 16: Results for the hierarchical same\u2013different task for a model in which both the input representations and the basic equality network are pretrained. The \u2018no pretrain\u2019 model is the best one from Figure 6a (25-dimensional embeddings, 100-dimensional hidden representations). The input-pretrained models use this same configuration.",
            "categories": "['cs.LG cs.AI cs.CL']",
            "figure_id": "2006.07968v2-Figure16-1",
            "image_path": "2006.07968v2-Figure16-1.png",
            "instance_id": "bd712a646a591e9850dd729315d3a78b",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the green line consistently lower than the black line?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the green line (no pretraining) is consistently lower than the black line (3-task pretraining) in the graph.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 16: Results for the hierarchical same\u2013different task for a model in which both the input representations and the basic equality network are pretrained. The \u2018no pretrain\u2019 model is the best one from Figure 6a (25-dimensional embeddings, 100-dimensional hidden representations). The input-pretrained models use this same configuration.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 16: Results for the hierarchical same\u2013different task for a model in which both the input representations and the basic equality network are pretrained. The \u2018no pretrain\u2019 model is the best one from Figure 6a (25-dimensional embeddings, 100-dimensional hidden representations). The input-pretrained models use this same configuration.",
            "categories": "['cs.LG cs.AI cs.CL']",
            "figure_id": "2006.07968v2-Figure16-1",
            "image_path": "2006.07968v2-Figure16-1.png",
            "instance_id": "16ae0aca4faa2d10696cedd4134b8d18",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is there a model whose mean accuracy only always increases with additional hierarchical premack training examples?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Green"
                    },
                    {
                        "B": "Black"
                    },
                    {
                        "C": "Pink"
                    },
                    {
                        "D": "Yellow"
                    }
                ],
                "caption": "Figure 16: Results for the hierarchical same\u2013different task for a model in which both the input representations and the basic equality network are pretrained. The \u2018no pretrain\u2019 model is the best one from Figure 6a (25-dimensional embeddings, 100-dimensional hidden representations). The input-pretrained models use this same configuration.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 16: Results for the hierarchical same\u2013different task for a model in which both the input representations and the basic equality network are pretrained. The \u2018no pretrain\u2019 model is the best one from Figure 6a (25-dimensional embeddings, 100-dimensional hidden representations). The input-pretrained models use this same configuration.",
            "categories": "['cs.LG cs.AI cs.CL']",
            "figure_id": "2006.07968v2-Figure16-1",
            "image_path": "2006.07968v2-Figure16-1.png",
            "instance_id": "a809bfddd2440e77aefe5883882c9507",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line is highest at 250 additional hierarchical premach training examples?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "1-task pretraining"
                    },
                    {
                        "B": "3-task pretraining"
                    },
                    {
                        "C": "5-task pretraining"
                    },
                    {
                        "D": "10-task pretraining"
                    }
                ],
                "caption": "Figure 16: Results for the hierarchical same\u2013different task for a model in which both the input representations and the basic equality network are pretrained. The \u2018no pretrain\u2019 model is the best one from Figure 6a (25-dimensional embeddings, 100-dimensional hidden representations). The input-pretrained models use this same configuration.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 16: Results for the hierarchical same\u2013different task for a model in which both the input representations and the basic equality network are pretrained. The \u2018no pretrain\u2019 model is the best one from Figure 6a (25-dimensional embeddings, 100-dimensional hidden representations). The input-pretrained models use this same configuration.",
            "categories": "['cs.LG cs.AI cs.CL']",
            "figure_id": "2006.07968v2-Figure16-1",
            "image_path": "2006.07968v2-Figure16-1.png",
            "instance_id": "4cfbba707a67d94c1791db3d71cee6b7",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following pretraining configurations is compared to the 'no pretrain' model?",
            "reference_answer": "B, C, D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "BCD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 16: Results for the hierarchical same\u2013different task for a model in which both the input representations and the basic equality network are pretrained. The \u2018no pretrain\u2019 model is the best one from Figure 6a (25-dimensional embeddings, 100-dimensional hidden representations). The input-pretrained models use this same configuration.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 16: Results for the hierarchical same\u2013different task for a model in which both the input representations and the basic equality network are pretrained. The \u2018no pretrain\u2019 model is the best one from Figure 6a (25-dimensional embeddings, 100-dimensional hidden representations). The input-pretrained models use this same configuration.",
            "categories": "['cs.LG cs.AI cs.CL']",
            "figure_id": "2006.07968v2-Figure16-1",
            "image_path": "2006.07968v2-Figure16-1.png",
            "instance_id": "cc8aa432008c3acf86a4a1eda39524ac",
            "qa_pair_type": "unanswerable",
            "question": "What are the specific tasks used in the 3-task, 5-task, and 10-task pretraining?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3.8: The English Wikipedia precision-recall curves for different code dimensionalities and different model variants. For real-valued codes cosine distance was used as a similarity measure. For binary codes the Hamming distance was used as a similarity measure.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3.8: The English Wikipedia precision-recall curves for different code dimensionalities and different model variants. For real-valued codes cosine distance was used as a similarity measure. For binary codes the Hamming distance was used as a similarity measure.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1901.01695v1-Figure3.8-1",
            "image_path": "1901.01695v1-Figure3.8-1.png",
            "instance_id": "9101c3bc7572828d745e5e1645846223",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of precision at recall = 0.01 for the green line in the lower left quadrant?",
            "reference_answer": "Approximately 0.69"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3.8: The English Wikipedia precision-recall curves for different code dimensionalities and different model variants. For real-valued codes cosine distance was used as a similarity measure. For binary codes the Hamming distance was used as a similarity measure.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3.8: The English Wikipedia precision-recall curves for different code dimensionalities and different model variants. For real-valued codes cosine distance was used as a similarity measure. For binary codes the Hamming distance was used as a similarity measure.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1901.01695v1-Figure3.8-1",
            "image_path": "1901.01695v1-Figure3.8-1.png",
            "instance_id": "54f99fc102c292cb6e158ae8a54b52f7",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the maximum precision value marked on the y axes?",
            "reference_answer": "0.7"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The maximum precision value marked on the y axes is 0.7.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3.8: The English Wikipedia precision-recall curves for different code dimensionalities and different model variants. For real-valued codes cosine distance was used as a similarity measure. For binary codes the Hamming distance was used as a similarity measure.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3.8: The English Wikipedia precision-recall curves for different code dimensionalities and different model variants. For real-valued codes cosine distance was used as a similarity measure. For binary codes the Hamming distance was used as a similarity measure.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1901.01695v1-Figure3.8-1",
            "image_path": "1901.01695v1-Figure3.8-1.png",
            "instance_id": "3485522a8001a59806a29e6f4fb0791b",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the red line in the bottom-left subplot consistently higher than the blue line?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3.8: The English Wikipedia precision-recall curves for different code dimensionalities and different model variants. For real-valued codes cosine distance was used as a similarity measure. For binary codes the Hamming distance was used as a similarity measure.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3.8: The English Wikipedia precision-recall curves for different code dimensionalities and different model variants. For real-valued codes cosine distance was used as a similarity measure. For binary codes the Hamming distance was used as a similarity measure.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1901.01695v1-Figure3.8-1",
            "image_path": "1901.01695v1-Figure3.8-1.png",
            "instance_id": "c3f782c156ec0eed687a669b69fb7135",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Do the x axes use the logarithmic scale?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the x axes use a logarithmic scale.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Top left"
                    },
                    {
                        "B": "Top right"
                    },
                    {
                        "C": "Bottom left"
                    },
                    {
                        "D": "Bottom right"
                    }
                ],
                "caption": "Figure 3.8: The English Wikipedia precision-recall curves for different code dimensionalities and different model variants. For real-valued codes cosine distance was used as a similarity measure. For binary codes the Hamming distance was used as a similarity measure.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3.8: The English Wikipedia precision-recall curves for different code dimensionalities and different model variants. For real-valued codes cosine distance was used as a similarity measure. For binary codes the Hamming distance was used as a similarity measure.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1901.01695v1-Figure3.8-1",
            "image_path": "1901.01695v1-Figure3.8-1.png",
            "instance_id": "3892f5957d7ce408beb65427a365ad63",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "In which graph is the blue line lower than the other curves?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "(a)"
                    },
                    {
                        "B": "(b)"
                    },
                    {
                        "C": "(c)"
                    },
                    {
                        "D": "(d)"
                    }
                ],
                "caption": "Figure 3.8: The English Wikipedia precision-recall curves for different code dimensionalities and different model variants. For real-valued codes cosine distance was used as a similarity measure. For binary codes the Hamming distance was used as a similarity measure.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3.8: The English Wikipedia precision-recall curves for different code dimensionalities and different model variants. For real-valued codes cosine distance was used as a similarity measure. For binary codes the Hamming distance was used as a similarity measure.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1901.01695v1-Figure3.8-1",
            "image_path": "1901.01695v1-Figure3.8-1.png",
            "instance_id": "9444010b398f594a44fd8436e80322d0",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which graph corresponds to 128 dimensions?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3.8: The English Wikipedia precision-recall curves for different code dimensionalities and different model variants. For real-valued codes cosine distance was used as a similarity measure. For binary codes the Hamming distance was used as a similarity measure.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3.8: The English Wikipedia precision-recall curves for different code dimensionalities and different model variants. For real-valued codes cosine distance was used as a similarity measure. For binary codes the Hamming distance was used as a similarity measure.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1901.01695v1-Figure3.8-1",
            "image_path": "1901.01695v1-Figure3.8-1.png",
            "instance_id": "b3a179350ee6ad991663f446e6fdfd55",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific task or experiment the precision-recall curves are measuring in this Figure 3.8?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Flow chart of our proposed approach",
                "compound": false,
                "figure_type": "Flow chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Flow chart of our proposed approach",
            "categories": "nan",
            "figure_id": "Y11-1001.pdf-Figure1",
            "image_path": "Y11-1001.pdf-Figure1.png",
            "instance_id": "3186298e23a7e83d83a730a4f7131f4b",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the label of the oval with incoming arrow labeled Internet retrieval?",
            "reference_answer": "Snippets"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The label of the oval with the incoming arrow labeled \"Internet retrieval\" is \"Snippets.\"",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Flow chart of our proposed approach",
                "compound": false,
                "figure_type": "Flow chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Flow chart of our proposed approach",
            "categories": "nan",
            "figure_id": "Y11-1001.pdf-Figure1",
            "image_path": "Y11-1001.pdf-Figure1.png",
            "instance_id": "399eb7851b8c32a222fbbc858bb3ce13",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the first step in the proposed approach?",
            "reference_answer": "OOV query"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The first step in the proposed approach is \"OOV query.\"",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Flow chart of our proposed approach",
                "compound": false,
                "figure_type": "Flow chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Flow chart of our proposed approach",
            "categories": "nan",
            "figure_id": "Y11-1001.pdf-Figure1",
            "image_path": "Y11-1001.pdf-Figure1.png",
            "instance_id": "9a40296d9cc93a48de93fa919ea6f91b",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the shape of 'Selected features' an oval?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the shape of 'Selected features' is an oval.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Flow chart of our proposed approach",
                "compound": false,
                "figure_type": "Flow chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Flow chart of our proposed approach",
            "categories": "nan",
            "figure_id": "Y11-1001.pdf-Figure1",
            "image_path": "Y11-1001.pdf-Figure1.png",
            "instance_id": "d0194d1d122a0d705a39203176c377f6",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the proposed approach involve translation selection?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The proposed approach involves translation selection as indicated in the flowchart.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Translation features"
                    },
                    {
                        "B": "Translation candidates"
                    },
                    {
                        "C": "Selected features"
                    },
                    {
                        "D": "Selected translations"
                    }
                ],
                "caption": "Figure 1: Flow chart of our proposed approach",
                "compound": false,
                "figure_type": "Flow chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Flow chart of our proposed approach",
            "categories": "nan",
            "figure_id": "Y11-1001.pdf-Figure1",
            "image_path": "Y11-1001.pdf-Figure1.png",
            "instance_id": "af2786a3451fe447c7f6cc61e3b7e5bd",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What is the label of the oval that the 'Feature extraction' arrow points to?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Internet retrieval"
                    },
                    {
                        "B": "Feature extraction"
                    },
                    {
                        "C": "Translation selection"
                    },
                    {
                        "D": "Regular expression"
                    }
                ],
                "caption": "Figure 1: Flow chart of our proposed approach",
                "compound": false,
                "figure_type": "Flow chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Flow chart of our proposed approach",
            "categories": "nan",
            "figure_id": "Y11-1001.pdf-Figure1",
            "image_path": "Y11-1001.pdf-Figure1.png",
            "instance_id": "cbc3bbccf37b1ed78b73eb80d4034be1",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following are steps involved in the proposed approach? ",
            "reference_answer": "ABCD"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ABCD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Flow chart of our proposed approach",
                "compound": false,
                "figure_type": "Flow chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Flow chart of our proposed approach",
            "categories": "nan",
            "figure_id": "Y11-1001.pdf-Figure1",
            "image_path": "Y11-1001.pdf-Figure1.png",
            "instance_id": "78b2e292930b19b812ee822b83fd9131",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific algorithm used for 'Internet feature extraction'?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Typed DAG and structurally annotated proof for Lassy sample WS-U-E-A-0000000236.p.11.s.1.xml, depicting an analysis for the phrase Waarover gaat de machtstrijd (What is the power struggle about?).",
                "compound": true,
                "figure_type": "Tree",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Typed DAG and structurally annotated proof for Lassy sample WS-U-E-A-0000000236.p.11.s.1.xml, depicting an analysis for the phrase Waarover gaat de machtstrijd (What is the power struggle about?).",
            "categories": "nan",
            "figure_id": "2020.lrec-1.647.pdf-Figure1",
            "image_path": "2020.lrec-1.647.pdf-Figure1.png",
            "instance_id": "4611b515b657d780bef75b7841509cb4",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the numerical label in the rectangle at the bottom left of the dependency graph in the top figure?",
            "reference_answer": "2"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The numerical label in the rectangle at the bottom left of the dependency graph is 2.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Typed DAG and structurally annotated proof for Lassy sample WS-U-E-A-0000000236.p.11.s.1.xml, depicting an analysis for the phrase Waarover gaat de machtstrijd (What is the power struggle about?).",
                "compound": true,
                "figure_type": "Tree",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Typed DAG and structurally annotated proof for Lassy sample WS-U-E-A-0000000236.p.11.s.1.xml, depicting an analysis for the phrase Waarover gaat de machtstrijd (What is the power struggle about?).",
            "categories": "nan",
            "figure_id": "2020.lrec-1.647.pdf-Figure1",
            "image_path": "2020.lrec-1.647.pdf-Figure1.png",
            "instance_id": "2180242f2c10def4240fd97b1c98d634",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "Which nodes are dependents of node 3?",
            "reference_answer": "2, 4, and 5"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The dependents of node 3 (SV1) are nodes 4 (gaat) and 5 (NP).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Typed DAG and structurally annotated proof for Lassy sample WS-U-E-A-0000000236.p.11.s.1.xml, depicting an analysis for the phrase Waarover gaat de machtstrijd (What is the power struggle about?).",
                "compound": true,
                "figure_type": "Tree",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Typed DAG and structurally annotated proof for Lassy sample WS-U-E-A-0000000236.p.11.s.1.xml, depicting an analysis for the phrase Waarover gaat de machtstrijd (What is the power struggle about?).",
            "categories": "nan",
            "figure_id": "2020.lrec-1.647.pdf-Figure1",
            "image_path": "2020.lrec-1.647.pdf-Figure1.png",
            "instance_id": "32c4ae2e8725cf7b1df9ef14a6f27e25",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is node 3, labeled 'SV1', positioned below node 1, labeled 'WHQ', in the dependency graph?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. Node 3, labeled 'SV1', is positioned below node 1, labeled 'WHQ', in the dependency graph.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Typed DAG and structurally annotated proof for Lassy sample WS-U-E-A-0000000236.p.11.s.1.xml, depicting an analysis for the phrase Waarover gaat de machtstrijd (What is the power struggle about?).",
                "compound": true,
                "figure_type": "Tree",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Typed DAG and structurally annotated proof for Lassy sample WS-U-E-A-0000000236.p.11.s.1.xml, depicting an analysis for the phrase Waarover gaat de machtstrijd (What is the power struggle about?).",
            "categories": "nan",
            "figure_id": "2020.lrec-1.647.pdf-Figure1",
            "image_path": "2020.lrec-1.647.pdf-Figure1.png",
            "instance_id": "a08940feaffa5b9a88cace322a606c2c",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the reduction tree have exactly as many leaf nodes as words in the phrase under analysis?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "L"
                    },
                    {
                        "B": "E"
                    },
                    {
                        "C": "I"
                    },
                    {
                        "D": "WHQ"
                    }
                ],
                "caption": "Figure 1: Typed DAG and structurally annotated proof for Lassy sample WS-U-E-A-0000000236.p.11.s.1.xml, depicting an analysis for the phrase Waarover gaat de machtstrijd (What is the power struggle about?).",
                "compound": true,
                "figure_type": "Tree",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Typed DAG and structurally annotated proof for Lassy sample WS-U-E-A-0000000236.p.11.s.1.xml, depicting an analysis for the phrase Waarover gaat de machtstrijd (What is the power struggle about?).",
            "categories": "nan",
            "figure_id": "2020.lrec-1.647.pdf-Figure1",
            "image_path": "2020.lrec-1.647.pdf-Figure1.png",
            "instance_id": "3acad075664d0da0505b71e49c2d5a53",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which symbol is situated furthest to the right in the entire image of the bottom figure?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "1"
                    },
                    {
                        "B": "2"
                    },
                    {
                        "C": "3"
                    },
                    {
                        "D": "5"
                    }
                ],
                "caption": "Figure 1: Typed DAG and structurally annotated proof for Lassy sample WS-U-E-A-0000000236.p.11.s.1.xml, depicting an analysis for the phrase Waarover gaat de machtstrijd (What is the power struggle about?).",
                "compound": true,
                "figure_type": "Tree",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Typed DAG and structurally annotated proof for Lassy sample WS-U-E-A-0000000236.p.11.s.1.xml, depicting an analysis for the phrase Waarover gaat de machtstrijd (What is the power struggle about?).",
            "categories": "nan",
            "figure_id": "2020.lrec-1.647.pdf-Figure1",
            "image_path": "2020.lrec-1.647.pdf-Figure1.png",
            "instance_id": "2bf562ea56b65ad6daaa950814ad08d7",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which node has the highest number of dependents in the dependency graph?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Typed DAG and structurally annotated proof for Lassy sample WS-U-E-A-0000000236.p.11.s.1.xml, depicting an analysis for the phrase Waarover gaat de machtstrijd (What is the power struggle about?).",
                "compound": true,
                "figure_type": "Tree",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Typed DAG and structurally annotated proof for Lassy sample WS-U-E-A-0000000236.p.11.s.1.xml, depicting an analysis for the phrase Waarover gaat de machtstrijd (What is the power struggle about?).",
            "categories": "nan",
            "figure_id": "2020.lrec-1.647.pdf-Figure1",
            "image_path": "2020.lrec-1.647.pdf-Figure1.png",
            "instance_id": "3e1a4eb497a81e3bc7df3db6f8c6c31b",
            "qa_pair_type": "unanswerable",
            "question": "In what programming language was the algorithm implemented?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8: Automaton A for the move up constraint in Figure 7",
                "compound": false,
                "figure_type": "Graph",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: Automaton A for the move up constraint in Figure 7",
            "categories": "nan",
            "figure_id": "W12-4625.pdf-Figure8",
            "image_path": "W12-4625.pdf-Figure8.png",
            "instance_id": "0e904773a391cc9e73e17067cd52e9cb",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the label of the arrow leading from state q0 to state q1?",
            "reference_answer": "mod_rel"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The label of the arrow leading from state \\( q0 \\) to state \\( q1 \\) is \\( \\text{mod\\_rel} \\).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8: Automaton A for the move up constraint in Figure 7",
                "compound": false,
                "figure_type": "Graph",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: Automaton A for the move up constraint in Figure 7",
            "categories": "nan",
            "figure_id": "W12-4625.pdf-Figure8",
            "image_path": "W12-4625.pdf-Figure8.png",
            "instance_id": "480cbfac5a49ac2b680268e1197c8a4b",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "Which state represents the final state in Automaton A?",
            "reference_answer": "q1"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The final state in Automaton A is represented by \\( q_1 \\).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8: Automaton A for the move up constraint in Figure 7",
                "compound": false,
                "figure_type": "Graph",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: Automaton A for the move up constraint in Figure 7",
            "categories": "nan",
            "figure_id": "W12-4625.pdf-Figure8",
            "image_path": "W12-4625.pdf-Figure8.png",
            "instance_id": "eae3ed914558453770270fc9f7441893",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the arrow labeled 'mod_rel' point from the leftmost circle to the rightmost circle?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the arrow labeled 'mod_rel' points from the leftmost circle (q0) to the rightmost circle (q1).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8: Automaton A for the move up constraint in Figure 7",
                "compound": false,
                "figure_type": "Graph",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: Automaton A for the move up constraint in Figure 7",
            "categories": "nan",
            "figure_id": "W12-4625.pdf-Figure8",
            "image_path": "W12-4625.pdf-Figure8.png",
            "instance_id": "2a34f365cf0265c7e937d5e2ce36c934",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is q0 the start state of the automaton?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, q0 is the start state of the automaton.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "0"
                    },
                    {
                        "B": "1"
                    },
                    {
                        "C": "2"
                    },
                    {
                        "D": "3"
                    }
                ],
                "caption": "Figure 8: Automaton A for the move up constraint in Figure 7",
                "compound": false,
                "figure_type": "Graph",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: Automaton A for the move up constraint in Figure 7",
            "categories": "nan",
            "figure_id": "W12-4625.pdf-Figure8",
            "image_path": "W12-4625.pdf-Figure8.png",
            "instance_id": "982176cd45aff7498be5bcb5840a5f16",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "How many outgoing arrows does the circle with a double border have?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "q0"
                    },
                    {
                        "B": "q1"
                    },
                    {
                        "C": "Both"
                    },
                    {
                        "D": "Neither"
                    }
                ],
                "caption": "Figure 8: Automaton A for the move up constraint in Figure 7",
                "compound": false,
                "figure_type": "Graph",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: Automaton A for the move up constraint in Figure 7",
            "categories": "nan",
            "figure_id": "W12-4625.pdf-Figure8",
            "image_path": "W12-4625.pdf-Figure8.png",
            "instance_id": "b59fabc813028f7c1aa9b746a529bd76",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which states in the automaton have a self-loop?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8: Automaton A for the move up constraint in Figure 7",
                "compound": false,
                "figure_type": "Graph",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: Automaton A for the move up constraint in Figure 7",
            "categories": "nan",
            "figure_id": "W12-4625.pdf-Figure8",
            "image_path": "W12-4625.pdf-Figure8.png",
            "instance_id": "e28e9eab66998f34728ace84f05f86e6",
            "qa_pair_type": "unanswerable",
            "question": "What is the move up constraint?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6 An abstract syntax tree and word alignment for infix to postfix (Java to Java Virtual Machine) translation.",
                "compound": true,
                "figure_type": "Tree,Graph",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6 An abstract syntax tree and word alignment for infix to postfix (Java to Java Virtual Machine) translation.",
            "categories": "nan",
            "figure_id": "2020.cl-2.6.pdf-Figure6",
            "image_path": "2020.cl-2.6.pdf-Figure6.png",
            "instance_id": "bace5f827f67ba3b2119e16a6c3ebd77",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "How many rectangular boxes are present in the right-hand column of the word-alignment in the right half of Figure 6, and what is the text in the top-most box?",
            "reference_answer": "Five, 13"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "There are five rectangular boxes in the right-hand column of the word-alignment, and the text in the top-most box is \"13\".",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6 An abstract syntax tree and word alignment for infix to postfix (Java to Java Virtual Machine) translation.",
                "compound": true,
                "figure_type": "Tree,Graph",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6 An abstract syntax tree and word alignment for infix to postfix (Java to Java Virtual Machine) translation.",
            "categories": "nan",
            "figure_id": "2020.cl-2.6.pdf-Figure6",
            "image_path": "2020.cl-2.6.pdf-Figure6.png",
            "instance_id": "36a3dec317ba06f9d4f004fbb7daefce",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What label is used for numbers like 2 and 13, represented by i_2 and i_13 in the abstract syntax tree respectively?",
            "reference_answer": "Const"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The label used for numbers like 2 and 13, represented by i_2 and i_13 in the abstract syntax tree, is \"Const\".",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6 An abstract syntax tree and word alignment for infix to postfix (Java to Java Virtual Machine) translation.",
                "compound": true,
                "figure_type": "Tree,Graph",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6 An abstract syntax tree and word alignment for infix to postfix (Java to Java Virtual Machine) translation.",
            "categories": "nan",
            "figure_id": "2020.cl-2.6.pdf-Figure6",
            "image_path": "2020.cl-2.6.pdf-Figure6.png",
            "instance_id": "e73d8401f2b990d3650389a0af273626",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the abstract syntax tree on the left side of Figure 6 have a vertical height greater than the word alignment on the right side?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6 An abstract syntax tree and word alignment for infix to postfix (Java to Java Virtual Machine) translation.",
                "compound": true,
                "figure_type": "Tree,Graph",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6 An abstract syntax tree and word alignment for infix to postfix (Java to Java Virtual Machine) translation.",
            "categories": "nan",
            "figure_id": "2020.cl-2.6.pdf-Figure6",
            "image_path": "2020.cl-2.6.pdf-Figure6.png",
            "instance_id": "5a5a1687efe4857608ad1aa6b771448b",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Are the number of non-leaf nodes in the abstract syntax tree the same as the number of \"word\"s in each column of the word-alignment from infix to postfix?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "To determine if the number of non-leaf nodes in the abstract syntax tree (AST) matches the number of \"words\" in the word-alignment, we need to analyze both components.\n\n### Non-Leaf Nodes in the AST:\n1. **Add** (root node) - 1\n2. **Mul** - 1\n\nTotal non-leaf nodes in the AST = 2\n\n### \"Words\" in the Word-Alignment:\n1. bipush 13\n2. iconst_2\n3. iload 8\n4. imul\n5. iadd\n\nTotal \"words\" in the word-alignment = 5\n\n### Conclusion:\nThe number of non-leaf nodes (2) is not the same as the number of \"words\" (5) in the alignment.\n\n**Final Answer**: No, the number of non-leaf nodes in the abstract syntax tree is not the same as the number of \"words\" in each column of the word-alignment.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The abstract syntax tree is positioned to the left of the word alignment, and its elements are connected by lines indicating hierarchical relationships."
                    },
                    {
                        "B": "The word alignment is represented by a rectangular structure divided into horizontal segments, each containing a JVM instruction, and curved arrows depict the data flow."
                    },
                    {
                        "C": "The color of the text in the abstract syntax tree is different from the color of the text in the word alignment."
                    },
                    {
                        "D": "Some of the arrows in the word-alignment intersect one another."
                    }
                ],
                "caption": "Figure 6 An abstract syntax tree and word alignment for infix to postfix (Java to Java Virtual Machine) translation.",
                "compound": true,
                "figure_type": "Tree,Graph",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6 An abstract syntax tree and word alignment for infix to postfix (Java to Java Virtual Machine) translation.",
            "categories": "nan",
            "figure_id": "2020.cl-2.6.pdf-Figure6",
            "image_path": "2020.cl-2.6.pdf-Figure6.png",
            "instance_id": "bf88b8b65b295e75383de740a4cf0e6f",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Considering Figure 6, which of the following statements about the visual elements representing the translation from Java to the Java Virtual Machine are correct?",
            "reference_answer": "A,B,D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ABCD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "bipush"
                    },
                    {
                        "B": "iadd"
                    },
                    {
                        "C": "imul"
                    },
                    {
                        "D": "isub"
                    }
                ],
                "caption": "Figure 6 An abstract syntax tree and word alignment for infix to postfix (Java to Java Virtual Machine) translation.",
                "compound": true,
                "figure_type": "Tree,Graph",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6 An abstract syntax tree and word alignment for infix to postfix (Java to Java Virtual Machine) translation.",
            "categories": "nan",
            "figure_id": "2020.cl-2.6.pdf-Figure6",
            "image_path": "2020.cl-2.6.pdf-Figure6.png",
            "instance_id": "29cd40170a8363cd0abfd365c283fc5e",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Based on the provided caption and figure, which of the following operations are present in the Java Virtual Machine (JVM) code represented in the figure?",
            "reference_answer": "A, B, C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ABCD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6 An abstract syntax tree and word alignment for infix to postfix (Java to Java Virtual Machine) translation.",
                "compound": true,
                "figure_type": "Tree,Graph",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6 An abstract syntax tree and word alignment for infix to postfix (Java to Java Virtual Machine) translation.",
            "categories": "nan",
            "figure_id": "2020.cl-2.6.pdf-Figure6",
            "image_path": "2020.cl-2.6.pdf-Figure6.png",
            "instance_id": "a455e100d30bb2ae5cf163988134f7cb",
            "qa_pair_type": "unanswerable",
            "question": "What is the time complexity of the infix to postfix translation algorithm shown in Figure 6, considering the size of the input Java code as 'n'?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The time complexity of the infix to postfix translation algorithm is \\(O(n)\\), where \\(n\\) is the size of the input Java code. This is because the algorithm typically involves scanning the input expression a single time and using a stack to reorder the operators and operands, which operates in linear time relative to the number of elements processed.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Rule #1 diagram and example. C, V, T, and S are Consonant, Vowel, Tone, and Syllable respectively.",
                "compound": false,
                "figure_type": "Illustrative diagram",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Rule #1 diagram and example. C, V, T, and S are Consonant, Vowel, Tone, and Syllable respectively.",
            "categories": "nan",
            "figure_id": "Y18-1063.pdf-Figure4",
            "image_path": "Y18-1063.pdf-Figure4.png",
            "instance_id": "6a2cc545106dff61faf1b3dc44df658e",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the sequence of the symbols in the topmost row?",
            "reference_answer": "T1 T2 T1 T2"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The sequence of the symbols in the topmost row is: T1 C1 V1 C1 T2 C2 V2 C2.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Rule #1 diagram and example. C, V, T, and S are Consonant, Vowel, Tone, and Syllable respectively.",
                "compound": false,
                "figure_type": "Illustrative diagram",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Rule #1 diagram and example. C, V, T, and S are Consonant, Vowel, Tone, and Syllable respectively.",
            "categories": "nan",
            "figure_id": "Y18-1063.pdf-Figure4",
            "image_path": "Y18-1063.pdf-Figure4.png",
            "instance_id": "c9b38128e457873ea05743340f2a3981",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What does the phrase 't\u00e0i m\u00f4i' mean in English?",
            "reference_answer": "pale lips"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The phrase 't\u00e0i m\u00f4i' means \"pale lips\" in English.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Rule #1 diagram and example. C, V, T, and S are Consonant, Vowel, Tone, and Syllable respectively.",
                "compound": false,
                "figure_type": "Illustrative diagram",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Rule #1 diagram and example. C, V, T, and S are Consonant, Vowel, Tone, and Syllable respectively.",
            "categories": "nan",
            "figure_id": "Y18-1063.pdf-Figure4",
            "image_path": "Y18-1063.pdf-Figure4.png",
            "instance_id": "be696c019c8f6d656721f05e56102e7c",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is there anything in the image above the label 'Vietnamese Word' and to the left of T1 and C1V1C1?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Rule #1 diagram and example. C, V, T, and S are Consonant, Vowel, Tone, and Syllable respectively.",
                "compound": false,
                "figure_type": "Illustrative diagram",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Rule #1 diagram and example. C, V, T, and S are Consonant, Vowel, Tone, and Syllable respectively.",
            "categories": "nan",
            "figure_id": "Y18-1063.pdf-Figure4",
            "image_path": "Y18-1063.pdf-Figure4.png",
            "instance_id": "acd080846529fe287a25225efd88acd3",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the Vietnamese word 't\u1ed1i' contain two syllables?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Left"
                    },
                    {
                        "B": "Right"
                    },
                    {
                        "C": "Up"
                    },
                    {
                        "D": "Down"
                    }
                ],
                "caption": "Figure 4: Rule #1 diagram and example. C, V, T, and S are Consonant, Vowel, Tone, and Syllable respectively.",
                "compound": false,
                "figure_type": "Illustrative diagram",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Rule #1 diagram and example. C, V, T, and S are Consonant, Vowel, Tone, and Syllable respectively.",
            "categories": "nan",
            "figure_id": "Y18-1063.pdf-Figure4",
            "image_path": "Y18-1063.pdf-Figure4.png",
            "instance_id": "cac32fa084e745b1e8a271e587282db7",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What is the direction of the arrow in the figure?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "C1 V1 C1 T1 S1"
                    },
                    {
                        "B": "C2 V2 C2 T2 S2"
                    },
                    {
                        "C": "C1 V2 C2 T1 S1"
                    },
                    {
                        "D": "C2 V1 C1 T2 S2"
                    }
                ],
                "caption": "Figure 4: Rule #1 diagram and example. C, V, T, and S are Consonant, Vowel, Tone, and Syllable respectively.",
                "compound": false,
                "figure_type": "Illustrative diagram",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Rule #1 diagram and example. C, V, T, and S are Consonant, Vowel, Tone, and Syllable respectively.",
            "categories": "nan",
            "figure_id": "Y18-1063.pdf-Figure4",
            "image_path": "Y18-1063.pdf-Figure4.png",
            "instance_id": "e5bb98a212b5ac5794476c49464ebd36",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following represents the word 't\u00e1i'?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A C1 V1 C1 T1 S1",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Rule #1 diagram and example. C, V, T, and S are Consonant, Vowel, Tone, and Syllable respectively.",
                "compound": false,
                "figure_type": "Illustrative diagram",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Rule #1 diagram and example. C, V, T, and S are Consonant, Vowel, Tone, and Syllable respectively.",
            "categories": "nan",
            "figure_id": "Y18-1063.pdf-Figure4",
            "image_path": "Y18-1063.pdf-Figure4.png",
            "instance_id": "0bbd44a36cb11a97f7bfb99706fcf8ec",
            "qa_pair_type": "unanswerable",
            "question": "How does tone change the meaning of the Vietnamese word 't\u1ed1i'?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "In Vietnamese, tone changes the meaning of words significantly. The word \"t\u1ed1i\" with a different tone can mean \"tomorrow night\" (t\u1ed1i with a falling tone) or refer to \"dark\" (t\u1ed1i with a rising tone). Thus, the tone used directly alters the interpretation of the word.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: A) Histogram of PMI(i, j) values, for all pairs (i, j) with Nij > 0. B) Scatter plot of GloVe\u2019s learned biases. Both from a Wikipedia 2018 corpus.",
                "compound": true,
                "figure_type": "Line Chart,Scatter Plot",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: A) Histogram of PMI(i, j) values, for all pairs (i, j) with Nij > 0. B) Scatter plot of GloVe\u2019s learned biases. Both from a Wikipedia 2018 corpus.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2011.07013v1-Figure1-1",
            "image_path": "2011.07013v1-Figure1-1.png",
            "instance_id": "ff8fd2a0ff60413a46a5de4debd143fb",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate maximum value of the distribution in the left subplot?",
            "reference_answer": "215k"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: A) Histogram of PMI(i, j) values, for all pairs (i, j) with Nij > 0. B) Scatter plot of GloVe\u2019s learned biases. Both from a Wikipedia 2018 corpus.",
                "compound": true,
                "figure_type": "Line Chart,Scatter Plot",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: A) Histogram of PMI(i, j) values, for all pairs (i, j) with Nij > 0. B) Scatter plot of GloVe\u2019s learned biases. Both from a Wikipedia 2018 corpus.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2011.07013v1-Figure1-1",
            "image_path": "2011.07013v1-Figure1-1.png",
            "instance_id": "38a4b74a04456441046a7ec3dfc6b073",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the mean value of PMI(i, j) for all pairs with Nij > 0 in the Wikipedia 2018 corpus?",
            "reference_answer": "-0.99"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: A) Histogram of PMI(i, j) values, for all pairs (i, j) with Nij > 0. B) Scatter plot of GloVe\u2019s learned biases. Both from a Wikipedia 2018 corpus.",
                "compound": true,
                "figure_type": "Line Chart,Scatter Plot",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: A) Histogram of PMI(i, j) values, for all pairs (i, j) with Nij > 0. B) Scatter plot of GloVe\u2019s learned biases. Both from a Wikipedia 2018 corpus.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2011.07013v1-Figure1-1",
            "image_path": "2011.07013v1-Figure1-1.png",
            "instance_id": "a43f56780dc6fd3e82d68ea0a9d130b0",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the distribution curve in the left subplot look roughly symmetrical?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the distribution curve in the left subplot appears to be roughly symmetrical, centered around the mean.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: A) Histogram of PMI(i, j) values, for all pairs (i, j) with Nij > 0. B) Scatter plot of GloVe\u2019s learned biases. Both from a Wikipedia 2018 corpus.",
                "compound": true,
                "figure_type": "Line Chart,Scatter Plot",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: A) Histogram of PMI(i, j) values, for all pairs (i, j) with Nij > 0. B) Scatter plot of GloVe\u2019s learned biases. Both from a Wikipedia 2018 corpus.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2011.07013v1-Figure1-1",
            "image_path": "2011.07013v1-Figure1-1.png",
            "instance_id": "2301e8cc9a6db430c1d87cdf5a112469",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the mean of PMI(i, j) values greater than zero?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No. The mean of PMI(i, j) values is -0.99, which is less than zero.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Above the regression line"
                    },
                    {
                        "B": "Below the regression line"
                    },
                    {
                        "C": "Both"
                    },
                    {
                        "D": "Neither"
                    }
                ],
                "caption": "Figure 1: A) Histogram of PMI(i, j) values, for all pairs (i, j) with Nij > 0. B) Scatter plot of GloVe\u2019s learned biases. Both from a Wikipedia 2018 corpus.",
                "compound": true,
                "figure_type": "Line Chart,Scatter Plot",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: A) Histogram of PMI(i, j) values, for all pairs (i, j) with Nij > 0. B) Scatter plot of GloVe\u2019s learned biases. Both from a Wikipedia 2018 corpus.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2011.07013v1-Figure1-1",
            "image_path": "2011.07013v1-Figure1-1.png",
            "instance_id": "b05c29d1fcc3e1c5e086510837d5945b",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "There are data points in the subplot at x > 6 ...",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "bi"
                    },
                    {
                        "B": "lg"
                    },
                    {
                        "C": "Ni"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 1: A) Histogram of PMI(i, j) values, for all pairs (i, j) with Nij > 0. B) Scatter plot of GloVe\u2019s learned biases. Both from a Wikipedia 2018 corpus.",
                "compound": true,
                "figure_type": "Line Chart,Scatter Plot",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: A) Histogram of PMI(i, j) values, for all pairs (i, j) with Nij > 0. B) Scatter plot of GloVe\u2019s learned biases. Both from a Wikipedia 2018 corpus.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2011.07013v1-Figure1-1",
            "image_path": "2011.07013v1-Figure1-1.png",
            "instance_id": "34ac0fb12e00a622af3ccb407721426e",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the label of the y axis in the scatter plot of figure 1 B?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: A) Histogram of PMI(i, j) values, for all pairs (i, j) with Nij > 0. B) Scatter plot of GloVe\u2019s learned biases. Both from a Wikipedia 2018 corpus.",
                "compound": true,
                "figure_type": "Line Chart,Scatter Plot",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: A) Histogram of PMI(i, j) values, for all pairs (i, j) with Nij > 0. B) Scatter plot of GloVe\u2019s learned biases. Both from a Wikipedia 2018 corpus.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2011.07013v1-Figure1-1",
            "image_path": "2011.07013v1-Figure1-1.png",
            "instance_id": "20c874c796956bf04b53e4897675f348",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific method used for calculating the PMI(i, j) values in Figure 1A, and what are the specific values of Nij that were used in the calculation?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Linear relation between the average number of words per sentence and number of alignments per sentence",
                "compound": false,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Linear relation between the average number of words per sentence and number of alignments per sentence",
            "categories": "nan",
            "figure_id": "W12-0209.pdf-Figure1",
            "image_path": "W12-0209.pdf-Figure1.png",
            "instance_id": "181c8c4bf810fb6cad6011e1bd4aad8b",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What color are the data points shown in?",
            "reference_answer": "Black"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The data points shown in the plot are black.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Linear relation between the average number of words per sentence and number of alignments per sentence",
                "compound": false,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Linear relation between the average number of words per sentence and number of alignments per sentence",
            "categories": "nan",
            "figure_id": "W12-0209.pdf-Figure1",
            "image_path": "W12-0209.pdf-Figure1.png",
            "instance_id": "c9621e3202c7a7fdb1727873aed5f9ba",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the approximate number of alignments per sentence when the average sentence length is 10 words?",
            "reference_answer": "30"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Linear relation between the average number of words per sentence and number of alignments per sentence",
                "compound": false,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Linear relation between the average number of words per sentence and number of alignments per sentence",
            "categories": "nan",
            "figure_id": "W12-0209.pdf-Figure1",
            "image_path": "W12-0209.pdf-Figure1.png",
            "instance_id": "63c99766abc2486585a1bb979ab6792c",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Could you fit all the data points in a diagonal strip of length approximately one fourth the diagonal of the graph frame, going from the bottom left corner to the top right?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Linear relation between the average number of words per sentence and number of alignments per sentence",
                "compound": false,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Linear relation between the average number of words per sentence and number of alignments per sentence",
            "categories": "nan",
            "figure_id": "W12-0209.pdf-Figure1",
            "image_path": "W12-0209.pdf-Figure1.png",
            "instance_id": "5e3c38fc61a749ea2907e7f6d09ada6a",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Are there any data points with an average sentence length of more than 15 words?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, there are data points with an average sentence length of more than 15 words.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "diamonds"
                    },
                    {
                        "B": "dots"
                    },
                    {
                        "C": "circles"
                    },
                    {
                        "D": "x's"
                    }
                ],
                "caption": "Figure 1: Linear relation between the average number of words per sentence and number of alignments per sentence",
                "compound": false,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Linear relation between the average number of words per sentence and number of alignments per sentence",
            "categories": "nan",
            "figure_id": "W12-0209.pdf-Figure1",
            "image_path": "W12-0209.pdf-Figure1.png",
            "instance_id": "9962585d4a285c23c8cdd1fe1911ea1c",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What shape are the data points marked with?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "BC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "[10, 20]"
                    },
                    {
                        "B": "[20, 30]"
                    },
                    {
                        "C": "[30, 40]"
                    },
                    {
                        "D": "[40, 50]"
                    }
                ],
                "caption": "Figure 1: Linear relation between the average number of words per sentence and number of alignments per sentence",
                "compound": false,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Linear relation between the average number of words per sentence and number of alignments per sentence",
            "categories": "nan",
            "figure_id": "W12-0209.pdf-Figure1",
            "image_path": "W12-0209.pdf-Figure1.png",
            "instance_id": "f969fa03807d24ecf27b72f32b723998",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which y interval has fewest data points for the x interval [10, 15]?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Linear relation between the average number of words per sentence and number of alignments per sentence",
                "compound": false,
                "figure_type": "scatter plot",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Linear relation between the average number of words per sentence and number of alignments per sentence",
            "categories": "nan",
            "figure_id": "W12-0209.pdf-Figure1",
            "image_path": "W12-0209.pdf-Figure1.png",
            "instance_id": "294b17206b5b656a9f202c4c2596a317",
            "qa_pair_type": "unanswerable",
            "question": "Where were the studied sentences collected from?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 8: Social score against area Airbnb penetration rate (on a per city basis)",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 8: Social score against area Airbnb penetration rate (on a per city basis)",
            "categories": "['cs.CY cs.CL cs.LG cs.SI']",
            "figure_id": "2004.11604v1-Figure8-1",
            "image_path": "2004.11604v1-Figure8-1.png",
            "instance_id": "5532681c11c3ac9d3cb9930a43eb5c56",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate social score of the black line in the bottom left graph at an Airbnb penetration of 0.8?",
            "reference_answer": "Approximate -1.3"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 8: Social score against area Airbnb penetration rate (on a per city basis)",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 8: Social score against area Airbnb penetration rate (on a per city basis)",
            "categories": "['cs.CY cs.CL cs.LG cs.SI']",
            "figure_id": "2004.11604v1-Figure8-1",
            "image_path": "2004.11604v1-Figure8-1.png",
            "instance_id": "d7d0befa2f105c3adb7d8ae1c99c9e41",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the correlation coefficient between Airbnb penetration and social score in New York City?",
            "reference_answer": "-0.43"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The correlation coefficient between Airbnb penetration and social score in New York City is R = -0.43.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 8: Social score against area Airbnb penetration rate (on a per city basis)",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 8: Social score against area Airbnb penetration rate (on a per city basis)",
            "categories": "['cs.CY cs.CL cs.LG cs.SI']",
            "figure_id": "2004.11604v1-Figure8-1",
            "image_path": "2004.11604v1-Figure8-1.png",
            "instance_id": "6626bd55215d14dbafd32570b0e2465a",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the social score in the top center panel negative for all values of Airbnb penetration rate?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 8: Social score against area Airbnb penetration rate (on a per city basis)",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 8: Social score against area Airbnb penetration rate (on a per city basis)",
            "categories": "['cs.CY cs.CL cs.LG cs.SI']",
            "figure_id": "2004.11604v1-Figure8-1",
            "image_path": "2004.11604v1-Figure8-1.png",
            "instance_id": "db801444b0b421e86bc07199fa465997",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the social score negatively correlated with Airbnb penetration rate in every city?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the social score is negatively correlated with Airbnb penetration rate in every city shown in the chart.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Top center"
                    },
                    {
                        "B": "Bottom center"
                    },
                    {
                        "C": "Top right"
                    },
                    {
                        "D": "Top left"
                    }
                ],
                "caption": "Fig. 8: Social score against area Airbnb penetration rate (on a per city basis)",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 8: Social score against area Airbnb penetration rate (on a per city basis)",
            "categories": "['cs.CY cs.CL cs.LG cs.SI']",
            "figure_id": "2004.11604v1-Figure8-1",
            "image_path": "2004.11604v1-Figure8-1.png",
            "instance_id": "d2f8c0c1c196d065abf06c3246b1ca1b",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "In which subplot is the negative correlation between social score and Airbnb penetration the weakest?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Greater Manchester"
                    },
                    {
                        "B": "Melbourne"
                    },
                    {
                        "C": "New York City"
                    },
                    {
                        "D": "San Francisco"
                    }
                ],
                "caption": "Fig. 8: Social score against area Airbnb penetration rate (on a per city basis)",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 8: Social score against area Airbnb penetration rate (on a per city basis)",
            "categories": "['cs.CY cs.CL cs.LG cs.SI']",
            "figure_id": "2004.11604v1-Figure8-1",
            "image_path": "2004.11604v1-Figure8-1.png",
            "instance_id": "44e0ab1ab21334918c30db37234adc72",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which city has the lowest p-value?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ABC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 8: Social score against area Airbnb penetration rate (on a per city basis)",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 8: Social score against area Airbnb penetration rate (on a per city basis)",
            "categories": "['cs.CY cs.CL cs.LG cs.SI']",
            "figure_id": "2004.11604v1-Figure8-1",
            "image_path": "2004.11604v1-Figure8-1.png",
            "instance_id": "779196348c76463c58b0d225facdfb9d",
            "qa_pair_type": "unanswerable",
            "question": "How exactly is the social score calculated?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Averaged computational latency of different methods for English (upper) and Chinese (lower). Fullsentence method has its latency increasing with the sentence length, while our incremental methods have constant latency with different sentence lengths.",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Averaged computational latency of different methods for English (upper) and Chinese (lower). Fullsentence method has its latency increasing with the sentence length, while our incremental methods have constant latency with different sentence lengths.",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "1911.02750v3-Figure6-1",
            "image_path": "1911.02750v3-Figure6-1.png",
            "instance_id": "7ccff6107c70d574b30a8a35372f9c0b",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate latency of the black point at a phoneme number of 175?",
            "reference_answer": "2.2 seconds"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Averaged computational latency of different methods for English (upper) and Chinese (lower). Fullsentence method has its latency increasing with the sentence length, while our incremental methods have constant latency with different sentence lengths.",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Averaged computational latency of different methods for English (upper) and Chinese (lower). Fullsentence method has its latency increasing with the sentence length, while our incremental methods have constant latency with different sentence lengths.",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "1911.02750v3-Figure6-1",
            "image_path": "1911.02750v3-Figure6-1.png",
            "instance_id": "1e1de84c8ef6cb5c45d83edb5f4b7129",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the label of the x axis in both subplots?",
            "reference_answer": "Phoneme Numbers"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The label of the x-axis in both subplots is \"Phoneme Numbers\".",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Averaged computational latency of different methods for English (upper) and Chinese (lower). Fullsentence method has its latency increasing with the sentence length, while our incremental methods have constant latency with different sentence lengths.",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Averaged computational latency of different methods for English (upper) and Chinese (lower). Fullsentence method has its latency increasing with the sentence length, while our incremental methods have constant latency with different sentence lengths.",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "1911.02750v3-Figure6-1",
            "image_path": "1911.02750v3-Figure6-1.png",
            "instance_id": "b2340dd4132c4a43861ba753a239d4bd",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Are the legends of the two subplots positioned at the same corner of the graph frame?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the legends of the two subplots are positioned at the same corner of the graph frame.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Averaged computational latency of different methods for English (upper) and Chinese (lower). Fullsentence method has its latency increasing with the sentence length, while our incremental methods have constant latency with different sentence lengths.",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Averaged computational latency of different methods for English (upper) and Chinese (lower). Fullsentence method has its latency increasing with the sentence length, while our incremental methods have constant latency with different sentence lengths.",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "1911.02750v3-Figure6-1",
            "image_path": "1911.02750v3-Figure6-1.png",
            "instance_id": "f978ff2f3faac172b0fc242c5d94fe78",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Are the sentence length ranges the same for English and Chinese?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Blue"
                    },
                    {
                        "B": "Orange"
                    },
                    {
                        "C": "Black"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 6: Averaged computational latency of different methods for English (upper) and Chinese (lower). Fullsentence method has its latency increasing with the sentence length, while our incremental methods have constant latency with different sentence lengths.",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Averaged computational latency of different methods for English (upper) and Chinese (lower). Fullsentence method has its latency increasing with the sentence length, while our incremental methods have constant latency with different sentence lengths.",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "1911.02750v3-Figure6-1",
            "image_path": "1911.02750v3-Figure6-1.png",
            "instance_id": "da964f4ff7747edda358bd1b3250cd17",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which color represents Lookahead-1 in the figure?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "English"
                    },
                    {
                        "B": "Chinese"
                    },
                    {
                        "C": "Both"
                    },
                    {
                        "D": "Neither"
                    }
                ],
                "caption": "Figure 6: Averaged computational latency of different methods for English (upper) and Chinese (lower). Fullsentence method has its latency increasing with the sentence length, while our incremental methods have constant latency with different sentence lengths.",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Averaged computational latency of different methods for English (upper) and Chinese (lower). Fullsentence method has its latency increasing with the sentence length, while our incremental methods have constant latency with different sentence lengths.",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "1911.02750v3-Figure6-1",
            "image_path": "1911.02750v3-Figure6-1.png",
            "instance_id": "d66a798d91276df06f6f7b6b1dd38e43",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "For which language was the Lookahead-2 method tested?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Averaged computational latency of different methods for English (upper) and Chinese (lower). Fullsentence method has its latency increasing with the sentence length, while our incremental methods have constant latency with different sentence lengths.",
                "compound": true,
                "figure_type": "scatter plot",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Averaged computational latency of different methods for English (upper) and Chinese (lower). Fullsentence method has its latency increasing with the sentence length, while our incremental methods have constant latency with different sentence lengths.",
            "categories": "['cs.CL cs.SD eess.AS']",
            "figure_id": "1911.02750v3-Figure6-1",
            "image_path": "1911.02750v3-Figure6-1.png",
            "instance_id": "aeaab884507a452ad832baec435bdeb0",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific implementation of the \"Full-sentence\" method used in this study?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: System architecture of EVIDENCEMINER.",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: System architecture of EVIDENCEMINER.",
            "categories": "nan",
            "figure_id": "2020.acl-demos.8.pdf-Figure1",
            "image_path": "2020.acl-demos.8.pdf-Figure1.png",
            "instance_id": "c768a55a8556dae3cfabc2e6ad258fb0",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the color of the box containing the text \"Distantly-supervised NER:\"",
            "reference_answer": "Orange"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The box containing the text \"Distantly-supervised NER:\" is colored orange.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: System architecture of EVIDENCEMINER.",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: System architecture of EVIDENCEMINER.",
            "categories": "nan",
            "figure_id": "2020.acl-demos.8.pdf-Figure1",
            "image_path": "2020.acl-demos.8.pdf-Figure1.png",
            "instance_id": "eb0510d71bfed655398299940d89280f",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What does the final stage of evidenceminer consist of, after storage?",
            "reference_answer": "Text Evidence Retrieval, Annotation Result Visualization, Entity/Relation Summarization"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The final stage of EvidenceMiner consists of:\n\n1. Text Evidence Retrieval\n2. Annotation Result Visualization\n3. Entity/Relation Summarization",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: System architecture of EVIDENCEMINER.",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: System architecture of EVIDENCEMINER.",
            "categories": "nan",
            "figure_id": "2020.acl-demos.8.pdf-Figure1",
            "image_path": "2020.acl-demos.8.pdf-Figure1.png",
            "instance_id": "9d075b4a8bea270b001eb4c0e826ecca",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the 'User Query' component positioned above 'EvidenceMiner'?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, the 'User Query' component is positioned above the 'EvidenceMiner'.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: System architecture of EVIDENCEMINER.",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: System architecture of EVIDENCEMINER.",
            "categories": "nan",
            "figure_id": "2020.acl-demos.8.pdf-Figure1",
            "image_path": "2020.acl-demos.8.pdf-Figure1.png",
            "instance_id": "3aca80d15d6419389a593437e2718823",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does EVIDENCEMINER utilize multiple algorithms?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Distantly-supervised NER, Meta-pattern Discovery"
                    },
                    {
                        "B": "Corpora, Knowledge Bases"
                    },
                    {
                        "C": "User Query, EvidenceMiner"
                    },
                    {
                        "D": "Metadata Storage, Pattern Index, Full-text Index"
                    }
                ],
                "caption": "Figure 1: System architecture of EVIDENCEMINER.",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: System architecture of EVIDENCEMINER.",
            "categories": "nan",
            "figure_id": "2020.acl-demos.8.pdf-Figure1",
            "image_path": "2020.acl-demos.8.pdf-Figure1.png",
            "instance_id": "bdb00525491f916c8f54131113c62538",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What components of the system are part of the dashed box labeled Algorithm Pool, located at center height on the left side of the figure? ",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Corpora"
                    },
                    {
                        "B": "Knowledge Bases"
                    },
                    {
                        "C": "Algorithm Pool"
                    },
                    {
                        "D": "User Interface"
                    }
                ],
                "caption": "Figure 1: System architecture of EVIDENCEMINER.",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: System architecture of EVIDENCEMINER.",
            "categories": "nan",
            "figure_id": "2020.acl-demos.8.pdf-Figure1",
            "image_path": "2020.acl-demos.8.pdf-Figure1.png",
            "instance_id": "91a504b8a6ae25118f48dc9acd5ab9ae",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following is NOT a component of EVIDENCEMINER's system architecture?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: System architecture of EVIDENCEMINER.",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: System architecture of EVIDENCEMINER.",
            "categories": "nan",
            "figure_id": "2020.acl-demos.8.pdf-Figure1",
            "image_path": "2020.acl-demos.8.pdf-Figure1.png",
            "instance_id": "61adf28b97e965c28c0367224c54bfa6",
            "qa_pair_type": "unanswerable",
            "question": "What is the size of the full-text index database in terms of gigabytes?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: The architecture of GAIA multimedia knowledge extraction.",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: The architecture of GAIA multimedia knowledge extraction.",
            "categories": "nan",
            "figure_id": "2020.acl-demos.11.pdf-Figure3",
            "image_path": "2020.acl-demos.11.pdf-Figure3.png",
            "instance_id": "a537580b762c67c43b31e15f335f82cc",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the shape of the box containing the text \"Cross-modal Entity Linking\"?",
            "reference_answer": "Rectangle"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The shape of the box containing the text \"Cross-modal Entity Linking\" is rectangular.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: The architecture of GAIA multimedia knowledge extraction.",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: The architecture of GAIA multimedia knowledge extraction.",
            "categories": "nan",
            "figure_id": "2020.acl-demos.11.pdf-Figure3",
            "image_path": "2020.acl-demos.11.pdf-Figure3.png",
            "instance_id": "907f2602237c5efd87a5b056559f2cce",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the starting module in the architecture?",
            "reference_answer": "Multimedia News"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The starting module in the architecture is \"Multimedia News.\"",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: The architecture of GAIA multimedia knowledge extraction.",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: The architecture of GAIA multimedia knowledge extraction.",
            "categories": "nan",
            "figure_id": "2020.acl-demos.11.pdf-Figure3",
            "image_path": "2020.acl-demos.11.pdf-Figure3.png",
            "instance_id": "4030feb4a87c28d11e5c22e070c6098e",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the 'Textual Event Coreference' box positioned below the 'Textual KB' box?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: The architecture of GAIA multimedia knowledge extraction.",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: The architecture of GAIA multimedia knowledge extraction.",
            "categories": "nan",
            "figure_id": "2020.acl-demos.11.pdf-Figure3",
            "image_path": "2020.acl-demos.11.pdf-Figure3.png",
            "instance_id": "1179345160960c4b9c9cb082441947ba",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the GAIA multimedia knowledge extraction architecture include an applications module?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The GAIA multimedia knowledge extraction architecture includes an applications module, as indicated at the bottom of the diagram.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Visual Entity Linking"
                    },
                    {
                        "B": "Textual Entity Coreference"
                    },
                    {
                        "C": "Visual KB"
                    },
                    {
                        "D": "Cross-Media Fusion"
                    }
                ],
                "caption": "Figure 3: The architecture of GAIA multimedia knowledge extraction.",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: The architecture of GAIA multimedia knowledge extraction.",
            "categories": "nan",
            "figure_id": "2020.acl-demos.11.pdf-Figure3",
            "image_path": "2020.acl-demos.11.pdf-Figure3.png",
            "instance_id": "9bb8aaa99f3f2b59b9388e2da9be1ffe",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following tasks is not represented by a blue box in the architecture diagram?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Attentive Fine-Grained Entity Typing"
                    },
                    {
                        "B": "Rule based Fine-Grained Event Typing"
                    },
                    {
                        "C": "ELMo-LSTM CRF Entity Extractor"
                    },
                    {
                        "D": "Collective Entity Linking and NL Clustering"
                    }
                ],
                "caption": "Figure 3: The architecture of GAIA multimedia knowledge extraction.",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: The architecture of GAIA multimedia knowledge extraction.",
            "categories": "nan",
            "figure_id": "2020.acl-demos.11.pdf-Figure3",
            "image_path": "2020.acl-demos.11.pdf-Figure3.png",
            "instance_id": "93f8fcd8295104cf507a44c24bcacabf",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which module is part of Textual Event Extraction?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: The architecture of GAIA multimedia knowledge extraction.",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: The architecture of GAIA multimedia knowledge extraction.",
            "categories": "nan",
            "figure_id": "2020.acl-demos.11.pdf-Figure3",
            "image_path": "2020.acl-demos.11.pdf-Figure3.png",
            "instance_id": "02888150bccc31fbf6e34c74544681de",
            "qa_pair_type": "unanswerable",
            "question": "What is the accuracy of the GAIA multimedia knowledge extraction architecture in extracting information from images and videos?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Our model consists of a classifier, discriminator, and shared text encoder. The main task learns classification, while the auxiliary task gives negative supervision to generate distinct representations for sentences with different labels.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Our model consists of a classifier, discriminator, and shared text encoder. The main task learns classification, while the auxiliary task gives negative supervision to generate distinct representations for sentences with different labels.",
            "categories": "nan",
            "figure_id": "2020.acl-main.33.pdf-Figure1",
            "image_path": "2020.acl-main.33.pdf-Figure1.png",
            "instance_id": "732f71aeaec6e1056236bdfec2ea6fe7",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the color of the box that represents the Classifier?",
            "reference_answer": "Gray"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The color of the box that represents the Classifier is grey.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Our model consists of a classifier, discriminator, and shared text encoder. The main task learns classification, while the auxiliary task gives negative supervision to generate distinct representations for sentences with different labels.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Our model consists of a classifier, discriminator, and shared text encoder. The main task learns classification, while the auxiliary task gives negative supervision to generate distinct representations for sentences with different labels.",
            "categories": "nan",
            "figure_id": "2020.acl-main.33.pdf-Figure1",
            "image_path": "2020.acl-main.33.pdf-Figure1.png",
            "instance_id": "78e4b48f5f53b56687d055443f2bee85",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the output of the classifier in the figure?",
            "reference_answer": "Cold"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The output of the classifier in the figure is \"Cold.\"",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Our model consists of a classifier, discriminator, and shared text encoder. The main task learns classification, while the auxiliary task gives negative supervision to generate distinct representations for sentences with different labels.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Our model consists of a classifier, discriminator, and shared text encoder. The main task learns classification, while the auxiliary task gives negative supervision to generate distinct representations for sentences with different labels.",
            "categories": "nan",
            "figure_id": "2020.acl-main.33.pdf-Figure1",
            "image_path": "2020.acl-main.33.pdf-Figure1.png",
            "instance_id": "854008f8cbbe40355cb7c3d901448043",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the orange box labeled 'Encoder' have arrows pointing to both the left and right?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the orange box labeled 'Encoder' has arrows pointing to both the left and right.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Our model consists of a classifier, discriminator, and shared text encoder. The main task learns classification, while the auxiliary task gives negative supervision to generate distinct representations for sentences with different labels.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Our model consists of a classifier, discriminator, and shared text encoder. The main task learns classification, while the auxiliary task gives negative supervision to generate distinct representations for sentences with different labels.",
            "categories": "nan",
            "figure_id": "2020.acl-main.33.pdf-Figure1",
            "image_path": "2020.acl-main.33.pdf-Figure1.png",
            "instance_id": "e2fe4daee3862ae2b4c6e1f9cb2dde03",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the sentence 'A cold is a legit disease' included in the Main Task in the example of figure 1?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No. The sentence 'A cold is a legit disease' is part of the Auxiliary Task, not the Main Task.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Orange"
                    },
                    {
                        "B": "Blue"
                    },
                    {
                        "C": "Gray"
                    },
                    {
                        "D": "White"
                    }
                ],
                "caption": "Figure 1: Our model consists of a classifier, discriminator, and shared text encoder. The main task learns classification, while the auxiliary task gives negative supervision to generate distinct representations for sentences with different labels.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Our model consists of a classifier, discriminator, and shared text encoder. The main task learns classification, while the auxiliary task gives negative supervision to generate distinct representations for sentences with different labels.",
            "categories": "nan",
            "figure_id": "2020.acl-main.33.pdf-Figure1",
            "image_path": "2020.acl-main.33.pdf-Figure1.png",
            "instance_id": "a70199720bb69fbc897062187691b75f",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What is the color of the three intermediate boxes between the Encoder and the Classifier/Discriminator?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ACD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "I caught a cold."
                    },
                    {
                        "B": "I'm sneezing."
                    },
                    {
                        "C": "You will catch a cold."
                    },
                    {
                        "D": "I'm coughing."
                    }
                ],
                "caption": "Figure 1: Our model consists of a classifier, discriminator, and shared text encoder. The main task learns classification, while the auxiliary task gives negative supervision to generate distinct representations for sentences with different labels.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Our model consists of a classifier, discriminator, and shared text encoder. The main task learns classification, while the auxiliary task gives negative supervision to generate distinct representations for sentences with different labels.",
            "categories": "nan",
            "figure_id": "2020.acl-main.33.pdf-Figure1",
            "image_path": "2020.acl-main.33.pdf-Figure1.png",
            "instance_id": "7ef24116d1650bfe3841bf0bfd92f1ad",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following are inputs to the encoder? ",
            "reference_answer": "A,D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ACD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Our model consists of a classifier, discriminator, and shared text encoder. The main task learns classification, while the auxiliary task gives negative supervision to generate distinct representations for sentences with different labels.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Our model consists of a classifier, discriminator, and shared text encoder. The main task learns classification, while the auxiliary task gives negative supervision to generate distinct representations for sentences with different labels.",
            "categories": "nan",
            "figure_id": "2020.acl-main.33.pdf-Figure1",
            "image_path": "2020.acl-main.33.pdf-Figure1.png",
            "instance_id": "ee6ae45f7741d785f995b13cf9230d36",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific architecture of the text encoder used in this model?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: The UM-IU@LING confusion matrix for subtask A.",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: The UM-IU@LING confusion matrix for subtask A.",
            "categories": "nan",
            "figure_id": "S19-2138.pdf-Figure1",
            "image_path": "S19-2138.pdf-Figure1.png",
            "instance_id": "c0254657273cbb81dbf6957e52ab9243",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value represented by the darkest blue square in the confusion matrix shown in Figure 1?",
            "reference_answer": "44"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: The UM-IU@LING confusion matrix for subtask A.",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: The UM-IU@LING confusion matrix for subtask A.",
            "categories": "nan",
            "figure_id": "S19-2138.pdf-Figure1",
            "image_path": "S19-2138.pdf-Figure1.png",
            "instance_id": "b697a04dc0444a36ba769b18f284ba38",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the number of true positives for the 'OFF' class in the UM-IU@LING confusion matrix for subtask A?",
            "reference_answer": "161"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The number of true positives for the 'OFF' class in the given confusion matrix is 161.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: The UM-IU@LING confusion matrix for subtask A.",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: The UM-IU@LING confusion matrix for subtask A.",
            "categories": "nan",
            "figure_id": "S19-2138.pdf-Figure1",
            "image_path": "S19-2138.pdf-Figure1.png",
            "instance_id": "7940ba3c34d4e385fee2273f0f67c596",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the color of the cell representing true label 'OFF' and predicted label 'OFF' darker than that of the cell representing true label 'NOT' and predicted label 'OFF'?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: The UM-IU@LING confusion matrix for subtask A.",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: The UM-IU@LING confusion matrix for subtask A.",
            "categories": "nan",
            "figure_id": "S19-2138.pdf-Figure1",
            "image_path": "S19-2138.pdf-Figure1.png",
            "instance_id": "1cc8553b526df15569dbb73854a08f10",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Are there more instances with true label 'NOT' than there are instances with true label 'OFF'?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, there are more instances with true label 'NOT' (576) than with true label 'OFF' (240).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The cell representing 'True label: OFF' and 'Predicted label: OFF' has a value between 0.4 and 0.6."
                    },
                    {
                        "B": "The cell representing 'True label: NOT' and 'Predicted label: NOT' has the highest value."
                    },
                    {
                        "C": "The cell with the lowest value is colored dark blue/purple."
                    },
                    {
                        "D": "The cell representing 'True label: NOT' and 'Predicted label: OFF' has a value of approximately 0.08 based on the color scale."
                    }
                ],
                "caption": "Figure 1: The UM-IU@LING confusion matrix for subtask A.",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: The UM-IU@LING confusion matrix for subtask A.",
            "categories": "nan",
            "figure_id": "S19-2138.pdf-Figure1",
            "image_path": "S19-2138.pdf-Figure1.png",
            "instance_id": "f187922e8229bb0a40a5c102cc6b4959",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Considering the color scale on the right, which of the following statements about the confusion matrix in Figure 1 are true?  Select all that apply.",
            "reference_answer": "B,C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "BC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The number of true positives for 'NOT' is greater than 500."
                    },
                    {
                        "B": "The number of true negatives for 'OFF' is greater than 150."
                    },
                    {
                        "C": "The number of false positives for 'NOT' is less than 50."
                    },
                    {
                        "D": "The number of false negatives for 'OFF' is less than 100."
                    }
                ],
                "caption": "Figure 1: The UM-IU@LING confusion matrix for subtask A.",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: The UM-IU@LING confusion matrix for subtask A.",
            "categories": "nan",
            "figure_id": "S19-2138.pdf-Figure1",
            "image_path": "S19-2138.pdf-Figure1.png",
            "instance_id": "81dc6ec2bfd739eebb58efcdeece38d5",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Based on the UM-IU@LING confusion matrix for subtask A, which of the following statements are true?",
            "reference_answer": "A,B,D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A B C D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: The UM-IU@LING confusion matrix for subtask A.",
                "compound": false,
                "figure_type": "confusion matrix",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: The UM-IU@LING confusion matrix for subtask A.",
            "categories": "nan",
            "figure_id": "S19-2138.pdf-Figure1",
            "image_path": "S19-2138.pdf-Figure1.png",
            "instance_id": "ace69130efd46978ce613c418f89c09e",
            "qa_pair_type": "unanswerable",
            "question": "What model was used for the classifier that made the predictions in figure 1?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 15: Frequency-based classification accuracy on states from the ENRU decoder + lexical shortcuts.",
                "compound": false,
                "figure_type": "Heat Map",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 15: Frequency-based classification accuracy on states from the ENRU decoder + lexical shortcuts.",
            "categories": "nan",
            "figure_id": "W19-5211.pdf-Figure15",
            "image_path": "W19-5211.pdf-Figure15.png",
            "instance_id": "68ef5e800a81a199c4e68694611a1791",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What color corresponds to an accuracy of 1.0?",
            "reference_answer": "Red"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The color that corresponds to an accuracy of 1.0 is red.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 15: Frequency-based classification accuracy on states from the ENRU decoder + lexical shortcuts.",
                "compound": false,
                "figure_type": "Heat Map",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 15: Frequency-based classification accuracy on states from the ENRU decoder + lexical shortcuts.",
            "categories": "nan",
            "figure_id": "W19-5211.pdf-Figure15",
            "image_path": "W19-5211.pdf-Figure15.png",
            "instance_id": "e3de1ad798e7cf78a2aecb67393541d5",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the classification accuracy for layer 6, bin 10?",
            "reference_answer": "0.660"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The classification accuracy for layer 6, bin 10 is 1.000.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 15: Frequency-based classification accuracy on states from the ENRU decoder + lexical shortcuts.",
                "compound": false,
                "figure_type": "Heat Map",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 15: Frequency-based classification accuracy on states from the ENRU decoder + lexical shortcuts.",
            "categories": "nan",
            "figure_id": "W19-5211.pdf-Figure15",
            "image_path": "W19-5211.pdf-Figure15.png",
            "instance_id": "058861a2adb34f7747501ba1b2f82a23",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the width of the matrix larger than its height?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 15: Frequency-based classification accuracy on states from the ENRU decoder + lexical shortcuts.",
                "compound": false,
                "figure_type": "Heat Map",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 15: Frequency-based classification accuracy on states from the ENRU decoder + lexical shortcuts.",
            "categories": "nan",
            "figure_id": "W19-5211.pdf-Figure15",
            "image_path": "W19-5211.pdf-Figure15.png",
            "instance_id": "d049add34a7ae2cf28a025cee99c26c0",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the frequency-based classification accuracy for layer 6 and bin 10 higher than 0.6?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The frequency-based classification accuracy for layer 6 and bin 10 is 0.660, which is higher than 0.6.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Top left"
                    },
                    {
                        "B": "Top right"
                    },
                    {
                        "C": "Bottom left"
                    },
                    {
                        "D": "Bottom right"
                    }
                ],
                "caption": "Figure 15: Frequency-based classification accuracy on states from the ENRU decoder + lexical shortcuts.",
                "compound": false,
                "figure_type": "Heat Map",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 15: Frequency-based classification accuracy on states from the ENRU decoder + lexical shortcuts.",
            "categories": "nan",
            "figure_id": "W19-5211.pdf-Figure15",
            "image_path": "W19-5211.pdf-Figure15.png",
            "instance_id": "116fe3f198a6c56b7f36e9466b60f816",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which corner of the matrix has the highest value?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "bin 6"
                    },
                    {
                        "B": "bin 7"
                    },
                    {
                        "C": "bin 8"
                    },
                    {
                        "D": "bin 9"
                    }
                ],
                "caption": "Figure 15: Frequency-based classification accuracy on states from the ENRU decoder + lexical shortcuts.",
                "compound": false,
                "figure_type": "Heat Map",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 15: Frequency-based classification accuracy on states from the ENRU decoder + lexical shortcuts.",
            "categories": "nan",
            "figure_id": "W19-5211.pdf-Figure15",
            "image_path": "W19-5211.pdf-Figure15.png",
            "instance_id": "e4a9cab574e14a0fcae3f2e36bbbdd1b",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "For which of the following bins does accuracy conssitently descend with layer?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 15: Frequency-based classification accuracy on states from the ENRU decoder + lexical shortcuts.",
                "compound": false,
                "figure_type": "Heat Map",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 15: Frequency-based classification accuracy on states from the ENRU decoder + lexical shortcuts.",
            "categories": "nan",
            "figure_id": "W19-5211.pdf-Figure15",
            "image_path": "W19-5211.pdf-Figure15.png",
            "instance_id": "ea7ad23bec85bd66fe94b59cf190d267",
            "qa_pair_type": "unanswerable",
            "question": "What is the definition of the bins in figure 15?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4.2: Sentence augmented graphs for summarization in two successive iterations. GA(K): augmented graph in the iteration K. Virtual summary V = {s1, s3, s5}, which is constructed from x in the iteration (K1) by producingSummary. D = diag([C(s1), Cmax, C(s3), Cmax, C(s5)]). GA(K + 1): augmented graph in the iteration (K+1). V = {s1, s4, s5}, which is constructed from x in the iteration K by producingSummary. D = diag([C(s1), Cmax, Cmax, C(s4), C(s5)]). In both cases, Cmax equals to C(s1) indicating that sentence s1 has the maximum conductance.",
                "compound": true,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4.2: Sentence augmented graphs for summarization in two successive iterations. GA(K): augmented graph in the iteration K. Virtual summary V = {s1, s3, s5}, which is constructed from x in the iteration (K1) by producingSummary. D = diag([C(s1), Cmax, C(s3), Cmax, C(s5)]). GA(K + 1): augmented graph in the iteration (K+1). V = {s1, s4, s5}, which is constructed from x in the iteration K by producingSummary. D = diag([C(s1), Cmax, Cmax, C(s4), C(s5)]). In both cases, Cmax equals to C(s1) indicating that sentence s1 has the maximum conductance.",
            "categories": "nan",
            "figure_id": "D17-1020.pdf-Figure4.2",
            "image_path": "D17-1020.pdf-Figure4.2.png",
            "instance_id": "b42230830a737adc536c7796bda403e6",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "Which of the two graphs contains the node 'S4' connected to 'S1' with a solid line?",
            "reference_answer": "Both GA(K) and GA(K+1)"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The graph on the right, \\( G^A(K + 1) \\), contains the node 'S4' connected to 'S1' with a solid line.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4.2: Sentence augmented graphs for summarization in two successive iterations. GA(K): augmented graph in the iteration K. Virtual summary V = {s1, s3, s5}, which is constructed from x in the iteration (K1) by producingSummary. D = diag([C(s1), Cmax, C(s3), Cmax, C(s5)]). GA(K + 1): augmented graph in the iteration (K+1). V = {s1, s4, s5}, which is constructed from x in the iteration K by producingSummary. D = diag([C(s1), Cmax, Cmax, C(s4), C(s5)]). In both cases, Cmax equals to C(s1) indicating that sentence s1 has the maximum conductance.",
                "compound": true,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4.2: Sentence augmented graphs for summarization in two successive iterations. GA(K): augmented graph in the iteration K. Virtual summary V = {s1, s3, s5}, which is constructed from x in the iteration (K1) by producingSummary. D = diag([C(s1), Cmax, C(s3), Cmax, C(s5)]). GA(K + 1): augmented graph in the iteration (K+1). V = {s1, s4, s5}, which is constructed from x in the iteration K by producingSummary. D = diag([C(s1), Cmax, Cmax, C(s4), C(s5)]). In both cases, Cmax equals to C(s1) indicating that sentence s1 has the maximum conductance.",
            "categories": "nan",
            "figure_id": "D17-1020.pdf-Figure4.2",
            "image_path": "D17-1020.pdf-Figure4.2.png",
            "instance_id": "27abd0f6b1f21a0301981be3c9604902",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "How many vertices do each of the graphs in figure 4.2 have?",
            "reference_answer": "Both have 6 vertices."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Each of the graphs \\( G^A(K) \\) and \\( G^A(K+1) \\) in the figure has 6 vertices.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4.2: Sentence augmented graphs for summarization in two successive iterations. GA(K): augmented graph in the iteration K. Virtual summary V = {s1, s3, s5}, which is constructed from x in the iteration (K1) by producingSummary. D = diag([C(s1), Cmax, C(s3), Cmax, C(s5)]). GA(K + 1): augmented graph in the iteration (K+1). V = {s1, s4, s5}, which is constructed from x in the iteration K by producingSummary. D = diag([C(s1), Cmax, Cmax, C(s4), C(s5)]). In both cases, Cmax equals to C(s1) indicating that sentence s1 has the maximum conductance.",
                "compound": true,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4.2: Sentence augmented graphs for summarization in two successive iterations. GA(K): augmented graph in the iteration K. Virtual summary V = {s1, s3, s5}, which is constructed from x in the iteration (K1) by producingSummary. D = diag([C(s1), Cmax, C(s3), Cmax, C(s5)]). GA(K + 1): augmented graph in the iteration (K+1). V = {s1, s4, s5}, which is constructed from x in the iteration K by producingSummary. D = diag([C(s1), Cmax, Cmax, C(s4), C(s5)]). In both cases, Cmax equals to C(s1) indicating that sentence s1 has the maximum conductance.",
            "categories": "nan",
            "figure_id": "D17-1020.pdf-Figure4.2",
            "image_path": "D17-1020.pdf-Figure4.2.png",
            "instance_id": "6e098f4f7129229fb7f3bd99fe7949b5",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Are S1 and S4 connected to each other by a line in the graph on the right?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, S1 and S4 are connected to each other by a line in the graph on the right.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4.2: Sentence augmented graphs for summarization in two successive iterations. GA(K): augmented graph in the iteration K. Virtual summary V = {s1, s3, s5}, which is constructed from x in the iteration (K1) by producingSummary. D = diag([C(s1), Cmax, C(s3), Cmax, C(s5)]). GA(K + 1): augmented graph in the iteration (K+1). V = {s1, s4, s5}, which is constructed from x in the iteration K by producingSummary. D = diag([C(s1), Cmax, Cmax, C(s4), C(s5)]). In both cases, Cmax equals to C(s1) indicating that sentence s1 has the maximum conductance.",
                "compound": true,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4.2: Sentence augmented graphs for summarization in two successive iterations. GA(K): augmented graph in the iteration K. Virtual summary V = {s1, s3, s5}, which is constructed from x in the iteration (K1) by producingSummary. D = diag([C(s1), Cmax, C(s3), Cmax, C(s5)]). GA(K + 1): augmented graph in the iteration (K+1). V = {s1, s4, s5}, which is constructed from x in the iteration K by producingSummary. D = diag([C(s1), Cmax, Cmax, C(s4), C(s5)]). In both cases, Cmax equals to C(s1) indicating that sentence s1 has the maximum conductance.",
            "categories": "nan",
            "figure_id": "D17-1020.pdf-Figure4.2",
            "image_path": "D17-1020.pdf-Figure4.2.png",
            "instance_id": "479dda26d97011c71538dd279d8c5c39",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the subgraph restricted to vertices {S1, S2, S3, S4, S5} remain the same from GA(K) to GA(K+1)?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The virtual set corresponds in each case to the set of nodes that do not have any dashed lines attached to them."
                    },
                    {
                        "B": "S0 has a self loop i.e. a directed arrow to itself with a dashed line."
                    },
                    {
                        "C": "Dashed lines also connect node pairs that don't include S0."
                    },
                    {
                        "D": "There are dashed arrows going from S0 to other vertices."
                    }
                ],
                "caption": "Figure 4.2: Sentence augmented graphs for summarization in two successive iterations. GA(K): augmented graph in the iteration K. Virtual summary V = {s1, s3, s5}, which is constructed from x in the iteration (K1) by producingSummary. D = diag([C(s1), Cmax, C(s3), Cmax, C(s5)]). GA(K + 1): augmented graph in the iteration (K+1). V = {s1, s4, s5}, which is constructed from x in the iteration K by producingSummary. D = diag([C(s1), Cmax, Cmax, C(s4), C(s5)]). In both cases, Cmax equals to C(s1) indicating that sentence s1 has the maximum conductance.",
                "compound": true,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4.2: Sentence augmented graphs for summarization in two successive iterations. GA(K): augmented graph in the iteration K. Virtual summary V = {s1, s3, s5}, which is constructed from x in the iteration (K1) by producingSummary. D = diag([C(s1), Cmax, C(s3), Cmax, C(s5)]). GA(K + 1): augmented graph in the iteration (K+1). V = {s1, s4, s5}, which is constructed from x in the iteration K by producingSummary. D = diag([C(s1), Cmax, Cmax, C(s4), C(s5)]). In both cases, Cmax equals to C(s1) indicating that sentence s1 has the maximum conductance.",
            "categories": "nan",
            "figure_id": "D17-1020.pdf-Figure4.2",
            "image_path": "D17-1020.pdf-Figure4.2.png",
            "instance_id": "0b3051419a5c47f6151c4c5e542982fc",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following statements are true about the dashed lines in figure 4.2?",
            "reference_answer": "A,B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "BCDE",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "s2"
                    },
                    {
                        "B": "s3"
                    },
                    {
                        "C": "s4"
                    },
                    {
                        "D": "s5"
                    }
                ],
                "caption": "Figure 4.2: Sentence augmented graphs for summarization in two successive iterations. GA(K): augmented graph in the iteration K. Virtual summary V = {s1, s3, s5}, which is constructed from x in the iteration (K1) by producingSummary. D = diag([C(s1), Cmax, C(s3), Cmax, C(s5)]). GA(K + 1): augmented graph in the iteration (K+1). V = {s1, s4, s5}, which is constructed from x in the iteration K by producingSummary. D = diag([C(s1), Cmax, Cmax, C(s4), C(s5)]). In both cases, Cmax equals to C(s1) indicating that sentence s1 has the maximum conductance.",
                "compound": true,
                "figure_type": "graph",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4.2: Sentence augmented graphs for summarization in two successive iterations. GA(K): augmented graph in the iteration K. Virtual summary V = {s1, s3, s5}, which is constructed from x in the iteration (K1) by producingSummary. D = diag([C(s1), Cmax, C(s3), Cmax, C(s5)]). GA(K + 1): augmented graph in the iteration (K+1). V = {s1, s4, s5}, which is constructed from x in the iteration K by producingSummary. D = diag([C(s1), Cmax, Cmax, C(s4), C(s5)]). In both cases, Cmax equals to C(s1) indicating that sentence s1 has the maximum conductance.",
            "categories": "nan",
            "figure_id": "D17-1020.pdf-Figure4.2",
            "image_path": "D17-1020.pdf-Figure4.2.png",
            "instance_id": "f440551c2da0738323c8c8884d58838d",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which other vertices is S1 connected to in the graphs of figure 4.2?",
            "reference_answer": "A,B,C,D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ABCD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4.2: Sentence augmented graphs for summarization in two successive iterations. GA(K): augmented graph in the iteration K. Virtual summary V = {s1, s3, s5}, which is constructed from x in the iteration (K1) by producingSummary. D = diag([C(s1), Cmax, C(s3), Cmax, C(s5)]). GA(K + 1): augmented graph in the iteration (K+1). V = {s1, s4, s5}, which is constructed from x in the iteration K by producingSummary. D = diag([C(s1), Cmax, Cmax, C(s4), C(s5)]). In both cases, Cmax equals to C(s1) indicating that sentence s1 has the maximum conductance.",
                "compound": true,
                "figure_type": "graph",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4.2: Sentence augmented graphs for summarization in two successive iterations. GA(K): augmented graph in the iteration K. Virtual summary V = {s1, s3, s5}, which is constructed from x in the iteration (K1) by producingSummary. D = diag([C(s1), Cmax, C(s3), Cmax, C(s5)]). GA(K + 1): augmented graph in the iteration (K+1). V = {s1, s4, s5}, which is constructed from x in the iteration K by producingSummary. D = diag([C(s1), Cmax, Cmax, C(s4), C(s5)]). In both cases, Cmax equals to C(s1) indicating that sentence s1 has the maximum conductance.",
            "categories": "nan",
            "figure_id": "D17-1020.pdf-Figure4.2",
            "image_path": "D17-1020.pdf-Figure4.2.png",
            "instance_id": "0162cc562364f5d017365e26f1da4491",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific application of this sentence augmented graph, or what problem is it trying to solve? ",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The sentence augmented graph depicted here appears to illustrate a dynamic programming approach or an iterative process used in machine learning, particularly in reinforcement learning or decision-making scenarios. \n\nIn such contexts, this type of graph could be employed to visualize the state transitions and the reinforcement signals (rewards) for various states across time steps. Specifically, it may be used to represent:\n\n1. **Markov Decision Processes (MDPs)**: The nodes represent states, and the edges represent possible transitions between these states based on actions taken.\n\n2. **Temporal Difference Learning**: The graph could illustrate updates to state values as learning progresses.\n\n3. **Dynamic Programming Algorithms**: This can show how the states and actions are evaluated over multiple episodes or iterations.\n\nOverall, it likely addresses the problem of optimizing decision-making over time in a stochastic environment.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Comparing Speech Recognition Quality.",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Comparing Speech Recognition Quality.",
            "categories": "nan",
            "figure_id": "2007.sigdial-1.23.pdf-Figure6",
            "image_path": "2007.sigdial-1.23.pdf-Figure6.png",
            "instance_id": "5a89a17ec43952f92d35b7a2b8f6780f",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the lighter gray bar for the rejection percentage?",
            "reference_answer": "1"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Comparing Speech Recognition Quality.",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Comparing Speech Recognition Quality.",
            "categories": "nan",
            "figure_id": "2007.sigdial-1.23.pdf-Figure6",
            "image_path": "2007.sigdial-1.23.pdf-Figure6.png",
            "instance_id": "7afd2891054c7ba3bef31ea384f48f8a",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the highest value marked on the y axis?",
            "reference_answer": "1.4"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The highest value marked on the y-axis is 1.4.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Comparing Speech Recognition Quality.",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Comparing Speech Recognition Quality.",
            "categories": "nan",
            "figure_id": "2007.sigdial-1.23.pdf-Figure6",
            "image_path": "2007.sigdial-1.23.pdf-Figure6.png",
            "instance_id": "7993258c918f509cf839374d1fad261e",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the lighter gray bar for 'rejection%' taller than the darker gray bar for 'confScore'?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Comparing Speech Recognition Quality.",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Comparing Speech Recognition Quality.",
            "categories": "nan",
            "figure_id": "2007.sigdial-1.23.pdf-Figure6",
            "image_path": "2007.sigdial-1.23.pdf-Figure6.png",
            "instance_id": "1a7d213b2359eb3f663b01777f13d9f7",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the rejection percentage for 'real' speech higher than that for 'subject' speech?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The lighter bar on the left"
                    },
                    {
                        "B": "The darker bar on the left"
                    },
                    {
                        "C": "The lighter bar on the right"
                    },
                    {
                        "D": "The darker bar on the right"
                    }
                ],
                "caption": "Figure 6: Comparing Speech Recognition Quality.",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Comparing Speech Recognition Quality.",
            "categories": "nan",
            "figure_id": "2007.sigdial-1.23.pdf-Figure6",
            "image_path": "2007.sigdial-1.23.pdf-Figure6.png",
            "instance_id": "8b9e8eddd155fe599ef2de8b1234dd39",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "The error bars of which bar do not include or even touch the value 1.0?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "0.1"
                    },
                    {
                        "B": "0.2"
                    },
                    {
                        "C": "0.05"
                    },
                    {
                        "D": "0.5"
                    }
                ],
                "caption": "Figure 6: Comparing Speech Recognition Quality.",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Comparing Speech Recognition Quality.",
            "categories": "nan",
            "figure_id": "2007.sigdial-1.23.pdf-Figure6",
            "image_path": "2007.sigdial-1.23.pdf-Figure6.png",
            "instance_id": "42ce94b03be87ab791f620e3925ca5cd",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the difference between the values of two adjacent ticks on the y axis?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Comparing Speech Recognition Quality.",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Comparing Speech Recognition Quality.",
            "categories": "nan",
            "figure_id": "2007.sigdial-1.23.pdf-Figure6",
            "image_path": "2007.sigdial-1.23.pdf-Figure6.png",
            "instance_id": "ff3f6ca878fbbeab79138acfcbb3d2e4",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific speech recognition system used in the experiment?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Probability of a character being numeric (power transformed x 1 5 ).",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Probability of a character being numeric (power transformed x 1 5 ).",
            "categories": "['cs.CL']",
            "figure_id": "2010.07988v1-Figure1-1",
            "image_path": "2010.07988v1-Figure1-1.png",
            "instance_id": "3c82a9ce1d3ac9f408827758202e9785",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate height of the orange bar at a transformed percentage (1/5) of 0.0?",
            "reference_answer": "800"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Probability of a character being numeric (power transformed x 1 5 ).",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Probability of a character being numeric (power transformed x 1 5 ).",
            "categories": "['cs.CL']",
            "figure_id": "2010.07988v1-Figure1-1",
            "image_path": "2010.07988v1-Figure1-1.png",
            "instance_id": "d4e11a86ab5710961a9aac9f3fb8ad48",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the highest number of uninformative tweets observed for any transformed percentage?",
            "reference_answer": "Approximately 350"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Probability of a character being numeric (power transformed x 1 5 ).",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Probability of a character being numeric (power transformed x 1 5 ).",
            "categories": "['cs.CL']",
            "figure_id": "2010.07988v1-Figure1-1",
            "image_path": "2010.07988v1-Figure1-1.png",
            "instance_id": "f00f8fa15cab4236505811df0d48cb84",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Are orange bars higher than blue bars for x < 1.0?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The orange bars are higher than the blue bars for x < 1.0.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Probability of a character being numeric (power transformed x 1 5 ).",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Probability of a character being numeric (power transformed x 1 5 ).",
            "categories": "['cs.CL']",
            "figure_id": "2010.07988v1-Figure1-1",
            "image_path": "2010.07988v1-Figure1-1.png",
            "instance_id": "4d6b4c74a4bf21780e393a7ddef996f5",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the probability of a character being numeric higher for uninformative tweets at values of transformed percentage (1\\5) above 1.5?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Top left"
                    },
                    {
                        "B": "Top right"
                    },
                    {
                        "C": "Bottom left"
                    },
                    {
                        "D": "Bottom right"
                    }
                ],
                "caption": "Figure 1: Probability of a character being numeric (power transformed x 1 5 ).",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Probability of a character being numeric (power transformed x 1 5 ).",
            "categories": "['cs.CL']",
            "figure_id": "2010.07988v1-Figure1-1",
            "image_path": "2010.07988v1-Figure1-1.png",
            "instance_id": "34844030f51fe02ee8116386d1d7e264",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "In which corner of the figure does the legend appear?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "INFORMATIVE"
                    },
                    {
                        "B": "UNINFORMATIVE"
                    },
                    {
                        "C": "Both"
                    },
                    {
                        "D": "Neither"
                    }
                ],
                "caption": "Figure 1: Probability of a character being numeric (power transformed x 1 5 ).",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Probability of a character being numeric (power transformed x 1 5 ).",
            "categories": "['cs.CL']",
            "figure_id": "2010.07988v1-Figure1-1",
            "image_path": "2010.07988v1-Figure1-1.png",
            "instance_id": "36de4874c81f873ca75925ba076b9da7",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which category has a nonzero probability of a character being numeric at values of transformed percentage (1\\5) above 2.0?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Probability of a character being numeric (power transformed x 1 5 ).",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Probability of a character being numeric (power transformed x 1 5 ).",
            "categories": "['cs.CL']",
            "figure_id": "2010.07988v1-Figure1-1",
            "image_path": "2010.07988v1-Figure1-1.png",
            "instance_id": "bf0a7bcfcbd74ea2c54f32081f09d64c",
            "qa_pair_type": "unanswerable",
            "question": "What dataset was used for the chart in figure 1?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 1. Aggregate results. Outcome is aggregate score based on the raw data. There are major differences between article-unit analysis and paragraph-unit analysis when considering the impact of choices in preprocessing. Error bars are \u00b11 unadjusted SE based only on subset of scores at given factor combinations.",
                "compound": true,
                "figure_type": "Line Chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 1. Aggregate results. Outcome is aggregate score based on the raw data. There are major differences between article-unit analysis and paragraph-unit analysis when considering the impact of choices in preprocessing. Error bars are \u00b11 unadjusted SE based only on subset of scores at given factor combinations.",
            "categories": "['cs.CL stat.AP']",
            "figure_id": "1404.7362v1-Figure1-1",
            "image_path": "1404.7362v1-Figure1-1.png",
            "instance_id": "46d7cc10167b4582ca41b2606afc7a99",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of the highest point on the dashed line in the rightmost graph?",
            "reference_answer": "Approximately 4.4"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 1. Aggregate results. Outcome is aggregate score based on the raw data. There are major differences between article-unit analysis and paragraph-unit analysis when considering the impact of choices in preprocessing. Error bars are \u00b11 unadjusted SE based only on subset of scores at given factor combinations.",
                "compound": true,
                "figure_type": "Line Chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 1. Aggregate results. Outcome is aggregate score based on the raw data. There are major differences between article-unit analysis and paragraph-unit analysis when considering the impact of choices in preprocessing. Error bars are \u00b11 unadjusted SE based only on subset of scores at given factor combinations.",
            "categories": "['cs.CL stat.AP']",
            "figure_id": "1404.7362v1-Figure1-1",
            "image_path": "1404.7362v1-Figure1-1.png",
            "instance_id": "e623ea3c7a9e0a66994087d846e27762",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What does 'P' and 'A' stand for in the figure?",
            "reference_answer": "Paragraph-Unit and Article-Unit"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 1. Aggregate results. Outcome is aggregate score based on the raw data. There are major differences between article-unit analysis and paragraph-unit analysis when considering the impact of choices in preprocessing. Error bars are \u00b11 unadjusted SE based only on subset of scores at given factor combinations.",
                "compound": true,
                "figure_type": "Line Chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 1. Aggregate results. Outcome is aggregate score based on the raw data. There are major differences between article-unit analysis and paragraph-unit analysis when considering the impact of choices in preprocessing. Error bars are \u00b11 unadjusted SE based only on subset of scores at given factor combinations.",
            "categories": "['cs.CL stat.AP']",
            "figure_id": "1404.7362v1-Figure1-1",
            "image_path": "1404.7362v1-Figure1-1.png",
            "instance_id": "2ee734362874d69b95262ee3b4434f6b",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the highest aggregate score for the paragraph-unit analysis in the leftmost plot lower than 4.6?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the highest aggregate score for the paragraph-unit analysis in the leftmost plot is lower than 4.6.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 1. Aggregate results. Outcome is aggregate score based on the raw data. There are major differences between article-unit analysis and paragraph-unit analysis when considering the impact of choices in preprocessing. Error bars are \u00b11 unadjusted SE based only on subset of scores at given factor combinations.",
                "compound": true,
                "figure_type": "Line Chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 1. Aggregate results. Outcome is aggregate score based on the raw data. There are major differences between article-unit analysis and paragraph-unit analysis when considering the impact of choices in preprocessing. Error bars are \u00b11 unadjusted SE based only on subset of scores at given factor combinations.",
            "categories": "['cs.CL stat.AP']",
            "figure_id": "1404.7362v1-Figure1-1",
            "image_path": "1404.7362v1-Figure1-1.png",
            "instance_id": "0181fab9f1674fec9ef7f1eac9dc5177",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Are the aggregate scores for paragraph-unit analysis consistently higher than that for article-unit analysis?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "4.6"
                    },
                    {
                        "B": "4.4"
                    },
                    {
                        "C": "4.2"
                    },
                    {
                        "D": "4.0"
                    }
                ],
                "caption": "Fig. 1. Aggregate results. Outcome is aggregate score based on the raw data. There are major differences between article-unit analysis and paragraph-unit analysis when considering the impact of choices in preprocessing. Error bars are \u00b11 unadjusted SE based only on subset of scores at given factor combinations.",
                "compound": true,
                "figure_type": "Line Chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 1. Aggregate results. Outcome is aggregate score based on the raw data. There are major differences between article-unit analysis and paragraph-unit analysis when considering the impact of choices in preprocessing. Error bars are \u00b11 unadjusted SE based only on subset of scores at given factor combinations.",
            "categories": "['cs.CL stat.AP']",
            "figure_id": "1404.7362v1-Figure1-1",
            "image_path": "1404.7362v1-Figure1-1.png",
            "instance_id": "c943a77295d7b3624785e468fb96ffcb",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What is the approximate maximum value of the dotted line in the center graph?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "cooc"
                    },
                    {
                        "B": "corr"
                    },
                    {
                        "C": "lasso"
                    },
                    {
                        "D": "l1lr"
                    }
                ],
                "caption": "Fig. 1. Aggregate results. Outcome is aggregate score based on the raw data. There are major differences between article-unit analysis and paragraph-unit analysis when considering the impact of choices in preprocessing. Error bars are \u00b11 unadjusted SE based only on subset of scores at given factor combinations.",
                "compound": true,
                "figure_type": "Line Chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 1. Aggregate results. Outcome is aggregate score based on the raw data. There are major differences between article-unit analysis and paragraph-unit analysis when considering the impact of choices in preprocessing. Error bars are \u00b11 unadjusted SE based only on subset of scores at given factor combinations.",
            "categories": "['cs.CL stat.AP']",
            "figure_id": "1404.7362v1-Figure1-1",
            "image_path": "1404.7362v1-Figure1-1.png",
            "instance_id": "938a5aee41b0a2c61c35cc218fad1522",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "For which method is the aggregate score for paragraph-unit analysis the lowest?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 1. Aggregate results. Outcome is aggregate score based on the raw data. There are major differences between article-unit analysis and paragraph-unit analysis when considering the impact of choices in preprocessing. Error bars are \u00b11 unadjusted SE based only on subset of scores at given factor combinations.",
                "compound": true,
                "figure_type": "Line Chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 1. Aggregate results. Outcome is aggregate score based on the raw data. There are major differences between article-unit analysis and paragraph-unit analysis when considering the impact of choices in preprocessing. Error bars are \u00b11 unadjusted SE based only on subset of scores at given factor combinations.",
            "categories": "['cs.CL stat.AP']",
            "figure_id": "1404.7362v1-Figure1-1",
            "image_path": "1404.7362v1-Figure1-1.png",
            "instance_id": "2f61259bdb98c52e7676c5d737bde149",
            "qa_pair_type": "unanswerable",
            "question": "What dataset was used to obtain the results in the charts in figure 1?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Added Words improve Multiclass Classification between 1.5% and 13% in the range of 150 to 2000 training examples. Tests were conducted using equal size samples of Headlines categorized into \u2019World-Post\u2019, \u2019Crime\u2019, \u2019Politics\u2019, \u2019Entertainment\u2019, \u2019Sports\u2019 or \u2019Comedy\u2019. A 900 Estimator Random Forest classifier was trained for each each data point, tested using 2000 examples, and averaged using 10-fold cross validation.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Added Words improve Multiclass Classification between 1.5% and 13% in the range of 150 to 2000 training examples. Tests were conducted using equal size samples of Headlines categorized into \u2019World-Post\u2019, \u2019Crime\u2019, \u2019Politics\u2019, \u2019Entertainment\u2019, \u2019Sports\u2019 or \u2019Comedy\u2019. A 900 Estimator Random Forest classifier was trained for each each data point, tested using 2000 examples, and averaged using 10-fold cross validation.",
            "categories": "['cs.CL']",
            "figure_id": "1909.07512v1-Figure6-1",
            "image_path": "1909.07512v1-Figure6-1.png",
            "instance_id": "12ec67fa9c9576f4dff26a4c172eb767",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate Micro F1 score of the green line at a training size of 1500?",
            "reference_answer": "0.59"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Added Words improve Multiclass Classification between 1.5% and 13% in the range of 150 to 2000 training examples. Tests were conducted using equal size samples of Headlines categorized into \u2019World-Post\u2019, \u2019Crime\u2019, \u2019Politics\u2019, \u2019Entertainment\u2019, \u2019Sports\u2019 or \u2019Comedy\u2019. A 900 Estimator Random Forest classifier was trained for each each data point, tested using 2000 examples, and averaged using 10-fold cross validation.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Added Words improve Multiclass Classification between 1.5% and 13% in the range of 150 to 2000 training examples. Tests were conducted using equal size samples of Headlines categorized into \u2019World-Post\u2019, \u2019Crime\u2019, \u2019Politics\u2019, \u2019Entertainment\u2019, \u2019Sports\u2019 or \u2019Comedy\u2019. A 900 Estimator Random Forest classifier was trained for each each data point, tested using 2000 examples, and averaged using 10-fold cross validation.",
            "categories": "['cs.CL']",
            "figure_id": "1909.07512v1-Figure6-1",
            "image_path": "1909.07512v1-Figure6-1.png",
            "instance_id": "d808e40197f6a6a39a739288e7166fa3",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the approximate range of the lowest and highest micro f1 score of the models?",
            "reference_answer": "Between 0.2 and 0.65"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Based on the graph, the approximate range of the lowest micro F1 score is around 0.2 to the highest micro F1 score of about 0.6.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Added Words improve Multiclass Classification between 1.5% and 13% in the range of 150 to 2000 training examples. Tests were conducted using equal size samples of Headlines categorized into \u2019World-Post\u2019, \u2019Crime\u2019, \u2019Politics\u2019, \u2019Entertainment\u2019, \u2019Sports\u2019 or \u2019Comedy\u2019. A 900 Estimator Random Forest classifier was trained for each each data point, tested using 2000 examples, and averaged using 10-fold cross validation.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Added Words improve Multiclass Classification between 1.5% and 13% in the range of 150 to 2000 training examples. Tests were conducted using equal size samples of Headlines categorized into \u2019World-Post\u2019, \u2019Crime\u2019, \u2019Politics\u2019, \u2019Entertainment\u2019, \u2019Sports\u2019 or \u2019Comedy\u2019. A 900 Estimator Random Forest classifier was trained for each each data point, tested using 2000 examples, and averaged using 10-fold cross validation.",
            "categories": "['cs.CL']",
            "figure_id": "1909.07512v1-Figure6-1",
            "image_path": "1909.07512v1-Figure6-1.png",
            "instance_id": "49710f07d57a54215b26898639acaec8",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the green line representing 'Extended Pseudo Headlines' consistently higher than the blue line representing 'Original Headlines'?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the green line representing 'Extended Pseudo Headlines' is consistently higher than the blue line representing 'Original Headlines' throughout the training size range displayed in the graph.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Added Words improve Multiclass Classification between 1.5% and 13% in the range of 150 to 2000 training examples. Tests were conducted using equal size samples of Headlines categorized into \u2019World-Post\u2019, \u2019Crime\u2019, \u2019Politics\u2019, \u2019Entertainment\u2019, \u2019Sports\u2019 or \u2019Comedy\u2019. A 900 Estimator Random Forest classifier was trained for each each data point, tested using 2000 examples, and averaged using 10-fold cross validation.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Added Words improve Multiclass Classification between 1.5% and 13% in the range of 150 to 2000 training examples. Tests were conducted using equal size samples of Headlines categorized into \u2019World-Post\u2019, \u2019Crime\u2019, \u2019Politics\u2019, \u2019Entertainment\u2019, \u2019Sports\u2019 or \u2019Comedy\u2019. A 900 Estimator Random Forest classifier was trained for each each data point, tested using 2000 examples, and averaged using 10-fold cross validation.",
            "categories": "['cs.CL']",
            "figure_id": "1909.07512v1-Figure6-1",
            "image_path": "1909.07512v1-Figure6-1.png",
            "instance_id": "2e36aa48c89ed9889c043459709284c8",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the performance of the classifier with extended pseudo headlines better than the performance of the classifier with original headlines at a training size of 2000?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the performance of the classifier with extended pseudo headlines is better than the performance of the classifier with original headlines at a training size of 2000.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The green line is higher than the blue line across all training sizes."
                    },
                    {
                        "B": "The green line has similar values to the blue line at the beginning of the x-axis."
                    },
                    {
                        "C": "The green line has similar values to the blue line at the end of the x-axis."
                    },
                    {
                        "D": "The green line has better micro f1 scores than the blue line at training size 500."
                    }
                ],
                "caption": "Figure 6: Added Words improve Multiclass Classification between 1.5% and 13% in the range of 150 to 2000 training examples. Tests were conducted using equal size samples of Headlines categorized into \u2019World-Post\u2019, \u2019Crime\u2019, \u2019Politics\u2019, \u2019Entertainment\u2019, \u2019Sports\u2019 or \u2019Comedy\u2019. A 900 Estimator Random Forest classifier was trained for each each data point, tested using 2000 examples, and averaged using 10-fold cross validation.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Added Words improve Multiclass Classification between 1.5% and 13% in the range of 150 to 2000 training examples. Tests were conducted using equal size samples of Headlines categorized into \u2019World-Post\u2019, \u2019Crime\u2019, \u2019Politics\u2019, \u2019Entertainment\u2019, \u2019Sports\u2019 or \u2019Comedy\u2019. A 900 Estimator Random Forest classifier was trained for each each data point, tested using 2000 examples, and averaged using 10-fold cross validation.",
            "categories": "['cs.CL']",
            "figure_id": "1909.07512v1-Figure6-1",
            "image_path": "1909.07512v1-Figure6-1.png",
            "instance_id": "e871642a3f4a0dc4526911bcb3111216",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What can be said about the relationship between the blue and green line?",
            "reference_answer": "B,C,D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ABCD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The lowest micro f1 score is approximately 0.2."
                    },
                    {
                        "B": "The highest micro f1 score is approximately 0.8."
                    },
                    {
                        "C": "At a training size of 2500, the classifier with extended pseudo headlines outperforms the classifier with original headlines."
                    },
                    {
                        "D": "At a training size of 500, the classifier has a micro f1 score of approximately 0.6."
                    }
                ],
                "caption": "Figure 6: Added Words improve Multiclass Classification between 1.5% and 13% in the range of 150 to 2000 training examples. Tests were conducted using equal size samples of Headlines categorized into \u2019World-Post\u2019, \u2019Crime\u2019, \u2019Politics\u2019, \u2019Entertainment\u2019, \u2019Sports\u2019 or \u2019Comedy\u2019. A 900 Estimator Random Forest classifier was trained for each each data point, tested using 2000 examples, and averaged using 10-fold cross validation.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Added Words improve Multiclass Classification between 1.5% and 13% in the range of 150 to 2000 training examples. Tests were conducted using equal size samples of Headlines categorized into \u2019World-Post\u2019, \u2019Crime\u2019, \u2019Politics\u2019, \u2019Entertainment\u2019, \u2019Sports\u2019 or \u2019Comedy\u2019. A 900 Estimator Random Forest classifier was trained for each each data point, tested using 2000 examples, and averaged using 10-fold cross validation.",
            "categories": "['cs.CL']",
            "figure_id": "1909.07512v1-Figure6-1",
            "image_path": "1909.07512v1-Figure6-1.png",
            "instance_id": "fefde9b5202512147d97b2c91546ab13",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following statements concerning the classifier with original headlines is true?",
            "reference_answer": "A,C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Added Words improve Multiclass Classification between 1.5% and 13% in the range of 150 to 2000 training examples. Tests were conducted using equal size samples of Headlines categorized into \u2019World-Post\u2019, \u2019Crime\u2019, \u2019Politics\u2019, \u2019Entertainment\u2019, \u2019Sports\u2019 or \u2019Comedy\u2019. A 900 Estimator Random Forest classifier was trained for each each data point, tested using 2000 examples, and averaged using 10-fold cross validation.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Added Words improve Multiclass Classification between 1.5% and 13% in the range of 150 to 2000 training examples. Tests were conducted using equal size samples of Headlines categorized into \u2019World-Post\u2019, \u2019Crime\u2019, \u2019Politics\u2019, \u2019Entertainment\u2019, \u2019Sports\u2019 or \u2019Comedy\u2019. A 900 Estimator Random Forest classifier was trained for each each data point, tested using 2000 examples, and averaged using 10-fold cross validation.",
            "categories": "['cs.CL']",
            "figure_id": "1909.07512v1-Figure6-1",
            "image_path": "1909.07512v1-Figure6-1.png",
            "instance_id": "db2b41f1ac968c43e8785bc51bca9685",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific technique used to generate the pseudo headlines?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Comparison of greedy BLEU scores whether using the critic-aware exploration or not on Ru-En Dataset. The green line means the BLEU score achieved by greedy decoding from the underlying NMT model.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Comparison of greedy BLEU scores whether using the critic-aware exploration or not on Ru-En Dataset. The green line means the BLEU score achieved by greedy decoding from the underlying NMT model.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1702.02429v1-Figure3-1",
            "image_path": "1702.02429v1-Figure3-1.png",
            "instance_id": "0062283f9c422fa5313765d29a69ffed",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate maximum BLEU value of the blue line representing \"without Critic-Aware Learning\"?",
            "reference_answer": "19.9"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Comparison of greedy BLEU scores whether using the critic-aware exploration or not on Ru-En Dataset. The green line means the BLEU score achieved by greedy decoding from the underlying NMT model.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Comparison of greedy BLEU scores whether using the critic-aware exploration or not on Ru-En Dataset. The green line means the BLEU score achieved by greedy decoding from the underlying NMT model.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1702.02429v1-Figure3-1",
            "image_path": "1702.02429v1-Figure3-1.png",
            "instance_id": "935a6bcc647e5d078506134e0120f109",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the maximum value of the y-axis?",
            "reference_answer": "20.0"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The maximum value of the y-axis is 20.0.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Comparison of greedy BLEU scores whether using the critic-aware exploration or not on Ru-En Dataset. The green line means the BLEU score achieved by greedy decoding from the underlying NMT model.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Comparison of greedy BLEU scores whether using the critic-aware exploration or not on Ru-En Dataset. The green line means the BLEU score achieved by greedy decoding from the underlying NMT model.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1702.02429v1-Figure3-1",
            "image_path": "1702.02429v1-Figure3-1.png",
            "instance_id": "fc8f48093c338c8f8224e44eb516f248",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the blue line show a higher BLEU score at the update value of 1000 than the red line?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Comparison of greedy BLEU scores whether using the critic-aware exploration or not on Ru-En Dataset. The green line means the BLEU score achieved by greedy decoding from the underlying NMT model.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Comparison of greedy BLEU scores whether using the critic-aware exploration or not on Ru-En Dataset. The green line means the BLEU score achieved by greedy decoding from the underlying NMT model.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1702.02429v1-Figure3-1",
            "image_path": "1702.02429v1-Figure3-1.png",
            "instance_id": "bc675f946fd0842ef162ab07f3e869dc",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the BLEU score achieved using critic-aware exploration initially increase with updates?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the BLEU score achieved using critic-aware exploration initially increases with updates.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The yellow line"
                    },
                    {
                        "B": "The red line"
                    },
                    {
                        "C": "The blue line"
                    },
                    {
                        "D": "the red dotted line"
                    }
                ],
                "caption": "Figure 3: Comparison of greedy BLEU scores whether using the critic-aware exploration or not on Ru-En Dataset. The green line means the BLEU score achieved by greedy decoding from the underlying NMT model.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Comparison of greedy BLEU scores whether using the critic-aware exploration or not on Ru-En Dataset. The green line means the BLEU score achieved by greedy decoding from the underlying NMT model.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1702.02429v1-Figure3-1",
            "image_path": "1702.02429v1-Figure3-1.png",
            "instance_id": "c832adeb790c85ed71daf5dcab7f6a90",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line is positioned above the green dotted line at update value 10^4?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "BC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Critic-Aware Learning"
                    },
                    {
                        "B": "Greedy Decoding"
                    },
                    {
                        "C": "without Critic-Aware Learning"
                    },
                    {
                        "D": "there is no difference between the methods"
                    }
                ],
                "caption": "Figure 3: Comparison of greedy BLEU scores whether using the critic-aware exploration or not on Ru-En Dataset. The green line means the BLEU score achieved by greedy decoding from the underlying NMT model.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Comparison of greedy BLEU scores whether using the critic-aware exploration or not on Ru-En Dataset. The green line means the BLEU score achieved by greedy decoding from the underlying NMT model.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1702.02429v1-Figure3-1",
            "image_path": "1702.02429v1-Figure3-1.png",
            "instance_id": "807fe80dbd64330f298af4c418b20083",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which method has a higher BLEU score when updates is 10^3?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Comparison of greedy BLEU scores whether using the critic-aware exploration or not on Ru-En Dataset. The green line means the BLEU score achieved by greedy decoding from the underlying NMT model.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Comparison of greedy BLEU scores whether using the critic-aware exploration or not on Ru-En Dataset. The green line means the BLEU score achieved by greedy decoding from the underlying NMT model.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1702.02429v1-Figure3-1",
            "image_path": "1702.02429v1-Figure3-1.png",
            "instance_id": "f9eb49effa8977cab237148f37ec8f7b",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific implementation of the critic-aware exploration used in this experiment? ",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: When considering only one answer option as correct, the calibrator is almost perfectly calibrated on both in-domain and out-of-domain examples.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: When considering only one answer option as correct, the calibrator is almost perfectly calibrated on both in-domain and out-of-domain examples.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2006.09462v1-Figure7-1",
            "image_path": "2006.09462v1-Figure7-1.png",
            "instance_id": "92d310828308b960ac2aef2d54f9df2e",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the blue 'in-domain' line at the calibrator probability of 0.6?",
            "reference_answer": "0.65"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: When considering only one answer option as correct, the calibrator is almost perfectly calibrated on both in-domain and out-of-domain examples.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: When considering only one answer option as correct, the calibrator is almost perfectly calibrated on both in-domain and out-of-domain examples.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2006.09462v1-Figure7-1",
            "image_path": "2006.09462v1-Figure7-1.png",
            "instance_id": "eb2ccdb85c35e6074340548a068121b9",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the title of the figure?",
            "reference_answer": "Calibration plot for Calibrator Probability"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The title of the figure is \"Calibration plot for Calibrator Probability.\"",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: When considering only one answer option as correct, the calibrator is almost perfectly calibrated on both in-domain and out-of-domain examples.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: When considering only one answer option as correct, the calibrator is almost perfectly calibrated on both in-domain and out-of-domain examples.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2006.09462v1-Figure7-1",
            "image_path": "2006.09462v1-Figure7-1.png",
            "instance_id": "ad8eee0d1e50247e5a48859e8df18261",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the blue line representing in-domain examples follow a diagonal path?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the blue line representing in-domain examples tends to follow a diagonal path, suggesting that the probabilities are well calibrated.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: When considering only one answer option as correct, the calibrator is almost perfectly calibrated on both in-domain and out-of-domain examples.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: When considering only one answer option as correct, the calibrator is almost perfectly calibrated on both in-domain and out-of-domain examples.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2006.09462v1-Figure7-1",
            "image_path": "2006.09462v1-Figure7-1.png",
            "instance_id": "7c4a17e77374e9a109ae3d0b21aaacde",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Do the in-domain examples have consistently lower values for probability of correctness than out-of-domain examples?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "0.89"
                    },
                    {
                        "B": "0.69"
                    },
                    {
                        "C": "0.39"
                    },
                    {
                        "D": "0.19"
                    }
                ],
                "caption": "Figure 7: When considering only one answer option as correct, the calibrator is almost perfectly calibrated on both in-domain and out-of-domain examples.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: When considering only one answer option as correct, the calibrator is almost perfectly calibrated on both in-domain and out-of-domain examples.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2006.09462v1-Figure7-1",
            "image_path": "2006.09462v1-Figure7-1.png",
            "instance_id": "b58cad53d9296d11aecf96038de5054b",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What is the approximate value of the y-axis for the orange line at an x-axis value of 0.2?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "0.9"
                    },
                    {
                        "B": "0.7"
                    },
                    {
                        "C": "0.8"
                    },
                    {
                        "D": "1.0"
                    }
                ],
                "caption": "Figure 7: When considering only one answer option as correct, the calibrator is almost perfectly calibrated on both in-domain and out-of-domain examples.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: When considering only one answer option as correct, the calibrator is almost perfectly calibrated on both in-domain and out-of-domain examples.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2006.09462v1-Figure7-1",
            "image_path": "2006.09462v1-Figure7-1.png",
            "instance_id": "d335c548fc048845e19a720c291dd1f5",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the maximum value of the x-axis representing the calibrator probability?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7: When considering only one answer option as correct, the calibrator is almost perfectly calibrated on both in-domain and out-of-domain examples.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7: When considering only one answer option as correct, the calibrator is almost perfectly calibrated on both in-domain and out-of-domain examples.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2006.09462v1-Figure7-1",
            "image_path": "2006.09462v1-Figure7-1.png",
            "instance_id": "ac78cabee1f6e4bc86b56e7709f9e9e9",
            "qa_pair_type": "unanswerable",
            "question": "What is the average value for the probability of correctness for in- and out-of-domain examples, respectively?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 6: Average User-Brand Interactions in Each Industry",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 6: Average User-Brand Interactions in Each Industry",
            "categories": "['cs.CL cs.IR cs.SI']",
            "figure_id": "1709.07434v1-Figure6-1",
            "image_path": "1709.07434v1-Figure6-1.png",
            "instance_id": "ec6ecbb843672d846397ed739e731408",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "Where is the bar labeled \"internet\" located?",
            "reference_answer": "The last bar on the right "
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 6: Average User-Brand Interactions in Each Industry",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 6: Average User-Brand Interactions in Each Industry",
            "categories": "['cs.CL cs.IR cs.SI']",
            "figure_id": "1709.07434v1-Figure6-1",
            "image_path": "1709.07434v1-Figure6-1.png",
            "instance_id": "ff08e334a6334ab3fcc6bb57132739ab",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the industry with the lowest average user-brand interaction?",
            "reference_answer": "Heavy-equipment and mining-and-metals"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 6: Average User-Brand Interactions in Each Industry",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 6: Average User-Brand Interactions in Each Industry",
            "categories": "['cs.CL cs.IR cs.SI']",
            "figure_id": "1709.07434v1-Figure6-1",
            "image_path": "1709.07434v1-Figure6-1.png",
            "instance_id": "846625cff51e54af97bfa5fe2575ff1f",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the bar representing 'heavy-equipment' colored in rose?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 6: Average User-Brand Interactions in Each Industry",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 6: Average User-Brand Interactions in Each Industry",
            "categories": "['cs.CL cs.IR cs.SI']",
            "figure_id": "1709.07434v1-Figure6-1",
            "image_path": "1709.07434v1-Figure6-1.png",
            "instance_id": "8f6d2963d4df137c5e5871e3e148d4f4",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the average user-brand interaction higher in the 'heavy-equipment' industry than in the 'internet' industry?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "heavy-equipment, mining-and-metals and construction"
                    },
                    {
                        "B": "sports-media, internet, heavy-equipment"
                    },
                    {
                        "C": "newspapers-and-magazines, construction, internet"
                    },
                    {
                        "D": "none of the above"
                    }
                ],
                "caption": "Fig. 6: Average User-Brand Interactions in Each Industry",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 6: Average User-Brand Interactions in Each Industry",
            "categories": "['cs.CL cs.IR cs.SI']",
            "figure_id": "1709.07434v1-Figure6-1",
            "image_path": "1709.07434v1-Figure6-1.png",
            "instance_id": "464774006426509ea1bfc7615f694496",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What are the labels of the three smallest bars?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "fitness"
                    },
                    {
                        "B": "publishing"
                    },
                    {
                        "C": "internet"
                    },
                    {
                        "D": "construction"
                    }
                ],
                "caption": "Fig. 6: Average User-Brand Interactions in Each Industry",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 6: Average User-Brand Interactions in Each Industry",
            "categories": "['cs.CL cs.IR cs.SI']",
            "figure_id": "1709.07434v1-Figure6-1",
            "image_path": "1709.07434v1-Figure6-1.png",
            "instance_id": "af6d106e5ed813d39db35abb6fce69e7",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which industry has a lower average user-brand interaction than entertainment?",
            "reference_answer": "A,B,D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ABD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 6: Average User-Brand Interactions in Each Industry",
                "compound": false,
                "figure_type": "bar chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 6: Average User-Brand Interactions in Each Industry",
            "categories": "['cs.CL cs.IR cs.SI']",
            "figure_id": "1709.07434v1-Figure6-1",
            "image_path": "1709.07434v1-Figure6-1.png",
            "instance_id": "6190e3ae7e65959fe52fe80be224eac2",
            "qa_pair_type": "unanswerable",
            "question": "What is the average number of User-Brand interactions for the 'Internet' industry?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Emission Scorer with L-TapNet. It first constructs a projection space M by linear error nulling for given domain, and then predicts a words emission score with its distance to label representation  in the projection space.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Emission Scorer with L-TapNet. It first constructs a projection space M by linear error nulling for given domain, and then predicts a words emission score with its distance to label representation  in the projection space.",
            "categories": "nan",
            "figure_id": "2020.acl-main.128.pdf-Figure4",
            "image_path": "2020.acl-main.128.pdf-Figure4.png",
            "instance_id": "8f3682dfcb252ed0c7acf24f29556134",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What color are the boxes representing 'Prototype' and 'References' in the provided figure?",
            "reference_answer": "Yellow"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The box representing 'Prototype' is colored in black, and the box representing 'References' is colored in yellow.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Emission Scorer with L-TapNet. It first constructs a projection space M by linear error nulling for given domain, and then predicts a words emission score with its distance to label representation  in the projection space.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Emission Scorer with L-TapNet. It first constructs a projection space M by linear error nulling for given domain, and then predicts a words emission score with its distance to label representation  in the projection space.",
            "categories": "nan",
            "figure_id": "2020.acl-main.128.pdf-Figure4",
            "image_path": "2020.acl-main.128.pdf-Figure4.png",
            "instance_id": "7a27023890dfd3be030f724b1ce43ca8",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the input of the Prototype c?",
            "reference_answer": "Support Set S"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The input of the Prototype \\(c\\) is the Support Set \\(S\\).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Emission Scorer with L-TapNet. It first constructs a projection space M by linear error nulling for given domain, and then predicts a words emission score with its distance to label representation  in the projection space.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Emission Scorer with L-TapNet. It first constructs a projection space M by linear error nulling for given domain, and then predicts a words emission score with its distance to label representation  in the projection space.",
            "categories": "nan",
            "figure_id": "2020.acl-main.128.pdf-Figure4",
            "image_path": "2020.acl-main.128.pdf-Figure4.png",
            "instance_id": "1143d995ab864ca36ac129bdffd7c242",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the softmax function shown in a blue rectangle as part of the architecture?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The softmax function is shown in a blue rectangle as part of the architecture.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Emission Scorer with L-TapNet. It first constructs a projection space M by linear error nulling for given domain, and then predicts a words emission score with its distance to label representation  in the projection space.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Emission Scorer with L-TapNet. It first constructs a projection space M by linear error nulling for given domain, and then predicts a words emission score with its distance to label representation  in the projection space.",
            "categories": "nan",
            "figure_id": "2020.acl-main.128.pdf-Figure4",
            "image_path": "2020.acl-main.128.pdf-Figure4.png",
            "instance_id": "224816fe9f715106b645622367d910da",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the Emission Scorer with L-TapNet utilize a projection space M as an input to linear error nulling?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The diagram indicates that the projection space \\( M \\) is used as an input to linear error nulling.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Yellow and Blue"
                    },
                    {
                        "B": "Light Blue and White"
                    },
                    {
                        "C": "Light Blue and Light Blue"
                    },
                    {
                        "D": "Yellow and Light Blue"
                    }
                ],
                "caption": "Figure 4: Emission Scorer with L-TapNet. It first constructs a projection space M by linear error nulling for given domain, and then predicts a words emission score with its distance to label representation  in the projection space.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Emission Scorer with L-TapNet. It first constructs a projection space M by linear error nulling for given domain, and then predicts a words emission score with its distance to label representation  in the projection space.",
            "categories": "nan",
            "figure_id": "2020.acl-main.128.pdf-Figure4",
            "image_path": "2020.acl-main.128.pdf-Figure4.png",
            "instance_id": "a2181927c5e5585bdfbbdbc141a091db",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Based on Figure 4 and its caption, which colors are used to represent the 'Linear Error Nulling' and 'Projection Space' blocks, respectively?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "is it strong wind outside"
                    },
                    {
                        "B": "will it snow next Friday"
                    },
                    {
                        "C": "will there be a thunder storm today"
                    },
                    {
                        "D": "will it rain tonight"
                    }
                ],
                "caption": "Figure 4: Emission Scorer with L-TapNet. It first constructs a projection space M by linear error nulling for given domain, and then predicts a words emission score with its distance to label representation  in the projection space.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Emission Scorer with L-TapNet. It first constructs a projection space M by linear error nulling for given domain, and then predicts a words emission score with its distance to label representation  in the projection space.",
            "categories": "nan",
            "figure_id": "2020.acl-main.128.pdf-Figure4",
            "image_path": "2020.acl-main.128.pdf-Figure4.png",
            "instance_id": "201b573f5a244478ed39afe708432dae",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the example query in this figure?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Emission Scorer with L-TapNet. It first constructs a projection space M by linear error nulling for given domain, and then predicts a words emission score with its distance to label representation  in the projection space.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Emission Scorer with L-TapNet. It first constructs a projection space M by linear error nulling for given domain, and then predicts a words emission score with its distance to label representation  in the projection space.",
            "categories": "nan",
            "figure_id": "2020.acl-main.128.pdf-Figure4",
            "image_path": "2020.acl-main.128.pdf-Figure4.png",
            "instance_id": "be3304b1cb21d26ac0e5eb1befec362d",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific value of the SIM function's output in the softmax layer for the input query 'will it rain tonight', considering the  provided support set S and the parameters of the Linear Error Nulling and projection space M,  without accessing external data like the full research paper?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Rearrangement aware paraphrasing (REAP) model. The gray area corresponds to the standard transformer encoder-decoder system. Our model adds position embeddings corresponding to the target reordering to encoder outputs. The decoder attends over these augmented encodings during both training and inference.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Rearrangement aware paraphrasing (REAP) model. The gray area corresponds to the standard transformer encoder-decoder system. Our model adds position embeddings corresponding to the target reordering to encoder outputs. The decoder attends over these augmented encodings during both training and inference.",
            "categories": "nan",
            "figure_id": "2020.acl-main.22.pdf-Figure2",
            "image_path": "2020.acl-main.22.pdf-Figure2.png",
            "instance_id": "13c479fbf5f38c93c57015738c924aad",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the color of the box labeled \"Decoder\"?",
            "reference_answer": "Blue"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The color of the box labeled \"Decoder\" is blue.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Rearrangement aware paraphrasing (REAP) model. The gray area corresponds to the standard transformer encoder-decoder system. Our model adds position embeddings corresponding to the target reordering to encoder outputs. The decoder attends over these augmented encodings during both training and inference.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Rearrangement aware paraphrasing (REAP) model. The gray area corresponds to the standard transformer encoder-decoder system. Our model adds position embeddings corresponding to the target reordering to encoder outputs. The decoder attends over these augmented encodings during both training and inference.",
            "categories": "nan",
            "figure_id": "2020.acl-main.22.pdf-Figure2",
            "image_path": "2020.acl-main.22.pdf-Figure2.png",
            "instance_id": "458c288d1ea6b38425da5cab2f68a13a",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What are the input tokens in the figure?",
            "reference_answer": "Clippers won the game"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The input tokens in the figure are \"Clippers won the game\".",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Rearrangement aware paraphrasing (REAP) model. The gray area corresponds to the standard transformer encoder-decoder system. Our model adds position embeddings corresponding to the target reordering to encoder outputs. The decoder attends over these augmented encodings during both training and inference.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Rearrangement aware paraphrasing (REAP) model. The gray area corresponds to the standard transformer encoder-decoder system. Our model adds position embeddings corresponding to the target reordering to encoder outputs. The decoder attends over these augmented encodings during both training and inference.",
            "categories": "nan",
            "figure_id": "2020.acl-main.22.pdf-Figure2",
            "image_path": "2020.acl-main.22.pdf-Figure2.png",
            "instance_id": "93da57689dc3ad9a0499985db6cfcd08",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the second layer positioned above the input tokens consider the original order of the tokens?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the second layer positioned above the input tokens considers the original order of the tokens, as indicated by the \"Original Order Token embeddings\" that feed into that layer.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Rearrangement aware paraphrasing (REAP) model. The gray area corresponds to the standard transformer encoder-decoder system. Our model adds position embeddings corresponding to the target reordering to encoder outputs. The decoder attends over these augmented encodings during both training and inference.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Rearrangement aware paraphrasing (REAP) model. The gray area corresponds to the standard transformer encoder-decoder system. Our model adds position embeddings corresponding to the target reordering to encoder outputs. The decoder attends over these augmented encodings during both training and inference.",
            "categories": "nan",
            "figure_id": "2020.acl-main.22.pdf-Figure2",
            "image_path": "2020.acl-main.22.pdf-Figure2.png",
            "instance_id": "8e9fabc29113964c90318b35f403968a",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the first encoder output serve as a direct input to the decoder?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Orange"
                    },
                    {
                        "B": "Gray"
                    },
                    {
                        "C": "Teal"
                    },
                    {
                        "D": "Purple"
                    }
                ],
                "caption": "Figure 2: Rearrangement aware paraphrasing (REAP) model. The gray area corresponds to the standard transformer encoder-decoder system. Our model adds position embeddings corresponding to the target reordering to encoder outputs. The decoder attends over these augmented encodings during both training and inference.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Rearrangement aware paraphrasing (REAP) model. The gray area corresponds to the standard transformer encoder-decoder system. Our model adds position embeddings corresponding to the target reordering to encoder outputs. The decoder attends over these augmented encodings during both training and inference.",
            "categories": "nan",
            "figure_id": "2020.acl-main.22.pdf-Figure2",
            "image_path": "2020.acl-main.22.pdf-Figure2.png",
            "instance_id": "084c135adb8c74b9154caf95859f90a6",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What color is the box that represents the encoder?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "BD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Word2Vec"
                    },
                    {
                        "B": "CNN"
                    },
                    {
                        "C": "Encoder"
                    },
                    {
                        "D": "Decoder"
                    }
                ],
                "caption": "Figure 2: Rearrangement aware paraphrasing (REAP) model. The gray area corresponds to the standard transformer encoder-decoder system. Our model adds position embeddings corresponding to the target reordering to encoder outputs. The decoder attends over these augmented encodings during both training and inference.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Rearrangement aware paraphrasing (REAP) model. The gray area corresponds to the standard transformer encoder-decoder system. Our model adds position embeddings corresponding to the target reordering to encoder outputs. The decoder attends over these augmented encodings during both training and inference.",
            "categories": "nan",
            "figure_id": "2020.acl-main.22.pdf-Figure2",
            "image_path": "2020.acl-main.22.pdf-Figure2.png",
            "instance_id": "f79cd1bef2cb91f040e37df229a0a3af",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following are components of the REAP model?",
            "reference_answer": "C,D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "CD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Rearrangement aware paraphrasing (REAP) model. The gray area corresponds to the standard transformer encoder-decoder system. Our model adds position embeddings corresponding to the target reordering to encoder outputs. The decoder attends over these augmented encodings during both training and inference.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Rearrangement aware paraphrasing (REAP) model. The gray area corresponds to the standard transformer encoder-decoder system. Our model adds position embeddings corresponding to the target reordering to encoder outputs. The decoder attends over these augmented encodings during both training and inference.",
            "categories": "nan",
            "figure_id": "2020.acl-main.22.pdf-Figure2",
            "image_path": "2020.acl-main.22.pdf-Figure2.png",
            "instance_id": "e31a7ee152a9721fbb09097a2b7a18e2",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific implementation of the position embedding in the REAP model?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: CARNN for dialog.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: CARNN for dialog.",
            "categories": "nan",
            "figure_id": "N18-1115.pdf-Figure2",
            "image_path": "N18-1115.pdf-Figure2.png",
            "instance_id": "75d4259badd9ec2a678e28a0147c41f1",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the color of the box labeled 'CARNN'?",
            "reference_answer": "Yellow"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The color of the box labeled 'CARNN' is yellow.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: CARNN for dialog.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: CARNN for dialog.",
            "categories": "nan",
            "figure_id": "N18-1115.pdf-Figure2",
            "image_path": "N18-1115.pdf-Figure2.png",
            "instance_id": "7d2b6393cf6ebcab7642ee0a6a0f5c37",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What transforms candidates into candidate embeddings?",
            "reference_answer": "Position Encoder"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The process that transforms candidates into candidate embeddings is represented by the \"Position Encoder\" in the diagram.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: CARNN for dialog.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: CARNN for dialog.",
            "categories": "nan",
            "figure_id": "N18-1115.pdf-Figure2",
            "image_path": "N18-1115.pdf-Figure2.png",
            "instance_id": "122392f6d83dfeabaa3a56992dcb4acc",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Are there three white boxes inside the yellow box?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. There are three white boxes inside the yellow box.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: CARNN for dialog.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: CARNN for dialog.",
            "categories": "nan",
            "figure_id": "N18-1115.pdf-Figure2",
            "image_path": "N18-1115.pdf-Figure2.png",
            "instance_id": "01e88a8baae70c5f54bbd94045691f3e",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is e1 the final output of CARNN?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Circle"
                    },
                    {
                        "B": "Square"
                    },
                    {
                        "C": "Triangle"
                    },
                    {
                        "D": "Rectangle"
                    }
                ],
                "caption": "Figure 2: CARNN for dialog.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: CARNN for dialog.",
            "categories": "nan",
            "figure_id": "N18-1115.pdf-Figure2",
            "image_path": "N18-1115.pdf-Figure2.png",
            "instance_id": "bacd8f2af75cea2fc40cb4ccdf3b33d8",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What are the shapes of the boxes labeled with 'h' inside the yellow box labeled CARNN?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "BD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "e1"
                    },
                    {
                        "B": "e2"
                    },
                    {
                        "C": "context"
                    },
                    {
                        "D": "candidates"
                    }
                ],
                "caption": "Figure 2: CARNN for dialog.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: CARNN for dialog.",
            "categories": "nan",
            "figure_id": "N18-1115.pdf-Figure2",
            "image_path": "N18-1115.pdf-Figure2.png",
            "instance_id": "ef618bbfed7e4611ce7b57d7302586d6",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What are components that serve as immediate input to the CARNN module?",
            "reference_answer": "A,B,C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: CARNN for dialog.",
                "compound": false,
                "figure_type": "neural networks",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: CARNN for dialog.",
            "categories": "nan",
            "figure_id": "N18-1115.pdf-Figure2",
            "image_path": "N18-1115.pdf-Figure2.png",
            "instance_id": "70ce998e596e7a9ad6e1c5488f82952a",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific type of Recurrent Neural Network (RNN) used in the CARNN architecture for dialog?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The specific type of Recurrent Neural Network (RNN) used in the CARNN architecture for dialog is the **Context-Aware Recurrent Neural Network (CARNN)**.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4. Structure of LCGMM",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4. Structure of LCGMM",
            "categories": "nan",
            "figure_id": "O04-3005.pdf-Figure4",
            "image_path": "O04-3005.pdf-Figure4.png",
            "instance_id": "dda8c9a96cdf97edbb8245c43d4914a3",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "How many labels of rectangular boxes contain 'GMM'?",
            "reference_answer": "3"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "There are L+1 labels of rectangular boxes that contain 'GMM'.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4. Structure of LCGMM",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4. Structure of LCGMM",
            "categories": "nan",
            "figure_id": "O04-3005.pdf-Figure4",
            "image_path": "O04-3005.pdf-Figure4.png",
            "instance_id": "c23119ac463ace9750e1a17316afa14d",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the name of the last step in the process?",
            "reference_answer": "Likelihood Recombination"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The name of the last step in the process is \"Likelihood Recombination.\"",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4. Structure of LCGMM",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4. Structure of LCGMM",
            "categories": "nan",
            "figure_id": "O04-3005.pdf-Figure4",
            "image_path": "O04-3005.pdf-Figure4.png",
            "instance_id": "68bf653bcba253bcd31f939731514559",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the box labeled \"Input Speech Signals\" on the left directly connected by a red arrow to the box labeled \"Subband-L\"?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4. Structure of LCGMM",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4. Structure of LCGMM",
            "categories": "nan",
            "figure_id": "O04-3005.pdf-Figure4",
            "image_path": "O04-3005.pdf-Figure4.png",
            "instance_id": "14318d418031d16aff56df8dfbd1bdda",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the process involve extracting LPCC for each subband?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the process involves extracting LPCC for each subband.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Subband-1"
                    },
                    {
                        "B": "Full-band"
                    },
                    {
                        "C": "LSTM"
                    },
                    {
                        "D": "GUM"
                    }
                ],
                "caption": "Figure 4. Structure of LCGMM",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4. Structure of LCGMM",
            "categories": "nan",
            "figure_id": "O04-3005.pdf-Figure4",
            "image_path": "O04-3005.pdf-Figure4.png",
            "instance_id": "f34684fd867e4c216dd7cfc84b505aa0",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following are labels of rectangles in the figure?",
            "reference_answer": "A,B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Subband-1, GMM-1, Extract-LPCC"
                    },
                    {
                        "B": "Wavelet Transform Decomposition, Full-Band, Extract-LPCC"
                    },
                    {
                        "C": "Wavelet Transform Decomposition, Input Speech Signals, Subband-L"
                    },
                    {
                        "D": "Input Speech Signals, Wavelet Transform Decomposition, Subband-L"
                    }
                ],
                "caption": "Figure 4. Structure of LCGMM",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4. Structure of LCGMM",
            "categories": "nan",
            "figure_id": "O04-3005.pdf-Figure4",
            "image_path": "O04-3005.pdf-Figure4.png",
            "instance_id": "dd64be2e152bf8264162a51b5cbb4eaf",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following steps are listed in the correct order according to the figure?",
            "reference_answer": "B,D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4. Structure of LCGMM",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4. Structure of LCGMM",
            "categories": "nan",
            "figure_id": "O04-3005.pdf-Figure4",
            "image_path": "O04-3005.pdf-Figure4.png",
            "instance_id": "a49a019ba2522ff313dc7fb8c473a911",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific type of wavelet transform used in the LCGMM structure shown in Figure 4?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1. The overall framework of the NTNU broadcast news system.",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1. The overall framework of the NTNU broadcast news system.",
            "categories": "nan",
            "figure_id": "O05-2001.pdf-Figure1",
            "image_path": "O05-2001.pdf-Figure1.png",
            "instance_id": "5bdf4de2b8b6369c6c65c954d6bd12ed",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the shape of the box containing \"Speech Recognition\"?",
            "reference_answer": "Rectangle"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The shape of the box containing \"Speech Recognition\" is a rectangle.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1. The overall framework of the NTNU broadcast news system.",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1. The overall framework of the NTNU broadcast news system.",
            "categories": "nan",
            "figure_id": "O05-2001.pdf-Figure1",
            "image_path": "O05-2001.pdf-Figure1.png",
            "instance_id": "132dcda3d22d78ff984a3c9e4ee1945a",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the input of the Acoustic Model Training?",
            "reference_answer": "Automatically Transcribed Broadcast News Corpus"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The input of the Acoustic Model Training is the \"Manually Transcribed Broadcast News Corpus\" and \"Automatically Transcribed Broadcast News Corpus.\"",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1. The overall framework of the NTNU broadcast news system.",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1. The overall framework of the NTNU broadcast news system.",
            "categories": "nan",
            "figure_id": "O05-2001.pdf-Figure1",
            "image_path": "O05-2001.pdf-Figure1.png",
            "instance_id": "387ef2c359dfbbddd64ad5c241cc1f1a",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the box labeled 'Front-End Processing' located directly below the box labeled 'Contemporary Text Corpus'?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The box labeled 'Front-End Processing' is located directly below the box labeled 'Contemporary Text Corpus'.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1. The overall framework of the NTNU broadcast news system.",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1. The overall framework of the NTNU broadcast news system.",
            "categories": "nan",
            "figure_id": "O05-2001.pdf-Figure1",
            "image_path": "O05-2001.pdf-Figure1.png",
            "instance_id": "b8b89e901da7287ecf70b082fad1f29f",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the system utilize both automatically and manually transcribed broadcast news corpus?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The system utilizes both automatically transcribed and manually transcribed broadcast news corpus.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Internet"
                    },
                    {
                        "B": "Segmented Broadcast News Streams"
                    },
                    {
                        "C": "Audio Indexing"
                    },
                    {
                        "D": "Contemporary text"
                    }
                ],
                "caption": "Figure 1. The overall framework of the NTNU broadcast news system.",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1. The overall framework of the NTNU broadcast news system.",
            "categories": "nan",
            "figure_id": "O05-2001.pdf-Figure1",
            "image_path": "O05-2001.pdf-Figure1.png",
            "instance_id": "06a3ed37bbdde93667025445f314137c",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What is the label of the arrow pointing right towards the Automatically Transcribed Broadcast News Corpus?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Front-End Processing"
                    },
                    {
                        "B": "Language Models"
                    },
                    {
                        "C": "Acoustic Models"
                    },
                    {
                        "D": "Lexicon"
                    }
                ],
                "caption": "Figure 1. The overall framework of the NTNU broadcast news system.",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1. The overall framework of the NTNU broadcast news system.",
            "categories": "nan",
            "figure_id": "O05-2001.pdf-Figure1",
            "image_path": "O05-2001.pdf-Figure1.png",
            "instance_id": "1d4785601dc3361428b38c998f118459",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following are inputs to the Speech Recognition component in the NTNU broadcast news system?",
            "reference_answer": "A,B,C,D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ABCD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1. The overall framework of the NTNU broadcast news system.",
                "compound": false,
                "figure_type": "architecture diagram",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1. The overall framework of the NTNU broadcast news system.",
            "categories": "nan",
            "figure_id": "O05-2001.pdf-Figure1",
            "image_path": "O05-2001.pdf-Figure1.png",
            "instance_id": "74177256e0cd85676b2ea05f36807557",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific size of the manually transcribed broadcast news corpus used in the NTNU broadcast news system?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Using the 9-dimensional RPAS vector we use the Imposter Method and compare Christopher Marlowe\u2019s Hero and Leander to Edward III scene chunks using min max and cosine similarity detection. Marlowe\u2019s work is dissimilar to Kyd\u2019s, and therefore, the work furthest away from Marlowe\u2019s is Kyd\u2019s. Logically, if there are only two authors in Edward III, then the work closest to Marlowe must be Shakespeare. We see the \u2018Shakespeare 5\u2019 (chunks 6, 8, 15, 16, 17) appear in the top cluster closest to Marlowe\u2019s work, but with the inclusion of cluster 11. Of note, the four Shakespearian clusters marked with a red circle are those commonly attributed to Shakespeare, and they all fall close to Kyd. Further, the ellipses are our visual clustering assignment.",
                "compound": false,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Using the 9-dimensional RPAS vector we use the Imposter Method and compare Christopher Marlowe\u2019s Hero and Leander to Edward III scene chunks using min max and cosine similarity detection. Marlowe\u2019s work is dissimilar to Kyd\u2019s, and therefore, the work furthest away from Marlowe\u2019s is Kyd\u2019s. Logically, if there are only two authors in Edward III, then the work closest to Marlowe must be Shakespeare. We see the \u2018Shakespeare 5\u2019 (chunks 6, 8, 15, 16, 17) appear in the top cluster closest to Marlowe\u2019s work, but with the inclusion of cluster 11. Of note, the four Shakespearian clusters marked with a red circle are those commonly attributed to Shakespeare, and they all fall close to Kyd. Further, the ellipses are our visual clustering assignment.",
            "categories": "['cs.CL']",
            "figure_id": "1801.04017v1-Figure5-1",
            "image_path": "1801.04017v1-Figure5-1.png",
            "instance_id": "9bf86bc9c5d3d2a1cf574432764ef288",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "How many red circles are present in the smaller blue oval form?",
            "reference_answer": "Three red circles"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "There are 2 red circles present in the smaller blue oval form.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Using the 9-dimensional RPAS vector we use the Imposter Method and compare Christopher Marlowe\u2019s Hero and Leander to Edward III scene chunks using min max and cosine similarity detection. Marlowe\u2019s work is dissimilar to Kyd\u2019s, and therefore, the work furthest away from Marlowe\u2019s is Kyd\u2019s. Logically, if there are only two authors in Edward III, then the work closest to Marlowe must be Shakespeare. We see the \u2018Shakespeare 5\u2019 (chunks 6, 8, 15, 16, 17) appear in the top cluster closest to Marlowe\u2019s work, but with the inclusion of cluster 11. Of note, the four Shakespearian clusters marked with a red circle are those commonly attributed to Shakespeare, and they all fall close to Kyd. Further, the ellipses are our visual clustering assignment.",
                "compound": false,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Using the 9-dimensional RPAS vector we use the Imposter Method and compare Christopher Marlowe\u2019s Hero and Leander to Edward III scene chunks using min max and cosine similarity detection. Marlowe\u2019s work is dissimilar to Kyd\u2019s, and therefore, the work furthest away from Marlowe\u2019s is Kyd\u2019s. Logically, if there are only two authors in Edward III, then the work closest to Marlowe must be Shakespeare. We see the \u2018Shakespeare 5\u2019 (chunks 6, 8, 15, 16, 17) appear in the top cluster closest to Marlowe\u2019s work, but with the inclusion of cluster 11. Of note, the four Shakespearian clusters marked with a red circle are those commonly attributed to Shakespeare, and they all fall close to Kyd. Further, the ellipses are our visual clustering assignment.",
            "categories": "['cs.CL']",
            "figure_id": "1801.04017v1-Figure5-1",
            "image_path": "1801.04017v1-Figure5-1.png",
            "instance_id": "ff784cacf0408f6567dc0a54dd5f4582",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the approximate cosine similarity range of the 'Shakespeare 5'?",
            "reference_answer": "0.32-0.52"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Using the 9-dimensional RPAS vector we use the Imposter Method and compare Christopher Marlowe\u2019s Hero and Leander to Edward III scene chunks using min max and cosine similarity detection. Marlowe\u2019s work is dissimilar to Kyd\u2019s, and therefore, the work furthest away from Marlowe\u2019s is Kyd\u2019s. Logically, if there are only two authors in Edward III, then the work closest to Marlowe must be Shakespeare. We see the \u2018Shakespeare 5\u2019 (chunks 6, 8, 15, 16, 17) appear in the top cluster closest to Marlowe\u2019s work, but with the inclusion of cluster 11. Of note, the four Shakespearian clusters marked with a red circle are those commonly attributed to Shakespeare, and they all fall close to Kyd. Further, the ellipses are our visual clustering assignment.",
                "compound": false,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Using the 9-dimensional RPAS vector we use the Imposter Method and compare Christopher Marlowe\u2019s Hero and Leander to Edward III scene chunks using min max and cosine similarity detection. Marlowe\u2019s work is dissimilar to Kyd\u2019s, and therefore, the work furthest away from Marlowe\u2019s is Kyd\u2019s. Logically, if there are only two authors in Edward III, then the work closest to Marlowe must be Shakespeare. We see the \u2018Shakespeare 5\u2019 (chunks 6, 8, 15, 16, 17) appear in the top cluster closest to Marlowe\u2019s work, but with the inclusion of cluster 11. Of note, the four Shakespearian clusters marked with a red circle are those commonly attributed to Shakespeare, and they all fall close to Kyd. Further, the ellipses are our visual clustering assignment.",
            "categories": "['cs.CL']",
            "figure_id": "1801.04017v1-Figure5-1",
            "image_path": "1801.04017v1-Figure5-1.png",
            "instance_id": "8f1b31e5b2dee89675ec6dc26b3882ef",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Are all the red circles, representing Shakespearean clusters, located closer to the x-axis than the blue ellipse encompassing the 'unknown' clusters?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, not all the red circles representing Shakespearean clusters are located closer to the x-axis than the blue ellipse encompassing the 'unknown' clusters.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Using the 9-dimensional RPAS vector we use the Imposter Method and compare Christopher Marlowe\u2019s Hero and Leander to Edward III scene chunks using min max and cosine similarity detection. Marlowe\u2019s work is dissimilar to Kyd\u2019s, and therefore, the work furthest away from Marlowe\u2019s is Kyd\u2019s. Logically, if there are only two authors in Edward III, then the work closest to Marlowe must be Shakespeare. We see the \u2018Shakespeare 5\u2019 (chunks 6, 8, 15, 16, 17) appear in the top cluster closest to Marlowe\u2019s work, but with the inclusion of cluster 11. Of note, the four Shakespearian clusters marked with a red circle are those commonly attributed to Shakespeare, and they all fall close to Kyd. Further, the ellipses are our visual clustering assignment.",
                "compound": false,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Using the 9-dimensional RPAS vector we use the Imposter Method and compare Christopher Marlowe\u2019s Hero and Leander to Edward III scene chunks using min max and cosine similarity detection. Marlowe\u2019s work is dissimilar to Kyd\u2019s, and therefore, the work furthest away from Marlowe\u2019s is Kyd\u2019s. Logically, if there are only two authors in Edward III, then the work closest to Marlowe must be Shakespeare. We see the \u2018Shakespeare 5\u2019 (chunks 6, 8, 15, 16, 17) appear in the top cluster closest to Marlowe\u2019s work, but with the inclusion of cluster 11. Of note, the four Shakespearian clusters marked with a red circle are those commonly attributed to Shakespeare, and they all fall close to Kyd. Further, the ellipses are our visual clustering assignment.",
            "categories": "['cs.CL']",
            "figure_id": "1801.04017v1-Figure5-1",
            "image_path": "1801.04017v1-Figure5-1.png",
            "instance_id": "d06b14045d0d57eb46231e9334e0daae",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the y-axis representing min/max values?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "All red circles are located within the same ellipse."
                    },
                    {
                        "B": "One ellipse consists of blue crosses only."
                    },
                    {
                        "C": "At least one red circle is positioned outside of either ellipse."
                    },
                    {
                        "D": "All data points are evenly distributed across the graph."
                    }
                ],
                "caption": "Figure 5: Using the 9-dimensional RPAS vector we use the Imposter Method and compare Christopher Marlowe\u2019s Hero and Leander to Edward III scene chunks using min max and cosine similarity detection. Marlowe\u2019s work is dissimilar to Kyd\u2019s, and therefore, the work furthest away from Marlowe\u2019s is Kyd\u2019s. Logically, if there are only two authors in Edward III, then the work closest to Marlowe must be Shakespeare. We see the \u2018Shakespeare 5\u2019 (chunks 6, 8, 15, 16, 17) appear in the top cluster closest to Marlowe\u2019s work, but with the inclusion of cluster 11. Of note, the four Shakespearian clusters marked with a red circle are those commonly attributed to Shakespeare, and they all fall close to Kyd. Further, the ellipses are our visual clustering assignment.",
                "compound": false,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Using the 9-dimensional RPAS vector we use the Imposter Method and compare Christopher Marlowe\u2019s Hero and Leander to Edward III scene chunks using min max and cosine similarity detection. Marlowe\u2019s work is dissimilar to Kyd\u2019s, and therefore, the work furthest away from Marlowe\u2019s is Kyd\u2019s. Logically, if there are only two authors in Edward III, then the work closest to Marlowe must be Shakespeare. We see the \u2018Shakespeare 5\u2019 (chunks 6, 8, 15, 16, 17) appear in the top cluster closest to Marlowe\u2019s work, but with the inclusion of cluster 11. Of note, the four Shakespearian clusters marked with a red circle are those commonly attributed to Shakespeare, and they all fall close to Kyd. Further, the ellipses are our visual clustering assignment.",
            "categories": "['cs.CL']",
            "figure_id": "1801.04017v1-Figure5-1",
            "image_path": "1801.04017v1-Figure5-1.png",
            "instance_id": "1ac3aebb8eec4819a95cf57fc7a735d3",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Based on Figure 5, which of the following statements about the plotted data points are true?  Consider shape, color, and relative position within the ellipses.",
            "reference_answer": "B,C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Christopher Marlowe's Work in Comparison to Shakespeare's."
                    },
                    {
                        "B": "Shakespeare 5"
                    },
                    {
                        "C": "Christopher Marlowe\u2019s Hero"
                    },
                    {
                        "D": "Similarity Detection: Edward III vs. Shakespeare"
                    }
                ],
                "caption": "Figure 5: Using the 9-dimensional RPAS vector we use the Imposter Method and compare Christopher Marlowe\u2019s Hero and Leander to Edward III scene chunks using min max and cosine similarity detection. Marlowe\u2019s work is dissimilar to Kyd\u2019s, and therefore, the work furthest away from Marlowe\u2019s is Kyd\u2019s. Logically, if there are only two authors in Edward III, then the work closest to Marlowe must be Shakespeare. We see the \u2018Shakespeare 5\u2019 (chunks 6, 8, 15, 16, 17) appear in the top cluster closest to Marlowe\u2019s work, but with the inclusion of cluster 11. Of note, the four Shakespearian clusters marked with a red circle are those commonly attributed to Shakespeare, and they all fall close to Kyd. Further, the ellipses are our visual clustering assignment.",
                "compound": false,
                "figure_type": "scatter plot",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Using the 9-dimensional RPAS vector we use the Imposter Method and compare Christopher Marlowe\u2019s Hero and Leander to Edward III scene chunks using min max and cosine similarity detection. Marlowe\u2019s work is dissimilar to Kyd\u2019s, and therefore, the work furthest away from Marlowe\u2019s is Kyd\u2019s. Logically, if there are only two authors in Edward III, then the work closest to Marlowe must be Shakespeare. We see the \u2018Shakespeare 5\u2019 (chunks 6, 8, 15, 16, 17) appear in the top cluster closest to Marlowe\u2019s work, but with the inclusion of cluster 11. Of note, the four Shakespearian clusters marked with a red circle are those commonly attributed to Shakespeare, and they all fall close to Kyd. Further, the ellipses are our visual clustering assignment.",
            "categories": "['cs.CL']",
            "figure_id": "1801.04017v1-Figure5-1",
            "image_path": "1801.04017v1-Figure5-1.png",
            "instance_id": "3fbe8083ebbd991fe72caf6f4bb674cc",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the title of the plot?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Using the 9-dimensional RPAS vector we use the Imposter Method and compare Christopher Marlowe\u2019s Hero and Leander to Edward III scene chunks using min max and cosine similarity detection. Marlowe\u2019s work is dissimilar to Kyd\u2019s, and therefore, the work furthest away from Marlowe\u2019s is Kyd\u2019s. Logically, if there are only two authors in Edward III, then the work closest to Marlowe must be Shakespeare. We see the \u2018Shakespeare 5\u2019 (chunks 6, 8, 15, 16, 17) appear in the top cluster closest to Marlowe\u2019s work, but with the inclusion of cluster 11. Of note, the four Shakespearian clusters marked with a red circle are those commonly attributed to Shakespeare, and they all fall close to Kyd. Further, the ellipses are our visual clustering assignment.",
                "compound": false,
                "figure_type": "scatter plot",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Using the 9-dimensional RPAS vector we use the Imposter Method and compare Christopher Marlowe\u2019s Hero and Leander to Edward III scene chunks using min max and cosine similarity detection. Marlowe\u2019s work is dissimilar to Kyd\u2019s, and therefore, the work furthest away from Marlowe\u2019s is Kyd\u2019s. Logically, if there are only two authors in Edward III, then the work closest to Marlowe must be Shakespeare. We see the \u2018Shakespeare 5\u2019 (chunks 6, 8, 15, 16, 17) appear in the top cluster closest to Marlowe\u2019s work, but with the inclusion of cluster 11. Of note, the four Shakespearian clusters marked with a red circle are those commonly attributed to Shakespeare, and they all fall close to Kyd. Further, the ellipses are our visual clustering assignment.",
            "categories": "['cs.CL']",
            "figure_id": "1801.04017v1-Figure5-1",
            "image_path": "1801.04017v1-Figure5-1.png",
            "instance_id": "f7a30f72e103c2776867cc2bbbeab937",
            "qa_pair_type": "unanswerable",
            "question": "Did the analysis include stop words?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 14- exponential curves for share of opinion portions related to Number of deviated steps (a, d and g). Distribution of percentage of share for 16 paths (b, e and h). Distribution of percentage share for choices of each experiment (c, f and i). Experiment-1, with 22 Participants. Experiment-2, with 92 Participants. Experiment-3, with 3084 Participants.",
                "compound": true,
                "figure_type": "Line Chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 14- exponential curves for share of opinion portions related to Number of deviated steps (a, d and g). Distribution of percentage of share for 16 paths (b, e and h). Distribution of percentage share for choices of each experiment (c, f and i). Experiment-1, with 22 Participants. Experiment-2, with 92 Participants. Experiment-3, with 3084 Participants.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1908.09080v5-Figure14-1",
            "image_path": "1908.09080v5-Figure14-1.png",
            "instance_id": "d43f0326c81f8d85c2bf671fdeb554ef",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate y-axis value of the green dotted line at 4 deviated steps in figure d?",
            "reference_answer": "0"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 14- exponential curves for share of opinion portions related to Number of deviated steps (a, d and g). Distribution of percentage of share for 16 paths (b, e and h). Distribution of percentage share for choices of each experiment (c, f and i). Experiment-1, with 22 Participants. Experiment-2, with 92 Participants. Experiment-3, with 3084 Participants.",
                "compound": true,
                "figure_type": "Line Chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 14- exponential curves for share of opinion portions related to Number of deviated steps (a, d and g). Distribution of percentage of share for 16 paths (b, e and h). Distribution of percentage share for choices of each experiment (c, f and i). Experiment-1, with 22 Participants. Experiment-2, with 92 Participants. Experiment-3, with 3084 Participants.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1908.09080v5-Figure14-1",
            "image_path": "1908.09080v5-Figure14-1.png",
            "instance_id": "4093d65d510ca502ba0245a0646c6e49",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the maximum percentage share of opinion portions, presented on the y-axis, for Experiment 2?",
            "reference_answer": "70"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 14- exponential curves for share of opinion portions related to Number of deviated steps (a, d and g). Distribution of percentage of share for 16 paths (b, e and h). Distribution of percentage share for choices of each experiment (c, f and i). Experiment-1, with 22 Participants. Experiment-2, with 92 Participants. Experiment-3, with 3084 Participants.",
                "compound": true,
                "figure_type": "Line Chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 14- exponential curves for share of opinion portions related to Number of deviated steps (a, d and g). Distribution of percentage of share for 16 paths (b, e and h). Distribution of percentage share for choices of each experiment (c, f and i). Experiment-1, with 22 Participants. Experiment-2, with 92 Participants. Experiment-3, with 3084 Participants.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1908.09080v5-Figure14-1",
            "image_path": "1908.09080v5-Figure14-1.png",
            "instance_id": "4fe54f4834914d684e5fe2962753c6cc",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is there a blue dot in the top left graph located at a y-value of 30?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 14- exponential curves for share of opinion portions related to Number of deviated steps (a, d and g). Distribution of percentage of share for 16 paths (b, e and h). Distribution of percentage share for choices of each experiment (c, f and i). Experiment-1, with 22 Participants. Experiment-2, with 92 Participants. Experiment-3, with 3084 Participants.",
                "compound": true,
                "figure_type": "Line Chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 14- exponential curves for share of opinion portions related to Number of deviated steps (a, d and g). Distribution of percentage of share for 16 paths (b, e and h). Distribution of percentage share for choices of each experiment (c, f and i). Experiment-1, with 22 Participants. Experiment-2, with 92 Participants. Experiment-3, with 3084 Participants.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1908.09080v5-Figure14-1",
            "image_path": "1908.09080v5-Figure14-1.png",
            "instance_id": "ffa4230843998c3c87fdb24a96dd00fc",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the percentage share of opinion portions decreasing with an increasing number of deviated steps in figure a?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the percentage share of opinion portions is decreasing with an increasing number of deviated steps in figure a.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "All three graphs share the same x-axis labels"
                    },
                    {
                        "B": "Graph e shows the highest peak"
                    },
                    {
                        "C": "All three graphs have peaks located at approximately the same location on the x-axis"
                    },
                    {
                        "D": "All three graphs are colored with green and red lines"
                    }
                ],
                "caption": "Figure 14- exponential curves for share of opinion portions related to Number of deviated steps (a, d and g). Distribution of percentage of share for 16 paths (b, e and h). Distribution of percentage share for choices of each experiment (c, f and i). Experiment-1, with 22 Participants. Experiment-2, with 92 Participants. Experiment-3, with 3084 Participants.",
                "compound": true,
                "figure_type": "Line Chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 14- exponential curves for share of opinion portions related to Number of deviated steps (a, d and g). Distribution of percentage of share for 16 paths (b, e and h). Distribution of percentage share for choices of each experiment (c, f and i). Experiment-1, with 22 Participants. Experiment-2, with 92 Participants. Experiment-3, with 3084 Participants.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1908.09080v5-Figure14-1",
            "image_path": "1908.09080v5-Figure14-1.png",
            "instance_id": "f27d83e82702af9b1474c14e526a7bf5",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following options are true for the three graphs located in the middle of the image?",
            "reference_answer": "A,B,C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "0.8288"
                    },
                    {
                        "B": "0.9473"
                    },
                    {
                        "C": "0.9731"
                    },
                    {
                        "D": "0.6782"
                    }
                ],
                "caption": "Figure 14- exponential curves for share of opinion portions related to Number of deviated steps (a, d and g). Distribution of percentage of share for 16 paths (b, e and h). Distribution of percentage share for choices of each experiment (c, f and i). Experiment-1, with 22 Participants. Experiment-2, with 92 Participants. Experiment-3, with 3084 Participants.",
                "compound": true,
                "figure_type": "Line Chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 14- exponential curves for share of opinion portions related to Number of deviated steps (a, d and g). Distribution of percentage of share for 16 paths (b, e and h). Distribution of percentage share for choices of each experiment (c, f and i). Experiment-1, with 22 Participants. Experiment-2, with 92 Participants. Experiment-3, with 3084 Participants.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1908.09080v5-Figure14-1",
            "image_path": "1908.09080v5-Figure14-1.png",
            "instance_id": "f775e310fea8f8d67ab56bc6b63cf46c",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the value of R2 for figure d?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 14- exponential curves for share of opinion portions related to Number of deviated steps (a, d and g). Distribution of percentage of share for 16 paths (b, e and h). Distribution of percentage share for choices of each experiment (c, f and i). Experiment-1, with 22 Participants. Experiment-2, with 92 Participants. Experiment-3, with 3084 Participants.",
                "compound": true,
                "figure_type": "Line Chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 14- exponential curves for share of opinion portions related to Number of deviated steps (a, d and g). Distribution of percentage of share for 16 paths (b, e and h). Distribution of percentage share for choices of each experiment (c, f and i). Experiment-1, with 22 Participants. Experiment-2, with 92 Participants. Experiment-3, with 3084 Participants.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1908.09080v5-Figure14-1",
            "image_path": "1908.09080v5-Figure14-1.png",
            "instance_id": "08d1b61cf26860ae236a1d977c96de9e",
            "qa_pair_type": "unanswerable",
            "question": "What is the average age of the participants?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Syntactic tree visualization.",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Syntactic tree visualization.",
            "categories": "nan",
            "figure_id": "2020.lrec-1.126.pdf-Figure4",
            "image_path": "2020.lrec-1.126.pdf-Figure4.png",
            "instance_id": "58bff5a95ba1614f57fc962d500a2a8c",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What color is the node labeled 'born'?",
            "reference_answer": "pink"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The node labeled 'born' is purple.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Syntactic tree visualization.",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Syntactic tree visualization.",
            "categories": "nan",
            "figure_id": "2020.lrec-1.126.pdf-Figure4",
            "image_path": "2020.lrec-1.126.pdf-Figure4.png",
            "instance_id": "bdb23c326d55c4671f278b55f3c46ab3",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the name of the root node in the syntactic tree?",
            "reference_answer": "born"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The name of the root node in the syntactic tree is \"born.\"",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Syntactic tree visualization.",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Syntactic tree visualization.",
            "categories": "nan",
            "figure_id": "2020.lrec-1.126.pdf-Figure4",
            "image_path": "2020.lrec-1.126.pdf-Figure4.png",
            "instance_id": "ccf0bc81729db193bc9e85b297be0caf",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the word 'born' connected to the word 'how' by a pink arrow?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the word 'born' is connected to the word 'how' by a pink arrow.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Syntactic tree visualization.",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Syntactic tree visualization.",
            "categories": "nan",
            "figure_id": "2020.lrec-1.126.pdf-Figure4",
            "image_path": "2020.lrec-1.126.pdf-Figure4.png",
            "instance_id": "0ae0cbf14bb7ceaab2ac1f425df7011f",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the tree in Figure 4 binary?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Blue, Yellow, Red"
                    },
                    {
                        "B": "Blue, Red, Purple, Yellow"
                    },
                    {
                        "C": "Green, Purple, Orange"
                    },
                    {
                        "D": "Green, Purple, Red, Blue, Orange, Yellow"
                    }
                ],
                "caption": "Figure 4: Syntactic tree visualization.",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Syntactic tree visualization.",
            "categories": "nan",
            "figure_id": "2020.lrec-1.126.pdf-Figure4",
            "image_path": "2020.lrec-1.126.pdf-Figure4.png",
            "instance_id": "c5ec2e87b476cc2a2eddc731dda1a220",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following colors are used to represent the nodes in the image?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Punctuation"
                    },
                    {
                        "B": "Adverbial Modifier"
                    },
                    {
                        "C": "Aux Pass"
                    },
                    {
                        "D": "All of the above"
                    }
                ],
                "caption": "Figure 4: Syntactic tree visualization.",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Syntactic tree visualization.",
            "categories": "nan",
            "figure_id": "2020.lrec-1.126.pdf-Figure4",
            "image_path": "2020.lrec-1.126.pdf-Figure4.png",
            "instance_id": "78ca2f9b2623baa65a10b52a751209a2",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What are the relationships between the nodes in the syntactic tree?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Syntactic tree visualization.",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Syntactic tree visualization.",
            "categories": "nan",
            "figure_id": "2020.lrec-1.126.pdf-Figure4",
            "image_path": "2020.lrec-1.126.pdf-Figure4.png",
            "instance_id": "f096692c7736ae783076afc34d37e472",
            "qa_pair_type": "unanswerable",
            "question": "How was the syntactic tree generated?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "FIGURE 1 A CAMR graph and its corresponding graph",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIGURE 1 A CAMR graph and its corresponding graph",
            "categories": "nan",
            "figure_id": "2019.lilt-18.2.pdf-Figure1",
            "image_path": "2019.lilt-18.2.pdf-Figure1.png",
            "instance_id": "be53d882b74dc903c9ea30718f903fb6",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "How many different colors are used in the tree?",
            "reference_answer": "1"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "FIGURE 1 A CAMR graph and its corresponding graph",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIGURE 1 A CAMR graph and its corresponding graph",
            "categories": "nan",
            "figure_id": "2019.lilt-18.2.pdf-Figure1",
            "image_path": "2019.lilt-18.2.pdf-Figure1.png",
            "instance_id": "7bbb9537fc8040232fcbf52bf6a006da",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the location where the girl wants to study?",
            "reference_answer": "New York"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "New York",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "FIGURE 1 A CAMR graph and its corresponding graph",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIGURE 1 A CAMR graph and its corresponding graph",
            "categories": "nan",
            "figure_id": "2019.lilt-18.2.pdf-Figure1",
            "image_path": "2019.lilt-18.2.pdf-Figure1.png",
            "instance_id": "a77daec08a4e5eb7add76d7e6905428d",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the word 'study-01' positioned above of 'city'?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the word 'study-01' is positioned above 'city'.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "FIGURE 1 A CAMR graph and its corresponding graph",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIGURE 1 A CAMR graph and its corresponding graph",
            "categories": "nan",
            "figure_id": "2019.lilt-18.2.pdf-Figure1",
            "image_path": "2019.lilt-18.2.pdf-Figure1.png",
            "instance_id": "f05df432ee06cd523c44ec005e979d1f",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the city name associated with the 'want' graph the same as the city name associated with the '\u60f3' graph?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The city name associated with both the 'want' graph and the '\u60f3' graph is New York.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "city"
                    },
                    {
                        "B": "girl"
                    },
                    {
                        "C": "study-01"
                    },
                    {
                        "D": "all of the above"
                    }
                ],
                "caption": "FIGURE 1 A CAMR graph and its corresponding graph",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIGURE 1 A CAMR graph and its corresponding graph",
            "categories": "nan",
            "figure_id": "2019.lilt-18.2.pdf-Figure1",
            "image_path": "2019.lilt-18.2.pdf-Figure1.png",
            "instance_id": "a0b82e8f5b854f4768b8ac59e5ee0296",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following are entities in the graph?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": ":arg0"
                    },
                    {
                        "B": ":location"
                    },
                    {
                        "C": ":arg1-of"
                    },
                    {
                        "D": ":name"
                    }
                ],
                "caption": "FIGURE 1 A CAMR graph and its corresponding graph",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIGURE 1 A CAMR graph and its corresponding graph",
            "categories": "nan",
            "figure_id": "2019.lilt-18.2.pdf-Figure1",
            "image_path": "2019.lilt-18.2.pdf-Figure1.png",
            "instance_id": "c86f0418b090a66d01497665fef65f22",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which AMR relation does not appear in either graph?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "FIGURE 1 A CAMR graph and its corresponding graph",
                "compound": true,
                "figure_type": "tree",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIGURE 1 A CAMR graph and its corresponding graph",
            "categories": "nan",
            "figure_id": "2019.lilt-18.2.pdf-Figure1",
            "image_path": "2019.lilt-18.2.pdf-Figure1.png",
            "instance_id": "503058ba472b587527302bba2d1b1cc5",
            "qa_pair_type": "unanswerable",
            "question": "What are the main differences between English AMR and CAMR?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "To identify the main differences between English Abstract Meaning Representation (AMR) and Chinese Abstract Meaning Representation (CAMR):\n\n1. **Language Structure**: AMR is designed for English sentences, while CAMR is tailored for Chinese, reflecting the unique syntactical and semantic characteristics of each language.\n\n2. **Lexical Choices**: The vocabulary and concepts represented in AMR may differ significantly from those in CAMR due to cultural and linguistic differences, including idiomatic expressions and common usage.\n\n3. **Argument Structure**: The way arguments (e.g., subjects, objects) are structured may vary between English and Chinese, as illustrated by the different representations of verbs and their arguments.\n\n4. **Translation Challenges**: CAMR may include challenges that arise from directly translating concepts that do not have one-to-one mappings in English, affecting representation.\n\n5. **Syntax Representation**: The visual representation may differ in how the hierarchical relationships among concepts and actions are illustrated due to the divergence in language syntax.\n\nThese points outline the foundational differences in representation and handling between AMR and CAMR.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: A monolingual trie storing three sentences.",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: A monolingual trie storing three sentences.",
            "categories": "nan",
            "figure_id": "2020.acl-main.152.pdf-Figure1",
            "image_path": "2020.acl-main.152.pdf-Figure1.png",
            "instance_id": "5d41fbbdd5a0aeea7fd256dfe2e8de1d",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the color of the text?",
            "reference_answer": "Black"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: A monolingual trie storing three sentences.",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: A monolingual trie storing three sentences.",
            "categories": "nan",
            "figure_id": "2020.acl-main.152.pdf-Figure1",
            "image_path": "2020.acl-main.152.pdf-Figure1.png",
            "instance_id": "1217bc5d88b9c5e57e7651f3aeb328ca",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What are the sentences stored in the trie?",
            "reference_answer": "I like strudels, I like cakes, Cakes are the best"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The sentences stored in the trie are:\n\n1. \"I like strudels.\"\n2. \"Cakes are the best.\"",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: A monolingual trie storing three sentences.",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: A monolingual trie storing three sentences.",
            "categories": "nan",
            "figure_id": "2020.acl-main.152.pdf-Figure1",
            "image_path": "2020.acl-main.152.pdf-Figure1.png",
            "instance_id": "79d18250cc14eeee9387666095077cd9",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "In the trie, are connections between nodes represented as black arrows?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: A monolingual trie storing three sentences.",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: A monolingual trie storing three sentences.",
            "categories": "nan",
            "figure_id": "2020.acl-main.152.pdf-Figure1",
            "image_path": "2020.acl-main.152.pdf-Figure1.png",
            "instance_id": "fcd141f6fea081fcce2b0de579364949",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the structure in Figure 1 a binary tree?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The root node '<s >' is positioned to the far left, with branches extending rightwards."
                    },
                    {
                        "B": "The node 'I' is a child node of the root node '<s >' and is positioned to the right of the root node."
                    },
                    {
                        "C": "The node 'like' is a child node of the node 'I' and is positioned to the right of the node 'I'."
                    },
                    {
                        "D": "All of the above"
                    }
                ],
                "caption": "Figure 1: A monolingual trie storing three sentences.",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: A monolingual trie storing three sentences.",
            "categories": "nan",
            "figure_id": "2020.acl-main.152.pdf-Figure1",
            "image_path": "2020.acl-main.152.pdf-Figure1.png",
            "instance_id": "4c2e0161e73cc245ff7505332f261465",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Considering the visual representation of the monolingual trie in Figure 1, which of the following statements about the position and branching of the nodes are true?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "I like strudels"
                    },
                    {
                        "B": "Strudels are the best"
                    },
                    {
                        "C": "I like cakes"
                    },
                    {
                        "D": "Cakes are the best"
                    }
                ],
                "caption": "Figure 1: A monolingual trie storing three sentences.",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: A monolingual trie storing three sentences.",
            "categories": "nan",
            "figure_id": "2020.acl-main.152.pdf-Figure1",
            "image_path": "2020.acl-main.152.pdf-Figure1.png",
            "instance_id": "2c0842e98ec7ddb40026e959a7623f2e",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following sentences are not stored in the monolingual trie?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: A monolingual trie storing three sentences.",
                "compound": false,
                "figure_type": "tree",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: A monolingual trie storing three sentences.",
            "categories": "nan",
            "figure_id": "2020.acl-main.152.pdf-Figure1",
            "image_path": "2020.acl-main.152.pdf-Figure1.png",
            "instance_id": "6ab9f5a3cd17b94e026b8426881895b8",
            "qa_pair_type": "unanswerable",
            "question": "What is the purpose of storing sentences in the form of a trie?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Storing sentences in the form of a trie (prefix tree) serves several purposes:\n\n1. **Efficient Storage**: A trie can store multiple strings with common prefixes more efficiently than storing each string separately.\n\n2. **Fast Retrieval**: It allows for faster searching of words or phrases, as you can navigate through the trie by following paths defined by the characters of the string.\n\n3. **Auto-completion**: Tries are useful for implementing auto-completion features, as they can quickly find all strings that share a common prefix.\n\n4. **Memory Efficiency**: By sharing common prefixes, tries can potentially save memory compared to other data structures like hash tables or arrays.\n\n5. **Ordered Traversal**: Tries can also facilitate lexicographical traversal of words, which can be useful for various applications.\n\nOverall, the trie structure optimizes both storage and retrieval based on shared prefixes among the sentences.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 9: Percentage of subtitles in the MuST-Cinema training data conforming to CPL< 42 after segmenting with different models.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: Percentage of subtitles in the MuST-Cinema training data conforming to CPL< 42 after segmenting with different models.",
            "categories": "['cs.CL']",
            "figure_id": "2002.10829v1-Figure9-1",
            "image_path": "2002.10829v1-Figure9-1.png",
            "instance_id": "8ead6776f3262db4241e4c3328a8c0fb",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What language is represented by the orange line?",
            "reference_answer": "Romanian"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ES",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 9: Percentage of subtitles in the MuST-Cinema training data conforming to CPL< 42 after segmenting with different models.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: Percentage of subtitles in the MuST-Cinema training data conforming to CPL< 42 after segmenting with different models.",
            "categories": "['cs.CL']",
            "figure_id": "2002.10829v1-Figure9-1",
            "image_path": "2002.10829v1-Figure9-1.png",
            "instance_id": "f90409557a152a830ac0c3e965d1e6cf",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What language has the highest percentage of subtitles conforming to CPL > 42 after segmenting with the 'ft iter1' model?",
            "reference_answer": "Italian"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 9: Percentage of subtitles in the MuST-Cinema training data conforming to CPL< 42 after segmenting with different models.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: Percentage of subtitles in the MuST-Cinema training data conforming to CPL< 42 after segmenting with different models.",
            "categories": "['cs.CL']",
            "figure_id": "2002.10829v1-Figure9-1",
            "image_path": "2002.10829v1-Figure9-1.png",
            "instance_id": "21dbd8fefe782623cace412ed51fd405",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the value of the blue line at 'ft iter1' higher than the value of the red line at the same point?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 9: Percentage of subtitles in the MuST-Cinema training data conforming to CPL< 42 after segmenting with different models.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: Percentage of subtitles in the MuST-Cinema training data conforming to CPL< 42 after segmenting with different models.",
            "categories": "['cs.CL']",
            "figure_id": "2002.10829v1-Figure9-1",
            "image_path": "2002.10829v1-Figure9-1.png",
            "instance_id": "dcd6e2e5c48f92d53e00e56be068f263",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the percentage of subtitles conforming to CPL< 42 for DE higher than that of FR for the 'ft iter1' model?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Italian"
                    },
                    {
                        "B": "Spanish"
                    },
                    {
                        "C": "Dutch"
                    },
                    {
                        "D": "Portuguese"
                    }
                ],
                "caption": "Figure 9: Percentage of subtitles in the MuST-Cinema training data conforming to CPL< 42 after segmenting with different models.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: Percentage of subtitles in the MuST-Cinema training data conforming to CPL< 42 after segmenting with different models.",
            "categories": "['cs.CL']",
            "figure_id": "2002.10829v1-Figure9-1",
            "image_path": "2002.10829v1-Figure9-1.png",
            "instance_id": "c0ecaed83c7fab1bce3ffd5245b68199",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following languages is represented by a green line?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "IT"
                    },
                    {
                        "B": "FR"
                    },
                    {
                        "C": "DE"
                    },
                    {
                        "D": "ES"
                    }
                ],
                "caption": "Figure 9: Percentage of subtitles in the MuST-Cinema training data conforming to CPL< 42 after segmenting with different models.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: Percentage of subtitles in the MuST-Cinema training data conforming to CPL< 42 after segmenting with different models.",
            "categories": "['cs.CL']",
            "figure_id": "2002.10829v1-Figure9-1",
            "image_path": "2002.10829v1-Figure9-1.png",
            "instance_id": "501350d5f5c4559e92bd8dd26fe078b9",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following languages has the lowest percentage of subtitles conforming to CPL<42 after segmenting with the 'None' model?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 9: Percentage of subtitles in the MuST-Cinema training data conforming to CPL< 42 after segmenting with different models.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 9: Percentage of subtitles in the MuST-Cinema training data conforming to CPL< 42 after segmenting with different models.",
            "categories": "['cs.CL']",
            "figure_id": "2002.10829v1-Figure9-1",
            "image_path": "2002.10829v1-Figure9-1.png",
            "instance_id": "f1f77c65d365ad66b0091fa8861190a6",
            "qa_pair_type": "unanswerable",
            "question": "What does CPL stand for?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8: We maintain 100% precision while recall increases with the number of training examples.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: We maintain 100% precision while recall increases with the number of training examples.",
            "categories": "['cs.LG cs.AI cs.CL']",
            "figure_id": "1606.06368v2-Figure8-1",
            "image_path": "1606.06368v2-Figure8-1.png",
            "instance_id": "761c8681c432702a4c1533e8f8f49df4",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of the red line at the x-axis value of 0.4?",
            "reference_answer": "0.4"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8: We maintain 100% precision while recall increases with the number of training examples.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: We maintain 100% precision while recall increases with the number of training examples.",
            "categories": "['cs.LG cs.AI cs.CL']",
            "figure_id": "1606.06368v2-Figure8-1",
            "image_path": "1606.06368v2-Figure8-1.png",
            "instance_id": "874c11ec49fd463e31440ccb38e3ea34",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the highest recall value achieved?",
            "reference_answer": "0.7"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The highest recall value achieved is 1.0.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8: We maintain 100% precision while recall increases with the number of training examples.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: We maintain 100% precision while recall increases with the number of training examples.",
            "categories": "['cs.LG cs.AI cs.CL']",
            "figure_id": "1606.06368v2-Figure8-1",
            "image_path": "1606.06368v2-Figure8-1.png",
            "instance_id": "7dac9ba6a201732f260d195271120dc5",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the blue line representing precision remain constant throughout the graph?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the blue line representing precision remains constant throughout the graph.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8: We maintain 100% precision while recall increases with the number of training examples.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: We maintain 100% precision while recall increases with the number of training examples.",
            "categories": "['cs.LG cs.AI cs.CL']",
            "figure_id": "1606.06368v2-Figure8-1",
            "image_path": "1606.06368v2-Figure8-1.png",
            "instance_id": "ffa20bf1713f71d3f6b7aad08396129a",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does precision remain constant as the number of training examples increases?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, precision remains constant as the number of training examples increases, as indicated by the horizontal line in the graph.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "0.5"
                    },
                    {
                        "B": "1.0"
                    },
                    {
                        "C": "0.25"
                    },
                    {
                        "D": "0.75"
                    }
                ],
                "caption": "Figure 8: We maintain 100% precision while recall increases with the number of training examples.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: We maintain 100% precision while recall increases with the number of training examples.",
            "categories": "['cs.LG cs.AI cs.CL']",
            "figure_id": "1606.06368v2-Figure8-1",
            "image_path": "1606.06368v2-Figure8-1.png",
            "instance_id": "fe0f3e2e9ca4b969d5e30b3069dcdef5",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What is the approximate value of the redd line on the y-axis at 20% of data?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "0"
                    },
                    {
                        "B": "0.4"
                    },
                    {
                        "C": "0.6"
                    },
                    {
                        "D": "1"
                    }
                ],
                "caption": "Figure 8: We maintain 100% precision while recall increases with the number of training examples.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: We maintain 100% precision while recall increases with the number of training examples.",
            "categories": "['cs.LG cs.AI cs.CL']",
            "figure_id": "1606.06368v2-Figure8-1",
            "image_path": "1606.06368v2-Figure8-1.png",
            "instance_id": "a27880d13ab83381cee5e698cdefbc5f",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "At what percentage of data is the difference between the precision and recall values the smallest?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B C D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 8: We maintain 100% precision while recall increases with the number of training examples.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 8: We maintain 100% precision while recall increases with the number of training examples.",
            "categories": "['cs.LG cs.AI cs.CL']",
            "figure_id": "1606.06368v2-Figure8-1",
            "image_path": "1606.06368v2-Figure8-1.png",
            "instance_id": "169d81cb51bb1c083800be7e3e3bed68",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific machine learning algorithm used to generate the precision and recall values shown in Figure 8?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Expected maximum performance of a BCN classifier on SST. We compare three embedding approaches (GloVe embeddings, GloVe + frozen ELMo, and GloVe + fine-tuned ELMo). The x-axis is time, on a log scale. We omit the variance for visual clarity. For each of the three model families, we sampled 50 hyperparameter values, and plot the expected maximum performance with the x-axis values scaled by the average training duration. The plot shows that for each approach (GloVe, ELMo frozen, and ELMo fine-tuned), there exists a budget for which it is preferable.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Expected maximum performance of a BCN classifier on SST. We compare three embedding approaches (GloVe embeddings, GloVe + frozen ELMo, and GloVe + fine-tuned ELMo). The x-axis is time, on a log scale. We omit the variance for visual clarity. For each of the three model families, we sampled 50 hyperparameter values, and plot the expected maximum performance with the x-axis values scaled by the average training duration. The plot shows that for each approach (GloVe, ELMo frozen, and ELMo fine-tuned), there exists a budget for which it is preferable.",
            "categories": "['cs.LG cs.CL stat.ME stat.ML']",
            "figure_id": "1909.03004v1-Figure2-1",
            "image_path": "1909.03004v1-Figure2-1.png",
            "instance_id": "e2cf73c1b9a146c0e63f9ff1f9b2423d",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate expected validation accuracy of the orange line at the training duration of 1 day?",
            "reference_answer": "0.87"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Expected maximum performance of a BCN classifier on SST. We compare three embedding approaches (GloVe embeddings, GloVe + frozen ELMo, and GloVe + fine-tuned ELMo). The x-axis is time, on a log scale. We omit the variance for visual clarity. For each of the three model families, we sampled 50 hyperparameter values, and plot the expected maximum performance with the x-axis values scaled by the average training duration. The plot shows that for each approach (GloVe, ELMo frozen, and ELMo fine-tuned), there exists a budget for which it is preferable.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Expected maximum performance of a BCN classifier on SST. We compare three embedding approaches (GloVe embeddings, GloVe + frozen ELMo, and GloVe + fine-tuned ELMo). The x-axis is time, on a log scale. We omit the variance for visual clarity. For each of the three model families, we sampled 50 hyperparameter values, and plot the expected maximum performance with the x-axis values scaled by the average training duration. The plot shows that for each approach (GloVe, ELMo frozen, and ELMo fine-tuned), there exists a budget for which it is preferable.",
            "categories": "['cs.LG cs.CL stat.ME stat.ML']",
            "figure_id": "1909.03004v1-Figure2-1",
            "image_path": "1909.03004v1-Figure2-1.png",
            "instance_id": "db31e944caaa2e41797750f244f1cc78",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the highest possible training duration represented in the chart?",
            "reference_answer": "10 days"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "10d",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Expected maximum performance of a BCN classifier on SST. We compare three embedding approaches (GloVe embeddings, GloVe + frozen ELMo, and GloVe + fine-tuned ELMo). The x-axis is time, on a log scale. We omit the variance for visual clarity. For each of the three model families, we sampled 50 hyperparameter values, and plot the expected maximum performance with the x-axis values scaled by the average training duration. The plot shows that for each approach (GloVe, ELMo frozen, and ELMo fine-tuned), there exists a budget for which it is preferable.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Expected maximum performance of a BCN classifier on SST. We compare three embedding approaches (GloVe embeddings, GloVe + frozen ELMo, and GloVe + fine-tuned ELMo). The x-axis is time, on a log scale. We omit the variance for visual clarity. For each of the three model families, we sampled 50 hyperparameter values, and plot the expected maximum performance with the x-axis values scaled by the average training duration. The plot shows that for each approach (GloVe, ELMo frozen, and ELMo fine-tuned), there exists a budget for which it is preferable.",
            "categories": "['cs.LG cs.CL stat.ME stat.ML']",
            "figure_id": "1909.03004v1-Figure2-1",
            "image_path": "1909.03004v1-Figure2-1.png",
            "instance_id": "9ca3136c4851425367a239da84323b23",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the brown line representing GloVe + ELMo (FT) reach the highest expected validation accuracy at 10 days of training?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Expected maximum performance of a BCN classifier on SST. We compare three embedding approaches (GloVe embeddings, GloVe + frozen ELMo, and GloVe + fine-tuned ELMo). The x-axis is time, on a log scale. We omit the variance for visual clarity. For each of the three model families, we sampled 50 hyperparameter values, and plot the expected maximum performance with the x-axis values scaled by the average training duration. The plot shows that for each approach (GloVe, ELMo frozen, and ELMo fine-tuned), there exists a budget for which it is preferable.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Expected maximum performance of a BCN classifier on SST. We compare three embedding approaches (GloVe embeddings, GloVe + frozen ELMo, and GloVe + fine-tuned ELMo). The x-axis is time, on a log scale. We omit the variance for visual clarity. For each of the three model families, we sampled 50 hyperparameter values, and plot the expected maximum performance with the x-axis values scaled by the average training duration. The plot shows that for each approach (GloVe, ELMo frozen, and ELMo fine-tuned), there exists a budget for which it is preferable.",
            "categories": "['cs.LG cs.CL stat.ME stat.ML']",
            "figure_id": "1909.03004v1-Figure2-1",
            "image_path": "1909.03004v1-Figure2-1.png",
            "instance_id": "8efe54c7d518bf7fc539a600ea62447c",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the expected maximum performance of the GloVe + fine-tuned ELMo model consistently surpass the performance of the GloVe model across all training durations?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The expected maximum performance of the GloVe + fine-tuned ELMo model consistently surpasses the performance of the GloVe model across all training durations shown in the graph.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "GloVe + ELMo (FT)"
                    },
                    {
                        "B": "GloVe + ELMo (FR)"
                    },
                    {
                        "C": "GloVe"
                    },
                    {
                        "D": "All reach the same maximum value"
                    }
                ],
                "caption": "Figure 2: Expected maximum performance of a BCN classifier on SST. We compare three embedding approaches (GloVe embeddings, GloVe + frozen ELMo, and GloVe + fine-tuned ELMo). The x-axis is time, on a log scale. We omit the variance for visual clarity. For each of the three model families, we sampled 50 hyperparameter values, and plot the expected maximum performance with the x-axis values scaled by the average training duration. The plot shows that for each approach (GloVe, ELMo frozen, and ELMo fine-tuned), there exists a budget for which it is preferable.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Expected maximum performance of a BCN classifier on SST. We compare three embedding approaches (GloVe embeddings, GloVe + frozen ELMo, and GloVe + fine-tuned ELMo). The x-axis is time, on a log scale. We omit the variance for visual clarity. For each of the three model families, we sampled 50 hyperparameter values, and plot the expected maximum performance with the x-axis values scaled by the average training duration. The plot shows that for each approach (GloVe, ELMo frozen, and ELMo fine-tuned), there exists a budget for which it is preferable.",
            "categories": "['cs.LG cs.CL stat.ME stat.ML']",
            "figure_id": "1909.03004v1-Figure2-1",
            "image_path": "1909.03004v1-Figure2-1.png",
            "instance_id": "2502fd80403f7f30b55143f99b286d3a",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line in the plot reaches the highest value on the y-axis?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "GloVe"
                    },
                    {
                        "B": "GloVe + ELMo (FR)"
                    },
                    {
                        "C": "GloVe + ELMo (FT)"
                    },
                    {
                        "D": "All three approaches have equal performance"
                    }
                ],
                "caption": "Figure 2: Expected maximum performance of a BCN classifier on SST. We compare three embedding approaches (GloVe embeddings, GloVe + frozen ELMo, and GloVe + fine-tuned ELMo). The x-axis is time, on a log scale. We omit the variance for visual clarity. For each of the three model families, we sampled 50 hyperparameter values, and plot the expected maximum performance with the x-axis values scaled by the average training duration. The plot shows that for each approach (GloVe, ELMo frozen, and ELMo fine-tuned), there exists a budget for which it is preferable.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Expected maximum performance of a BCN classifier on SST. We compare three embedding approaches (GloVe embeddings, GloVe + frozen ELMo, and GloVe + fine-tuned ELMo). The x-axis is time, on a log scale. We omit the variance for visual clarity. For each of the three model families, we sampled 50 hyperparameter values, and plot the expected maximum performance with the x-axis values scaled by the average training duration. The plot shows that for each approach (GloVe, ELMo frozen, and ELMo fine-tuned), there exists a budget for which it is preferable.",
            "categories": "['cs.LG cs.CL stat.ME stat.ML']",
            "figure_id": "1909.03004v1-Figure2-1",
            "image_path": "1909.03004v1-Figure2-1.png",
            "instance_id": "e57b2f71f534352f673a6cb6c659146b",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following embedding approaches has the highest expected maximum performance for a training duration of 6 hours?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Expected maximum performance of a BCN classifier on SST. We compare three embedding approaches (GloVe embeddings, GloVe + frozen ELMo, and GloVe + fine-tuned ELMo). The x-axis is time, on a log scale. We omit the variance for visual clarity. For each of the three model families, we sampled 50 hyperparameter values, and plot the expected maximum performance with the x-axis values scaled by the average training duration. The plot shows that for each approach (GloVe, ELMo frozen, and ELMo fine-tuned), there exists a budget for which it is preferable.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Expected maximum performance of a BCN classifier on SST. We compare three embedding approaches (GloVe embeddings, GloVe + frozen ELMo, and GloVe + fine-tuned ELMo). The x-axis is time, on a log scale. We omit the variance for visual clarity. For each of the three model families, we sampled 50 hyperparameter values, and plot the expected maximum performance with the x-axis values scaled by the average training duration. The plot shows that for each approach (GloVe, ELMo frozen, and ELMo fine-tuned), there exists a budget for which it is preferable.",
            "categories": "['cs.LG cs.CL stat.ME stat.ML']",
            "figure_id": "1909.03004v1-Figure2-1",
            "image_path": "1909.03004v1-Figure2-1.png",
            "instance_id": "6953919c4d76c4556594bff3240e2b35",
            "qa_pair_type": "unanswerable",
            "question": "What are the specific hyperparameter values sampled for each of the three model families?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Fine-grained sentiment analysis accuracy vs. sentence length. The results of LSTM, Bi-LSTM and TreeLSTM are from Tai, Socher, and Manning (2015) and the result of DiSAN is the average over five random trials.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Fine-grained sentiment analysis accuracy vs. sentence length. The results of LSTM, Bi-LSTM and TreeLSTM are from Tai, Socher, and Manning (2015) and the result of DiSAN is the average over five random trials.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1709.04696v3-Figure5-1",
            "image_path": "1709.04696v3-Figure5-1.png",
            "instance_id": "d6c442ac6dfae6e4dc268d64789cc75f",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the second label from the left of the x-axis?",
            "reference_answer": "5"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The second label from the left of the x-axis is \"5\".",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Fine-grained sentiment analysis accuracy vs. sentence length. The results of LSTM, Bi-LSTM and TreeLSTM are from Tai, Socher, and Manning (2015) and the result of DiSAN is the average over five random trials.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Fine-grained sentiment analysis accuracy vs. sentence length. The results of LSTM, Bi-LSTM and TreeLSTM are from Tai, Socher, and Manning (2015) and the result of DiSAN is the average over five random trials.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1709.04696v3-Figure5-1",
            "image_path": "1709.04696v3-Figure5-1.png",
            "instance_id": "4dd2fca04908046417a8b364d09c65e6",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "Which model has approximately the highest accuracy for sentence length of 1?",
            "reference_answer": "DiSAN"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Fine-grained sentiment analysis accuracy vs. sentence length. The results of LSTM, Bi-LSTM and TreeLSTM are from Tai, Socher, and Manning (2015) and the result of DiSAN is the average over five random trials.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Fine-grained sentiment analysis accuracy vs. sentence length. The results of LSTM, Bi-LSTM and TreeLSTM are from Tai, Socher, and Manning (2015) and the result of DiSAN is the average over five random trials.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1709.04696v3-Figure5-1",
            "image_path": "1709.04696v3-Figure5-1.png",
            "instance_id": "734e62d8b990482307f9ce2e1a893718",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the blue line representing DiSAN have a higher accuracy than the green line representing Bi-LSTM at the sentence length of 35?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Fine-grained sentiment analysis accuracy vs. sentence length. The results of LSTM, Bi-LSTM and TreeLSTM are from Tai, Socher, and Manning (2015) and the result of DiSAN is the average over five random trials.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Fine-grained sentiment analysis accuracy vs. sentence length. The results of LSTM, Bi-LSTM and TreeLSTM are from Tai, Socher, and Manning (2015) and the result of DiSAN is the average over five random trials.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1709.04696v3-Figure5-1",
            "image_path": "1709.04696v3-Figure5-1.png",
            "instance_id": "cb0ad8a77d169c83d7dd13563be3f613",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the accuracy of DiSAN consistently higher than the accuracy of Tree-LSTM for different sentence lengths?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "LSTM"
                    },
                    {
                        "B": "Bi-LSTM"
                    },
                    {
                        "C": "Tree-LSTM"
                    },
                    {
                        "D": "DiSAN"
                    }
                ],
                "caption": "Figure 5: Fine-grained sentiment analysis accuracy vs. sentence length. The results of LSTM, Bi-LSTM and TreeLSTM are from Tai, Socher, and Manning (2015) and the result of DiSAN is the average over five random trials.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Fine-grained sentiment analysis accuracy vs. sentence length. The results of LSTM, Bi-LSTM and TreeLSTM are from Tai, Socher, and Manning (2015) and the result of DiSAN is the average over five random trials.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1709.04696v3-Figure5-1",
            "image_path": "1709.04696v3-Figure5-1.png",
            "instance_id": "52288a5f31f829b7d00f19aee5dfafa5",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line has the lowest value at a sentence length of approximately 6?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "LSTM"
                    },
                    {
                        "B": "Bi-LSTM"
                    },
                    {
                        "C": "Tree-LSTM"
                    },
                    {
                        "D": "DiSAN"
                    }
                ],
                "caption": "Figure 5: Fine-grained sentiment analysis accuracy vs. sentence length. The results of LSTM, Bi-LSTM and TreeLSTM are from Tai, Socher, and Manning (2015) and the result of DiSAN is the average over five random trials.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Fine-grained sentiment analysis accuracy vs. sentence length. The results of LSTM, Bi-LSTM and TreeLSTM are from Tai, Socher, and Manning (2015) and the result of DiSAN is the average over five random trials.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1709.04696v3-Figure5-1",
            "image_path": "1709.04696v3-Figure5-1.png",
            "instance_id": "b5b801be62cef3dc49a36f59a753608a",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following models have an accuracy of at least 0.70 for sentence lengths of less than 5?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: Fine-grained sentiment analysis accuracy vs. sentence length. The results of LSTM, Bi-LSTM and TreeLSTM are from Tai, Socher, and Manning (2015) and the result of DiSAN is the average over five random trials.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: Fine-grained sentiment analysis accuracy vs. sentence length. The results of LSTM, Bi-LSTM and TreeLSTM are from Tai, Socher, and Manning (2015) and the result of DiSAN is the average over five random trials.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1709.04696v3-Figure5-1",
            "image_path": "1709.04696v3-Figure5-1.png",
            "instance_id": "c349b7df2d548ff76c9b0d48d6c9e426",
            "qa_pair_type": "unanswerable",
            "question": "What is the exact average accuracy of all models for sentences of length 10?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 2: Comparing AspeRa with GloVe (SGNS clusters), ABAE (SGNS clusters), and LDA with the same vocabulary and 10 topics on Instant Videos; more is better. X-axis: number of top-ranked representative words per aspect, Y-axis: topic coherence scores.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2: Comparing AspeRa with GloVe (SGNS clusters), ABAE (SGNS clusters), and LDA with the same vocabulary and 10 topics on Instant Videos; more is better. X-axis: number of top-ranked representative words per aspect, Y-axis: topic coherence scores.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1901.07829v1-Figure2-1",
            "image_path": "1901.07829v1-Figure2-1.png",
            "instance_id": "79b89aaf4736d6f9051349cd1dcaecf5",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "Which color has the line that is located at the bottom of the figure in the line chart on the left?",
            "reference_answer": "Green"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The line that is located at the bottom of the figure in the line chart on the left is colored red.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 2: Comparing AspeRa with GloVe (SGNS clusters), ABAE (SGNS clusters), and LDA with the same vocabulary and 10 topics on Instant Videos; more is better. X-axis: number of top-ranked representative words per aspect, Y-axis: topic coherence scores.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2: Comparing AspeRa with GloVe (SGNS clusters), ABAE (SGNS clusters), and LDA with the same vocabulary and 10 topics on Instant Videos; more is better. X-axis: number of top-ranked representative words per aspect, Y-axis: topic coherence scores.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1901.07829v1-Figure2-1",
            "image_path": "1901.07829v1-Figure2-1.png",
            "instance_id": "e20940fe9e1471d4167f27210c68904a",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "Which method has the second highest topic coherence score in Figure (a) at x=10?",
            "reference_answer": "OnlineLDA"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 2: Comparing AspeRa with GloVe (SGNS clusters), ABAE (SGNS clusters), and LDA with the same vocabulary and 10 topics on Instant Videos; more is better. X-axis: number of top-ranked representative words per aspect, Y-axis: topic coherence scores.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2: Comparing AspeRa with GloVe (SGNS clusters), ABAE (SGNS clusters), and LDA with the same vocabulary and 10 topics on Instant Videos; more is better. X-axis: number of top-ranked representative words per aspect, Y-axis: topic coherence scores.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1901.07829v1-Figure2-1",
            "image_path": "1901.07829v1-Figure2-1.png",
            "instance_id": "51e5a4e805cc82914eb6c1056519e0c0",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the purple line located at the top of the right figure, but at the bottom of the left figure?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 2: Comparing AspeRa with GloVe (SGNS clusters), ABAE (SGNS clusters), and LDA with the same vocabulary and 10 topics on Instant Videos; more is better. X-axis: number of top-ranked representative words per aspect, Y-axis: topic coherence scores.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2: Comparing AspeRa with GloVe (SGNS clusters), ABAE (SGNS clusters), and LDA with the same vocabulary and 10 topics on Instant Videos; more is better. X-axis: number of top-ranked representative words per aspect, Y-axis: topic coherence scores.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1901.07829v1-Figure2-1",
            "image_path": "1901.07829v1-Figure2-1.png",
            "instance_id": "df22f31ced74f723e8bc3a6c7563d061",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the topic coherence score for OnlineLDA higher in Figure (b) than in Figure (a) at x=10?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "0.021"
                    },
                    {
                        "B": "0.070"
                    },
                    {
                        "C": "0.060"
                    },
                    {
                        "D": "0.043"
                    }
                ],
                "caption": "Fig. 2: Comparing AspeRa with GloVe (SGNS clusters), ABAE (SGNS clusters), and LDA with the same vocabulary and 10 topics on Instant Videos; more is better. X-axis: number of top-ranked representative words per aspect, Y-axis: topic coherence scores.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2: Comparing AspeRa with GloVe (SGNS clusters), ABAE (SGNS clusters), and LDA with the same vocabulary and 10 topics on Instant Videos; more is better. X-axis: number of top-ranked representative words per aspect, Y-axis: topic coherence scores.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1901.07829v1-Figure2-1",
            "image_path": "1901.07829v1-Figure2-1.png",
            "instance_id": "a04617105c4b0e16b1c231cce3172dd7",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What is the approximate topic coherence value of OnlineLDA at x=20 in Figure (b)?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B: 0.070",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "24"
                    },
                    {
                        "B": "34"
                    },
                    {
                        "C": "14"
                    },
                    {
                        "D": "18"
                    }
                ],
                "caption": "Fig. 2: Comparing AspeRa with GloVe (SGNS clusters), ABAE (SGNS clusters), and LDA with the same vocabulary and 10 topics on Instant Videos; more is better. X-axis: number of top-ranked representative words per aspect, Y-axis: topic coherence scores.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2: Comparing AspeRa with GloVe (SGNS clusters), ABAE (SGNS clusters), and LDA with the same vocabulary and 10 topics on Instant Videos; more is better. X-axis: number of top-ranked representative words per aspect, Y-axis: topic coherence scores.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1901.07829v1-Figure2-1",
            "image_path": "1901.07829v1-Figure2-1.png",
            "instance_id": "fd5e0acd837512d09d2e9206a15abcde",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "At which approximate x-axis value do OnlineLDA and SGNS-init. AspeRA intersect in Figure (a)?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "BD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 2: Comparing AspeRa with GloVe (SGNS clusters), ABAE (SGNS clusters), and LDA with the same vocabulary and 10 topics on Instant Videos; more is better. X-axis: number of top-ranked representative words per aspect, Y-axis: topic coherence scores.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2: Comparing AspeRa with GloVe (SGNS clusters), ABAE (SGNS clusters), and LDA with the same vocabulary and 10 topics on Instant Videos; more is better. X-axis: number of top-ranked representative words per aspect, Y-axis: topic coherence scores.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1901.07829v1-Figure2-1",
            "image_path": "1901.07829v1-Figure2-1.png",
            "instance_id": "e3302781f9425b25407c5cff64035c2f",
            "qa_pair_type": "unanswerable",
            "question": "What is the exact value of topic coherence scores for SGNS-init. AspeRA with 10 top-ranked representative words per aspect in the PMI figure?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "FIG. 2: (A) The unit step (Heaviside function) with phase transition at \u03bb = 0.41. (B) The unit ramp function on domain [0, 1].",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIG. 2: (A) The unit step (Heaviside function) with phase transition at \u03bb = 0.41. (B) The unit ramp function on domain [0, 1].",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1812.01431v1-Figure2-1",
            "image_path": "1812.01431v1-Figure2-1.png",
            "instance_id": "0084e52fed63b85fadcae14dd66c02bc",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of the red line at the point x = 0.6 in the left figure?",
            "reference_answer": "1"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The value of the red line at the point \\( x = 0.6 \\) in the left figure is \\( 1 \\).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "FIG. 2: (A) The unit step (Heaviside function) with phase transition at \u03bb = 0.41. (B) The unit ramp function on domain [0, 1].",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIG. 2: (A) The unit step (Heaviside function) with phase transition at \u03bb = 0.41. (B) The unit ramp function on domain [0, 1].",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1812.01431v1-Figure2-1",
            "image_path": "1812.01431v1-Figure2-1.png",
            "instance_id": "6694bb3d5d29c2d89991867e38bebde8",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the approximate value of the function in B when x=0.4?",
            "reference_answer": "0.4"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The approximate value of the function in B when \\( x = 0.4 \\) is about 0.4.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "FIG. 2: (A) The unit step (Heaviside function) with phase transition at \u03bb = 0.41. (B) The unit ramp function on domain [0, 1].",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIG. 2: (A) The unit step (Heaviside function) with phase transition at \u03bb = 0.41. (B) The unit ramp function on domain [0, 1].",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1812.01431v1-Figure2-1",
            "image_path": "1812.01431v1-Figure2-1.png",
            "instance_id": "e41dddd4bbe59a339ff59134d02503aa",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the red line in graph B start at the point where x equals 0?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the red line in graph B starts at the point where x equals 0.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "FIG. 2: (A) The unit step (Heaviside function) with phase transition at \u03bb = 0.41. (B) The unit ramp function on domain [0, 1].",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIG. 2: (A) The unit step (Heaviside function) with phase transition at \u03bb = 0.41. (B) The unit ramp function on domain [0, 1].",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1812.01431v1-Figure2-1",
            "image_path": "1812.01431v1-Figure2-1.png",
            "instance_id": "ccf75a607f041ae9c61cd6fcd66e2a0a",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the function in Figure A show a consistent increase of y with an increase in x?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, the function in Figure A does not show a consistent increase of \\( f(x) \\) with an increase in \\( x \\).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "0"
                    },
                    {
                        "B": "1"
                    },
                    {
                        "C": "0.41"
                    },
                    {
                        "D": "0.5"
                    }
                ],
                "caption": "FIG. 2: (A) The unit step (Heaviside function) with phase transition at \u03bb = 0.41. (B) The unit ramp function on domain [0, 1].",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIG. 2: (A) The unit step (Heaviside function) with phase transition at \u03bb = 0.41. (B) The unit ramp function on domain [0, 1].",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1812.01431v1-Figure2-1",
            "image_path": "1812.01431v1-Figure2-1.png",
            "instance_id": "18843e8d972c23303cb65a3c0b3bf14b",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What is the maximum y-axis value of the red line in the figure labeled 'A'?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "1"
                    },
                    {
                        "B": "0.8"
                    },
                    {
                        "C": "0.6"
                    },
                    {
                        "D": "0.5"
                    }
                ],
                "caption": "FIG. 2: (A) The unit step (Heaviside function) with phase transition at \u03bb = 0.41. (B) The unit ramp function on domain [0, 1].",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIG. 2: (A) The unit step (Heaviside function) with phase transition at \u03bb = 0.41. (B) The unit ramp function on domain [0, 1].",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1812.01431v1-Figure2-1",
            "image_path": "1812.01431v1-Figure2-1.png",
            "instance_id": "d98fa6d6440a05a7be70659e32c08046",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the highest x-axis value in Figure B?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "FIG. 2: (A) The unit step (Heaviside function) with phase transition at \u03bb = 0.41. (B) The unit ramp function on domain [0, 1].",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "FIG. 2: (A) The unit step (Heaviside function) with phase transition at \u03bb = 0.41. (B) The unit ramp function on domain [0, 1].",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1812.01431v1-Figure2-1",
            "image_path": "1812.01431v1-Figure2-1.png",
            "instance_id": "e4a5d6f772546d4721674cfed855330f",
            "qa_pair_type": "unanswerable",
            "question": "What is the exact equation of the Heaviside function in Figure A?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The Heaviside function, as depicted in Figure A, can be defined as:\n\n\\[\nf(x) = \n\\begin{cases} \n0 & \\text{if } x < 0.4 \\\\ \n1 & \\text{if } x \\geq 0.4 \n\\end{cases}\n\\]",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 12: Retraining accuracy using different penalty factors on MNLI dataset with DistilBERT model.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 12: Retraining accuracy using different penalty factors on MNLI dataset with DistilBERT model.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "2009.08065v4-Figure12-1",
            "image_path": "2009.08065v4-Figure12-1.png",
            "instance_id": "c8834a0523e744dbf61deb233e36c0c5",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate accuracy of the green dashed line at 10000 steps?",
            "reference_answer": "0.65"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 12: Retraining accuracy using different penalty factors on MNLI dataset with DistilBERT model.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 12: Retraining accuracy using different penalty factors on MNLI dataset with DistilBERT model.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "2009.08065v4-Figure12-1",
            "image_path": "2009.08065v4-Figure12-1.png",
            "instance_id": "11fcb261ab657c9aa32e70e93986856d",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "For around how many steps was the DistilBERT model trained per penalty factor?",
            "reference_answer": "12000"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 12: Retraining accuracy using different penalty factors on MNLI dataset with DistilBERT model.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 12: Retraining accuracy using different penalty factors on MNLI dataset with DistilBERT model.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "2009.08065v4-Figure12-1",
            "image_path": "2009.08065v4-Figure12-1.png",
            "instance_id": "23ca4bb219d9d8df79f2d235afd09ef0",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the dark red line representing 3.00E-04 penalty factor reach an accuracy greater than 0.7?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The dark red line representing a penalty factor of 3.00E-04 does reach an accuracy greater than 0.7.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 12: Retraining accuracy using different penalty factors on MNLI dataset with DistilBERT model.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 12: Retraining accuracy using different penalty factors on MNLI dataset with DistilBERT model.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "2009.08065v4-Figure12-1",
            "image_path": "2009.08065v4-Figure12-1.png",
            "instance_id": "6a1bdf59c9ef1eac9c097393a9eb4be3",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the retraining accuracy increase with the number of steps?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the retraining accuracy increases with the number of steps based on the trends shown in the graph.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "3.00E-05"
                    },
                    {
                        "B": "1.00E-04"
                    },
                    {
                        "C": "3.00E-04"
                    },
                    {
                        "D": "1.00E-03"
                    }
                ],
                "caption": "Figure 12: Retraining accuracy using different penalty factors on MNLI dataset with DistilBERT model.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 12: Retraining accuracy using different penalty factors on MNLI dataset with DistilBERT model.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "2009.08065v4-Figure12-1",
            "image_path": "2009.08065v4-Figure12-1.png",
            "instance_id": "52a734659f778a3fc7ab2c00d32a629a",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which penalty factor is represented by a yellow line?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "3.00E-05, 1.00E-04, 3.00E-04, 1.00E-03"
                    },
                    {
                        "B": "1.00E-05, 3.00E-04, 1.00E-03, 3.00E-05"
                    },
                    {
                        "C": "1.00E-04, 3.00E-04, 3.00E-05, 1.00E-02"
                    },
                    {
                        "D": "3.00E-01, 1.00E-03, 3.00E-05, 1.00E-04"
                    }
                ],
                "caption": "Figure 12: Retraining accuracy using different penalty factors on MNLI dataset with DistilBERT model.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 12: Retraining accuracy using different penalty factors on MNLI dataset with DistilBERT model.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "2009.08065v4-Figure12-1",
            "image_path": "2009.08065v4-Figure12-1.png",
            "instance_id": "3fb843c42d72bfb11e86cca94f3f70d4",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which penalty factors are used for retraining accuracy on MNLI dataset?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 12: Retraining accuracy using different penalty factors on MNLI dataset with DistilBERT model.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 12: Retraining accuracy using different penalty factors on MNLI dataset with DistilBERT model.",
            "categories": "['cs.CL cs.AI cs.LG']",
            "figure_id": "2009.08065v4-Figure12-1",
            "image_path": "2009.08065v4-Figure12-1.png",
            "instance_id": "a71a5760985ac38d8d52767c5dddb2d6",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific hyperparameter configuration used for the DistilBERT model to achieve the highest retraining accuracy in this experiment?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: The Meteor scores of ESD on Oxford test dataset with different M and K, where M is the number of discrete latent variables used in ESD, and K is the number of categories.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: The Meteor scores of ESD on Oxford test dataset with different M and K, where M is the number of discrete latent variables used in ESD, and K is the number of categories.",
            "categories": "nan",
            "figure_id": "2020.acl-main.65.pdf-Figure2",
            "image_path": "2020.acl-main.65.pdf-Figure2.png",
            "instance_id": "27e227d827e63dd8340e8497e958721e",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the number of categories K represented by the purple line with stars?",
            "reference_answer": "1024"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The purple line with stars represents K=1024.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: The Meteor scores of ESD on Oxford test dataset with different M and K, where M is the number of discrete latent variables used in ESD, and K is the number of categories.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: The Meteor scores of ESD on Oxford test dataset with different M and K, where M is the number of discrete latent variables used in ESD, and K is the number of categories.",
            "categories": "nan",
            "figure_id": "2020.acl-main.65.pdf-Figure2",
            "image_path": "2020.acl-main.65.pdf-Figure2.png",
            "instance_id": "7eeb06aecf648bf13402567f005bfae2",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "According to Figure 2, what is the highest Meteor score achieved when K=256?",
            "reference_answer": "11.0"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The highest Meteor score achieved when K=256 is approximately 10.5.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: The Meteor scores of ESD on Oxford test dataset with different M and K, where M is the number of discrete latent variables used in ESD, and K is the number of categories.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: The Meteor scores of ESD on Oxford test dataset with different M and K, where M is the number of discrete latent variables used in ESD, and K is the number of categories.",
            "categories": "nan",
            "figure_id": "2020.acl-main.65.pdf-Figure2",
            "image_path": "2020.acl-main.65.pdf-Figure2.png",
            "instance_id": "3345042d4d905814a8cd86169bc2b4df",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the green line representing K=256 show a consistently higher Meteor score than the orange line representing K=128 across all values of M?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, the green line (K=256) does not show a consistently higher Meteor score than the orange line (K=128) across all values of M. At M=1, the orange line is higher, and at M=4, both are equal. K=256 surpasses K=128 at M=8, M=16, and M=32.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: The Meteor scores of ESD on Oxford test dataset with different M and K, where M is the number of discrete latent variables used in ESD, and K is the number of categories.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: The Meteor scores of ESD on Oxford test dataset with different M and K, where M is the number of discrete latent variables used in ESD, and K is the number of categories.",
            "categories": "nan",
            "figure_id": "2020.acl-main.65.pdf-Figure2",
            "image_path": "2020.acl-main.65.pdf-Figure2.png",
            "instance_id": "d3e23975d216abb7a89dca7ecfbe9c12",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Are higher numbers of categories K generally associated with higher Meteor Scores? ",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The green line shows an overall increasing trend from left to right."
                    },
                    {
                        "B": "The green line reaches its peak at M=8."
                    },
                    {
                        "C": "The green line is positioned above all other lines at M=16."
                    },
                    {
                        "D": "The green line's Meteor Score is below 10 at M=1."
                    }
                ],
                "caption": "Figure 2: The Meteor scores of ESD on Oxford test dataset with different M and K, where M is the number of discrete latent variables used in ESD, and K is the number of categories.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: The Meteor scores of ESD on Oxford test dataset with different M and K, where M is the number of discrete latent variables used in ESD, and K is the number of categories.",
            "categories": "nan",
            "figure_id": "2020.acl-main.65.pdf-Figure2",
            "image_path": "2020.acl-main.65.pdf-Figure2.png",
            "instance_id": "804576581d818094b4c3c0b0d6991b26",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Considering the green line in Figure 2, which of the following statements is not true regarding its shape, position, and value?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "BC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "K=64"
                    },
                    {
                        "B": "K=128"
                    },
                    {
                        "C": "K=256"
                    },
                    {
                        "D": "K=512"
                    }
                ],
                "caption": "Figure 2: The Meteor scores of ESD on Oxford test dataset with different M and K, where M is the number of discrete latent variables used in ESD, and K is the number of categories.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: The Meteor scores of ESD on Oxford test dataset with different M and K, where M is the number of discrete latent variables used in ESD, and K is the number of categories.",
            "categories": "nan",
            "figure_id": "2020.acl-main.65.pdf-Figure2",
            "image_path": "2020.acl-main.65.pdf-Figure2.png",
            "instance_id": "7559bdb1654b74b4b152f49be0328b96",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "For which value of K is the Meteor Score not at it's highest at M=8?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ACD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: The Meteor scores of ESD on Oxford test dataset with different M and K, where M is the number of discrete latent variables used in ESD, and K is the number of categories.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: The Meteor scores of ESD on Oxford test dataset with different M and K, where M is the number of discrete latent variables used in ESD, and K is the number of categories.",
            "categories": "nan",
            "figure_id": "2020.acl-main.65.pdf-Figure2",
            "image_path": "2020.acl-main.65.pdf-Figure2.png",
            "instance_id": "6d7b0ba2d6792debed6aa3e0f9104b60",
            "qa_pair_type": "unanswerable",
            "question": "What does ESD stand for?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Relative weight change { \u2206w w } at every 100 update for the encoders of the trained H-LSTM. The figure legend indicates different combinations of encoder-decoder hidden sizes.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Relative weight change { \u2206w w } at every 100 update for the encoders of the trained H-LSTM. The figure legend indicates different combinations of encoder-decoder hidden sizes.",
            "categories": "['cs.CL']",
            "figure_id": "2002.09084v1-Figure2-1",
            "image_path": "2002.09084v1-Figure2-1.png",
            "instance_id": "3cef1c857194bc33f79c6d8c91565cc6",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What color represents the encoder-decoder pair where the encoder and decoder have the same hidden size?",
            "reference_answer": "Blue"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The color representing the encoder-decoder pair where the encoder and decoder have the same hidden size is blue.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Relative weight change { \u2206w w } at every 100 update for the encoders of the trained H-LSTM. The figure legend indicates different combinations of encoder-decoder hidden sizes.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Relative weight change { \u2206w w } at every 100 update for the encoders of the trained H-LSTM. The figure legend indicates different combinations of encoder-decoder hidden sizes.",
            "categories": "['cs.CL']",
            "figure_id": "2002.09084v1-Figure2-1",
            "image_path": "2002.09084v1-Figure2-1.png",
            "instance_id": "fd20d0a10cfa1fdba9e4f4fa32681be1",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the maximum relative weight change for the encoder with size 1024 and decoder with size 256 in graph (a)?",
            "reference_answer": "5%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Relative weight change { \u2206w w } at every 100 update for the encoders of the trained H-LSTM. The figure legend indicates different combinations of encoder-decoder hidden sizes.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Relative weight change { \u2206w w } at every 100 update for the encoders of the trained H-LSTM. The figure legend indicates different combinations of encoder-decoder hidden sizes.",
            "categories": "['cs.CL']",
            "figure_id": "2002.09084v1-Figure2-1",
            "image_path": "2002.09084v1-Figure2-1.png",
            "instance_id": "aa8a7a34938436ae7485e6e89720f412",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the blue line corresponding to Encoder(256)-Decoder(256) consistently above the yellow line corresponding to Encoder(1024)-Decoder(256) in the right subplot?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Relative weight change { \u2206w w } at every 100 update for the encoders of the trained H-LSTM. The figure legend indicates different combinations of encoder-decoder hidden sizes.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Relative weight change { \u2206w w } at every 100 update for the encoders of the trained H-LSTM. The figure legend indicates different combinations of encoder-decoder hidden sizes.",
            "categories": "['cs.CL']",
            "figure_id": "2002.09084v1-Figure2-1",
            "image_path": "2002.09084v1-Figure2-1.png",
            "instance_id": "fc5f631fde7840d436c193bc696a6b61",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the weight change of the 'Encoder(256)-Decoder(256)' model ever exceed 10% for the document encoder?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the weight change of the 'Encoder(256)-Decoder(256)' model exceeds 10% for the document encoder.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Blue"
                    },
                    {
                        "B": "Red"
                    },
                    {
                        "C": "Yellow"
                    },
                    {
                        "D": "Blue and red"
                    }
                ],
                "caption": "Figure 2: Relative weight change { \u2206w w } at every 100 update for the encoders of the trained H-LSTM. The figure legend indicates different combinations of encoder-decoder hidden sizes.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Relative weight change { \u2206w w } at every 100 update for the encoders of the trained H-LSTM. The figure legend indicates different combinations of encoder-decoder hidden sizes.",
            "categories": "['cs.CL']",
            "figure_id": "2002.09084v1-Figure2-1",
            "image_path": "2002.09084v1-Figure2-1.png",
            "instance_id": "c87a57fdddc72c55a4de420ccb61a401",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following lines shows the highest weight change in the Document Encoder section?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "0%"
                    },
                    {
                        "B": "2%"
                    },
                    {
                        "C": "4%"
                    },
                    {
                        "D": "6%"
                    }
                ],
                "caption": "Figure 2: Relative weight change { \u2206w w } at every 100 update for the encoders of the trained H-LSTM. The figure legend indicates different combinations of encoder-decoder hidden sizes.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Relative weight change { \u2206w w } at every 100 update for the encoders of the trained H-LSTM. The figure legend indicates different combinations of encoder-decoder hidden sizes.",
            "categories": "['cs.CL']",
            "figure_id": "2002.09084v1-Figure2-1",
            "image_path": "2002.09084v1-Figure2-1.png",
            "instance_id": "4cfea70614479b3e1566d68754de5efb",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the approximate highest relative weight change of the sentence encoder with encoder size 256 and decoder size 1024?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Relative weight change { \u2206w w } at every 100 update for the encoders of the trained H-LSTM. The figure legend indicates different combinations of encoder-decoder hidden sizes.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Relative weight change { \u2206w w } at every 100 update for the encoders of the trained H-LSTM. The figure legend indicates different combinations of encoder-decoder hidden sizes.",
            "categories": "['cs.CL']",
            "figure_id": "2002.09084v1-Figure2-1",
            "image_path": "2002.09084v1-Figure2-1.png",
            "instance_id": "6b4d0dee42f0d7d7ec4fab85817af6ae",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific dataset that was used?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6.4 \u2013 Average training and testing success rates with 95% confidence, for 100 runs over the number of epochs, for both models: with and without transfer learning. The model with transfer learning is not warm-started.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6.4 \u2013 Average training and testing success rates with 95% confidence, for 100 runs over the number of epochs, for both models: with and without transfer learning. The model with transfer learning is not warm-started.",
            "categories": "['cs.CL']",
            "figure_id": "1806.00780v1-Figure6.4-1",
            "image_path": "1806.00780v1-Figure6.4-1.png",
            "instance_id": "0efa8dd3ed83c9b1d1dc071e75037140",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the maximum success rate reached by the blue line in the top left graph?",
            "reference_answer": "0.32"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6.4 \u2013 Average training and testing success rates with 95% confidence, for 100 runs over the number of epochs, for both models: with and without transfer learning. The model with transfer learning is not warm-started.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6.4 \u2013 Average training and testing success rates with 95% confidence, for 100 runs over the number of epochs, for both models: with and without transfer learning. The model with transfer learning is not warm-started.",
            "categories": "['cs.CL']",
            "figure_id": "1806.00780v1-Figure6.4-1",
            "image_path": "1806.00780v1-Figure6.4-1.png",
            "instance_id": "db0857eff3f7a0a25ee025ed1af6add1",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What domain is the model used for Restaurant Booking pre-trained on?",
            "reference_answer": "Movie Booking"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The model used for Restaurant Booking is pre-trained on the Movie Booking domain.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6.4 \u2013 Average training and testing success rates with 95% confidence, for 100 runs over the number of epochs, for both models: with and without transfer learning. The model with transfer learning is not warm-started.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6.4 \u2013 Average training and testing success rates with 95% confidence, for 100 runs over the number of epochs, for both models: with and without transfer learning. The model with transfer learning is not warm-started.",
            "categories": "['cs.CL']",
            "figure_id": "1806.00780v1-Figure6.4-1",
            "image_path": "1806.00780v1-Figure6.4-1.png",
            "instance_id": "4e3818d4065fc8150ddf0dcbb27f21c0",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the blue line in the top left plot representing the success rate of the transfer learning model higher than the red line for the number of epochs 20?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the blue line representing the success rate of the transfer learning model is higher than the red line for the number of epochs 20 in the top left plot.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6.4 \u2013 Average training and testing success rates with 95% confidence, for 100 runs over the number of epochs, for both models: with and without transfer learning. The model with transfer learning is not warm-started.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6.4 \u2013 Average training and testing success rates with 95% confidence, for 100 runs over the number of epochs, for both models: with and without transfer learning. The model with transfer learning is not warm-started.",
            "categories": "['cs.CL']",
            "figure_id": "1806.00780v1-Figure6.4-1",
            "image_path": "1806.00780v1-Figure6.4-1.png",
            "instance_id": "1df86757aacd94c4a72d7fd3a3b9e3b0",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the model with transfer learning achieve a higher success rate than the model without transfer learning on the training dataset for the Tourist Info task?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the model with transfer learning achieves a higher success rate than the model without transfer learning on the training dataset for the Tourist Info task.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The top left graph"
                    },
                    {
                        "B": "The top right graph"
                    },
                    {
                        "C": "The bottom left graph"
                    },
                    {
                        "D": "The bottom right graph"
                    }
                ],
                "caption": "Figure 6.4 \u2013 Average training and testing success rates with 95% confidence, for 100 runs over the number of epochs, for both models: with and without transfer learning. The model with transfer learning is not warm-started.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6.4 \u2013 Average training and testing success rates with 95% confidence, for 100 runs over the number of epochs, for both models: with and without transfer learning. The model with transfer learning is not warm-started.",
            "categories": "['cs.CL']",
            "figure_id": "1806.00780v1-Figure6.4-1",
            "image_path": "1806.00780v1-Figure6.4-1.png",
            "instance_id": "d90a16fb77dadc025f303bae6059e23c",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the four graphs displays the highest success rate for the model with transfer learning after 50 epochs?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B C D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Restaurant Booking with pre-training on Restaurant Booking domain"
                    },
                    {
                        "B": "Tourist Info with pre-training on Tourist Info domain"
                    },
                    {
                        "C": "Tourist Info with pre-training on Movie Booking domain"
                    },
                    {
                        "D": "Restaurant Booking with pre-training on Movie Booking domain"
                    }
                ],
                "caption": "Figure 6.4 \u2013 Average training and testing success rates with 95% confidence, for 100 runs over the number of epochs, for both models: with and without transfer learning. The model with transfer learning is not warm-started.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6.4 \u2013 Average training and testing success rates with 95% confidence, for 100 runs over the number of epochs, for both models: with and without transfer learning. The model with transfer learning is not warm-started.",
            "categories": "['cs.CL']",
            "figure_id": "1806.00780v1-Figure6.4-1",
            "image_path": "1806.00780v1-Figure6.4-1.png",
            "instance_id": "79832b3cb7e4f7e513e5bf19db4a3701",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following task and pre-training domains are combined in the provided figure?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "CD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6.4 \u2013 Average training and testing success rates with 95% confidence, for 100 runs over the number of epochs, for both models: with and without transfer learning. The model with transfer learning is not warm-started.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6.4 \u2013 Average training and testing success rates with 95% confidence, for 100 runs over the number of epochs, for both models: with and without transfer learning. The model with transfer learning is not warm-started.",
            "categories": "['cs.CL']",
            "figure_id": "1806.00780v1-Figure6.4-1",
            "image_path": "1806.00780v1-Figure6.4-1.png",
            "instance_id": "f950c1a0f4b464ee0c132a5d942186ad",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific type of machine learning model used in the experiment?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Overall and antipodal RMSE of the ranked participating systems and BASELINE for Subtask 1.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Overall and antipodal RMSE of the ranked participating systems and BASELINE for Subtask 1.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2008.00304v1-Figure3-1",
            "image_path": "2008.00304v1-Figure3-1.png",
            "instance_id": "31654351d3e1f8c2a93ee5e7abf0be59",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the RMSE value at system rank 35 for the red dashed line?",
            "reference_answer": "0.64"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Overall and antipodal RMSE of the ranked participating systems and BASELINE for Subtask 1.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Overall and antipodal RMSE of the ranked participating systems and BASELINE for Subtask 1.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2008.00304v1-Figure3-1",
            "image_path": "2008.00304v1-Figure3-1.png",
            "instance_id": "31edb21ae72d3319888adfa9b7ebd1ce",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the System Rank value of BASELINE?",
            "reference_answer": "33"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Overall and antipodal RMSE of the ranked participating systems and BASELINE for Subtask 1.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Overall and antipodal RMSE of the ranked participating systems and BASELINE for Subtask 1.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2008.00304v1-Figure3-1",
            "image_path": "2008.00304v1-Figure3-1.png",
            "instance_id": "cf6c1cc66c8402cf7edb7bf3bd216a83",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the blue dashed line representing RMSE@10 reach a value greater than 1.1?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Overall and antipodal RMSE of the ranked participating systems and BASELINE for Subtask 1.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Overall and antipodal RMSE of the ranked participating systems and BASELINE for Subtask 1.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2008.00304v1-Figure3-1",
            "image_path": "2008.00304v1-Figure3-1.png",
            "instance_id": "be8efb12af3c3f462127bcd8cf049799",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the RMSE@20 value remain constant across all system ranks?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, the RMSE@20 value does not remain constant across all system ranks. The graph shows fluctuations in the RMSE@20 value as the system rank changes.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Blue"
                    },
                    {
                        "B": "Orange"
                    },
                    {
                        "C": "Green"
                    },
                    {
                        "D": "Red"
                    }
                ],
                "caption": "Figure 3: Overall and antipodal RMSE of the ranked participating systems and BASELINE for Subtask 1.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Overall and antipodal RMSE of the ranked participating systems and BASELINE for Subtask 1.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2008.00304v1-Figure3-1",
            "image_path": "2008.00304v1-Figure3-1.png",
            "instance_id": "d6fee9d89d05801b0f5bc0d11f55f5e7",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following lines has the lowest value at system rank 45?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "RMSE@5"
                    },
                    {
                        "B": "RMSE@15"
                    },
                    {
                        "C": "RMSE@25"
                    },
                    {
                        "D": "All of the above"
                    }
                ],
                "caption": "Figure 3: Overall and antipodal RMSE of the ranked participating systems and BASELINE for Subtask 1.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Overall and antipodal RMSE of the ranked participating systems and BASELINE for Subtask 1.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2008.00304v1-Figure3-1",
            "image_path": "2008.00304v1-Figure3-1.png",
            "instance_id": "9647faded01dafd920728ab326f1a883",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What type of RMSE is not shown in Figure 3?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Overall and antipodal RMSE of the ranked participating systems and BASELINE for Subtask 1.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Overall and antipodal RMSE of the ranked participating systems and BASELINE for Subtask 1.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2008.00304v1-Figure3-1",
            "image_path": "2008.00304v1-Figure3-1.png",
            "instance_id": "c4d0b1bea2b500569e135f5151305479",
            "qa_pair_type": "unanswerable",
            "question": "What does RMSE stand for?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "RMSE stands for Root Mean Square Error.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: BLI performance in the comparable setting.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: BLI performance in the comparable setting.",
            "categories": "nan",
            "figure_id": "2020.acl-main.94.pdf-Figure3",
            "image_path": "2020.acl-main.94.pdf-Figure3.png",
            "instance_id": "bbe556437854a4b95b727365a256058a",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the red dashed line at a window size of 10?",
            "reference_answer": "0.25"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: BLI performance in the comparable setting.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: BLI performance in the comparable setting.",
            "categories": "nan",
            "figure_id": "2020.acl-main.94.pdf-Figure3",
            "image_path": "2020.acl-main.94.pdf-Figure3.png",
            "instance_id": "c48331a9ac752260072d71ad39b11050",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "Which languages are included in the study?",
            "reference_answer": "French, German, Russian, Japanese"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The languages included in the study are:\n\n- French (fr)\n- German (de)\n- Russian (ru)\n- Japanese (ja)",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: BLI performance in the comparable setting.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: BLI performance in the comparable setting.",
            "categories": "nan",
            "figure_id": "2020.acl-main.94.pdf-Figure3",
            "image_path": "2020.acl-main.94.pdf-Figure3.png",
            "instance_id": "d0acc0e1e132fc936db31cf4d3bff63a",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the blue line consistently higher than all other lines in the plot?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the blue line is consistently higher than all other lines in the plot.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: BLI performance in the comparable setting.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: BLI performance in the comparable setting.",
            "categories": "nan",
            "figure_id": "2020.acl-main.94.pdf-Figure3",
            "image_path": "2020.acl-main.94.pdf-Figure3.png",
            "instance_id": "2380af838d2608cf4fab3b0ca618cadf",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the BLI performance for 'de' ever exceed 0.4?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Blue"
                    },
                    {
                        "B": "Green"
                    },
                    {
                        "C": "Orange"
                    },
                    {
                        "D": "Red"
                    }
                ],
                "caption": "Figure 3: BLI performance in the comparable setting.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: BLI performance in the comparable setting.",
            "categories": "nan",
            "figure_id": "2020.acl-main.94.pdf-Figure3",
            "image_path": "2020.acl-main.94.pdf-Figure3.png",
            "instance_id": "cd2895a9e771bde6c180dd1bf93e3905",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the lines has the second-lowest BLI at 20 source/target window size?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "fr"
                    },
                    {
                        "B": "de"
                    },
                    {
                        "C": "ru"
                    },
                    {
                        "D": "ja"
                    }
                ],
                "caption": "Figure 3: BLI performance in the comparable setting.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: BLI performance in the comparable setting.",
            "categories": "nan",
            "figure_id": "2020.acl-main.94.pdf-Figure3",
            "image_path": "2020.acl-main.94.pdf-Figure3.png",
            "instance_id": "3d68916fcedc4bb7cc13295e4e021e26",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following languages have a BLI performance lower than 0.3 for a window size of 15?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "BCD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: BLI performance in the comparable setting.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: BLI performance in the comparable setting.",
            "categories": "nan",
            "figure_id": "2020.acl-main.94.pdf-Figure3",
            "image_path": "2020.acl-main.94.pdf-Figure3.png",
            "instance_id": "f232ebabf99740f94434c99f21d36b96",
            "qa_pair_type": "unanswerable",
            "question": "What is the effect of increasing the source/target window size on the BLI (mmr) for the Hungarian language?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 11. Success of ACER on summary action space compared to ACER on master action space with execution mask. Shaded areas represent a 95% confidence interval.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 11. Success of ACER on summary action space compared to ACER on master action space with execution mask. Shaded areas represent a 95% confidence interval.",
            "categories": "['cs.CL cs.AI cs.LG stat.ML']",
            "figure_id": "1802.03753v1-Figure11-1",
            "image_path": "1802.03753v1-Figure11-1.png",
            "instance_id": "438ddc99968665c3c7a1c4919eed9b0c",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate success rate (%) of ACER on summary action space, represented by the black line, at 3500 training dialogues?",
            "reference_answer": "97%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 11. Success of ACER on summary action space compared to ACER on master action space with execution mask. Shaded areas represent a 95% confidence interval.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 11. Success of ACER on summary action space compared to ACER on master action space with execution mask. Shaded areas represent a 95% confidence interval.",
            "categories": "['cs.CL cs.AI cs.LG stat.ML']",
            "figure_id": "1802.03753v1-Figure11-1",
            "image_path": "1802.03753v1-Figure11-1.png",
            "instance_id": "ec858948d89f2f0c9f1164f455849339",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the maximum number of training dialogues?",
            "reference_answer": "4000"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The maximum number of training dialogues shown in the graph is 4000.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 11. Success of ACER on summary action space compared to ACER on master action space with execution mask. Shaded areas represent a 95% confidence interval.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 11. Success of ACER on summary action space compared to ACER on master action space with execution mask. Shaded areas represent a 95% confidence interval.",
            "categories": "['cs.CL cs.AI cs.LG stat.ML']",
            "figure_id": "1802.03753v1-Figure11-1",
            "image_path": "1802.03753v1-Figure11-1.png",
            "instance_id": "c177400e5ffe8bd21ff0c37ec96a772f",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the black line representing ACER on summary action space have a higher success rate than the blue line representing ACER on master action space at approximately 200 training dialogues?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the black line representing ACER on summary action space has a higher success rate than the blue line representing ACER on master action space at approximately 200 training dialogues.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 11. Success of ACER on summary action space compared to ACER on master action space with execution mask. Shaded areas represent a 95% confidence interval.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 11. Success of ACER on summary action space compared to ACER on master action space with execution mask. Shaded areas represent a 95% confidence interval.",
            "categories": "['cs.CL cs.AI cs.LG stat.ML']",
            "figure_id": "1802.03753v1-Figure11-1",
            "image_path": "1802.03753v1-Figure11-1.png",
            "instance_id": "b5d39404185162f0ffe2f6d572d7a03b",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the success rate start at 0%?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "1"
                    },
                    {
                        "B": "0"
                    },
                    {
                        "C": "2"
                    },
                    {
                        "D": "3"
                    }
                ],
                "caption": "Fig. 11. Success of ACER on summary action space compared to ACER on master action space with execution mask. Shaded areas represent a 95% confidence interval.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 11. Success of ACER on summary action space compared to ACER on master action space with execution mask. Shaded areas represent a 95% confidence interval.",
            "categories": "['cs.CL cs.AI cs.LG stat.ML']",
            "figure_id": "1802.03753v1-Figure11-1",
            "image_path": "1802.03753v1-Figure11-1.png",
            "instance_id": "219e2d3b64f13d93f85ed174114732b7",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "How many lines have a success rate below 75% at 1500 training dialogues?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "ACER on master action space sometimes has a lower success rate than ACER on summary action space"
                    },
                    {
                        "B": "ACER on summary action space always has a higher success rate than ACER on master action space"
                    },
                    {
                        "C": "ACER on master action space and ACER on summary action space both show a decreasing success rate at the beginning"
                    },
                    {
                        "D": "ACER on master action space and ACER on summary action space both consistently decrease over time"
                    }
                ],
                "caption": "Fig. 11. Success of ACER on summary action space compared to ACER on master action space with execution mask. Shaded areas represent a 95% confidence interval.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 11. Success of ACER on summary action space compared to ACER on master action space with execution mask. Shaded areas represent a 95% confidence interval.",
            "categories": "['cs.CL cs.AI cs.LG stat.ML']",
            "figure_id": "1802.03753v1-Figure11-1",
            "image_path": "1802.03753v1-Figure11-1.png",
            "instance_id": "2c1f4f17bddfc6628a79a9c8c74e5496",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following are true about the success rate of ACER on summary and master action spaces? (Select all that apply)",
            "reference_answer": "A,B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 11. Success of ACER on summary action space compared to ACER on master action space with execution mask. Shaded areas represent a 95% confidence interval.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 11. Success of ACER on summary action space compared to ACER on master action space with execution mask. Shaded areas represent a 95% confidence interval.",
            "categories": "['cs.CL cs.AI cs.LG stat.ML']",
            "figure_id": "1802.03753v1-Figure11-1",
            "image_path": "1802.03753v1-Figure11-1.png",
            "instance_id": "714aad1d510cb302d09917184b77ba67",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific implementation of ACER used in the experiment represented by the blue line?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 2. The Quasi-Ergodicity of Embarrassingly Parallel MCMC for Multimodal",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2. The Quasi-Ergodicity of Embarrassingly Parallel MCMC for Multimodal",
            "categories": "['cs.LG cs.CL cs.IR stat.ML']",
            "figure_id": "1708.03052v1-Figure2-1",
            "image_path": "1708.03052v1-Figure2-1.png",
            "instance_id": "4a8267ecb9de43aab2c260384c8af4eb",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "How many different lines are plotted in this figure?",
            "reference_answer": "4"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "There are four different lines plotted in this figure.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 2. The Quasi-Ergodicity of Embarrassingly Parallel MCMC for Multimodal",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2. The Quasi-Ergodicity of Embarrassingly Parallel MCMC for Multimodal",
            "categories": "['cs.LG cs.CL cs.IR stat.ML']",
            "figure_id": "1708.03052v1-Figure2-1",
            "image_path": "1708.03052v1-Figure2-1.png",
            "instance_id": "c270ccdb1ba931e60ea707c449fbeb0f",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "How many sub-posteriors are present in the figure?",
            "reference_answer": "3"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "There are three sub-posteriors present in the figure.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 2. The Quasi-Ergodicity of Embarrassingly Parallel MCMC for Multimodal",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2. The Quasi-Ergodicity of Embarrassingly Parallel MCMC for Multimodal",
            "categories": "['cs.LG cs.CL cs.IR stat.ML']",
            "figure_id": "1708.03052v1-Figure2-1",
            "image_path": "1708.03052v1-Figure2-1.png",
            "instance_id": "e25478cf1f9a0eb374c65b2130e42238",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the real posterior represented by a solid line?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 2. The Quasi-Ergodicity of Embarrassingly Parallel MCMC for Multimodal",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2. The Quasi-Ergodicity of Embarrassingly Parallel MCMC for Multimodal",
            "categories": "['cs.LG cs.CL cs.IR stat.ML']",
            "figure_id": "1708.03052v1-Figure2-1",
            "image_path": "1708.03052v1-Figure2-1.png",
            "instance_id": "2fcb1c3739af2d620b98e713cdbe2a5a",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the 'real posterior' consistently higher than the 'sub-posterior 3' throughout the graph?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "red solid line"
                    },
                    {
                        "B": "purple dashed-dotted line"
                    },
                    {
                        "C": "purple dotted line"
                    },
                    {
                        "D": "blue dashed line"
                    }
                ],
                "caption": "Fig. 2. The Quasi-Ergodicity of Embarrassingly Parallel MCMC for Multimodal",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2. The Quasi-Ergodicity of Embarrassingly Parallel MCMC for Multimodal",
            "categories": "['cs.LG cs.CL cs.IR stat.ML']",
            "figure_id": "1708.03052v1-Figure2-1",
            "image_path": "1708.03052v1-Figure2-1.png",
            "instance_id": "56665e9a5cf69298d17e487a32841858",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the lines represents 'sub-posterior 2'?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "sub-posterior 1"
                    },
                    {
                        "B": "sub-posterior 2"
                    },
                    {
                        "C": "sub-posterior 3"
                    },
                    {
                        "D": "All of the above"
                    }
                ],
                "caption": "Fig. 2. The Quasi-Ergodicity of Embarrassingly Parallel MCMC for Multimodal",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2. The Quasi-Ergodicity of Embarrassingly Parallel MCMC for Multimodal",
            "categories": "['cs.LG cs.CL cs.IR stat.ML']",
            "figure_id": "1708.03052v1-Figure2-1",
            "image_path": "1708.03052v1-Figure2-1.png",
            "instance_id": "539f81227c641534775f46bfc4fad4c8",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following posteriors are approximations of the real posterior?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 2. The Quasi-Ergodicity of Embarrassingly Parallel MCMC for Multimodal",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 2. The Quasi-Ergodicity of Embarrassingly Parallel MCMC for Multimodal",
            "categories": "['cs.LG cs.CL cs.IR stat.ML']",
            "figure_id": "1708.03052v1-Figure2-1",
            "image_path": "1708.03052v1-Figure2-1.png",
            "instance_id": "318753e3b1eb2c2d26e3ea595c82b7e3",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific algorithm used to generate the sub-posteriors in Figure 2?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: CHRF++ scores with respect to (a) the graph size, (b) the graph diameter, and (c) the the number of reentrancies.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: CHRF++ scores with respect to (a) the graph size, (b) the graph diameter, and (c) the the number of reentrancies.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1911.07470v2-Figure3-1",
            "image_path": "1911.07470v2-Figure3-1.png",
            "instance_id": "87eec04bed9ed4933ee7b31baaf53f53",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate CHRF++ score of the red line in the Graph Reentrancies category with 4-5 reentrancies?",
            "reference_answer": "60.0"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: CHRF++ scores with respect to (a) the graph size, (b) the graph diameter, and (c) the the number of reentrancies.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: CHRF++ scores with respect to (a) the graph size, (b) the graph diameter, and (c) the the number of reentrancies.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1911.07470v2-Figure3-1",
            "image_path": "1911.07470v2-Figure3-1.png",
            "instance_id": "6cd30585d19bf898d281aa882934e083",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the approximate CHRF++ score of Guo'19 for a graph with a diameter between 8 and 14?",
            "reference_answer": "58"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: CHRF++ scores with respect to (a) the graph size, (b) the graph diameter, and (c) the the number of reentrancies.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: CHRF++ scores with respect to (a) the graph size, (b) the graph diameter, and (c) the the number of reentrancies.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1911.07470v2-Figure3-1",
            "image_path": "1911.07470v2-Figure3-1.png",
            "instance_id": "466fbac17fb47e812822ef1e6479f333",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the red circle in the first graph consistently above the blue square?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. The red circle representing \"Ours\" is consistently above the blue square representing \"Guo'19\" in the first graph (Graph Size).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: CHRF++ scores with respect to (a) the graph size, (b) the graph diameter, and (c) the the number of reentrancies.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: CHRF++ scores with respect to (a) the graph size, (b) the graph diameter, and (c) the the number of reentrancies.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1911.07470v2-Figure3-1",
            "image_path": "1911.07470v2-Figure3-1.png",
            "instance_id": "77021d401d8438baae9e59009724809c",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the CHRF++ score for 'Ours' consistently higher than the score for 'Guo'19' when considering Graph Reentrancies?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the CHRF++ score for 'Ours' is consistently higher than the score for 'Guo'19' when considering Graph Reentrancies.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "61.5"
                    },
                    {
                        "B": "54"
                    },
                    {
                        "C": "59.0"
                    },
                    {
                        "D": "56.5"
                    }
                ],
                "caption": "Figure 3: CHRF++ scores with respect to (a) the graph size, (b) the graph diameter, and (c) the the number of reentrancies.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: CHRF++ scores with respect to (a) the graph size, (b) the graph diameter, and (c) the the number of reentrancies.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1911.07470v2-Figure3-1",
            "image_path": "1911.07470v2-Figure3-1.png",
            "instance_id": "0b9544917217a248336cd4f743420828",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What is the approximate value of chrF++ of Guo\u201919 (blue line) at 4-5 at Graph Reentrancies?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Graph Size"
                    },
                    {
                        "B": "Graph Diameter"
                    },
                    {
                        "C": "Graph Reentrancies"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 3: CHRF++ scores with respect to (a) the graph size, (b) the graph diameter, and (c) the the number of reentrancies.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: CHRF++ scores with respect to (a) the graph size, (b) the graph diameter, and (c) the the number of reentrancies.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1911.07470v2-Figure3-1",
            "image_path": "1911.07470v2-Figure3-1.png",
            "instance_id": "0843dee31b5de1c4800e435cef3beb1f",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following graph properties is associated with CHRF++ scores higher than 61?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: CHRF++ scores with respect to (a) the graph size, (b) the graph diameter, and (c) the the number of reentrancies.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: CHRF++ scores with respect to (a) the graph size, (b) the graph diameter, and (c) the the number of reentrancies.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "1911.07470v2-Figure3-1",
            "image_path": "1911.07470v2-Figure3-1.png",
            "instance_id": "8696837664aa32645843fe7fe315643a",
            "qa_pair_type": "unanswerable",
            "question": "What datasets were used in this experiment?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Dimension of value vectors across the encoder layers in schuBERT-all for various model sizes.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Dimension of value vectors across the encoder layers in schuBERT-all for various model sizes.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2005.06628v1-Figure6-1",
            "image_path": "2005.06628v1-Figure6-1.png",
            "instance_id": "ff0b44ed139e16fb3a2527de97322dc0",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the blue line at the 6th layer?",
            "reference_answer": "60"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Dimension of value vectors across the encoder layers in schuBERT-all for various model sizes.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Dimension of value vectors across the encoder layers in schuBERT-all for various model sizes.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2005.06628v1-Figure6-1",
            "image_path": "2005.06628v1-Figure6-1.png",
            "instance_id": "38949af8fc227c56d35ff3d8dd7b22f9",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the filter size for the 33M model at layer 6?",
            "reference_answer": "30"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Dimension of value vectors across the encoder layers in schuBERT-all for various model sizes.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Dimension of value vectors across the encoder layers in schuBERT-all for various model sizes.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2005.06628v1-Figure6-1",
            "image_path": "2005.06628v1-Figure6-1.png",
            "instance_id": "33404bb89d92ff2fa7a8bb6577fa4c60",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the filter size for the orange line consistently decreasing across the encoder layers?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Dimension of value vectors across the encoder layers in schuBERT-all for various model sizes.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Dimension of value vectors across the encoder layers in schuBERT-all for various model sizes.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2005.06628v1-Figure6-1",
            "image_path": "2005.06628v1-Figure6-1.png",
            "instance_id": "570ce537a1369e079671c58228ed41ef",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the dimension of value vectors for the 33M model consistently higher than that of the 44M model across all encoder layers?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Yellow line"
                    },
                    {
                        "B": "Green line"
                    },
                    {
                        "C": "Cyan line"
                    },
                    {
                        "D": "Purple line"
                    }
                ],
                "caption": "Figure 6: Dimension of value vectors across the encoder layers in schuBERT-all for various model sizes.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Dimension of value vectors across the encoder layers in schuBERT-all for various model sizes.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2005.06628v1-Figure6-1",
            "image_path": "2005.06628v1-Figure6-1.png",
            "instance_id": "eabfde980d342bae200c7a3db5a1cd17",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line represents the '55M' model? ",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "33M"
                    },
                    {
                        "B": "44M"
                    },
                    {
                        "C": "55M"
                    },
                    {
                        "D": "66M"
                    }
                ],
                "caption": "Figure 6: Dimension of value vectors across the encoder layers in schuBERT-all for various model sizes.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Dimension of value vectors across the encoder layers in schuBERT-all for various model sizes.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2005.06628v1-Figure6-1",
            "image_path": "2005.06628v1-Figure6-1.png",
            "instance_id": "27feb0498f32ca8670bb0dd4adee4f4c",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following model sizes has the highest filter size at layer 4?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 6: Dimension of value vectors across the encoder layers in schuBERT-all for various model sizes.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 6: Dimension of value vectors across the encoder layers in schuBERT-all for various model sizes.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2005.06628v1-Figure6-1",
            "image_path": "2005.06628v1-Figure6-1.png",
            "instance_id": "c6de6d6a8ace9d49ec0895508279aee0",
            "qa_pair_type": "unanswerable",
            "question": "Why were these model sizes chosen for the experiment?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Mean and standard error of extraction scores with increasing amounts of evidence annotations.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Mean and standard error of extraction scores with increasing amounts of evidence annotations.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2011.01459v1-Figure1-1",
            "image_path": "2011.01459v1-Figure1-1.png",
            "instance_id": "d533c28ee61ed8c132b0853191087aa9",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximante value of the red line at the point where the x-axis value is 1000 on the right plot?",
            "reference_answer": "35"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Mean and standard error of extraction scores with increasing amounts of evidence annotations.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Mean and standard error of extraction scores with increasing amounts of evidence annotations.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2011.01459v1-Figure1-1",
            "image_path": "2011.01459v1-Figure1-1.png",
            "instance_id": "6567c207cb8d59cf994f6f75d38563d7",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "In what range is the baseline score for the sentiment analysis dataset?",
            "reference_answer": "between 25 and 30"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Mean and standard error of extraction scores with increasing amounts of evidence annotations.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Mean and standard error of extraction scores with increasing amounts of evidence annotations.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2011.01459v1-Figure1-1",
            "image_path": "2011.01459v1-Figure1-1.png",
            "instance_id": "dca28e49467b3ddec6da7e6c131a28a1",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the blue line on the right graph represent the 'Extract Only' method?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Mean and standard error of extraction scores with increasing amounts of evidence annotations.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Mean and standard error of extraction scores with increasing amounts of evidence annotations.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2011.01459v1-Figure1-1",
            "image_path": "2011.01459v1-Figure1-1.png",
            "instance_id": "5e2c040646ced14587e38245bf1aadeb",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the extraction score increase as the number of evidence annotations increase?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the extraction score increases as the number of evidence annotations increases for both datasets shown in the graphs.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Black"
                    },
                    {
                        "B": "Red"
                    },
                    {
                        "C": "Blue"
                    },
                    {
                        "D": "Dotted"
                    }
                ],
                "caption": "Figure 1: Mean and standard error of extraction scores with increasing amounts of evidence annotations.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Mean and standard error of extraction scores with increasing amounts of evidence annotations.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2011.01459v1-Figure1-1",
            "image_path": "2011.01459v1-Figure1-1.png",
            "instance_id": "3949144ed5e389e1b804de08b6088b73",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line in the left plot has the highest value at 1000 examples?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Precision"
                    },
                    {
                        "B": "F1 Score"
                    },
                    {
                        "C": "Recall"
                    },
                    {
                        "D": "Mean Squared Error"
                    }
                ],
                "caption": "Figure 1: Mean and standard error of extraction scores with increasing amounts of evidence annotations.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Mean and standard error of extraction scores with increasing amounts of evidence annotations.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2011.01459v1-Figure1-1",
            "image_path": "2011.01459v1-Figure1-1.png",
            "instance_id": "9362fe6d7d0066a33d1c90703e2d5317",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What metric is used to score performance in Figure 1?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Mean and standard error of extraction scores with increasing amounts of evidence annotations.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Mean and standard error of extraction scores with increasing amounts of evidence annotations.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2011.01459v1-Figure1-1",
            "image_path": "2011.01459v1-Figure1-1.png",
            "instance_id": "f93d321894f1ad86944c3d37571b89e0",
            "qa_pair_type": "unanswerable",
            "question": "What unsupervised method was used as a baseline?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The unsupervised method used as a baseline is labeled as \"Unsupervised baseline\" in the graphs.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Syntactic pattern diversity of various corpora",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Syntactic pattern diversity of various corpora",
            "categories": "nan",
            "figure_id": "2020.acl-main.92.pdf-Figure4",
            "image_path": "2020.acl-main.92.pdf-Figure4.png",
            "instance_id": "a55fc429b6affff00b308a61e716840a",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "In what range is the value of the sky blue line at the syntactic pattern diversity of 0.25?",
            "reference_answer": "between 10 and 20"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "At a syntactic pattern diversity of 0.25, the value of the sky blue line (AI2) appears to be around 10%.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Syntactic pattern diversity of various corpora",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Syntactic pattern diversity of various corpora",
            "categories": "nan",
            "figure_id": "2020.acl-main.92.pdf-Figure4",
            "image_path": "2020.acl-main.92.pdf-Figure4.png",
            "instance_id": "893c5c78780d21f3866593a3624d1a01",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the standard deviation of the MathQA corpus?",
            "reference_answer": "0.07"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The standard deviation of the MathQA corpus is 0.07.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Syntactic pattern diversity of various corpora",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Syntactic pattern diversity of various corpora",
            "categories": "nan",
            "figure_id": "2020.acl-main.92.pdf-Figure4",
            "image_path": "2020.acl-main.92.pdf-Figure4.png",
            "instance_id": "358cc3ade47aebbb7b7504a5357ce667",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the dark blue line labeled 'MathQA' reach a value of 20% of MWPs?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Syntactic pattern diversity of various corpora",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Syntactic pattern diversity of various corpora",
            "categories": "nan",
            "figure_id": "2020.acl-main.92.pdf-Figure4",
            "image_path": "2020.acl-main.92.pdf-Figure4.png",
            "instance_id": "3f69c8c46acd69e1dbdaa8f0a5f4b36f",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the percentage of MWPs for KAZB higher than that for ASDiv at a syntactic pattern diversity of 0.2?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Dark blue line"
                    },
                    {
                        "B": "Green line"
                    },
                    {
                        "C": "Purple line"
                    },
                    {
                        "D": "Orange line"
                    }
                ],
                "caption": "Figure 4: Syntactic pattern diversity of various corpora",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Syntactic pattern diversity of various corpora",
            "categories": "nan",
            "figure_id": "2020.acl-main.92.pdf-Figure4",
            "image_path": "2020.acl-main.92.pdf-Figure4.png",
            "instance_id": "77de78c4628803d8c2c7615826f92bf1",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the following lines have a peak percentage of MWPs at a syntactic pattern diversity value between 0.1 and 0.3?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "BD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "MathQA"
                    },
                    {
                        "B": "ASDiv"
                    },
                    {
                        "C": "AllArith"
                    },
                    {
                        "D": "DRAW"
                    }
                ],
                "caption": "Figure 4: Syntactic pattern diversity of various corpora",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Syntactic pattern diversity of various corpora",
            "categories": "nan",
            "figure_id": "2020.acl-main.92.pdf-Figure4",
            "image_path": "2020.acl-main.92.pdf-Figure4.png",
            "instance_id": "8eae718840e82461b84d5378a17e3f16",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which corpora has the lowest percentage of MWPs when syntactic pattern diversity is approximately 0.2?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: Syntactic pattern diversity of various corpora",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: Syntactic pattern diversity of various corpora",
            "categories": "nan",
            "figure_id": "2020.acl-main.92.pdf-Figure4",
            "image_path": "2020.acl-main.92.pdf-Figure4.png",
            "instance_id": "0ce149c60ee04029cb6bbece0abb85d1",
            "qa_pair_type": "unanswerable",
            "question": "What are the specific topics of the corpora represented by each line in the graph?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2. Topic coherence with error bars (standard error).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2. Topic coherence with error bars (standard error).",
            "categories": "['cs.IR cs.CL']",
            "figure_id": "1907.01638v1-Figure2-1",
            "image_path": "1907.01638v1-Figure2-1.png",
            "instance_id": "91a0116ede793a495b3be35e3156f1db",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the topic coherence (blue line) for the IDEA+Quality Score method?",
            "reference_answer": "0.215"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The approximate value of the topic coherence for the IDEA+Quality Score method is about 0.215.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2. Topic coherence with error bars (standard error).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2. Topic coherence with error bars (standard error).",
            "categories": "['cs.IR cs.CL']",
            "figure_id": "1907.01638v1-Figure2-1",
            "image_path": "1907.01638v1-Figure2-1.png",
            "instance_id": "54716747770bd303798c7e24644f7300",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "In what range is the topic coherence value for the IDEA model?",
            "reference_answer": "between 155 and 0.175"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The topic coherence value for the IDEA model is in the range of approximately 0.175 to 0.195.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2. Topic coherence with error bars (standard error).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2. Topic coherence with error bars (standard error).",
            "categories": "['cs.IR cs.CL']",
            "figure_id": "1907.01638v1-Figure2-1",
            "image_path": "1907.01638v1-Figure2-1.png",
            "instance_id": "a6083a39b24caf059105c766fa31e030",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is IDEA higher on the line of the topic coherence than OLDA?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2. Topic coherence with error bars (standard error).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2. Topic coherence with error bars (standard error).",
            "categories": "['cs.IR cs.CL']",
            "figure_id": "1907.01638v1-Figure2-1",
            "image_path": "1907.01638v1-Figure2-1.png",
            "instance_id": "a768c574663163845057754b94ca17cb",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the topic coherence for IDLA+Quality Score higher than that of OLDA?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "green"
                    },
                    {
                        "B": "brwon"
                    },
                    {
                        "C": "blue"
                    },
                    {
                        "D": "red"
                    }
                ],
                "caption": "Figure 2. Topic coherence with error bars (standard error).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2. Topic coherence with error bars (standard error).",
            "categories": "['cs.IR cs.CL']",
            "figure_id": "1907.01638v1-Figure2-1",
            "image_path": "1907.01638v1-Figure2-1.png",
            "instance_id": "692257ea6d6ae4bb19edb8b63ca1e1e7",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What color is the line that indicates the topic coherence with error bars?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "IDEA"
                    },
                    {
                        "B": "OLDA"
                    },
                    {
                        "C": "IDEA+Quality Score"
                    },
                    {
                        "D": "IEDL"
                    }
                ],
                "caption": "Figure 2. Topic coherence with error bars (standard error).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2. Topic coherence with error bars (standard error).",
            "categories": "['cs.IR cs.CL']",
            "figure_id": "1907.01638v1-Figure2-1",
            "image_path": "1907.01638v1-Figure2-1.png",
            "instance_id": "b1c4298d2172f1833e2a71f2ddebb664",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following methods has the highest topic coherence value ?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "ACD",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2. Topic coherence with error bars (standard error).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2. Topic coherence with error bars (standard error).",
            "categories": "['cs.IR cs.CL']",
            "figure_id": "1907.01638v1-Figure2-1",
            "image_path": "1907.01638v1-Figure2-1.png",
            "instance_id": "d306df0a09f0a2f95519fb99350c59ea",
            "qa_pair_type": "unanswerable",
            "question": "What are the confidence intervals for the topic coherence scores of each method?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 14: The same plot as Table 13, but the length is restricted to be larger than 2.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 14: The same plot as Table 13, but the length is restricted to be larger than 2.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2008.11649v2-Figure14-1",
            "image_path": "2008.11649v2-Figure14-1.png",
            "instance_id": "6c9f004ce6907ab856ed4ab80395cb44",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of the purple horizontal line in the left graph?",
            "reference_answer": "68"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The value of the purple horizontal line in the left graph is 68.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 14: The same plot as Table 13, but the length is restricted to be larger than 2.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 14: The same plot as Table 13, but the length is restricted to be larger than 2.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2008.11649v2-Figure14-1",
            "image_path": "2008.11649v2-Figure14-1.png",
            "instance_id": "bd58d59f0ced4bb33192965dace102b4",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the maximum value of total elapsed time on the x-axis in the left subgraphs?",
            "reference_answer": "40000"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 14: The same plot as Table 13, but the length is restricted to be larger than 2.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 14: The same plot as Table 13, but the length is restricted to be larger than 2.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2008.11649v2-Figure14-1",
            "image_path": "2008.11649v2-Figure14-1.png",
            "instance_id": "782b4fc0288262834b715b548d551c02",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the purple horizontal line in the right plot positioned higher than the purple horizontal line in the left plot?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 14: The same plot as Table 13, but the length is restricted to be larger than 2.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 14: The same plot as Table 13, but the length is restricted to be larger than 2.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2008.11649v2-Figure14-1",
            "image_path": "2008.11649v2-Figure14-1.png",
            "instance_id": "c3e34a8e7531cba31f24be3638cff019",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the value of the line p=seqsatlama above 68 at actual search time 6000?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "60"
                    },
                    {
                        "B": "80"
                    },
                    {
                        "C": "40"
                    },
                    {
                        "D": "20"
                    }
                ],
                "caption": "Figure 14: The same plot as Table 13, but the length is restricted to be larger than 2.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 14: The same plot as Table 13, but the length is restricted to be larger than 2.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2008.11649v2-Figure14-1",
            "image_path": "2008.11649v2-Figure14-1.png",
            "instance_id": "d292d5a1fccb58771415b6da8c38954f",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What is the approximate value of the green line at 'Total elapsed time' at 8000?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "120"
                    },
                    {
                        "B": "80"
                    },
                    {
                        "C": "60"
                    },
                    {
                        "D": "100"
                    }
                ],
                "caption": "Figure 14: The same plot as Table 13, but the length is restricted to be larger than 2.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 14: The same plot as Table 13, but the length is restricted to be larger than 2.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2008.11649v2-Figure14-1",
            "image_path": "2008.11649v2-Figure14-1.png",
            "instance_id": "0fc3834d9110adcaa4a5a48777919dae",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the maximum value reached by the line E=200 p=seqatlama on the subgraph labeled \"Actual search time'?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 14: The same plot as Table 13, but the length is restricted to be larger than 2.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 14: The same plot as Table 13, but the length is restricted to be larger than 2.",
            "categories": "['cs.CL cs.AI']",
            "figure_id": "2008.11649v2-Figure14-1",
            "image_path": "2008.11649v2-Figure14-1.png",
            "instance_id": "468fb4f017141bce71ef2fda2644a3b5",
            "qa_pair_type": "unanswerable",
            "question": "What is the name of the algorithm used to generate the plot in Figure 14?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Test error on IMDb dataset over different setting of selfdistillation weight \u03bb. T denotes the total number of iterations.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Test error on IMDb dataset over different setting of selfdistillation weight \u03bb. T denotes the total number of iterations.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2002.10345v1-Figure3-1",
            "image_path": "2002.10345v1-Figure3-1.png",
            "instance_id": "cbf98c8c99cb9114fab97d1d576221a7",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the test error rate for the black line at \u03bb = 4.0?",
            "reference_answer": "5.6%"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Test error on IMDb dataset over different setting of selfdistillation weight \u03bb. T denotes the total number of iterations.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Test error on IMDb dataset over different setting of selfdistillation weight \u03bb. T denotes the total number of iterations.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2002.10345v1-Figure3-1",
            "image_path": "2002.10345v1-Figure3-1.png",
            "instance_id": "11a0de9d8c42a90d6ce359c42297fa28",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "How many models are being compared in this graph?",
            "reference_answer": "5"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Test error on IMDb dataset over different setting of selfdistillation weight \u03bb. T denotes the total number of iterations.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Test error on IMDb dataset over different setting of selfdistillation weight \u03bb. T denotes the total number of iterations.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2002.10345v1-Figure3-1",
            "image_path": "2002.10345v1-Figure3-1.png",
            "instance_id": "79f0d3e4c62dc609d176866bc7567118",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the green line represent the test error of BERT SDA with K=5?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "No, the green line represents the test error of BERT SDV with K=5.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Test error on IMDb dataset over different setting of selfdistillation weight \u03bb. T denotes the total number of iterations.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Test error on IMDb dataset over different setting of selfdistillation weight \u03bb. T denotes the total number of iterations.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2002.10345v1-Figure3-1",
            "image_path": "2002.10345v1-Figure3-1.png",
            "instance_id": "166e76170041ac3a06a98c46eacc055e",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the test error rate for BERT_SDA (K = T - 1) decrease as the self-distillation weight lambda increases from 0.1 to 1.0?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the test error rate for BERT_SDA (K = T - 1) decreases as the self-distillation weight lambda increases from 0.1 to 1.0.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Blue dotted line"
                    },
                    {
                        "B": "Red line"
                    },
                    {
                        "C": "Green line"
                    },
                    {
                        "D": "Gray line"
                    }
                ],
                "caption": "Figure 3: Test error on IMDb dataset over different setting of selfdistillation weight \u03bb. T denotes the total number of iterations.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Test error on IMDb dataset over different setting of selfdistillation weight \u03bb. T denotes the total number of iterations.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2002.10345v1-Figure3-1",
            "image_path": "2002.10345v1-Figure3-1.png",
            "instance_id": "00742319a0628dd0463f0e6f4ac9c1a4",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line represents the BERT SDA model with K=T-1?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "6"
                    },
                    {
                        "B": "5.4"
                    },
                    {
                        "C": "5.8"
                    },
                    {
                        "D": "5.6"
                    }
                ],
                "caption": "Figure 3: Test error on IMDb dataset over different setting of selfdistillation weight \u03bb. T denotes the total number of iterations.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Test error on IMDb dataset over different setting of selfdistillation weight \u03bb. T denotes the total number of iterations.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2002.10345v1-Figure3-1",
            "image_path": "2002.10345v1-Figure3-1.png",
            "instance_id": "2768980b1c8c91c66d99d512962a9205",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the value of the test error rate baseline (BERT BASE)?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: Test error on IMDb dataset over different setting of selfdistillation weight \u03bb. T denotes the total number of iterations.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: Test error on IMDb dataset over different setting of selfdistillation weight \u03bb. T denotes the total number of iterations.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2002.10345v1-Figure3-1",
            "image_path": "2002.10345v1-Figure3-1.png",
            "instance_id": "f1122f4b3210d7ea27c1169e72434457",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific implementation of the self-distillation technique used in the BERT SDA model with K = T - 1?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Computational cost vs sequence length",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Computational cost vs sequence length",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2010.16407v1-Figure1-1",
            "image_path": "2010.16407v1-Figure1-1.png",
            "instance_id": "e8fd769e0a9a1004006854675f500eff",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximante value of the red line at the sequence length of 128?",
            "reference_answer": "6k"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Computational cost vs sequence length",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Computational cost vs sequence length",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2010.16407v1-Figure1-1",
            "image_path": "2010.16407v1-Figure1-1.png",
            "instance_id": "d1da82d871bd39bf6ace82340c757fa5",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the approximante computational cost in CO2 Emssion at a sequence length of 256?",
            "reference_answer": "0.0045"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Computational cost vs sequence length",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Computational cost vs sequence length",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2010.16407v1-Figure1-1",
            "image_path": "2010.16407v1-Figure1-1.png",
            "instance_id": "71921ec64ec474b2850e0ac633e4fc4c",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the value of the orange line higher than the value of the purple line at the sequence length of 384?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Computational cost vs sequence length",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Computational cost vs sequence length",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2010.16407v1-Figure1-1",
            "image_path": "2010.16407v1-Figure1-1.png",
            "instance_id": "80a63747f0433830456331f42504ab5f",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does GPU-memory usage increase as sequence length increases?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, GPU-memory usage increases as sequence length increases.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Orange"
                    },
                    {
                        "B": "Purple"
                    },
                    {
                        "C": "Blue"
                    },
                    {
                        "D": "Red"
                    }
                ],
                "caption": "Figure 1: Computational cost vs sequence length",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Computational cost vs sequence length",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2010.16407v1-Figure1-1",
            "image_path": "2010.16407v1-Figure1-1.png",
            "instance_id": "d3ac17b8289a51b0773b56b450816fb7",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line represents the computational cost in terms of GPU memory?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "#samples/second"
                    },
                    {
                        "B": "millisecond/batch"
                    },
                    {
                        "C": "GPU-memory (MB)"
                    },
                    {
                        "D": "CO2 Emission (gram eq.)"
                    }
                ],
                "caption": "Figure 1: Computational cost vs sequence length",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Computational cost vs sequence length",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2010.16407v1-Figure1-1",
            "image_path": "2010.16407v1-Figure1-1.png",
            "instance_id": "43a13bc350f3e18fc8aae518ea381996",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which of the following factors decreases with increasing sequence length?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1: Computational cost vs sequence length",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1: Computational cost vs sequence length",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2010.16407v1-Figure1-1",
            "image_path": "2010.16407v1-Figure1-1.png",
            "instance_id": "e219e8fbe2a7e731ff3e79b1716ddf3d",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific model architecture used for this experiment in Figure 1?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: F1 score on the validation set (y-axis) versus number of hidden units (x-axis) for different tasks trained with the sentence-level likelihood (SLL), as in Table 4. For SRL, we vary in this graph only the number of hidden units in the second layer. The scale is adapted for each task. We show the standard deviation (obtained over 5 runs with different random initialization), for the architecture we picked (300 hidden units for POS, CHUNK and NER, 500 for SRL).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: F1 score on the validation set (y-axis) versus number of hidden units (x-axis) for different tasks trained with the sentence-level likelihood (SLL), as in Table 4. For SRL, we vary in this graph only the number of hidden units in the second layer. The scale is adapted for each task. We show the standard deviation (obtained over 5 runs with different random initialization), for the architecture we picked (300 hidden units for POS, CHUNK and NER, 500 for SRL).",
            "categories": "['cs.LG cs.CL']",
            "figure_id": "1103.0398v1-Figure4-1",
            "image_path": "1103.0398v1-Figure4-1.png",
            "instance_id": "51dc29080624498b5d9d6ae091820928",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "In what range is the black line that indicates the F1 score for the SRL task when the number of hidden units is 500?",
            "reference_answer": "between 68.5 and 69"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: F1 score on the validation set (y-axis) versus number of hidden units (x-axis) for different tasks trained with the sentence-level likelihood (SLL), as in Table 4. For SRL, we vary in this graph only the number of hidden units in the second layer. The scale is adapted for each task. We show the standard deviation (obtained over 5 runs with different random initialization), for the architecture we picked (300 hidden units for POS, CHUNK and NER, 500 for SRL).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: F1 score on the validation set (y-axis) versus number of hidden units (x-axis) for different tasks trained with the sentence-level likelihood (SLL), as in Table 4. For SRL, we vary in this graph only the number of hidden units in the second layer. The scale is adapted for each task. We show the standard deviation (obtained over 5 runs with different random initialization), for the architecture we picked (300 hidden units for POS, CHUNK and NER, 500 for SRL).",
            "categories": "['cs.LG cs.CL']",
            "figure_id": "1103.0398v1-Figure4-1",
            "image_path": "1103.0398v1-Figure4-1.png",
            "instance_id": "3cbbca7cffa1dc70808fc01920c4c076",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "For which task is the F1 score the highest when the number of hidden units is 500?",
            "reference_answer": "POS"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The F1 score is the highest for the task \"POS\" when the number of hidden units is 500.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: F1 score on the validation set (y-axis) versus number of hidden units (x-axis) for different tasks trained with the sentence-level likelihood (SLL), as in Table 4. For SRL, we vary in this graph only the number of hidden units in the second layer. The scale is adapted for each task. We show the standard deviation (obtained over 5 runs with different random initialization), for the architecture we picked (300 hidden units for POS, CHUNK and NER, 500 for SRL).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: F1 score on the validation set (y-axis) versus number of hidden units (x-axis) for different tasks trained with the sentence-level likelihood (SLL), as in Table 4. For SRL, we vary in this graph only the number of hidden units in the second layer. The scale is adapted for each task. We show the standard deviation (obtained over 5 runs with different random initialization), for the architecture we picked (300 hidden units for POS, CHUNK and NER, 500 for SRL).",
            "categories": "['cs.LG cs.CL']",
            "figure_id": "1103.0398v1-Figure4-1",
            "image_path": "1103.0398v1-Figure4-1.png",
            "instance_id": "c4fa3faf17b773a7b254e5e42bcee5e1",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the line in the graph labeled 'SRL' have a steeper incline than the line in the graph labeled 'POS'?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: F1 score on the validation set (y-axis) versus number of hidden units (x-axis) for different tasks trained with the sentence-level likelihood (SLL), as in Table 4. For SRL, we vary in this graph only the number of hidden units in the second layer. The scale is adapted for each task. We show the standard deviation (obtained over 5 runs with different random initialization), for the architecture we picked (300 hidden units for POS, CHUNK and NER, 500 for SRL).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: F1 score on the validation set (y-axis) versus number of hidden units (x-axis) for different tasks trained with the sentence-level likelihood (SLL), as in Table 4. For SRL, we vary in this graph only the number of hidden units in the second layer. The scale is adapted for each task. We show the standard deviation (obtained over 5 runs with different random initialization), for the architecture we picked (300 hidden units for POS, CHUNK and NER, 500 for SRL).",
            "categories": "['cs.LG cs.CL']",
            "figure_id": "1103.0398v1-Figure4-1",
            "image_path": "1103.0398v1-Figure4-1.png",
            "instance_id": "4c528bd3fe0789f45b043a6c3de2cc56",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Is the lowest value of the F1 scale (y-axis) on the subraph labeled (c) NER the same as on the subgraph labeled (b) CHUNK??",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "(a) POS"
                    },
                    {
                        "B": "(b) CHUNK"
                    },
                    {
                        "C": "(c) NER"
                    },
                    {
                        "D": "(d) SRL"
                    }
                ],
                "caption": "Figure 4: F1 score on the validation set (y-axis) versus number of hidden units (x-axis) for different tasks trained with the sentence-level likelihood (SLL), as in Table 4. For SRL, we vary in this graph only the number of hidden units in the second layer. The scale is adapted for each task. We show the standard deviation (obtained over 5 runs with different random initialization), for the architecture we picked (300 hidden units for POS, CHUNK and NER, 500 for SRL).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: F1 score on the validation set (y-axis) versus number of hidden units (x-axis) for different tasks trained with the sentence-level likelihood (SLL), as in Table 4. For SRL, we vary in this graph only the number of hidden units in the second layer. The scale is adapted for each task. We show the standard deviation (obtained over 5 runs with different random initialization), for the architecture we picked (300 hidden units for POS, CHUNK and NER, 500 for SRL).",
            "categories": "['cs.LG cs.CL']",
            "figure_id": "1103.0398v1-Figure4-1",
            "image_path": "1103.0398v1-Figure4-1.png",
            "instance_id": "c51c08583a3b62b50dc10690af771ecf",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which graph shows the biggest standard deviation as indicated by the vertical line?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "POS"
                    },
                    {
                        "B": "CHUNK"
                    },
                    {
                        "C": "NER"
                    },
                    {
                        "D": "SRL"
                    }
                ],
                "caption": "Figure 4: F1 score on the validation set (y-axis) versus number of hidden units (x-axis) for different tasks trained with the sentence-level likelihood (SLL), as in Table 4. For SRL, we vary in this graph only the number of hidden units in the second layer. The scale is adapted for each task. We show the standard deviation (obtained over 5 runs with different random initialization), for the architecture we picked (300 hidden units for POS, CHUNK and NER, 500 for SRL).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: F1 score on the validation set (y-axis) versus number of hidden units (x-axis) for different tasks trained with the sentence-level likelihood (SLL), as in Table 4. For SRL, we vary in this graph only the number of hidden units in the second layer. The scale is adapted for each task. We show the standard deviation (obtained over 5 runs with different random initialization), for the architecture we picked (300 hidden units for POS, CHUNK and NER, 500 for SRL).",
            "categories": "['cs.LG cs.CL']",
            "figure_id": "1103.0398v1-Figure4-1",
            "image_path": "1103.0398v1-Figure4-1.png",
            "instance_id": "f9b8dc6acc94ea221fbd7d2886e839ff",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which task shows the highest F1 score on the validation set?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 4: F1 score on the validation set (y-axis) versus number of hidden units (x-axis) for different tasks trained with the sentence-level likelihood (SLL), as in Table 4. For SRL, we vary in this graph only the number of hidden units in the second layer. The scale is adapted for each task. We show the standard deviation (obtained over 5 runs with different random initialization), for the architecture we picked (300 hidden units for POS, CHUNK and NER, 500 for SRL).",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 4: F1 score on the validation set (y-axis) versus number of hidden units (x-axis) for different tasks trained with the sentence-level likelihood (SLL), as in Table 4. For SRL, we vary in this graph only the number of hidden units in the second layer. The scale is adapted for each task. We show the standard deviation (obtained over 5 runs with different random initialization), for the architecture we picked (300 hidden units for POS, CHUNK and NER, 500 for SRL).",
            "categories": "['cs.LG cs.CL']",
            "figure_id": "1103.0398v1-Figure4-1",
            "image_path": "1103.0398v1-Figure4-1.png",
            "instance_id": "81b5982cc6434dfa2d3f06b3d4f987d8",
            "qa_pair_type": "unanswerable",
            "question": "What is the size of the validation set?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: The classification accuracy for various ranging from 0 to 1.2 for three models on IMDB.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: The classification accuracy for various ranging from 0 to 1.2 for three models on IMDB.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1909.06723v3-Figure3-1",
            "image_path": "1909.06723v3-Figure3-1.png",
            "instance_id": "95d2e5a2b4499cb848e0feb4fd9a628f",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of the classification accuracy for the Bi-LSTM model (blue line) at the epsilon value of 1.2 on the top left subgraph?",
            "reference_answer": "0.85"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: The classification accuracy for various ranging from 0 to 1.2 for three models on IMDB.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: The classification accuracy for various ranging from 0 to 1.2 for three models on IMDB.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1909.06723v3-Figure3-1",
            "image_path": "1909.06723v3-Figure3-1.png",
            "instance_id": "d46d6d5d56b86540f71a3cf32212154a",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the range of the classification accuracy?",
            "reference_answer": "0 to 1.2"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: The classification accuracy for various ranging from 0 to 1.2 for three models on IMDB.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: The classification accuracy for various ranging from 0 to 1.2 for three models on IMDB.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1909.06723v3-Figure3-1",
            "image_path": "1909.06723v3-Figure3-1.png",
            "instance_id": "0eb866b3eaf914aae8ff90c4f10e9c1d",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the line with the highest accuracy value for Word-CNN under no attack greater than 0.87?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: The classification accuracy for various ranging from 0 to 1.2 for three models on IMDB.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: The classification accuracy for various ranging from 0 to 1.2 for three models on IMDB.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1909.06723v3-Figure3-1",
            "image_path": "1909.06723v3-Figure3-1.png",
            "instance_id": "c0a41214a0507822b494bf5a218c4cdc",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the accuracy of the models when under no attack decrease as the epsilon value increases?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the accuracy of the models under no attack decreases as the epsilon value increases, as indicated by the downward trend in the graph for models shown in part (a).",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "0.8"
                    },
                    {
                        "B": "0.7"
                    },
                    {
                        "C": "0.6"
                    },
                    {
                        "D": "0.5"
                    }
                ],
                "caption": "Figure 3: The classification accuracy for various ranging from 0 to 1.2 for three models on IMDB.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: The classification accuracy for various ranging from 0 to 1.2 for three models on IMDB.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1909.06723v3-Figure3-1",
            "image_path": "1909.06723v3-Figure3-1.png",
            "instance_id": "8f9ea26e4d28b787a6c411c89f4df0df",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "In the bottom left graph, what is the highest approximate value on the y-axis for the blue line?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "LSTM, Word-CNN, Bi-LSTM"
                    },
                    {
                        "B": "IGA, GA, PWWS, GSA"
                    },
                    {
                        "C": "Word-CNN, LSTM, Bi-LSTM, IGA, GA, PWWS, GSA"
                    },
                    {
                        "D": "Word-CNN, Bi-LSTM, PWWS"
                    }
                ],
                "caption": "Figure 3: The classification accuracy for various ranging from 0 to 1.2 for three models on IMDB.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: The classification accuracy for various ranging from 0 to 1.2 for three models on IMDB.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1909.06723v3-Figure3-1",
            "image_path": "1909.06723v3-Figure3-1.png",
            "instance_id": "1c9e1837a2a3736b2fc5dd356cada3b5",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which models are being evaluated?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A B C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 3: The classification accuracy for various ranging from 0 to 1.2 for three models on IMDB.",
                "compound": true,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 3: The classification accuracy for various ranging from 0 to 1.2 for three models on IMDB.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "1909.06723v3-Figure3-1",
            "image_path": "1909.06723v3-Figure3-1.png",
            "instance_id": "60f66bdcd0ac44382240f1bdf5459ae2",
            "qa_pair_type": "unanswerable",
            "question": "What is the exact dataset size for IMDB?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Comparison between supervised and unsupervised approaches on WMT\u201914 En-Fr, as we vary the number of parallel sentences for the supervised methods.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison between supervised and unsupervised approaches on WMT\u201914 En-Fr, as we vary the number of parallel sentences for the supervised methods.",
            "categories": "['cs.CL']",
            "figure_id": "1804.07755v2-Figure2-1",
            "image_path": "1804.07755v2-Figure2-1.png",
            "instance_id": "aec63671d91ef3cf30b172afa69ed943",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "In what range is the BLEU score of the dashed red line?",
            "reference_answer": "between 20 and 30"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Comparison between supervised and unsupervised approaches on WMT\u201914 En-Fr, as we vary the number of parallel sentences for the supervised methods.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison between supervised and unsupervised approaches on WMT\u201914 En-Fr, as we vary the number of parallel sentences for the supervised methods.",
            "categories": "['cs.CL']",
            "figure_id": "1804.07755v2-Figure2-1",
            "image_path": "1804.07755v2-Figure2-1.png",
            "instance_id": "f265a11a79cd3f84c7dad31577213164",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "Which supervised method achieves the highest BLEU score?",
            "reference_answer": "Supervised NMT"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Comparison between supervised and unsupervised approaches on WMT\u201914 En-Fr, as we vary the number of parallel sentences for the supervised methods.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison between supervised and unsupervised approaches on WMT\u201914 En-Fr, as we vary the number of parallel sentences for the supervised methods.",
            "categories": "['cs.CL']",
            "figure_id": "1804.07755v2-Figure2-1",
            "image_path": "1804.07755v2-Figure2-1.png",
            "instance_id": "13e910567e9432d3e37f72e4d52362e9",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the red solid line, representing supervised PBSMT, have a higher value than the blue dashed line, representing unsupervised NMT, at the highest value on the x-axis?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Comparison between supervised and unsupervised approaches on WMT\u201914 En-Fr, as we vary the number of parallel sentences for the supervised methods.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison between supervised and unsupervised approaches on WMT\u201914 En-Fr, as we vary the number of parallel sentences for the supervised methods.",
            "categories": "['cs.CL']",
            "figure_id": "1804.07755v2-Figure2-1",
            "image_path": "1804.07755v2-Figure2-1.png",
            "instance_id": "7bb4a195cb9016a28b8896857ee63ce1",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the supervised PBSMT approach always yield a higher BLEU score than the unsupervised NMT approach?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Solid red line"
                    },
                    {
                        "B": "Dashed blue line"
                    },
                    {
                        "C": "Dashed red line"
                    },
                    {
                        "D": "Solid blue line"
                    }
                ],
                "caption": "Figure 2: Comparison between supervised and unsupervised approaches on WMT\u201914 En-Fr, as we vary the number of parallel sentences for the supervised methods.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison between supervised and unsupervised approaches on WMT\u201914 En-Fr, as we vary the number of parallel sentences for the supervised methods.",
            "categories": "['cs.CL']",
            "figure_id": "1804.07755v2-Figure2-1",
            "image_path": "1804.07755v2-Figure2-1.png",
            "instance_id": "3ba2ebc4baaa7b5af9564404638b0e61",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line represents unsupervised PBSMT?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "10^3"
                    },
                    {
                        "B": "10^6"
                    },
                    {
                        "C": "10^2"
                    },
                    {
                        "D": "10^4"
                    }
                ],
                "caption": "Figure 2: Comparison between supervised and unsupervised approaches on WMT\u201914 En-Fr, as we vary the number of parallel sentences for the supervised methods.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison between supervised and unsupervised approaches on WMT\u201914 En-Fr, as we vary the number of parallel sentences for the supervised methods.",
            "categories": "['cs.CL']",
            "figure_id": "1804.07755v2-Figure2-1",
            "image_path": "1804.07755v2-Figure2-1.png",
            "instance_id": "906f6e1b48d4a0b229e537186d907327",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "Which is the minimum number of parallel training sentences shown in the plot?",
            "reference_answer": "D"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "D",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Comparison between supervised and unsupervised approaches on WMT\u201914 En-Fr, as we vary the number of parallel sentences for the supervised methods.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Comparison between supervised and unsupervised approaches on WMT\u201914 En-Fr, as we vary the number of parallel sentences for the supervised methods.",
            "categories": "['cs.CL']",
            "figure_id": "1804.07755v2-Figure2-1",
            "image_path": "1804.07755v2-Figure2-1.png",
            "instance_id": "37ff780c86837f88e374872daae3dc45",
            "qa_pair_type": "unanswerable",
            "question": "What is the size of WMT'14 En-Fr?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: BLEU-5 F1 score plotted against reverse temperature \u03b1 on EMNLP2017 News test set.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: BLEU-5 F1 score plotted against reverse temperature \u03b1 on EMNLP2017 News test set.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2010.05994v1-Figure5-1",
            "image_path": "2010.05994v1-Figure5-1.png",
            "instance_id": "22b9995f4dfec8b0d7d42e0cc9cc6f04",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate BLEU-F1 score for the yellow line when the reverse temperature is 1.2?",
            "reference_answer": "0.40"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: BLEU-5 F1 score plotted against reverse temperature \u03b1 on EMNLP2017 News test set.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: BLEU-5 F1 score plotted against reverse temperature \u03b1 on EMNLP2017 News test set.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2010.05994v1-Figure5-1",
            "image_path": "2010.05994v1-Figure5-1.png",
            "instance_id": "dc0d39325a041c5f178cd7d0a33aadc0",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the maximum Reverse Temperature shown in the plot?",
            "reference_answer": "1.5"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The maximum Reverse Temperature shown in the plot is 1.5.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: BLEU-5 F1 score plotted against reverse temperature \u03b1 on EMNLP2017 News test set.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: BLEU-5 F1 score plotted against reverse temperature \u03b1 on EMNLP2017 News test set.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2010.05994v1-Figure5-1",
            "image_path": "2010.05994v1-Figure5-1.png",
            "instance_id": "0238fb26dbe4d860440cd5a6b8b32b82",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the yellow line representing SFOT reach a higher BLEU-F1 score than the red line representing MLE at a reverse temperature of 1.4?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, at a reverse temperature of 1.4, the yellow line representing SFOT reaches a higher BLEU-F1 score than the red line representing MLE.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: BLEU-5 F1 score plotted against reverse temperature \u03b1 on EMNLP2017 News test set.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: BLEU-5 F1 score plotted against reverse temperature \u03b1 on EMNLP2017 News test set.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2010.05994v1-Figure5-1",
            "image_path": "2010.05994v1-Figure5-1.png",
            "instance_id": "bb3fa8b485d3e4d8a1af6b304e5ffa61",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the BLEU-F1 score for SFOT reach a higher value than the BLEU-F1 score for MLE at any point on the graph?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "0.38"
                    },
                    {
                        "B": "0.34"
                    },
                    {
                        "C": "0.36"
                    },
                    {
                        "D": "0.30"
                    }
                ],
                "caption": "Figure 5: BLEU-5 F1 score plotted against reverse temperature \u03b1 on EMNLP2017 News test set.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: BLEU-5 F1 score plotted against reverse temperature \u03b1 on EMNLP2017 News test set.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2010.05994v1-Figure5-1",
            "image_path": "2010.05994v1-Figure5-1.png",
            "instance_id": "a7d8c9bf46d1405cec953edac15fe444",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "What is the approximate BLEU-F1 Score reached by yellow line at a Reverse Temperature of 1.1?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "1.0"
                    },
                    {
                        "B": "1.1"
                    },
                    {
                        "C": "1.2"
                    },
                    {
                        "D": "1.5"
                    }
                ],
                "caption": "Figure 5: BLEU-5 F1 score plotted against reverse temperature \u03b1 on EMNLP2017 News test set.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: BLEU-5 F1 score plotted against reverse temperature \u03b1 on EMNLP2017 News test set.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2010.05994v1-Figure5-1",
            "image_path": "2010.05994v1-Figure5-1.png",
            "instance_id": "d14038bef0183b0cdca8283ab9eed13b",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What value of Reverse Temperature achieves an approximate value of 0.40 of BLEU-F1 Score for SFOT?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 5: BLEU-5 F1 score plotted against reverse temperature \u03b1 on EMNLP2017 News test set.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 5: BLEU-5 F1 score plotted against reverse temperature \u03b1 on EMNLP2017 News test set.",
            "categories": "['cs.CL cs.LG']",
            "figure_id": "2010.05994v1-Figure5-1",
            "image_path": "2010.05994v1-Figure5-1.png",
            "instance_id": "d299ce61660fc798d550bf339b6f5377",
            "qa_pair_type": "unanswerable",
            "question": "What is the size of the News test set?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Accuracy in identifying emotion cause decreases with reduction of \u201c-1\u201d emotion causes.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Accuracy in identifying emotion cause decreases with reduction of \u201c-1\u201d emotion causes.",
            "categories": "['cs.CL']",
            "figure_id": "2007.15066v1-Figure2-1",
            "image_path": "2007.15066v1-Figure2-1.png",
            "instance_id": "e667a783478d97fa60851f4ee71c7ed5",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "In what range is the F-measure value of the orange line at the point where the ratio of '-1' emotional causes is 45%?",
            "reference_answer": "between 0.60 and 0.65"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "The F-measure value of the orange line (PAEDGL) at the point where the ratio of '-1' emotional causes is 45% is in the range of 0.55 to 0.60.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Accuracy in identifying emotion cause decreases with reduction of \u201c-1\u201d emotion causes.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Accuracy in identifying emotion cause decreases with reduction of \u201c-1\u201d emotion causes.",
            "categories": "['cs.CL']",
            "figure_id": "2007.15066v1-Figure2-1",
            "image_path": "2007.15066v1-Figure2-1.png",
            "instance_id": "16df93b97af85037a5387f65371688b2",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "In what range  is the F-measure value of PAE at the point where the ratio of '-1' emotional causes is 40%?",
            "reference_answer": "between 0.55 and 0.60"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Accuracy in identifying emotion cause decreases with reduction of \u201c-1\u201d emotion causes.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Accuracy in identifying emotion cause decreases with reduction of \u201c-1\u201d emotion causes.",
            "categories": "['cs.CL']",
            "figure_id": "2007.15066v1-Figure2-1",
            "image_path": "2007.15066v1-Figure2-1.png",
            "instance_id": "dcf1a3c7412234b6878350d189f89081",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Does the blue line representing PAE show a decreasing trend as the ratio of '-1' emotional causes increases?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the blue line representing PAE shows a decreasing trend as the ratio of '-1' emotional causes increases.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Accuracy in identifying emotion cause decreases with reduction of \u201c-1\u201d emotion causes.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Accuracy in identifying emotion cause decreases with reduction of \u201c-1\u201d emotion causes.",
            "categories": "['cs.CL']",
            "figure_id": "2007.15066v1-Figure2-1",
            "image_path": "2007.15066v1-Figure2-1.png",
            "instance_id": "094b3b2aa7df4473bac2bb975a62902d",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Does the accuracy in identifying the emotion cause decrease with the reduction of '-1' emotion causes?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the accuracy in identifying the emotion cause decreases with the reduction of '-1' emotion causes, as indicated by the downward trends in the F-measure for all the methods as the ratio of '-1' emotional causes decreases.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "orange line"
                    },
                    {
                        "B": "blue line"
                    },
                    {
                        "C": "greenn line"
                    },
                    {
                        "D": "None of the above"
                    }
                ],
                "caption": "Figure 2: Accuracy in identifying emotion cause decreases with reduction of \u201c-1\u201d emotion causes.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Accuracy in identifying emotion cause decreases with reduction of \u201c-1\u201d emotion causes.",
            "categories": "['cs.CL']",
            "figure_id": "2007.15066v1-Figure2-1",
            "image_path": "2007.15066v1-Figure2-1.png",
            "instance_id": "15e6da8857826757c041cec89cbd4cb4",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line in the figure has a value of lower than 0.70 when the \"Ratio of '-1' emotional causes (%)\" is 55?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AC",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "40"
                    },
                    {
                        "B": "50"
                    },
                    {
                        "C": "65"
                    },
                    {
                        "D": "75"
                    }
                ],
                "caption": "Figure 2: Accuracy in identifying emotion cause decreases with reduction of \u201c-1\u201d emotion causes.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Accuracy in identifying emotion cause decreases with reduction of \u201c-1\u201d emotion causes.",
            "categories": "['cs.CL']",
            "figure_id": "2007.15066v1-Figure2-1",
            "image_path": "2007.15066v1-Figure2-1.png",
            "instance_id": "2783452297f7df9d3df0413e415f9347",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the approximate accuracy of identifying emotion causes decrease when the ratio of -1 emotional causes approaches 35%?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 2: Accuracy in identifying emotion cause decreases with reduction of \u201c-1\u201d emotion causes.",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 2: Accuracy in identifying emotion cause decreases with reduction of \u201c-1\u201d emotion causes.",
            "categories": "['cs.CL']",
            "figure_id": "2007.15066v1-Figure2-1",
            "image_path": "2007.15066v1-Figure2-1.png",
            "instance_id": "9c518346458bd6777d831dc93c644bef",
            "qa_pair_type": "unanswerable",
            "question": "What datasets were used in this experiment?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7. Distribution of actual marks of two teachers (Grade 1 and Grade 2) with distances from the model answer, the average marks of two teachers (TM) and the predicted marks by the mathematical model (MM).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7. Distribution of actual marks of two teachers (Grade 1 and Grade 2) with distances from the model answer, the average marks of two teachers (TM) and the predicted marks by the mathematical model (MM).",
            "categories": "['cs.CL']",
            "figure_id": "1807.10543v3-Figure7-1",
            "image_path": "1807.10543v3-Figure7-1.png",
            "instance_id": "5529f1fa81b335ace738e0ef2c27b245",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the value of the dashed green line at a distance of 2?",
            "reference_answer": "5"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7. Distribution of actual marks of two teachers (Grade 1 and Grade 2) with distances from the model answer, the average marks of two teachers (TM) and the predicted marks by the mathematical model (MM).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7. Distribution of actual marks of two teachers (Grade 1 and Grade 2) with distances from the model answer, the average marks of two teachers (TM) and the predicted marks by the mathematical model (MM).",
            "categories": "['cs.CL']",
            "figure_id": "1807.10543v3-Figure7-1",
            "image_path": "1807.10543v3-Figure7-1.png",
            "instance_id": "924f1bcfe41e019dd356701da2ac9783",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is represented by the 'MM' line?",
            "reference_answer": "Mathematical model"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7. Distribution of actual marks of two teachers (Grade 1 and Grade 2) with distances from the model answer, the average marks of two teachers (TM) and the predicted marks by the mathematical model (MM).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7. Distribution of actual marks of two teachers (Grade 1 and Grade 2) with distances from the model answer, the average marks of two teachers (TM) and the predicted marks by the mathematical model (MM).",
            "categories": "['cs.CL']",
            "figure_id": "1807.10543v3-Figure7-1",
            "image_path": "1807.10543v3-Figure7-1.png",
            "instance_id": "c3e3dbb074eee74153855f1b34c5e177",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the red line consistently higher than the green dashed line?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7. Distribution of actual marks of two teachers (Grade 1 and Grade 2) with distances from the model answer, the average marks of two teachers (TM) and the predicted marks by the mathematical model (MM).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7. Distribution of actual marks of two teachers (Grade 1 and Grade 2) with distances from the model answer, the average marks of two teachers (TM) and the predicted marks by the mathematical model (MM).",
            "categories": "['cs.CL']",
            "figure_id": "1807.10543v3-Figure7-1",
            "image_path": "1807.10543v3-Figure7-1.png",
            "instance_id": "4150f05da5037bf4896d3da88bf2cfca",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Are the average marks of the two teachers (TM) consistently higher than the predicted marks by the mathematical model (MM)?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Red solid line"
                    },
                    {
                        "B": "Green dashed line"
                    },
                    {
                        "C": "Blue crosses"
                    },
                    {
                        "D": "Orange crosses"
                    }
                ],
                "caption": "Figure 7. Distribution of actual marks of two teachers (Grade 1 and Grade 2) with distances from the model answer, the average marks of two teachers (TM) and the predicted marks by the mathematical model (MM).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7. Distribution of actual marks of two teachers (Grade 1 and Grade 2) with distances from the model answer, the average marks of two teachers (TM) and the predicted marks by the mathematical model (MM).",
            "categories": "['cs.CL']",
            "figure_id": "1807.10543v3-Figure7-1",
            "image_path": "1807.10543v3-Figure7-1.png",
            "instance_id": "fd407b992dc7530970493f843d575968",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which of the lines represent the predicted marks by the mathematical model?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "AB",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "10"
                    },
                    {
                        "B": "100"
                    },
                    {
                        "C": "5"
                    },
                    {
                        "D": "3"
                    }
                ],
                "caption": "Figure 7. Distribution of actual marks of two teachers (Grade 1 and Grade 2) with distances from the model answer, the average marks of two teachers (TM) and the predicted marks by the mathematical model (MM).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7. Distribution of actual marks of two teachers (Grade 1 and Grade 2) with distances from the model answer, the average marks of two teachers (TM) and the predicted marks by the mathematical model (MM).",
            "categories": "['cs.CL']",
            "figure_id": "1807.10543v3-Figure7-1",
            "image_path": "1807.10543v3-Figure7-1.png",
            "instance_id": "55363140511e44268a52c5d1fb9f4422",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "What is the maximum value of grades in this graph?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 7. Distribution of actual marks of two teachers (Grade 1 and Grade 2) with distances from the model answer, the average marks of two teachers (TM) and the predicted marks by the mathematical model (MM).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 7. Distribution of actual marks of two teachers (Grade 1 and Grade 2) with distances from the model answer, the average marks of two teachers (TM) and the predicted marks by the mathematical model (MM).",
            "categories": "['cs.CL']",
            "figure_id": "1807.10543v3-Figure7-1",
            "image_path": "1807.10543v3-Figure7-1.png",
            "instance_id": "a3290d5c08ff9f9dd35d0ab88c3129c6",
            "qa_pair_type": "unanswerable",
            "question": "What is the specific mathematical model used to predict the marks (MM) in the graph?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 3 - Word rank score for the occurrences of \u201cbasket ball\u201d (blue) and \u201cbasketball\u201d (black) in the Chronicling America Archive (CAA).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 3 - Word rank score for the occurrences of \u201cbasket ball\u201d (blue) and \u201cbasketball\u201d (black) in the Chronicling America Archive (CAA).",
            "categories": "['cs.CL']",
            "figure_id": "1806.01185v1-Figure3-1",
            "image_path": "1806.01185v1-Figure3-1.png",
            "instance_id": "ec4befc58ad4d173093475e1d806fe0f",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of the black line at the year 1920?",
            "reference_answer": "2.00e-5"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 3 - Word rank score for the occurrences of \u201cbasket ball\u201d (blue) and \u201cbasketball\u201d (black) in the Chronicling America Archive (CAA).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 3 - Word rank score for the occurrences of \u201cbasket ball\u201d (blue) and \u201cbasketball\u201d (black) in the Chronicling America Archive (CAA).",
            "categories": "['cs.CL']",
            "figure_id": "1806.01185v1-Figure3-1",
            "image_path": "1806.01185v1-Figure3-1.png",
            "instance_id": "ef112fe0963905169594ae9a40e9ac46",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "What is the highest value of Word Rank Score shown in the y-axis?",
            "reference_answer": "2.50e-5"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 3 - Word rank score for the occurrences of \u201cbasket ball\u201d (blue) and \u201cbasketball\u201d (black) in the Chronicling America Archive (CAA).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 3 - Word rank score for the occurrences of \u201cbasket ball\u201d (blue) and \u201cbasketball\u201d (black) in the Chronicling America Archive (CAA).",
            "categories": "['cs.CL']",
            "figure_id": "1806.01185v1-Figure3-1",
            "image_path": "1806.01185v1-Figure3-1.png",
            "instance_id": "823b4fa82cb5e0287799cb9f838ce1f2",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the blue line representing 'basket ball (caa)' consistently lower than the black line representing 'basketball (caa)' after the year 1908?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes, the blue line representing 'basket ball (caa)' is consistently lower than the black line representing 'basketball (caa)' after the year 1908.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 3 - Word rank score for the occurrences of \u201cbasket ball\u201d (blue) and \u201cbasketball\u201d (black) in the Chronicling America Archive (CAA).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 3 - Word rank score for the occurrences of \u201cbasket ball\u201d (blue) and \u201cbasketball\u201d (black) in the Chronicling America Archive (CAA).",
            "categories": "['cs.CL']",
            "figure_id": "1806.01185v1-Figure3-1",
            "image_path": "1806.01185v1-Figure3-1.png",
            "instance_id": "99cfaea7570e54aa52d096ccb3f91bf4",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Did the word 'basketball' have a higher word rank score than 'basket ball' in 1920?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "Yes. In 1920, the word 'basketball' had a higher word rank score than 'basket ball'.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "The blue line"
                    },
                    {
                        "B": "The black line"
                    },
                    {
                        "C": "The red line"
                    },
                    {
                        "D": "The green line"
                    }
                ],
                "caption": "Fig. 3 - Word rank score for the occurrences of \u201cbasket ball\u201d (blue) and \u201cbasketball\u201d (black) in the Chronicling America Archive (CAA).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 3 - Word rank score for the occurrences of \u201cbasket ball\u201d (blue) and \u201cbasketball\u201d (black) in the Chronicling America Archive (CAA).",
            "categories": "['cs.CL']",
            "figure_id": "1806.01185v1-Figure3-1",
            "image_path": "1806.01185v1-Figure3-1.png",
            "instance_id": "abd6a80909e66d55a2fec48adce51c63",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line represents the word rank score for \"basket ball\"?",
            "reference_answer": "A"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "1842"
                    },
                    {
                        "B": "1820"
                    },
                    {
                        "C": "1836"
                    },
                    {
                        "D": "1830"
                    }
                ],
                "caption": "Fig. 3 - Word rank score for the occurrences of \u201cbasket ball\u201d (blue) and \u201cbasketball\u201d (black) in the Chronicling America Archive (CAA).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 3 - Word rank score for the occurrences of \u201cbasket ball\u201d (blue) and \u201cbasketball\u201d (black) in the Chronicling America Archive (CAA).",
            "categories": "['cs.CL']",
            "figure_id": "1806.01185v1-Figure3-1",
            "image_path": "1806.01185v1-Figure3-1.png",
            "instance_id": "36c12aa78df43224a17f45e597940e59",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "On what year does the x-axis start?",
            "reference_answer": "C"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "C",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Fig. 3 - Word rank score for the occurrences of \u201cbasket ball\u201d (blue) and \u201cbasketball\u201d (black) in the Chronicling America Archive (CAA).",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Fig. 3 - Word rank score for the occurrences of \u201cbasket ball\u201d (blue) and \u201cbasketball\u201d (black) in the Chronicling America Archive (CAA).",
            "categories": "['cs.CL']",
            "figure_id": "1806.01185v1-Figure3-1",
            "image_path": "1806.01185v1-Figure3-1.png",
            "instance_id": "38acbd5cccc43fae3bd7cfcc79559018",
            "qa_pair_type": "unanswerable",
            "question": "Does this study explore Word Rank Scores of other words?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1. Zipfian curves of 14 corpora suggest a common trend. (Character distributions)",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1. Zipfian curves of 14 corpora suggest a common trend. (Character distributions)",
            "categories": "['cs.CL cs.DL']",
            "figure_id": "1709.05587v1-Figure1-1",
            "image_path": "1709.05587v1-Figure1-1.png",
            "instance_id": "6b81a93e1cce9b999b05564beda9ba52",
            "qa_pair_type": "closed-ended infinite answer set visual",
            "question": "What is the approximate value of log(f/N) for the blue line labeled 'DCR' at a log(rank) value of 3.5?",
            "reference_answer": "-5"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1. Zipfian curves of 14 corpora suggest a common trend. (Character distributions)",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended infinite answer set non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1. Zipfian curves of 14 corpora suggest a common trend. (Character distributions)",
            "categories": "['cs.CL cs.DL']",
            "figure_id": "1709.05587v1-Figure1-1",
            "image_path": "1709.05587v1-Figure1-1.png",
            "instance_id": "b8bf2d4f87f9f6d43b1bf739f1922f5a",
            "qa_pair_type": "closed-ended infinite answer set non-visual",
            "question": "How many corpora are represented in Figure 1?",
            "reference_answer": "14"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1. Zipfian curves of 14 corpora suggest a common trend. (Character distributions)",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1. Zipfian curves of 14 corpora suggest a common trend. (Character distributions)",
            "categories": "['cs.CL cs.DL']",
            "figure_id": "1709.05587v1-Figure1-1",
            "image_path": "1709.05587v1-Figure1-1.png",
            "instance_id": "7a0f73ec88f17f31e2a08376d23dca84",
            "qa_pair_type": "closed-ended finite answer set binary visual",
            "question": "Is the blue line labeled 'SJ' consistently higher than the orange line labeled 'LCSJ'?",
            "reference_answer": "No"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1. Zipfian curves of 14 corpora suggest a common trend. (Character distributions)",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1. Zipfian curves of 14 corpora suggest a common trend. (Character distributions)",
            "categories": "['cs.CL cs.DL']",
            "figure_id": "1709.05587v1-Figure1-1",
            "image_path": "1709.05587v1-Figure1-1.png",
            "instance_id": "0e67bbdd963139fc5091c1618a16c6f9",
            "qa_pair_type": "closed-ended finite answer set binary non-visual",
            "question": "Do the Zipfian curves in Figure 1 represent more than 10 corpora?",
            "reference_answer": "Yes"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "Red"
                    },
                    {
                        "B": "Gray"
                    },
                    {
                        "C": "Blue"
                    },
                    {
                        "D": "Orange"
                    }
                ],
                "caption": "Figure 1. Zipfian curves of 14 corpora suggest a common trend. (Character distributions)",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1. Zipfian curves of 14 corpora suggest a common trend. (Character distributions)",
            "categories": "['cs.CL cs.DL']",
            "figure_id": "1709.05587v1-Figure1-1",
            "image_path": "1709.05587v1-Figure1-1.png",
            "instance_id": "c5797c78a8e23a35e46e9c5caeecdd3c",
            "qa_pair_type": "closed-ended finite answer set non-binary visual",
            "question": "Which line is the closest to the green line at the x-axis value of 4?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "B",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": [
                    {
                        "A": "10"
                    },
                    {
                        "B": "14"
                    },
                    {
                        "C": "18"
                    },
                    {
                        "D": "22"
                    }
                ],
                "caption": "Figure 1. Zipfian curves of 14 corpora suggest a common trend. (Character distributions)",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "closed-ended finite answer set non-binary non-visual"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1. Zipfian curves of 14 corpora suggest a common trend. (Character distributions)",
            "categories": "['cs.CL cs.DL']",
            "figure_id": "1709.05587v1-Figure1-1",
            "image_path": "1709.05587v1-Figure1-1.png",
            "instance_id": "b3214172ac959e643ffaa8a562a20c67",
            "qa_pair_type": "closed-ended finite answer set non-binary non-visual",
            "question": "How many corpora are shown in Figure 1?",
            "reference_answer": "B"
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "A",
        "sys_prompt": null,
        "user_prompt": null
    },
    {
        "arrival_time": null,
        "context": {
            "documents": [],
            "prompt_vars": {
                "answer_options": null,
                "caption": "Figure 1. Zipfian curves of 14 corpora suggest a common trend. (Character distributions)",
                "compound": false,
                "figure_type": "line chart",
                "qa_pair_type": "unanswerable"
            }
        },
        "conversation": null,
        "conversation_id": null,
        "finished_time": null,
        "id": null,
        "meta_data": {
            "caption": "Figure 1. Zipfian curves of 14 corpora suggest a common trend. (Character distributions)",
            "categories": "['cs.CL cs.DL']",
            "figure_id": "1709.05587v1-Figure1-1",
            "image_path": "1709.05587v1-Figure1-1.png",
            "instance_id": "9f7c0e9042e13637990049c67979c22a",
            "qa_pair_type": "unanswerable",
            "question": "What are the specific corpora and languages represented by each of the 14 curves in Figure 1?",
            "reference_answer": "It is not possible to answer this question based only on the provided data."
        },
        "model": "gpt-4o-mini",
        "processing_time": null,
        "prompt_id": null,
        "request_id": null,
        "response": "It is not possible to answer this question based only on the provided data.",
        "sys_prompt": null,
        "user_prompt": null
    }
]